<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Logistic Regression | Stat 455: Advanced Statistical Modeling Notes</title>
  <meta name="description" content="Chapter 7 Logistic Regression | Stat 455: Advanced Statistical Modeling Notes" />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Logistic Regression | Stat 455: Advanced Statistical Modeling Notes" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Logistic Regression | Stat 455: Advanced Statistical Modeling Notes" />
  
  
  



<meta name="date" content="2023-12-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="poisson-regression.html"/>
<link rel="next" href="multilevel-generalized-linear-models.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Stat 455 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html"><i class="fa fa-check"></i><b>1</b> Review of Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="1.1" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>1.1</b> Exploratory Data Analysis</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#kentucky-derby-data"><i class="fa fa-check"></i><b>1.1.1</b> Kentucky Derby Data</a></li>
<li class="chapter" data-level="1.1.2" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#some-data-wrangling"><i class="fa fa-check"></i><b>1.1.2</b> Some Data Wrangling</a></li>
<li class="chapter" data-level="1.1.3" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#univariate-graphical-summaries"><i class="fa fa-check"></i><b>1.1.3</b> Univariate Graphical Summaries</a></li>
<li class="chapter" data-level="1.1.4" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#bivariate-graphical-summaries"><i class="fa fa-check"></i><b>1.1.4</b> Bivariate Graphical Summaries</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#simple-linear-regression-model"><i class="fa fa-check"></i><b>1.2</b> Simple Linear Regression Model</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#model-for-winning-time-and-year"><i class="fa fa-check"></i><b>1.2.1</b> Model for Winning Time and Year</a></li>
<li class="chapter" data-level="1.2.2" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#first-model-r-output"><i class="fa fa-check"></i><b>1.2.2</b> First Model R Output</a></li>
<li class="chapter" data-level="1.2.3" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#calculations-in-slr"><i class="fa fa-check"></i><b>1.2.3</b> Calculations in SLR</a></li>
<li class="chapter" data-level="1.2.4" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#checking-model-assumptions"><i class="fa fa-check"></i><b>1.2.4</b> Checking Model Assumptions</a></li>
<li class="chapter" data-level="1.2.5" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#quadratic-term-for-year"><i class="fa fa-check"></i><b>1.2.5</b> Quadratic Term for Year</a></li>
<li class="chapter" data-level="1.2.6" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#quadratic-model-in-r"><i class="fa fa-check"></i><b>1.2.6</b> Quadratic Model in R</a></li>
<li class="chapter" data-level="1.2.7" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#quadratic-model-residual-plots"><i class="fa fa-check"></i><b>1.2.7</b> Quadratic Model Residual Plots</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#multiple-linear-regression-with-two-predictors"><i class="fa fa-check"></i><b>1.3</b> Multiple Linear Regression with Two Predictors</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#model-with-year-and-fast-track"><i class="fa fa-check"></i><b>1.3.1</b> Model with Year and Fast Track</a></li>
<li class="chapter" data-level="1.3.2" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#multiple-regression-model-in-r"><i class="fa fa-check"></i><b>1.3.2</b> Multiple Regression Model in R</a></li>
<li class="chapter" data-level="1.3.3" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#confidence-intervals-from-mlr-model"><i class="fa fa-check"></i><b>1.3.3</b> Confidence Intervals from MLR Model</a></li>
<li class="chapter" data-level="1.3.4" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#slopes-for-fast-non-fast-tracks"><i class="fa fa-check"></i><b>1.3.4</b> Slopes for Fast, non-Fast Tracks</a></li>
<li class="chapter" data-level="1.3.5" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#mlr-model-with-interaction"><i class="fa fa-check"></i><b>1.3.5</b> MLR Model with Interaction</a></li>
<li class="chapter" data-level="1.3.6" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#model-equations-for-fast-non-fast-tracks"><i class="fa fa-check"></i><b>1.3.6</b> Model Equations for Fast, Non-Fast Tracks</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#building-a-multiple-linear-regression-model"><i class="fa fa-check"></i><b>1.4</b> Building a Multiple Linear Regression Model</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#model-building-considerations"><i class="fa fa-check"></i><b>1.4.1</b> Model Building Considerations</a></li>
<li class="chapter" data-level="1.4.2" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#model-diagnostics"><i class="fa fa-check"></i><b>1.4.2</b> Model Diagnostics</a></li>
<li class="chapter" data-level="1.4.3" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#three-possible-models"><i class="fa fa-check"></i><b>1.4.3</b> Three Possible Models</a></li>
<li class="chapter" data-level="1.4.4" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#mlr-models-fit-in-r"><i class="fa fa-check"></i><b>1.4.4</b> MLR Models Fit in R</a></li>
<li class="chapter" data-level="1.4.5" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#model-0a-output"><i class="fa fa-check"></i><b>1.4.5</b> Model 0A Output</a></li>
<li class="chapter" data-level="1.4.6" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#model-0b-output"><i class="fa fa-check"></i><b>1.4.6</b> Model 0B Output</a></li>
<li class="chapter" data-level="1.4.7" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#model-0c-output"><i class="fa fa-check"></i><b>1.4.7</b> Model 0C Output</a></li>
<li class="chapter" data-level="1.4.8" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#goodness-of-fit-tests"><i class="fa fa-check"></i><b>1.4.8</b> Goodness of Fit Tests</a></li>
<li class="chapter" data-level="1.4.9" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#anova-f-statistic"><i class="fa fa-check"></i><b>1.4.9</b> ANOVA F-Statistic</a></li>
<li class="chapter" data-level="1.4.10" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#final-model-residual-plots"><i class="fa fa-check"></i><b>1.4.10</b> Final Model Residual Plots</a></li>
<li class="chapter" data-level="1.4.11" data-path="review-of-multiple-linear-regression.html"><a href="review-of-multiple-linear-regression.html#overall-conclusions"><i class="fa fa-check"></i><b>1.4.11</b> Overall Conclusions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html"><i class="fa fa-check"></i><b>2</b> Introduction to Correlated Data</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#introduction-to-correlated-data-1"><i class="fa fa-check"></i><b>2.1</b> Introduction to Correlated Data</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#weight-gain-in-mice-experiment-design-1"><i class="fa fa-check"></i><b>2.1.1</b> Weight Gain in Mice: Experiment Design #1</a></li>
<li class="chapter" data-level="2.1.2" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#mice-experiment-1-data"><i class="fa fa-check"></i><b>2.1.2</b> Mice Experiment 1 Data</a></li>
<li class="chapter" data-level="2.1.3" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#a-naive-graphical-analysis"><i class="fa fa-check"></i><b>2.1.3</b> A Naive Graphical Analysis</a></li>
<li class="chapter" data-level="2.1.4" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#a-more-informed-graphical-analysis"><i class="fa fa-check"></i><b>2.1.4</b> A More Informed Graphical Analysis</a></li>
<li class="chapter" data-level="2.1.5" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#table-of-mean-weight-by-diet"><i class="fa fa-check"></i><b>2.1.5</b> Table of Mean Weight By Diet</a></li>
<li class="chapter" data-level="2.1.6" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#table-of-mean-weight-by-diet-and-litter"><i class="fa fa-check"></i><b>2.1.6</b> Table of Mean Weight By Diet and Litter</a></li>
<li class="chapter" data-level="2.1.7" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#assessing-evidence-of-differences"><i class="fa fa-check"></i><b>2.1.7</b> Assessing Evidence of Differences</a></li>
<li class="chapter" data-level="2.1.8" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#an-improper-statistical-analysis"><i class="fa fa-check"></i><b>2.1.8</b> An Improper Statistical Analysis</a></li>
<li class="chapter" data-level="2.1.9" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#a-more-appropriate-statistical-analysis"><i class="fa fa-check"></i><b>2.1.9</b> A More Appropriate Statistical Analysis</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#linear-mixed-effects-models"><i class="fa fa-check"></i><b>2.2</b> Linear Mixed Effects Models</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#llsr-model-for-mice-experiment"><i class="fa fa-check"></i><b>2.2.1</b> LLSR Model for Mice Experiment</a></li>
<li class="chapter" data-level="2.2.2" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#model-accounting-for-correlation"><i class="fa fa-check"></i><b>2.2.2</b> Model Accounting For Correlation</a></li>
<li class="chapter" data-level="2.2.3" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#questions-of-interest"><i class="fa fa-check"></i><b>2.2.3</b> Questions of Interest</a></li>
<li class="chapter" data-level="2.2.4" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#fixed-and-random-effects"><i class="fa fa-check"></i><b>2.2.4</b> Fixed and Random Effects</a></li>
<li class="chapter" data-level="2.2.5" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#fitting-the-model-in-r"><i class="fa fa-check"></i><b>2.2.5</b> Fitting the Model in R</a></li>
<li class="chapter" data-level="2.2.6" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#why-not-fixed-effect-for-litter"><i class="fa fa-check"></i><b>2.2.6</b> Why Not Fixed Effect for Litter?</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#a-second-mice-experiment"><i class="fa fa-check"></i><b>2.3</b> A Second Mice Experiment</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#weight-gain-in-mice-experiment-2"><i class="fa fa-check"></i><b>2.3.1</b> Weight Gain in Mice: Experiment 2</a></li>
<li class="chapter" data-level="2.3.2" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#mice-experiment-2-data"><i class="fa fa-check"></i><b>2.3.2</b> Mice Experiment 2 Data</a></li>
<li class="chapter" data-level="2.3.3" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#a-naive-graphical-analysis-for-experiment-2"><i class="fa fa-check"></i><b>2.3.3</b> A Naive Graphical Analysis for Experiment 2</a></li>
<li class="chapter" data-level="2.3.4" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#a-more-informed-graphical-analysis-for-experiment-2"><i class="fa fa-check"></i><b>2.3.4</b> A More Informed Graphical Analysis for Experiment 2</a></li>
<li class="chapter" data-level="2.3.5" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#table-of-mean-weight-by-diet-for-experiment-2"><i class="fa fa-check"></i><b>2.3.5</b> Table of Mean Weight By Diet for Experiment 2</a></li>
<li class="chapter" data-level="2.3.6" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#table-comparing-litters-means-by-diet-for-experiment-2"><i class="fa fa-check"></i><b>2.3.6</b> Table Comparing Litters Means by Diet for Experiment 2</a></li>
<li class="chapter" data-level="2.3.7" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#an-inappropriate-model-for-the-second-design"><i class="fa fa-check"></i><b>2.3.7</b> An Inappropriate Model for the Second Design</a></li>
<li class="chapter" data-level="2.3.8" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#a-more-appropriate-model-for-experiment-2"><i class="fa fa-check"></i><b>2.3.8</b> A More Appropriate Model for Experiment 2</a></li>
<li class="chapter" data-level="2.3.9" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#model-for-litter-means"><i class="fa fa-check"></i><b>2.3.9</b> Model for Litter Means</a></li>
<li class="chapter" data-level="2.3.10" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#fixed-effect-for-litter-in-experiment-2"><i class="fa fa-check"></i><b>2.3.10</b> Fixed Effect for Litter in Experiment 2</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#a-multilevel-experiment"><i class="fa fa-check"></i><b>2.4</b> A Multilevel Experiment</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#experiment-2-illustration"><i class="fa fa-check"></i><b>2.4.1</b> Experiment 2 Illustration</a></li>
<li class="chapter" data-level="2.4.2" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#experiment-with-variables-assigned-at-different-levels"><i class="fa fa-check"></i><b>2.4.2</b> Experiment with Variables Assigned at Different Levels</a></li>
<li class="chapter" data-level="2.4.3" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#experiment-3-data"><i class="fa fa-check"></i><b>2.4.3</b> Experiment 3 Data</a></li>
<li class="chapter" data-level="2.4.4" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#graphical-analysis-for-experiment-3"><i class="fa fa-check"></i><b>2.4.4</b> Graphical Analysis for Experiment 3</a></li>
<li class="chapter" data-level="2.4.5" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#an-inappropriate-model-for-the-3rd-design"><i class="fa fa-check"></i><b>2.4.5</b> An Inappropriate Model for the 3rd Design</a></li>
<li class="chapter" data-level="2.4.6" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#a-more-appropriate-model-for-experiment-3"><i class="fa fa-check"></i><b>2.4.6</b> A More Appropriate Model for Experiment 3</a></li>
<li class="chapter" data-level="2.4.7" data-path="introduction-to-correlated-data.html"><a href="introduction-to-correlated-data.html#comparison-of-llsr-and-lme-models"><i class="fa fa-check"></i><b>2.4.7</b> Comparison of LLSR and LME Models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="multilevel-models.html"><a href="multilevel-models.html"><i class="fa fa-check"></i><b>3</b> Multilevel Models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="multilevel-models.html"><a href="multilevel-models.html#music-performance-anxiety-study-data-and-exploratory-analysis"><i class="fa fa-check"></i><b>3.1</b> Music Performance Anxiety Study: Data and Exploratory Analysis</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="multilevel-models.html"><a href="multilevel-models.html#description-of-the-study"><i class="fa fa-check"></i><b>3.1.1</b> Description of the Study</a></li>
<li class="chapter" data-level="3.1.2" data-path="multilevel-models.html"><a href="multilevel-models.html#variables"><i class="fa fa-check"></i><b>3.1.2</b> Variables</a></li>
<li class="chapter" data-level="3.1.3" data-path="multilevel-models.html"><a href="multilevel-models.html#the-data"><i class="fa fa-check"></i><b>3.1.3</b> The Data</a></li>
<li class="chapter" data-level="3.1.4" data-path="multilevel-models.html"><a href="multilevel-models.html#some-data-wrangling-1"><i class="fa fa-check"></i><b>3.1.4</b> Some Data Wrangling</a></li>
<li class="chapter" data-level="3.1.5" data-path="multilevel-models.html"><a href="multilevel-models.html#multilevel-structure"><i class="fa fa-check"></i><b>3.1.5</b> Multilevel Structure</a></li>
<li class="chapter" data-level="3.1.6" data-path="multilevel-models.html"><a href="multilevel-models.html#questions-of-interest-1"><i class="fa fa-check"></i><b>3.1.6</b> Questions of Interest</a></li>
<li class="chapter" data-level="3.1.7" data-path="multilevel-models.html"><a href="multilevel-models.html#number-of-performances-by-musician"><i class="fa fa-check"></i><b>3.1.7</b> Number of Performances by Musician</a></li>
<li class="chapter" data-level="3.1.8" data-path="multilevel-models.html"><a href="multilevel-models.html#number-of-performances-of-each-type"><i class="fa fa-check"></i><b>3.1.8</b> Number of Performances of Each Type</a></li>
<li class="chapter" data-level="3.1.9" data-path="multilevel-models.html"><a href="multilevel-models.html#distribution-of-negative-affect-for-all-performances"><i class="fa fa-check"></i><b>3.1.9</b> Distribution of Negative Affect for All Performances</a></li>
<li class="chapter" data-level="3.1.10" data-path="multilevel-models.html"><a href="multilevel-models.html#distribution-of-average-negative-affect-for-each-musician"><i class="fa fa-check"></i><b>3.1.10</b> Distribution of Average Negative Affect for each Musician</a></li>
<li class="chapter" data-level="3.1.11" data-path="multilevel-models.html"><a href="multilevel-models.html#distribution-of-level-two-covariates"><i class="fa fa-check"></i><b>3.1.11</b> Distribution of Level Two Covariates</a></li>
<li class="chapter" data-level="3.1.12" data-path="multilevel-models.html"><a href="multilevel-models.html#distributions-of-nem-pem-absorption"><i class="fa fa-check"></i><b>3.1.12</b> Distributions of NEM, PEM, Absorption</a></li>
<li class="chapter" data-level="3.1.13" data-path="multilevel-models.html"><a href="multilevel-models.html#negative-affect-by-performance-type-audience-type-and-previous-performances"><i class="fa fa-check"></i><b>3.1.13</b> Negative Affect by Performance Type, Audience Type, and Previous Performances</a></li>
<li class="chapter" data-level="3.1.14" data-path="multilevel-models.html"><a href="multilevel-models.html#lattice-plot-for-negative-affect-by-performance-type"><i class="fa fa-check"></i><b>3.1.14</b> Lattice Plot for Negative Affect by Performance Type</a></li>
<li class="chapter" data-level="3.1.15" data-path="multilevel-models.html"><a href="multilevel-models.html#lattice-plot-for-negative-affect-by-audience-type"><i class="fa fa-check"></i><b>3.1.15</b> Lattice Plot for Negative Affect by Audience Type</a></li>
<li class="chapter" data-level="3.1.16" data-path="multilevel-models.html"><a href="multilevel-models.html#lattice-plot-for-previous-performances-vs-negative-affect"><i class="fa fa-check"></i><b>3.1.16</b> Lattice Plot for Previous Performances vs Negative Affect</a></li>
<li class="chapter" data-level="3.1.17" data-path="multilevel-models.html"><a href="multilevel-models.html#negative-affect-by-instrument-type"><i class="fa fa-check"></i><b>3.1.17</b> Negative Affect by Instrument Type</a></li>
<li class="chapter" data-level="3.1.18" data-path="multilevel-models.html"><a href="multilevel-models.html#more-data-wrangling"><i class="fa fa-check"></i><b>3.1.18</b> More Data Wrangling</a></li>
<li class="chapter" data-level="3.1.19" data-path="multilevel-models.html"><a href="multilevel-models.html#lattice-plot-for-large-ensemble-effect"><i class="fa fa-check"></i><b>3.1.19</b> Lattice Plot for Large Ensemble Effect</a></li>
<li class="chapter" data-level="3.1.20" data-path="multilevel-models.html"><a href="multilevel-models.html#boxplots-for-orchestral-instrument-effect"><i class="fa fa-check"></i><b>3.1.20</b> Boxplots for Orchestral Instrument Effect</a></li>
<li class="chapter" data-level="3.1.21" data-path="multilevel-models.html"><a href="multilevel-models.html#negative-affect-by-pem-nem-absorption"><i class="fa fa-check"></i><b>3.1.21</b> Negative Affect by PEM, NEM, Absorption</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="multilevel-models.html"><a href="multilevel-models.html#modeling-the-musician-data"><i class="fa fa-check"></i><b>3.2</b> Modeling the Musician Data</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="multilevel-models.html"><a href="multilevel-models.html#model-notation"><i class="fa fa-check"></i><b>3.2.1</b> Model Notation</a></li>
<li class="chapter" data-level="3.2.2" data-path="multilevel-models.html"><a href="multilevel-models.html#llsr-model-clearly-inappropriate"><i class="fa fa-check"></i><b>3.2.2</b> LLSR Model (Clearly inappropriate)</a></li>
<li class="chapter" data-level="3.2.3" data-path="multilevel-models.html"><a href="multilevel-models.html#llsr-model-output"><i class="fa fa-check"></i><b>3.2.3</b> LLSR Model Output</a></li>
<li class="chapter" data-level="3.2.4" data-path="multilevel-models.html"><a href="multilevel-models.html#random-vs.-fixed-effects"><i class="fa fa-check"></i><b>3.2.4</b> Random vs. Fixed Effects</a></li>
<li class="chapter" data-level="3.2.5" data-path="multilevel-models.html"><a href="multilevel-models.html#an-initial-linear-mixed-effect-model"><i class="fa fa-check"></i><b>3.2.5</b> An Initial Linear Mixed Effect Model</a></li>
<li class="chapter" data-level="3.2.6" data-path="multilevel-models.html"><a href="multilevel-models.html#initial-mixed-effects-model-in-r"><i class="fa fa-check"></i><b>3.2.6</b> Initial Mixed Effects Model in R</a></li>
<li class="chapter" data-level="3.2.7" data-path="multilevel-models.html"><a href="multilevel-models.html#mixed-effects-model-interpretations"><i class="fa fa-check"></i><b>3.2.7</b> Mixed Effects Model Interpretations</a></li>
<li class="chapter" data-level="3.2.8" data-path="multilevel-models.html"><a href="multilevel-models.html#mixed-effects-model-without-interaction"><i class="fa fa-check"></i><b>3.2.8</b> Mixed Effects Model Without Interaction</a></li>
<li class="chapter" data-level="3.2.9" data-path="multilevel-models.html"><a href="multilevel-models.html#interpretations-for-model-without-interaction"><i class="fa fa-check"></i><b>3.2.9</b> Interpretations for Model without Interaction</a></li>
<li class="chapter" data-level="3.2.10" data-path="multilevel-models.html"><a href="multilevel-models.html#assumptions-in-first-mixed-effects-model"><i class="fa fa-check"></i><b>3.2.10</b> Assumptions in First Mixed Effects Model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="multilevel-models.html"><a href="multilevel-models.html#random-slopes-model"><i class="fa fa-check"></i><b>3.3</b> Random Slopes Model</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="multilevel-models.html"><a href="multilevel-models.html#differences-in-large-vs-smallsolo"><i class="fa fa-check"></i><b>3.3.1</b> Differences in Large vs Small/Solo</a></li>
<li class="chapter" data-level="3.3.2" data-path="multilevel-models.html"><a href="multilevel-models.html#illustration-of-previous-model"><i class="fa fa-check"></i><b>3.3.2</b> Illustration of Previous Model</a></li>
<li class="chapter" data-level="3.3.3" data-path="multilevel-models.html"><a href="multilevel-models.html#illustration-of-new-random-slopes-model"><i class="fa fa-check"></i><b>3.3.3</b> Illustration of New (Random Slopes) Model</a></li>
<li class="chapter" data-level="3.3.4" data-path="multilevel-models.html"><a href="multilevel-models.html#random-slopes-model-1"><i class="fa fa-check"></i><b>3.3.4</b> Random Slopes Model</a></li>
<li class="chapter" data-level="3.3.5" data-path="multilevel-models.html"><a href="multilevel-models.html#specifying-distribution-of-random-effects"><i class="fa fa-check"></i><b>3.3.5</b> Specifying Distribution of Random Effects</a></li>
<li class="chapter" data-level="3.3.6" data-path="multilevel-models.html"><a href="multilevel-models.html#random-slopes-model-with-error-term-distributions"><i class="fa fa-check"></i><b>3.3.6</b> Random Slopes Model with Error Term Distributions</a></li>
<li class="chapter" data-level="3.3.7" data-path="multilevel-models.html"><a href="multilevel-models.html#random-slopes-model-in-r"><i class="fa fa-check"></i><b>3.3.7</b> Random Slopes Model in R</a></li>
<li class="chapter" data-level="3.3.8" data-path="multilevel-models.html"><a href="multilevel-models.html#more-on-interpreting-parameters"><i class="fa fa-check"></i><b>3.3.8</b> More on Interpreting Parameters</a></li>
<li class="chapter" data-level="3.3.9" data-path="multilevel-models.html"><a href="multilevel-models.html#model-comparisons"><i class="fa fa-check"></i><b>3.3.9</b> Model Comparisons</a></li>
<li class="chapter" data-level="3.3.10" data-path="multilevel-models.html"><a href="multilevel-models.html#random-slopes-model-with-interaction"><i class="fa fa-check"></i><b>3.3.10</b> Random Slopes Model with Interaction</a></li>
<li class="chapter" data-level="3.3.11" data-path="multilevel-models.html"><a href="multilevel-models.html#random-slopes-model-with-interaction-in-r"><i class="fa fa-check"></i><b>3.3.11</b> Random Slopes Model with Interaction in R</a></li>
<li class="chapter" data-level="3.3.12" data-path="multilevel-models.html"><a href="multilevel-models.html#random-slope-vs-interaction-term"><i class="fa fa-check"></i><b>3.3.12</b> Random Slope vs Interaction Term</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="multilevel-models.html"><a href="multilevel-models.html#unconditional-means-model"><i class="fa fa-check"></i><b>3.4</b> Unconditional Means Model</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="multilevel-models.html"><a href="multilevel-models.html#unconditional-means-model-formulation"><i class="fa fa-check"></i><b>3.4.1</b> Unconditional Means Model Formulation</a></li>
<li class="chapter" data-level="3.4.2" data-path="multilevel-models.html"><a href="multilevel-models.html#unconditional-means-model-in-r"><i class="fa fa-check"></i><b>3.4.2</b> Unconditional Means Model in R</a></li>
<li class="chapter" data-level="3.4.3" data-path="multilevel-models.html"><a href="multilevel-models.html#unconditional-means-model-interpretations"><i class="fa fa-check"></i><b>3.4.3</b> Unconditional Means Model Interpretations</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="multilevel-models.html"><a href="multilevel-models.html#building-a-multilevel-model"><i class="fa fa-check"></i><b>3.5</b> Building A Multilevel Model</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="multilevel-models.html"><a href="multilevel-models.html#centering-covariates"><i class="fa fa-check"></i><b>3.5.1</b> Centering Covariates</a></li>
<li class="chapter" data-level="3.5.2" data-path="multilevel-models.html"><a href="multilevel-models.html#a-possible-final-model"><i class="fa fa-check"></i><b>3.5.2</b> A Possible Final Model</a></li>
<li class="chapter" data-level="3.5.3" data-path="multilevel-models.html"><a href="multilevel-models.html#more-data-wrangling-1"><i class="fa fa-check"></i><b>3.5.3</b> More Data Wrangling</a></li>
<li class="chapter" data-level="3.5.4" data-path="multilevel-models.html"><a href="multilevel-models.html#fitting-model-a"><i class="fa fa-check"></i><b>3.5.4</b> Fitting Model A</a></li>
<li class="chapter" data-level="3.5.5" data-path="multilevel-models.html"><a href="multilevel-models.html#a-model-without-random-slopes"><i class="fa fa-check"></i><b>3.5.5</b> A Model Without Random Slopes</a></li>
<li class="chapter" data-level="3.5.6" data-path="multilevel-models.html"><a href="multilevel-models.html#fitting-model-b-in-r"><i class="fa fa-check"></i><b>3.5.6</b> Fitting Model B in R</a></li>
<li class="chapter" data-level="3.5.7" data-path="multilevel-models.html"><a href="multilevel-models.html#one-more-possible-model"><i class="fa fa-check"></i><b>3.5.7</b> One More Possible Model</a></li>
<li class="chapter" data-level="3.5.8" data-path="multilevel-models.html"><a href="multilevel-models.html#aic-and-bic-comparisons-for-models-b-and-c"><i class="fa fa-check"></i><b>3.5.8</b> AIC and BIC Comparisons for Models B and C</a></li>
<li class="chapter" data-level="3.5.9" data-path="multilevel-models.html"><a href="multilevel-models.html#likelihood-ratio-test"><i class="fa fa-check"></i><b>3.5.9</b> Likelihood Ratio Test</a></li>
<li class="chapter" data-level="3.5.10" data-path="multilevel-models.html"><a href="multilevel-models.html#final-conclusions"><i class="fa fa-check"></i><b>3.5.10</b> Final Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="multilevel-models.html"><a href="multilevel-models.html#conceptual-questions"><i class="fa fa-check"></i><b>3.6</b> Conceptual Questions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="longitudinal-data.html"><a href="longitudinal-data.html"><i class="fa fa-check"></i><b>4</b> Longitudinal Data</a>
<ul>
<li class="chapter" data-level="4.1" data-path="longitudinal-data.html"><a href="longitudinal-data.html#charter-schools-exploratory-analysis"><i class="fa fa-check"></i><b>4.1</b> Charter Schools Exploratory Analysis</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="longitudinal-data.html"><a href="longitudinal-data.html#data"><i class="fa fa-check"></i><b>4.1.1</b> Data Organization</a></li>
<li class="chapter" data-level="4.1.2" data-path="longitudinal-data.html"><a href="longitudinal-data.html#missing-data"><i class="fa fa-check"></i><b>4.1.2</b> Missing Data</a></li>
<li class="chapter" data-level="4.1.3" data-path="longitudinal-data.html"><a href="longitudinal-data.html#convert-to-tidy-form"><i class="fa fa-check"></i><b>4.1.3</b> Convert to Tidy Form</a></li>
<li class="chapter" data-level="4.1.4" data-path="longitudinal-data.html"><a href="longitudinal-data.html#exploratory-analyses-for-general-multilevel-models"><i class="fa fa-check"></i><b>4.1.4</b> Exploratory Analyses for General Multilevel Models</a></li>
<li class="chapter" data-level="4.1.5" data-path="longitudinal-data.html"><a href="longitudinal-data.html#exploratory-analyses-for-longitudinal-data"><i class="fa fa-check"></i><b>4.1.5</b> Exploratory Analyses for Longitudinal Data</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="longitudinal-data.html"><a href="longitudinal-data.html#multilevel-longitudinal-models"><i class="fa fa-check"></i><b>4.2</b> Multilevel Longitudinal Models</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="longitudinal-data.html"><a href="longitudinal-data.html#unconditional-means-model-1"><i class="fa fa-check"></i><b>4.2.1</b> Unconditional Means Model</a></li>
<li class="chapter" data-level="4.2.2" data-path="longitudinal-data.html"><a href="longitudinal-data.html#interpretations-in-unconditional-means-model"><i class="fa fa-check"></i><b>4.2.2</b> Interpretations in Unconditional Means Model</a></li>
<li class="chapter" data-level="4.2.3" data-path="longitudinal-data.html"><a href="longitudinal-data.html#intraclass-correlation-coefficient"><i class="fa fa-check"></i><b>4.2.3</b> Intraclass Correlation Coefficient:</a></li>
<li class="chapter" data-level="4.2.4" data-path="longitudinal-data.html"><a href="longitudinal-data.html#unconditional-growth-model"><i class="fa fa-check"></i><b>4.2.4</b> Unconditional Growth Model</a></li>
<li class="chapter" data-level="4.2.5" data-path="longitudinal-data.html"><a href="longitudinal-data.html#interpretations-in-unconditional-growth-model"><i class="fa fa-check"></i><b>4.2.5</b> Interpretations in Unconditional Growth Model</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="longitudinal-data.html"><a href="longitudinal-data.html#quadratic-and-piecewise-linear-models"><i class="fa fa-check"></i><b>4.3</b> Quadratic and Piecewise Linear Models</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="longitudinal-data.html"><a href="longitudinal-data.html#quadratic-trend-over-time"><i class="fa fa-check"></i><b>4.3.1</b> Quadratic Trend over Time</a></li>
<li class="chapter" data-level="4.3.2" data-path="longitudinal-data.html"><a href="longitudinal-data.html#quadratic-model"><i class="fa fa-check"></i><b>4.3.2</b> Quadratic Model</a></li>
<li class="chapter" data-level="4.3.3" data-path="longitudinal-data.html"><a href="longitudinal-data.html#quadratic-model-in-r-1"><i class="fa fa-check"></i><b>4.3.3</b> Quadratic Model in R</a></li>
<li class="chapter" data-level="4.3.4" data-path="longitudinal-data.html"><a href="longitudinal-data.html#estimated-response-curve"><i class="fa fa-check"></i><b>4.3.4</b> Estimated Response Curve</a></li>
<li class="chapter" data-level="4.3.5" data-path="longitudinal-data.html"><a href="longitudinal-data.html#linear-and-quadratic-error-terms"><i class="fa fa-check"></i><b>4.3.5</b> Linear and Quadratic Error Terms</a></li>
<li class="chapter" data-level="4.3.6" data-path="longitudinal-data.html"><a href="longitudinal-data.html#model-with-many-random-terms-in-r"><i class="fa fa-check"></i><b>4.3.6</b> Model with Many Random Terms in R</a></li>
<li class="chapter" data-level="4.3.7" data-path="longitudinal-data.html"><a href="longitudinal-data.html#only-a-linear-random-term"><i class="fa fa-check"></i><b>4.3.7</b> Only a Linear Random Term</a></li>
<li class="chapter" data-level="4.3.8" data-path="longitudinal-data.html"><a href="longitudinal-data.html#comments-on-random-terms"><i class="fa fa-check"></i><b>4.3.8</b> Comments on Random Terms</a></li>
<li class="chapter" data-level="4.3.9" data-path="longitudinal-data.html"><a href="longitudinal-data.html#model-comparison"><i class="fa fa-check"></i><b>4.3.9</b> Model Comparison</a></li>
<li class="chapter" data-level="4.3.10" data-path="longitudinal-data.html"><a href="longitudinal-data.html#piecewise-linear-model"><i class="fa fa-check"></i><b>4.3.10</b> Piecewise Linear Model</a></li>
<li class="chapter" data-level="4.3.11" data-path="longitudinal-data.html"><a href="longitudinal-data.html#piecewise-model-equation"><i class="fa fa-check"></i><b>4.3.11</b> Piecewise Model Equation</a></li>
<li class="chapter" data-level="4.3.12" data-path="longitudinal-data.html"><a href="longitudinal-data.html#estimated-response-curve-1"><i class="fa fa-check"></i><b>4.3.12</b> Estimated Response Curve</a></li>
<li class="chapter" data-level="4.3.13" data-path="longitudinal-data.html"><a href="longitudinal-data.html#comparing-quadratic-and-piecewise-models"><i class="fa fa-check"></i><b>4.3.13</b> Comparing Quadratic and Piecewise Models</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="longitudinal-data.html"><a href="longitudinal-data.html#model-for-school-type"><i class="fa fa-check"></i><b>4.4</b> Model for School Type</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="longitudinal-data.html"><a href="longitudinal-data.html#uncontrolled-effects-of-school-type"><i class="fa fa-check"></i><b>4.4.1</b> Uncontrolled Effects of School Type</a></li>
<li class="chapter" data-level="4.4.2" data-path="longitudinal-data.html"><a href="longitudinal-data.html#interpretations-for-school-type-model"><i class="fa fa-check"></i><b>4.4.2</b> Interpretations for School Type Model</a></li>
<li class="chapter" data-level="4.4.3" data-path="longitudinal-data.html"><a href="longitudinal-data.html#illustration"><i class="fa fa-check"></i><b>4.4.3</b> Illustration</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="longitudinal-data.html"><a href="longitudinal-data.html#covariance-structure-among-observations"><i class="fa fa-check"></i><b>4.5</b> Covariance Structure among Observations</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="longitudinal-data.html"><a href="longitudinal-data.html#standard-covariance-structure"><i class="fa fa-check"></i><b>4.5.1</b> Standard Covariance Structure</a></li>
<li class="chapter" data-level="4.5.2" data-path="longitudinal-data.html"><a href="longitudinal-data.html#derivation-of-vary_i1-optional"><i class="fa fa-check"></i><b>4.5.2</b> Derivation of <span class="math inline">\(Var(Y_{i1})\)</span> (optional)</a></li>
<li class="chapter" data-level="4.5.3" data-path="longitudinal-data.html"><a href="longitudinal-data.html#interpretations-of-vary_i1-and-covy_ij-y_ik"><i class="fa fa-check"></i><b>4.5.3</b> Interpretations of <span class="math inline">\(Var(Y_{i1})\)</span> and <span class="math inline">\(Cov(Y_{ij}, Y_{ik})\)</span></a></li>
<li class="chapter" data-level="4.5.4" data-path="longitudinal-data.html"><a href="longitudinal-data.html#variance-and-covariance-estimates"><i class="fa fa-check"></i><b>4.5.4</b> Variance and Covariance Estimates</a></li>
<li class="chapter" data-level="4.5.5" data-path="longitudinal-data.html"><a href="longitudinal-data.html#alternative-covariance-structure---uncorrelated"><i class="fa fa-check"></i><b>4.5.5</b> Alternative Covariance Structure - Uncorrelated</a></li>
<li class="chapter" data-level="4.5.6" data-path="longitudinal-data.html"><a href="longitudinal-data.html#alternative-covariance-structure---unstructured"><i class="fa fa-check"></i><b>4.5.6</b> Alternative Covariance Structure - Unstructured</a></li>
<li class="chapter" data-level="4.5.7" data-path="longitudinal-data.html"><a href="longitudinal-data.html#alternative-covariance-structure---compound-symmetry"><i class="fa fa-check"></i><b>4.5.7</b> Alternative Covariance Structure - Compound Symmetry</a></li>
<li class="chapter" data-level="4.5.8" data-path="longitudinal-data.html"><a href="longitudinal-data.html#alternative-covariance-structure---autogregressive"><i class="fa fa-check"></i><b>4.5.8</b> Alternative Covariance Structure - Autogregressive</a></li>
<li class="chapter" data-level="4.5.9" data-path="longitudinal-data.html"><a href="longitudinal-data.html#ar1-model-on-schools-data"><i class="fa fa-check"></i><b>4.5.9</b> AR(1) Model on Schools Data</a></li>
<li class="chapter" data-level="4.5.10" data-path="longitudinal-data.html"><a href="longitudinal-data.html#non-longitudinal-multilevel-models"><i class="fa fa-check"></i><b>4.5.10</b> Non-longitudinal Multilevel Models</a></li>
<li class="chapter" data-level="4.5.11" data-path="longitudinal-data.html"><a href="longitudinal-data.html#final-thoughts-regarding-covariance-structures"><i class="fa fa-check"></i><b>4.5.11</b> Final Thoughts Regarding Covariance Structures</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html"><i class="fa fa-check"></i><b>5</b> Data with Three or More Levels</a>
<ul>
<li class="chapter" data-level="5.1" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#three-level-plants-experiment"><i class="fa fa-check"></i><b>5.1</b> Three-Level Plants Experiment</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#experimental-design"><i class="fa fa-check"></i><b>5.1.1</b> Experimental Design</a></li>
<li class="chapter" data-level="5.1.2" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#the-data-1"><i class="fa fa-check"></i><b>5.1.2</b> The Data</a></li>
<li class="chapter" data-level="5.1.3" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#questions"><i class="fa fa-check"></i><b>5.1.3</b> Questions</a></li>
<li class="chapter" data-level="5.1.4" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#three-level-model"><i class="fa fa-check"></i><b>5.1.4</b> Three Level Model</a></li>
<li class="chapter" data-level="5.1.5" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#r-implementation-of-three-level-model"><i class="fa fa-check"></i><b>5.1.5</b> R Implementation of Three Level Model</a></li>
<li class="chapter" data-level="5.1.6" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#inappropriate-llsr-model"><i class="fa fa-check"></i><b>5.1.6</b> Inappropriate LLSR Model</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#three-level-model-with-random-slopes"><i class="fa fa-check"></i><b>5.2</b> Three-Level Model with Random Slopes</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#random-slope-for-phenoa"><i class="fa fa-check"></i><b>5.2.1</b> Random Slope for PhenoA</a></li>
<li class="chapter" data-level="5.2.2" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#r-output-for-random-slope-for-phenoa"><i class="fa fa-check"></i><b>5.2.2</b> R Output for Random Slope for PhenoA</a></li>
<li class="chapter" data-level="5.2.3" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#random-slope-for-fert"><i class="fa fa-check"></i><b>5.2.3</b> Random Slope for Fert</a></li>
<li class="chapter" data-level="5.2.4" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#r-output-for-random-slope-for-fert"><i class="fa fa-check"></i><b>5.2.4</b> R Output for Random Slope for Fert</a></li>
<li class="chapter" data-level="5.2.5" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#boundary-constraints"><i class="fa fa-check"></i><b>5.2.5</b> Boundary Constraints</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#longitudinal-component-to-plants-data"><i class="fa fa-check"></i><b>5.3</b> Longitudinal Component to Plants Data</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#repeated-measures-over-time"><i class="fa fa-check"></i><b>5.3.1</b> Repeated Measures over Time</a></li>
<li class="chapter" data-level="5.3.2" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#levels-and-variables"><i class="fa fa-check"></i><b>5.3.2</b> Levels and Variables</a></li>
<li class="chapter" data-level="5.3.3" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#model-for-longitudinal-plants-study"><i class="fa fa-check"></i><b>5.3.3</b> Model for Longitudinal Plants Study</a></li>
<li class="chapter" data-level="5.3.4" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#r-output-for-longitudinal-model"><i class="fa fa-check"></i><b>5.3.4</b> R Output for Longitudinal Model</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#four-level-longitudinal-model-with-random-slopes"><i class="fa fa-check"></i><b>5.4</b> Four-Level Longitudinal Model with Random Slopes</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#random-slope-for-time"><i class="fa fa-check"></i><b>5.4.1</b> Random Slope for Time</a></li>
<li class="chapter" data-level="5.4.2" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#more-random-slope-terms"><i class="fa fa-check"></i><b>5.4.2</b> More Random Slope Terms</a></li>
<li class="chapter" data-level="5.4.3" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#additional-random-slopes"><i class="fa fa-check"></i><b>5.4.3</b> Additional Random Slopes</a></li>
<li class="chapter" data-level="5.4.4" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#r---model-with-additional-random-slopes"><i class="fa fa-check"></i><b>5.4.4</b> R - Model with Additional Random Slopes</a></li>
<li class="chapter" data-level="5.4.5" data-path="data-with-three-or-more-levels.html"><a href="data-with-three-or-more-levels.html#when-not-to-add-random-slopes"><i class="fa fa-check"></i><b>5.4.5</b> When Not to Add Random Slopes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="poisson-regression.html"><a href="poisson-regression.html"><i class="fa fa-check"></i><b>6</b> Poisson Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="poisson-regression.html"><a href="poisson-regression.html#modeling-counts"><i class="fa fa-check"></i><b>6.1</b> Modeling Counts</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="poisson-regression.html"><a href="poisson-regression.html#case-study-household-size-in-the-philippines"><i class="fa fa-check"></i><b>6.1.1</b> Case Study: Household Size in the Philippines</a></li>
<li class="chapter" data-level="6.1.2" data-path="poisson-regression.html"><a href="poisson-regression.html#map-of-the-philippines"><i class="fa fa-check"></i><b>6.1.2</b> Map of the Philippines</a></li>
<li class="chapter" data-level="6.1.3" data-path="poisson-regression.html"><a href="poisson-regression.html#questions-of-interest-2"><i class="fa fa-check"></i><b>6.1.3</b> Questions of Interest</a></li>
<li class="chapter" data-level="6.1.4" data-path="poisson-regression.html"><a href="poisson-regression.html#the-data-2"><i class="fa fa-check"></i><b>6.1.4</b> The Data</a></li>
<li class="chapter" data-level="6.1.5" data-path="poisson-regression.html"><a href="poisson-regression.html#first-5-rows"><i class="fa fa-check"></i><b>6.1.5</b> First 5 Rows</a></li>
<li class="chapter" data-level="6.1.6" data-path="poisson-regression.html"><a href="poisson-regression.html#household-size-by-region"><i class="fa fa-check"></i><b>6.1.6</b> Household Size by Region</a></li>
<li class="chapter" data-level="6.1.7" data-path="poisson-regression.html"><a href="poisson-regression.html#household-size-by-region-plots"><i class="fa fa-check"></i><b>6.1.7</b> Household Size by Region Plots</a></li>
<li class="chapter" data-level="6.1.8" data-path="poisson-regression.html"><a href="poisson-regression.html#modeling-household-size"><i class="fa fa-check"></i><b>6.1.8</b> Modeling Household Size</a></li>
<li class="chapter" data-level="6.1.9" data-path="poisson-regression.html"><a href="poisson-regression.html#inappropriate-llsr-model-1"><i class="fa fa-check"></i><b>6.1.9</b> Inappropriate LLSR Model</a></li>
<li class="chapter" data-level="6.1.10" data-path="poisson-regression.html"><a href="poisson-regression.html#llsr-model-r-output"><i class="fa fa-check"></i><b>6.1.10</b> LLSR Model R Output</a></li>
<li class="chapter" data-level="6.1.11" data-path="poisson-regression.html"><a href="poisson-regression.html#llsr-assumptions"><i class="fa fa-check"></i><b>6.1.11</b> LLSR Assumptions</a></li>
<li class="chapter" data-level="6.1.12" data-path="poisson-regression.html"><a href="poisson-regression.html#distribution-in-visayas-region"><i class="fa fa-check"></i><b>6.1.12</b> Distribution in Visayas Region</a></li>
<li class="chapter" data-level="6.1.13" data-path="poisson-regression.html"><a href="poisson-regression.html#normal-quantile-quantile-plot"><i class="fa fa-check"></i><b>6.1.13</b> Normal Quantile Quantile Plot</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="poisson-regression.html"><a href="poisson-regression.html#poisson-regression-models"><i class="fa fa-check"></i><b>6.2</b> Poisson Regression Models</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="poisson-regression.html"><a href="poisson-regression.html#the-poisson-distribution"><i class="fa fa-check"></i><b>6.2.1</b> The Poisson Distribution</a></li>
<li class="chapter" data-level="6.2.2" data-path="poisson-regression.html"><a href="poisson-regression.html#poisson-distribution-for-lambda1"><i class="fa fa-check"></i><b>6.2.2</b> Poisson Distribution for <span class="math inline">\(\lambda=1\)</span></a></li>
<li class="chapter" data-level="6.2.3" data-path="poisson-regression.html"><a href="poisson-regression.html#poisson-distribution-for-lambdain135"><i class="fa fa-check"></i><b>6.2.3</b> Poisson Distribution for <span class="math inline">\(\lambda\in\{1,3,5\}\)</span></a></li>
<li class="chapter" data-level="6.2.4" data-path="poisson-regression.html"><a href="poisson-regression.html#connecting-expected-response-to-explatory-variables"><i class="fa fa-check"></i><b>6.2.4</b> Connecting Expected Response to Explatory Variables</a></li>
<li class="chapter" data-level="6.2.5" data-path="poisson-regression.html"><a href="poisson-regression.html#poisson-regression-assumptions"><i class="fa fa-check"></i><b>6.2.5</b> Poisson Regression Assumptions</a></li>
<li class="chapter" data-level="6.2.6" data-path="poisson-regression.html"><a href="poisson-regression.html#poisson-regression-illustration"><i class="fa fa-check"></i><b>6.2.6</b> Poisson Regression Illustration</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="poisson-regression.html"><a href="poisson-regression.html#poisson-model-for-household-size"><i class="fa fa-check"></i><b>6.3</b> Poisson Model for Household Size</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="poisson-regression.html"><a href="poisson-regression.html#poisson-regression-model-for-location"><i class="fa fa-check"></i><b>6.3.1</b> Poisson Regression Model for Location</a></li>
<li class="chapter" data-level="6.3.2" data-path="poisson-regression.html"><a href="poisson-regression.html#interpreting-model-parameters-in-poisson-regression"><i class="fa fa-check"></i><b>6.3.2</b> Interpreting Model Parameters in Poisson Regression</a></li>
<li class="chapter" data-level="6.3.3" data-path="poisson-regression.html"><a href="poisson-regression.html#wald-based-confidence-intervals-for-difference"><i class="fa fa-check"></i><b>6.3.3</b> Wald-Based Confidence Intervals for Difference</a></li>
<li class="chapter" data-level="6.3.4" data-path="poisson-regression.html"><a href="poisson-regression.html#mean-variance-assumption"><i class="fa fa-check"></i><b>6.3.4</b> Mean = Variance Assumption</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="poisson-regression.html"><a href="poisson-regression.html#poisson-model-with-multiple-explanatory-variables"><i class="fa fa-check"></i><b>6.4</b> Poisson Model with Multiple Explanatory Variables</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="poisson-regression.html"><a href="poisson-regression.html#accounting-for-age-of-head-of-household"><i class="fa fa-check"></i><b>6.4.1</b> Accounting for Age of Head of Household</a></li>
<li class="chapter" data-level="6.4.2" data-path="poisson-regression.html"><a href="poisson-regression.html#r-output-for-model-with-age"><i class="fa fa-check"></i><b>6.4.2</b> R Output for Model with Age</a></li>
<li class="chapter" data-level="6.4.3" data-path="poisson-regression.html"><a href="poisson-regression.html#interpreting-coefficients-for-numeric-explanatory-variable"><i class="fa fa-check"></i><b>6.4.3</b> Interpreting Coefficients for Numeric Explanatory Variable</a></li>
<li class="chapter" data-level="6.4.4" data-path="poisson-regression.html"><a href="poisson-regression.html#mean-variance-assumption-1"><i class="fa fa-check"></i><b>6.4.4</b> Mean = Variance Assumption</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="poisson-regression.html"><a href="poisson-regression.html#deviance-and-model-comparison"><i class="fa fa-check"></i><b>6.5</b> Deviance and Model Comparison</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="poisson-regression.html"><a href="poisson-regression.html#accounting-for-nonlinear-trend"><i class="fa fa-check"></i><b>6.5.1</b> Accounting for Nonlinear Trend</a></li>
<li class="chapter" data-level="6.5.2" data-path="poisson-regression.html"><a href="poisson-regression.html#quadratic-poisson-regresson-model"><i class="fa fa-check"></i><b>6.5.2</b> Quadratic Poisson Regresson Model</a></li>
<li class="chapter" data-level="6.5.3" data-path="poisson-regression.html"><a href="poisson-regression.html#residuals-for-poisson-models"><i class="fa fa-check"></i><b>6.5.3</b> Residuals for Poisson Models</a></li>
<li class="chapter" data-level="6.5.4" data-path="poisson-regression.html"><a href="poisson-regression.html#plot-of-deviance-residuals-for-first-order-poisson-model"><i class="fa fa-check"></i><b>6.5.4</b> Plot of Deviance Residuals for First-Order Poisson Model</a></li>
<li class="chapter" data-level="6.5.5" data-path="poisson-regression.html"><a href="poisson-regression.html#plot-of-deviance-residuals-for-quadratic-poisson-model"><i class="fa fa-check"></i><b>6.5.5</b> Plot of Deviance Residuals for Quadratic Poisson Model</a></li>
<li class="chapter" data-level="6.5.6" data-path="poisson-regression.html"><a href="poisson-regression.html#residual-deviance-for-a-model"><i class="fa fa-check"></i><b>6.5.6</b> Residual Deviance for a Model</a></li>
<li class="chapter" data-level="6.5.7" data-path="poisson-regression.html"><a href="poisson-regression.html#drop-in-deviance-test"><i class="fa fa-check"></i><b>6.5.7</b> Drop-in-Deviance Test</a></li>
<li class="chapter" data-level="6.5.8" data-path="poisson-regression.html"><a href="poisson-regression.html#drop-in-deviance-test-1"><i class="fa fa-check"></i><b>6.5.8</b> Drop-in-Deviance Test</a></li>
<li class="chapter" data-level="6.5.9" data-path="poisson-regression.html"><a href="poisson-regression.html#visual-of-chi2-test"><i class="fa fa-check"></i><b>6.5.9</b> Visual of <span class="math inline">\(\chi^2\)</span> Test</a></li>
<li class="chapter" data-level="6.5.10" data-path="poisson-regression.html"><a href="poisson-regression.html#adding-roofing-material-to-model"><i class="fa fa-check"></i><b>6.5.10</b> Adding Roofing Material to Model</a></li>
<li class="chapter" data-level="6.5.11" data-path="poisson-regression.html"><a href="poisson-regression.html#visual-of-chi2-test-for-roof"><i class="fa fa-check"></i><b>6.5.11</b> Visual of <span class="math inline">\(\chi^2\)</span> Test for Roof</a></li>
<li class="chapter" data-level="6.5.12" data-path="poisson-regression.html"><a href="poisson-regression.html#goodness-of-fit"><i class="fa fa-check"></i><b>6.5.12</b> Goodness-of-Fit</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="poisson-regression.html"><a href="poisson-regression.html#overdisperson"><i class="fa fa-check"></i><b>6.6</b> Overdisperson</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="poisson-regression.html"><a href="poisson-regression.html#quasi-poisson-model"><i class="fa fa-check"></i><b>6.6.1</b> Quasi-Poisson Model</a></li>
<li class="chapter" data-level="6.6.2" data-path="poisson-regression.html"><a href="poisson-regression.html#quasi-poisson-model-in-r"><i class="fa fa-check"></i><b>6.6.2</b> Quasi-Poisson Model in R</a></li>
<li class="chapter" data-level="6.6.3" data-path="poisson-regression.html"><a href="poisson-regression.html#standard-errors-in-quasi-poisson-model"><i class="fa fa-check"></i><b>6.6.3</b> Standard Errors in Quasi-Poisson Model</a></li>
<li class="chapter" data-level="6.6.4" data-path="poisson-regression.html"><a href="poisson-regression.html#drop-in-deviance-tests-for-quasi-poisson-model"><i class="fa fa-check"></i><b>6.6.4</b> Drop-in-Deviance Tests for Quasi-Poisson Model</a></li>
<li class="chapter" data-level="6.6.5" data-path="poisson-regression.html"><a href="poisson-regression.html#first-vs-second-order-quasi-poisson-models"><i class="fa fa-check"></i><b>6.6.5</b> First vs Second Order Quasi-Poisson Models</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="poisson-regression.html"><a href="poisson-regression.html#offsets-in-poisson-regression"><i class="fa fa-check"></i><b>6.7</b> Offsets in Poisson Regression</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="poisson-regression.html"><a href="poisson-regression.html#case-study-campus-crime"><i class="fa fa-check"></i><b>6.7.1</b> Case Study: Campus Crime</a></li>
<li class="chapter" data-level="6.7.2" data-path="poisson-regression.html"><a href="poisson-regression.html#distribution-of-number-of-crimes"><i class="fa fa-check"></i><b>6.7.2</b> Distribution of Number of Crimes</a></li>
<li class="chapter" data-level="6.7.3" data-path="poisson-regression.html"><a href="poisson-regression.html#crimes-by-type-of-institution-and-region"><i class="fa fa-check"></i><b>6.7.3</b> Crimes by Type of Institution and Region</a></li>
<li class="chapter" data-level="6.7.4" data-path="poisson-regression.html"><a href="poisson-regression.html#accounting-for-enrollment"><i class="fa fa-check"></i><b>6.7.4</b> Accounting for Enrollment</a></li>
<li class="chapter" data-level="6.7.5" data-path="poisson-regression.html"><a href="poisson-regression.html#offset-in-r"><i class="fa fa-check"></i><b>6.7.5</b> Offset in R</a></li>
<li class="chapter" data-level="6.7.6" data-path="poisson-regression.html"><a href="poisson-regression.html#model-with-interaction"><i class="fa fa-check"></i><b>6.7.6</b> Model with Interaction</a></li>
<li class="chapter" data-level="6.7.7" data-path="poisson-regression.html"><a href="poisson-regression.html#drop-in-deviance-test-for-interaction"><i class="fa fa-check"></i><b>6.7.7</b> Drop-in-Deviance Test for Interaction</a></li>
<li class="chapter" data-level="6.7.8" data-path="poisson-regression.html"><a href="poisson-regression.html#goodness-of-fit-test"><i class="fa fa-check"></i><b>6.7.8</b> Goodness of Fit Test</a></li>
<li class="chapter" data-level="6.7.9" data-path="poisson-regression.html"><a href="poisson-regression.html#quasi-poisson-model-1"><i class="fa fa-check"></i><b>6.7.9</b> Quasi-Poisson Model</a></li>
<li class="chapter" data-level="6.7.10" data-path="poisson-regression.html"><a href="poisson-regression.html#test-for-interaction"><i class="fa fa-check"></i><b>6.7.10</b> Test for Interaction</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="poisson-regression.html"><a href="poisson-regression.html#summaries"><i class="fa fa-check"></i><b>6.8</b> Summaries</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="poisson-regression.html"><a href="poisson-regression.html#llsr-vs.-poisson-regression-comparison"><i class="fa fa-check"></i><b>6.8.1</b> LLSR vs. Poisson Regression Comparison</a></li>
<li class="chapter" data-level="6.8.2" data-path="poisson-regression.html"><a href="poisson-regression.html#poisson-vs-quasi-poisson-inference"><i class="fa fa-check"></i><b>6.8.2</b> Poisson vs Quasi-Poisson Inference</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>7</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="logistic-regression.html"><a href="logistic-regression.html#binomial-logistic-regression"><i class="fa fa-check"></i><b>7.1</b> Binomial Logistic Regression</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-response-data"><i class="fa fa-check"></i><b>7.1.1</b> Binary Response Data</a></li>
<li class="chapter" data-level="7.1.2" data-path="logistic-regression.html"><a href="logistic-regression.html#binomial-response-data"><i class="fa fa-check"></i><b>7.1.2</b> Binomial Response Data</a></li>
<li class="chapter" data-level="7.1.3" data-path="logistic-regression.html"><a href="logistic-regression.html#wisconsin-election-data"><i class="fa fa-check"></i><b>7.1.3</b> 2020 Wisconsin Election Data</a></li>
<li class="chapter" data-level="7.1.4" data-path="logistic-regression.html"><a href="logistic-regression.html#correlation-between-explanatory-variables"><i class="fa fa-check"></i><b>7.1.4</b> Correlation Between Explanatory Variables</a></li>
<li class="chapter" data-level="7.1.5" data-path="logistic-regression.html"><a href="logistic-regression.html#modeling-number-of-votes"><i class="fa fa-check"></i><b>7.1.5</b> Modeling Number of Votes</a></li>
<li class="chapter" data-level="7.1.6" data-path="logistic-regression.html"><a href="logistic-regression.html#the-binomial-distribution"><i class="fa fa-check"></i><b>7.1.6</b> The Binomial Distribution</a></li>
<li class="chapter" data-level="7.1.7" data-path="logistic-regression.html"><a href="logistic-regression.html#binomial-distribution-for-n4-p0.6"><i class="fa fa-check"></i><b>7.1.7</b> Binomial Distribution for <span class="math inline">\(n=4, p=0.6\)</span></a></li>
<li class="chapter" data-level="7.1.8" data-path="logistic-regression.html"><a href="logistic-regression.html#more-binomial-distributions"><i class="fa fa-check"></i><b>7.1.8</b> More Binomial Distributions</a></li>
<li class="chapter" data-level="7.1.9" data-path="logistic-regression.html"><a href="logistic-regression.html#connecting-expected-response-to-explatory-variables-1"><i class="fa fa-check"></i><b>7.1.9</b> Connecting Expected Response to Explatory Variables</a></li>
<li class="chapter" data-level="7.1.10" data-path="logistic-regression.html"><a href="logistic-regression.html#odds-and-odds-ratio"><i class="fa fa-check"></i><b>7.1.10</b> Odds and Odds Ratio</a></li>
<li class="chapter" data-level="7.1.11" data-path="logistic-regression.html"><a href="logistic-regression.html#interpreting-regression-coefficients"><i class="fa fa-check"></i><b>7.1.11</b> Interpreting Regression Coefficients</a></li>
<li class="chapter" data-level="7.1.12" data-path="logistic-regression.html"><a href="logistic-regression.html#binomial-logistic-regression-assumptions"><i class="fa fa-check"></i><b>7.1.12</b> Binomial Logistic Regression Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="logistic-regression.html"><a href="logistic-regression.html#model-for-wisconsin-vote"><i class="fa fa-check"></i><b>7.2</b> Model for Wisconsin Vote</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="logistic-regression.html"><a href="logistic-regression.html#an-initial-model"><i class="fa fa-check"></i><b>7.2.1</b> An Initial Model</a></li>
<li class="chapter" data-level="7.2.2" data-path="logistic-regression.html"><a href="logistic-regression.html#checking-linearity-assumption"><i class="fa fa-check"></i><b>7.2.2</b> Checking Linearity Assumption</a></li>
<li class="chapter" data-level="7.2.3" data-path="logistic-regression.html"><a href="logistic-regression.html#overdispersion-in-binomial-counts"><i class="fa fa-check"></i><b>7.2.3</b> Overdispersion in Binomial Counts</a></li>
<li class="chapter" data-level="7.2.4" data-path="logistic-regression.html"><a href="logistic-regression.html#residuals-for-binomial-logistic-regression"><i class="fa fa-check"></i><b>7.2.4</b> Residuals for Binomial Logistic Regression</a></li>
<li class="chapter" data-level="7.2.5" data-path="logistic-regression.html"><a href="logistic-regression.html#quasi-binomial-model"><i class="fa fa-check"></i><b>7.2.5</b> Quasi-Binomial Model</a></li>
<li class="chapter" data-level="7.2.6" data-path="logistic-regression.html"><a href="logistic-regression.html#model-with-all-explanatory-variables"><i class="fa fa-check"></i><b>7.2.6</b> Model with All Explanatory Variables</a></li>
<li class="chapter" data-level="7.2.7" data-path="logistic-regression.html"><a href="logistic-regression.html#tests-for-significance-of-model-coefficients"><i class="fa fa-check"></i><b>7.2.7</b> Tests for Significance of Model Coefficients</a></li>
<li class="chapter" data-level="7.2.8" data-path="logistic-regression.html"><a href="logistic-regression.html#drop-in-deviance-test-2"><i class="fa fa-check"></i><b>7.2.8</b> Drop in Deviance Test</a></li>
<li class="chapter" data-level="7.2.9" data-path="logistic-regression.html"><a href="logistic-regression.html#deviance-residual-plot"><i class="fa fa-check"></i><b>7.2.9</b> Deviance Residual Plot</a></li>
<li class="chapter" data-level="7.2.10" data-path="logistic-regression.html"><a href="logistic-regression.html#llsr-vs-binomial-logistic-regression"><i class="fa fa-check"></i><b>7.2.10</b> LLSR vs Binomial Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="logistic-regression.html"><a href="logistic-regression.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>7.3</b> Maximum Likelihood Estimation</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#parameter-estimation"><i class="fa fa-check"></i><b>7.3.1</b> Parameter Estimation</a></li>
<li class="chapter" data-level="7.3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#steph-curry-3-point-shooting"><i class="fa fa-check"></i><b>7.3.2</b> Steph Curry 3-Point Shooting</a></li>
<li class="chapter" data-level="7.3.3" data-path="logistic-regression.html"><a href="logistic-regression.html#model-for-currys-shooting"><i class="fa fa-check"></i><b>7.3.3</b> Model for Curry’s Shooting</a></li>
<li class="chapter" data-level="7.3.4" data-path="logistic-regression.html"><a href="logistic-regression.html#likelihood-function"><i class="fa fa-check"></i><b>7.3.4</b> Likelihood Function</a></li>
<li class="chapter" data-level="7.3.5" data-path="logistic-regression.html"><a href="logistic-regression.html#plotting-likelihood-function"><i class="fa fa-check"></i><b>7.3.5</b> Plotting Likelihood Function</a></li>
<li class="chapter" data-level="7.3.6" data-path="logistic-regression.html"><a href="logistic-regression.html#numerical-maximization"><i class="fa fa-check"></i><b>7.3.6</b> Numerical Maximization</a></li>
<li class="chapter" data-level="7.3.7" data-path="logistic-regression.html"><a href="logistic-regression.html#mle-using-calculus"><i class="fa fa-check"></i><b>7.3.7</b> MLE Using Calculus</a></li>
<li class="chapter" data-level="7.3.8" data-path="logistic-regression.html"><a href="logistic-regression.html#likelihood-in-a-logistic-regression-model"><i class="fa fa-check"></i><b>7.3.8</b> Likelihood in a Logistic Regression Model</a></li>
<li class="chapter" data-level="7.3.9" data-path="logistic-regression.html"><a href="logistic-regression.html#plot-of-likelihood-function"><i class="fa fa-check"></i><b>7.3.9</b> Plot of Likelihood Function</a></li>
<li class="chapter" data-level="7.3.10" data-path="logistic-regression.html"><a href="logistic-regression.html#numerical-maximization-1"><i class="fa fa-check"></i><b>7.3.10</b> Numerical Maximization</a></li>
<li class="chapter" data-level="7.3.11" data-path="logistic-regression.html"><a href="logistic-regression.html#comparison-to-r-output"><i class="fa fa-check"></i><b>7.3.11</b> Comparison to R Output</a></li>
<li class="chapter" data-level="7.3.12" data-path="logistic-regression.html"><a href="logistic-regression.html#model-for-homeaway"><i class="fa fa-check"></i><b>7.3.12</b> Model for Home/Away</a></li>
<li class="chapter" data-level="7.3.13" data-path="logistic-regression.html"><a href="logistic-regression.html#numerical-optimization"><i class="fa fa-check"></i><b>7.3.13</b> Numerical Optimization</a></li>
<li class="chapter" data-level="7.3.14" data-path="logistic-regression.html"><a href="logistic-regression.html#comparison-to-r-output-1"><i class="fa fa-check"></i><b>7.3.14</b> Comparison to R Output</a></li>
<li class="chapter" data-level="7.3.15" data-path="logistic-regression.html"><a href="logistic-regression.html#applications-of-likelihood"><i class="fa fa-check"></i><b>7.3.15</b> Applications of Likelihood</a></li>
<li class="chapter" data-level="7.3.16" data-path="logistic-regression.html"><a href="logistic-regression.html#summary-maximum-likelihood-estimation"><i class="fa fa-check"></i><b>7.3.16</b> Summary Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="logistic-regression.html"><a href="logistic-regression.html#zero-inflated-poisson-model"><i class="fa fa-check"></i><b>7.4</b> Zero-Inflated Poisson Model</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="logistic-regression.html"><a href="logistic-regression.html#case-study-weekend-drinking"><i class="fa fa-check"></i><b>7.4.1</b> Case Study: Weekend Drinking</a></li>
<li class="chapter" data-level="7.4.2" data-path="logistic-regression.html"><a href="logistic-regression.html#questions-of-interest-3"><i class="fa fa-check"></i><b>7.4.2</b> Questions of Interest</a></li>
<li class="chapter" data-level="7.4.3" data-path="logistic-regression.html"><a href="logistic-regression.html#distribution-of-number-of-drinks"><i class="fa fa-check"></i><b>7.4.3</b> Distribution of Number of Drinks</a></li>
<li class="chapter" data-level="7.4.4" data-path="logistic-regression.html"><a href="logistic-regression.html#number-of-drinks-comparisons"><i class="fa fa-check"></i><b>7.4.4</b> Number of Drinks Comparisons</a></li>
<li class="chapter" data-level="7.4.5" data-path="logistic-regression.html"><a href="logistic-regression.html#proportion-of-drinkers"><i class="fa fa-check"></i><b>7.4.5</b> Proportion of Drinkers</a></li>
<li class="chapter" data-level="7.4.6" data-path="logistic-regression.html"><a href="logistic-regression.html#modeling-drinks"><i class="fa fa-check"></i><b>7.4.6</b> Modeling Drinks</a></li>
<li class="chapter" data-level="7.4.7" data-path="logistic-regression.html"><a href="logistic-regression.html#explaining-the-large-number-of-zeros"><i class="fa fa-check"></i><b>7.4.7</b> Explaining the Large Number of Zeros</a></li>
<li class="chapter" data-level="7.4.8" data-path="logistic-regression.html"><a href="logistic-regression.html#zero-inflated-poisson-model-1"><i class="fa fa-check"></i><b>7.4.8</b> Zero-Inflated Poisson Model</a></li>
<li class="chapter" data-level="7.4.9" data-path="logistic-regression.html"><a href="logistic-regression.html#developing-the-zero-inflated-poisson-model"><i class="fa fa-check"></i><b>7.4.9</b> Developing the Zero-Inflated Poisson Model</a></li>
<li class="chapter" data-level="7.4.10" data-path="logistic-regression.html"><a href="logistic-regression.html#deriving-the-zip-pmf"><i class="fa fa-check"></i><b>7.4.10</b> Deriving the ZIP PMF</a></li>
<li class="chapter" data-level="7.4.11" data-path="logistic-regression.html"><a href="logistic-regression.html#examples-of-zip-pmfs"><i class="fa fa-check"></i><b>7.4.11</b> Examples of ZIP PMF’s</a></li>
<li class="chapter" data-level="7.4.12" data-path="logistic-regression.html"><a href="logistic-regression.html#zip-model"><i class="fa fa-check"></i><b>7.4.12</b> ZIP Model</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="logistic-regression.html"><a href="logistic-regression.html#model-for-drinks-data"><i class="fa fa-check"></i><b>7.5</b> Model for Drinks Data</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="logistic-regression.html"><a href="logistic-regression.html#zip-for-drinks-data"><i class="fa fa-check"></i><b>7.5.1</b> ZIP for Drinks Data</a></li>
<li class="chapter" data-level="7.5.2" data-path="logistic-regression.html"><a href="logistic-regression.html#zip-model-in-r"><i class="fa fa-check"></i><b>7.5.2</b> ZIP Model in R</a></li>
<li class="chapter" data-level="7.5.3" data-path="logistic-regression.html"><a href="logistic-regression.html#residual-plot"><i class="fa fa-check"></i><b>7.5.3</b> Residual Plot</a></li>
<li class="chapter" data-level="7.5.4" data-path="logistic-regression.html"><a href="logistic-regression.html#limitations"><i class="fa fa-check"></i><b>7.5.4</b> Limitations</a></li>
<li class="chapter" data-level="7.5.5" data-path="logistic-regression.html"><a href="logistic-regression.html#final-thoughts-on-zero-inflated-models"><i class="fa fa-check"></i><b>7.5.5</b> Final Thoughts on Zero-Inflated Models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html"><i class="fa fa-check"></i><b>8</b> Multilevel Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#basketball-referees-dataset"><i class="fa fa-check"></i><b>8.1</b> Basketball Referees Dataset</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#data-overview"><i class="fa fa-check"></i><b>8.1.1</b> Data Overview</a></li>
<li class="chapter" data-level="8.1.2" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#histograms-for-level-one-covariates"><i class="fa fa-check"></i><b>8.1.2</b> Histograms for Level One Covariates</a></li>
<li class="chapter" data-level="8.1.3" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#average-fouls-by-team"><i class="fa fa-check"></i><b>8.1.3</b> Average Fouls by Team</a></li>
<li class="chapter" data-level="8.1.4" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#examining-bivariate-relationships"><i class="fa fa-check"></i><b>8.1.4</b> Examining Bivariate Relationships</a></li>
<li class="chapter" data-level="8.1.5" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#tabular-summary-by-fouling-team"><i class="fa fa-check"></i><b>8.1.5</b> Tabular Summary by Fouling Team</a></li>
<li class="chapter" data-level="8.1.6" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#mosaic-plots"><i class="fa fa-check"></i><b>8.1.6</b> Mosaic Plots</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#multilevel-generalized-linear-model"><i class="fa fa-check"></i><b>8.2</b> Multilevel Generalized Linear Model</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#motivation-for-a-statistical-model"><i class="fa fa-check"></i><b>8.2.1</b> Motivation for a Statistical Model</a></li>
<li class="chapter" data-level="8.2.2" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#a-glm-approach"><i class="fa fa-check"></i><b>8.2.2</b> A GLM Approach</a></li>
<li class="chapter" data-level="8.2.3" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#adding-random-effect-for-game"><i class="fa fa-check"></i><b>8.2.3</b> Adding Random Effect for Game</a></li>
<li class="chapter" data-level="8.2.4" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#two-level-logistic-model"><i class="fa fa-check"></i><b>8.2.4</b> Two Level Logistic Model</a></li>
<li class="chapter" data-level="8.2.5" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#multilevel-glm-in-r"><i class="fa fa-check"></i><b>8.2.5</b> Multilevel GLM in R</a></li>
<li class="chapter" data-level="8.2.6" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#add-random-slope"><i class="fa fa-check"></i><b>8.2.6</b> Add Random Slope</a></li>
<li class="chapter" data-level="8.2.7" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#random-slopes-model-in-r-1"><i class="fa fa-check"></i><b>8.2.7</b> Random Slopes Model in R</a></li>
<li class="chapter" data-level="8.2.8" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#aic-bic-comparison"><i class="fa fa-check"></i><b>8.2.8</b> AIC, BIC Comparison</a></li>
<li class="chapter" data-level="8.2.9" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#random-error-terms"><i class="fa fa-check"></i><b>8.2.9</b> Random Error Terms</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#crossed-random-effects"><i class="fa fa-check"></i><b>8.3</b> Crossed Random Effects</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#random-effects-for-teams"><i class="fa fa-check"></i><b>8.3.1</b> Random Effects for Teams</a></li>
<li class="chapter" data-level="8.3.2" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#crossed-vs-nested-random-effects"><i class="fa fa-check"></i><b>8.3.2</b> Crossed vs Nested Random Effects</a></li>
<li class="chapter" data-level="8.3.3" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#models-for-crossed-random-effects"><i class="fa fa-check"></i><b>8.3.3</b> Models for Crossed Random Effects</a></li>
<li class="chapter" data-level="8.3.4" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#fitting-model-with-crossed-random-effects-in-r"><i class="fa fa-check"></i><b>8.3.4</b> Fitting Model with Crossed Random Effects in R</a></li>
<li class="chapter" data-level="8.3.5" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#more-on-crossed-effects"><i class="fa fa-check"></i><b>8.3.5</b> More on Crossed Effects</a></li>
<li class="chapter" data-level="8.3.6" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#a-final-model-for-examining-referee-bias"><i class="fa fa-check"></i><b>8.3.6</b> A Final Model for Examining Referee Bias</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#parametric-bootstrapping"><i class="fa fa-check"></i><b>8.4</b> Parametric Bootstrapping</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#when-and-why-to-bootstrap"><i class="fa fa-check"></i><b>8.4.1</b> When and Why to Bootstrap</a></li>
<li class="chapter" data-level="8.4.2" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#parametric-bootstrap-procedure"><i class="fa fa-check"></i><b>8.4.2</b> Parametric Bootstrap Procedure</a></li>
<li class="chapter" data-level="8.4.3" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#a-simple-example"><i class="fa fa-check"></i><b>8.4.3</b> A Simple Example</a></li>
<li class="chapter" data-level="8.4.4" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#parametric-bootstrap-confidence-intervals"><i class="fa fa-check"></i><b>8.4.4</b> Parametric Bootstrap Confidence Intervals</a></li>
<li class="chapter" data-level="8.4.5" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#model-comparison-tests-with-parametric-bootstrap"><i class="fa fa-check"></i><b>8.4.5</b> Model Comparison Tests with Parametric Bootstrap</a></li>
<li class="chapter" data-level="8.4.6" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#model-comparison-for-kentucky-derby-data"><i class="fa fa-check"></i><b>8.4.6</b> Model Comparison for Kentucky Derby Data</a></li>
<li class="chapter" data-level="8.4.7" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#code-for-boostrap-model-comparison"><i class="fa fa-check"></i><b>8.4.7</b> Code for Boostrap Model Comparison</a></li>
<li class="chapter" data-level="8.4.8" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#simulation-based-f-test"><i class="fa fa-check"></i><b>8.4.8</b> Simulation-Based F-Test</a></li>
<li class="chapter" data-level="8.4.9" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#model-comparison-in-multilevel-glm"><i class="fa fa-check"></i><b>8.4.9</b> Model Comparison in Multilevel GLM</a></li>
<li class="chapter" data-level="8.4.10" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#multilevel-glm-bootstrap-code"><i class="fa fa-check"></i><b>8.4.10</b> Multilevel GLM Bootstrap Code</a></li>
<li class="chapter" data-level="8.4.11" data-path="multilevel-generalized-linear-models.html"><a href="multilevel-generalized-linear-models.html#simulation-based-chi2-test"><i class="fa fa-check"></i><b>8.4.11</b> Simulation-Based <span class="math inline">\(\chi^2\)</span> Test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="epilogue.html"><a href="epilogue.html"><i class="fa fa-check"></i><b>9</b> Epilogue</a>
<ul>
<li class="chapter" data-level="9.1" data-path="epilogue.html"><a href="epilogue.html#further-directions"><i class="fa fa-check"></i><b>9.1</b> Further Directions</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="epilogue.html"><a href="epilogue.html#more-on-glms"><i class="fa fa-check"></i><b>9.1.1</b> More on GLM’s</a></li>
<li class="chapter" data-level="9.1.2" data-path="epilogue.html"><a href="epilogue.html#models-beyond-glms"><i class="fa fa-check"></i><b>9.1.2</b> Models Beyond GLM’s</a></li>
<li class="chapter" data-level="9.1.3" data-path="epilogue.html"><a href="epilogue.html#statistics-courses-at-lawrence"><i class="fa fa-check"></i><b>9.1.3</b> Statistics Courses at Lawrence</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Stat 455: Advanced Statistical Modeling Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="logistic-regression" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number">Chapter 7</span> Logistic Regression<a href="logistic-regression.html#logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><strong>Chapter 6 Learning Outcomes</strong></p>
<ol start="40" style="list-style-type: decimal">
<li><p>State the assumptions associated with a binomial logistic regression model and determine whether the assumptions are satisfied.</p></li>
<li><p>Calculate probabilities and odds and expected changes associated with fixed effects in a binomial logistic regression model.</p></li>
<li><p>Interpret fixed effect coefficients in a binomial logistic regression model.</p></li>
<li><p>Analyze data using a binomial logistic regression model and Zero-Inflated Poisson Model in R.</p></li>
<li><p>Interpret fixed effect coefficients in a Zero-Inflated Poisson model.<br />
</p></li>
<li><p>Explain the role of a link function in a generalized linear model and determine which link function(s) might be appropriate in a given model.</p></li>
</ol>
<p>These notes provide a summary of Chapter 6 in <a href="https://bookdown.org/roback/bookdown-BeyondMLR/">Beyond Multiple Linear Regression</a> by Roback and Legler. The dataset we work with is different than those in the text, but much of the code and analysis is based off the examples in the text. <a href="https://github.com/proback/BeyondMLR/">Github repository</a>.</p>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb340-1"><a href="logistic-regression.html#cb340-1" tabindex="-1"></a><span class="co"># Packages required for Chapter 6</span></span>
<span id="cb340-2"><a href="logistic-regression.html#cb340-2" tabindex="-1"></a><span class="fu">library</span>(gridExtra)  </span>
<span id="cb340-3"><a href="logistic-regression.html#cb340-3" tabindex="-1"></a><span class="fu">library</span>(mnormt) </span>
<span id="cb340-4"><a href="logistic-regression.html#cb340-4" tabindex="-1"></a><span class="fu">library</span>(lme4) </span>
<span id="cb340-5"><a href="logistic-regression.html#cb340-5" tabindex="-1"></a><span class="fu">library</span>(knitr) </span>
<span id="cb340-6"><a href="logistic-regression.html#cb340-6" tabindex="-1"></a><span class="fu">library</span>(pander)</span>
<span id="cb340-7"><a href="logistic-regression.html#cb340-7" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb340-8"><a href="logistic-regression.html#cb340-8" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb340-9"><a href="logistic-regression.html#cb340-9" tabindex="-1"></a><span class="fu">library</span>(corrplot)</span></code></pre></div>
<div id="binomial-logistic-regression" class="section level2 hasAnchor" number="7.1">
<h2><span class="header-section-number">7.1</span> Binomial Logistic Regression<a href="logistic-regression.html#binomial-logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In Stat 255, we learned about Logistic regression models for binary response data. Please review sections 8.1-8.3 in the <a href="https://bookdown.org/ajsage/statistics_for_data_science_notes/">Stat 255 notes</a> prior to proceeding.</p>
<div id="binary-response-data" class="section level3 hasAnchor" number="7.1.1">
<h3><span class="header-section-number">7.1.1</span> Binary Response Data<a href="logistic-regression.html#binary-response-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can use logistic regression to model binary responses, such as whether or not a student person defaults on a credit card payment, as in the dataset below.</p>
<p>In this dataset, each row represents an individual with a single yes/no response.</p>
<div class="sourceCode" id="cb341"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb341-1"><a href="logistic-regression.html#cb341-1" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb341-2"><a href="logistic-regression.html#cb341-2" tabindex="-1"></a><span class="fu">data</span>(Default)</span>
<span id="cb341-3"><a href="logistic-regression.html#cb341-3" tabindex="-1"></a><span class="fu">head</span>(Default)</span></code></pre></div>
<pre><code>##   default student   balance    income
## 1      No      No  729.5265 44361.625
## 2      No     Yes  817.1804 12106.135
## 3      No      No 1073.5492 31767.139
## 4      No      No  529.2506 35704.494
## 5      No      No  785.6559 38463.496
## 6      No     Yes  919.5885  7491.559</code></pre>
</div>
<div id="binomial-response-data" class="section level3 hasAnchor" number="7.1.2">
<h3><span class="header-section-number">7.1.2</span> Binomial Response Data<a href="logistic-regression.html#binomial-response-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can also use logistic regression to model data where the rows represent the number of “successes” in a fixed number of trials.</p>
<p>For example:</p>
<ol style="list-style-type: decimal">
<li>Number of games won by a sports team in a given number of games.<br />
</li>
<li>Number of people who survive for at least 10 years after being diagnosed with a disease.<br />
</li>
<li>Number of people who vote for a candidate in election our of total number of voters.</li>
</ol>
<p>We’ll refer to this kind of regression as <strong>Binomial Logistic Regression</strong>, though the term <strong>logistic regression</strong> is used somewhat abmiguously and is sometimes applied to this context as well.</p>
</div>
<div id="wisconsin-election-data" class="section level3 hasAnchor" number="7.1.3">
<h3><span class="header-section-number">7.1.3</span> 2020 Wisconsin Election Data<a href="logistic-regression.html#wisconsin-election-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We’ll work with data on the 2020 presidential election in the state of Wisconsin. Each row of the dataset represents a county in Wisconsin. Variables include:</p>
<ul>
<li><code>County</code> - name of the county<br />
</li>
<li><code>Rvotes</code> - number of votes for Republican candidate (Donald Trump)<br />
</li>
<li><code>Dvotes</code> - number of votes for Democratic candidate (Joe Biden)<br />
</li>
<li><code>PctD</code> - percentage of 2-party vote that went to Biden (i.e. <code>Rvotes</code>/(<code>Rvotes</code> + <code>Dvotes</code>))<br />
</li>
<li><code>College</code> - percentage of residents with a college degree<br />
</li>
<li><code>Unemployment</code> - unemployment rate<br />
</li>
<li><code>WhitePct</code> - percentage of white residents<br />
</li>
<li><code>COVID_DeathRate</code> - number of deaths from covid-19 per 100,000 residents<br />
</li>
<li><code>Income</code> - median household income</li>
</ul>
<p>All variables were recorded at the time of the election.</p>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb343-1"><a href="logistic-regression.html#cb343-1" tabindex="-1"></a>Wisconsin <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;WisconsinVote.csv&quot;</span>)</span>
<span id="cb343-2"><a href="logistic-regression.html#cb343-2" tabindex="-1"></a><span class="fu">head</span>(Wisconsin, <span class="dv">10</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 × 10
##     ...1 County          Rvotes Dvotes  PctD College Unemployment WhitePct
##    &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;
##  1     1 Adams County      7362   4329  37.0    12.4          5.2     93.8
##  2     2 Ashland County    3841   4801  55.6    21.1          4.8     83.8
##  3     3 Barron County    15803   9194  36.8    19.9          4       95.3
##  4     4 Bayfield County   4617   6147  57.1    30.5          5.6     85.4
##  5     5 Brown County     75871  65511  46.3    29.6          3.1     87.8
##  6     6 Buffalo County    4834   2860  37.2    17.9          4.2     97.3
##  7     7 Burnett County    6462   3569  35.6    20            5.3     91.5
##  8     8 Calumet County   18156  12116  40.0    28.7          2.8     94.7
##  9     9 Chippewa County  21317  13983  39.6    20.1          3.8     94.7
## 10    10 Clark County     10002   4524  31.1    11.5          3.3     97.1
## # ℹ 2 more variables: COVID_DeathRate &lt;dbl&gt;, Income &lt;dbl&gt;</code></pre>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb345-1"><a href="logistic-regression.html#cb345-1" tabindex="-1"></a>P1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(Wisconsin, <span class="fu">aes</span>(<span class="at">x=</span>College, <span class="at">y=</span>PctD, <span class="at">size=</span>(Rvotes<span class="sc">+</span>Dvotes))) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb345-2"><a href="logistic-regression.html#cb345-2" tabindex="-1"></a> <span class="fu">geom_text</span>(<span class="at">data=</span>Wisconsin <span class="sc">%&gt;%</span> <span class="fu">filter</span>(County <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Dane County&quot;</span>, <span class="st">&quot;Door County&quot;</span> , <span class="st">&quot;Milwaukee County&quot;</span>, <span class="st">&quot;Menominee County&quot;</span>, <span class="st">&quot;Outagamie County&quot;</span>, <span class="st">&quot;Waukesha County&quot;</span>)), <span class="fu">aes</span>(<span class="at">x=</span>College, <span class="at">y=</span>PctD, <span class="at">label=</span>County, <span class="at">vjust=</span><span class="sc">-</span><span class="dv">1</span>), <span class="at">size=</span><span class="dv">3</span>, <span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb345-3"><a href="logistic-regression.html#cb345-3" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Percent with  College Degree&quot;</span>) <span class="sc">+</span></span>
<span id="cb345-4"><a href="logistic-regression.html#cb345-4" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Percent Voting for Biden&quot;</span>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position=</span><span class="st">&quot;none&quot;</span>)</span>
<span id="cb345-5"><a href="logistic-regression.html#cb345-5" tabindex="-1"></a>P2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(Wisconsin, <span class="fu">aes</span>(<span class="at">x=</span>Unemployment, <span class="at">y=</span>PctD, <span class="at">size=</span>(Rvotes<span class="sc">+</span>Dvotes))) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb345-6"><a href="logistic-regression.html#cb345-6" tabindex="-1"></a> <span class="fu">geom_text</span>(<span class="at">data=</span>Wisconsin <span class="sc">%&gt;%</span> <span class="fu">filter</span>(County <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Dane County&quot;</span>, <span class="st">&quot;Door County&quot;</span> , <span class="st">&quot;Milwaukee County&quot;</span>, <span class="st">&quot;Menominee County&quot;</span>, <span class="st">&quot;Outagamie County&quot;</span>, <span class="st">&quot;Waukesha County&quot;</span>)), <span class="fu">aes</span>(<span class="at">x=</span>Unemployment, <span class="at">y=</span>PctD, <span class="at">label=</span>County, <span class="at">vjust=</span><span class="sc">-</span><span class="dv">1</span>), <span class="at">size=</span><span class="dv">3</span>, <span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb345-7"><a href="logistic-regression.html#cb345-7" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Unemployment Rate&quot;</span>) <span class="sc">+</span></span>
<span id="cb345-8"><a href="logistic-regression.html#cb345-8" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Percent Voting for Biden&quot;</span>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position=</span><span class="st">&quot;none&quot;</span>)</span>
<span id="cb345-9"><a href="logistic-regression.html#cb345-9" tabindex="-1"></a>P3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(Wisconsin, <span class="fu">aes</span>(<span class="at">x=</span>WhitePct, <span class="at">y=</span>PctD, <span class="at">size=</span>(Rvotes<span class="sc">+</span>Dvotes))) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb345-10"><a href="logistic-regression.html#cb345-10" tabindex="-1"></a> <span class="fu">geom_text</span>(<span class="at">data=</span>Wisconsin <span class="sc">%&gt;%</span> <span class="fu">filter</span>(County <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Dane County&quot;</span>, <span class="st">&quot;Door County&quot;</span> , <span class="st">&quot;Milwaukee County&quot;</span>, <span class="st">&quot;Menominee County&quot;</span>, <span class="st">&quot;Outagamie County&quot;</span>, <span class="st">&quot;Waukesha County&quot;</span>)), <span class="fu">aes</span>(<span class="at">x=</span>WhitePct, <span class="at">y=</span>PctD, <span class="at">label=</span>County, <span class="at">vjust=</span><span class="sc">-</span><span class="dv">1</span>), <span class="at">size=</span><span class="dv">3</span>, <span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb345-11"><a href="logistic-regression.html#cb345-11" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Percent of Population White&quot;</span>) <span class="sc">+</span></span>
<span id="cb345-12"><a href="logistic-regression.html#cb345-12" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Percent Voting for Biden&quot;</span>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position=</span><span class="st">&quot;none&quot;</span>)</span>
<span id="cb345-13"><a href="logistic-regression.html#cb345-13" tabindex="-1"></a>P4 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(Wisconsin, <span class="fu">aes</span>(<span class="at">x=</span>COVID_DeathRate, <span class="at">y=</span>PctD, <span class="at">size=</span>(Rvotes<span class="sc">+</span>Dvotes))) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb345-14"><a href="logistic-regression.html#cb345-14" tabindex="-1"></a> <span class="fu">geom_text</span>(<span class="at">data=</span>Wisconsin <span class="sc">%&gt;%</span> <span class="fu">filter</span>(County <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Dane County&quot;</span>, <span class="st">&quot;Door County&quot;</span> , <span class="st">&quot;Milwaukee County&quot;</span>, <span class="st">&quot;Menominee County&quot;</span>, <span class="st">&quot;Outagamie County&quot;</span>, <span class="st">&quot;Waukesha County&quot;</span>)), <span class="fu">aes</span>(<span class="at">x=</span>COVID_DeathRate, <span class="at">y=</span>PctD, <span class="at">label=</span>County, <span class="at">vjust=</span><span class="sc">-</span><span class="dv">1</span>), <span class="at">size=</span><span class="dv">3</span>, <span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb345-15"><a href="logistic-regression.html#cb345-15" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Covid Deaths Per 100k&quot;</span>) <span class="sc">+</span></span>
<span id="cb345-16"><a href="logistic-regression.html#cb345-16" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Percent Voting for Biden&quot;</span>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position=</span><span class="st">&quot;none&quot;</span>)</span>
<span id="cb345-17"><a href="logistic-regression.html#cb345-17" tabindex="-1"></a>P5 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(Wisconsin, <span class="fu">aes</span>(<span class="at">x=</span>Income, <span class="at">y=</span>PctD, <span class="at">size=</span>(Rvotes<span class="sc">+</span>Dvotes))) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb345-18"><a href="logistic-regression.html#cb345-18" tabindex="-1"></a> <span class="fu">geom_text</span>(<span class="at">data=</span>Wisconsin <span class="sc">%&gt;%</span> <span class="fu">filter</span>(County <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Dane County&quot;</span>, <span class="st">&quot;Door County&quot;</span> , <span class="st">&quot;Milwaukee County&quot;</span>, <span class="st">&quot;Menominee County&quot;</span>, <span class="st">&quot;Outagamie County&quot;</span>, <span class="st">&quot;Waukesha County&quot;</span>)), <span class="fu">aes</span>(<span class="at">x=</span>Income, <span class="at">y=</span>PctD, <span class="at">label=</span>County, <span class="at">vjust=</span><span class="sc">-</span><span class="dv">1</span>), <span class="at">size=</span><span class="dv">3</span>, <span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb345-19"><a href="logistic-regression.html#cb345-19" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Median Income&quot;</span>) <span class="sc">+</span></span>
<span id="cb345-20"><a href="logistic-regression.html#cb345-20" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Percent Voting for Biden&quot;</span>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position=</span><span class="st">&quot;none&quot;</span>)</span>
<span id="cb345-21"><a href="logistic-regression.html#cb345-21" tabindex="-1"></a><span class="fu">grid.arrange</span>(P1, P2, P3, P4, P5, <span class="at">nrow=</span><span class="dv">3</span>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position=</span><span class="st">&quot;none&quot;</span>)</span></code></pre></div>
<p><img src="Stat-455-Notes_files/figure-html/unnamed-chunk-217-1.png" width="1152" /></p>
<pre><code>## NULL</code></pre>
</div>
<div id="correlation-between-explanatory-variables" class="section level3 hasAnchor" number="7.1.4">
<h3><span class="header-section-number">7.1.4</span> Correlation Between Explanatory Variables<a href="logistic-regression.html#correlation-between-explanatory-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb347-1"><a href="logistic-regression.html#cb347-1" tabindex="-1"></a>select <span class="ot">&lt;-</span> dplyr<span class="sc">::</span>select</span>
<span id="cb347-2"><a href="logistic-regression.html#cb347-2" tabindex="-1"></a>C <span class="ot">&lt;-</span> <span class="fu">cor</span>(Wisconsin <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="st">&quot;College&quot;</span>, <span class="st">&quot;Unemployment&quot;</span>, <span class="st">&quot;WhitePct&quot;</span>, <span class="st">&quot;COVID_DeathRate&quot;</span>, <span class="st">&quot;Income&quot;</span>))</span>
<span id="cb347-3"><a href="logistic-regression.html#cb347-3" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="fu">corrplot</span>(C, <span class="at">method=</span><span class="st">&quot;number&quot;</span>)</span></code></pre></div>
<p><img src="Stat-455-Notes_files/figure-html/unnamed-chunk-218-1.png" width="960" /></p>
<p>While there is some correlation between the explanatory variables, none of the correlations are strong enough to raise concerns about multicollinearity, so we’ll use all of them in our model.</p>
</div>
<div id="modeling-number-of-votes" class="section level3 hasAnchor" number="7.1.5">
<h3><span class="header-section-number">7.1.5</span> Modeling Number of Votes<a href="logistic-regression.html#modeling-number-of-votes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose we know the total number of votes in a county and the probability of a single voter choosing Biden.</p>
<p>Since the response is a count, we might think to use a Poisson distribution. However, a Poisson distribution does not place an upper bound on the number of votes a candidate could receive in a county. This is unrealistic since we know that in reality, a candidate will never be able to get more votes than the total number of voters.</p>
</div>
<div id="the-binomial-distribution" class="section level3 hasAnchor" number="7.1.6">
<h3><span class="header-section-number">7.1.6</span> The Binomial Distribution<a href="logistic-regression.html#the-binomial-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <strong>Binomial</strong> random variable is a discrete random variable that models the number of “successes” in a fixed number of independent trials. We let <span class="math inline">\(n\)</span> represent the number of trials, and <span class="math inline">\(p\)</span> represent the probability of success on any given trial.</p>
<p><strong>Notation</strong>: <span class="math inline">\(Y\sim Binom(n,p)\)</span>, <b style="word-space:2m">  </b>
<strong>Probability Mass Function</strong>: <span class="math inline">\(\text{P}(Y=y) = {n\choose y}p^y(1-p)^{n-y}\)</span> <b style="word-space:2m">  </b></p>
<p>For <span class="math inline">\(n = 4, p=0.6\)</span>,</p>
<p><span class="math display">\[ Pr(Y=0) = {4\choose 0}0.6^0(0.4)^{4} = 1(0.4)^4\approx(0.0256)
\]</span></p>
<p><span class="math display">\[ Pr(Y=1) = {4\choose 1}0.6^1(0.4)^{3} = 4(.6)(0.4)^3\approx(0.1536)
\]</span></p>
<p><span class="math display">\[ Pr(Y=2) = {4\choose 2}0.6^2(0.4)^{2} = 6(.6)^2(0.4)^2\approx(0.3456)
\]</span></p>
<p><span class="math display">\[ Pr(Y=3) = {4\choose 3}0.6^3(0.4)^{1} = 4(.6)^3(0.4)^1\approx(0.3456)
\]</span></p>
<p><span class="math display">\[ Pr(Y=4) = {4\choose 4}0.6^4(0.4)^{0} = 1(.6)^4(0.4)\approx(0.1296)
\]</span></p>
<p>In a binomial distribution, the mean is <span class="math inline">\(np\)</span>,</p>
<p>and the variance is <span class="math inline">\(np(1-p)\)</span>.</p>
<p>A binomial distribution with <span class="math inline">\(n=1\)</span> is called a <strong>Bernoulli Distribution</strong>, denoted <span class="math inline">\(Ber(p)\)</span>.</p>
</div>
<div id="binomial-distribution-for-n4-p0.6" class="section level3 hasAnchor" number="7.1.7">
<h3><span class="header-section-number">7.1.7</span> Binomial Distribution for <span class="math inline">\(n=4, p=0.6\)</span><a href="logistic-regression.html#binomial-distribution-for-n4-p0.6" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb348-1"><a href="logistic-regression.html#cb348-1" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">y =</span> <span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">size =</span> <span class="dv">4</span>, <span class="at">prob=</span><span class="fl">0.6</span>))</span>
<span id="cb348-2"><a href="logistic-regression.html#cb348-2" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span> <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>, <span class="at">col =</span> <span class="st">&quot;white&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;blue&quot;</span>) <span class="sc">+</span> </span>
<span id="cb348-3"><a href="logistic-regression.html#cb348-3" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">expand =</span> <span class="fu">c</span>(<span class="fl">0.01</span>, <span class="dv">0</span>)) <span class="sc">+</span> <span class="fu">scale_x_continuous</span>(<span class="at">breaks=</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">4</span>)) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;x&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&quot;p(x|&quot;</span>, p, <span class="st">&quot;)&quot;</span>))) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;n=4, p=0.6&quot;</span>) <span class="sc">+</span> <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb348-4"><a href="logistic-regression.html#cb348-4" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="fu">rel</span>(<span class="fl">1.2</span>), <span class="at">vjust =</span> <span class="fl">1.5</span>))</span></code></pre></div>
<p><img src="Stat-455-Notes_files/figure-html/unnamed-chunk-219-1.png" width="576" /></p>
<p>Mean = <span class="math inline">\(0.6 \times 4=2.4\)</span></p>
<p>Variance = <span class="math inline">\(4\times 0.6 \times 0.4=0.96\)</span></p>
</div>
<div id="more-binomial-distributions" class="section level3 hasAnchor" number="7.1.8">
<h3><span class="header-section-number">7.1.8</span> More Binomial Distributions<a href="logistic-regression.html#more-binomial-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We plot binomial distributions with <span class="math inline">\(n=10\)</span>, <span class="math inline">\(p=0.25, 0.6, 0.9\)</span></p>
<p><img src="Stat-455-Notes_files/figure-html/unnamed-chunk-220-1.png" width="960" /></p>
</div>
<div id="connecting-expected-response-to-explatory-variables-1" class="section level3 hasAnchor" number="7.1.9">
<h3><span class="header-section-number">7.1.9</span> Connecting Expected Response to Explatory Variables<a href="logistic-regression.html#connecting-expected-response-to-explatory-variables-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb349-1"><a href="logistic-regression.html#cb349-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">0</span>)</span>
<span id="cb349-2"><a href="logistic-regression.html#cb349-2" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">x=</span><span class="fu">runif</span>(<span class="dv">200</span>, <span class="sc">-</span><span class="dv">5</span>, <span class="dv">10</span>),</span>
<span id="cb349-3"><a href="logistic-regression.html#cb349-3" tabindex="-1"></a>                  <span class="at">p=</span><span class="fu">exp</span>(<span class="sc">-</span><span class="dv">2</span><span class="sc">+</span><span class="dv">1</span><span class="sc">*</span>x)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="sc">-</span><span class="dv">2</span><span class="sc">+</span><span class="dv">1</span><span class="sc">*</span>x)),</span>
<span id="cb349-4"><a href="logistic-regression.html#cb349-4" tabindex="-1"></a>                  <span class="at">y=</span><span class="fu">rbinom</span>(<span class="dv">200</span>, <span class="dv">1</span>, p),</span>
<span id="cb349-5"><a href="logistic-regression.html#cb349-5" tabindex="-1"></a>                  <span class="at">y2=</span>.<span class="dv">3408</span><span class="fl">+.0901</span><span class="sc">*</span>x,</span>
<span id="cb349-6"><a href="logistic-regression.html#cb349-6" tabindex="-1"></a>                  <span class="at">logit=</span><span class="fu">log</span>(p<span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span>p)))</span>
<span id="cb349-7"><a href="logistic-regression.html#cb349-7" tabindex="-1"></a>dat2 <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">c</span>(dat<span class="sc">$</span>x, dat<span class="sc">$</span>x),</span>
<span id="cb349-8"><a href="logistic-regression.html#cb349-8" tabindex="-1"></a>               <span class="at">y =</span> <span class="fu">c</span>(dat<span class="sc">$</span>y2, dat<span class="sc">$</span>p),</span>
<span id="cb349-9"><a href="logistic-regression.html#cb349-9" tabindex="-1"></a>               <span class="st">`</span><span class="at">Regression model</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;linear&quot;</span>, <span class="dv">200</span>),</span>
<span id="cb349-10"><a href="logistic-regression.html#cb349-10" tabindex="-1"></a>                                      <span class="fu">rep</span>(<span class="st">&quot;logistic&quot;</span>, <span class="dv">200</span>)))</span>
<span id="cb349-11"><a href="logistic-regression.html#cb349-11" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb349-12"><a href="logistic-regression.html#cb349-12" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> dat, <span class="fu">aes</span>(x, y)) <span class="sc">+</span></span>
<span id="cb349-13"><a href="logistic-regression.html#cb349-13" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> dat2, <span class="fu">aes</span>(x, y, <span class="at">linetype =</span> <span class="st">`</span><span class="at">Regression model</span><span class="st">`</span>))  <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;p&quot;</span>)</span></code></pre></div>
<p><img src="Stat-455-Notes_files/figure-html/unnamed-chunk-221-1.png" width="576" /></p>
<p>Let <span class="math inline">\(p_i\)</span> represent the probability that a voter in county <span class="math inline">\(i\)</span> votes for Biden.</p>
<p>We want to connect <span class="math inline">\(p_i\)</span> to our explanatory variables.</p>
<p>Assuming</p>
<p><span class="math display">\[p_i =  \beta_0+\beta_1X_{1} + \ldots + \beta_pX_p\]</span></p>
<p>is a bad idea since <span class="math inline">\(p_1\)</span> must stay between -1 and 1.</p>
<p>We’ll use a sigmoidal function of the form</p>
<p><span class="math display">\[p_i =  \frac{e^{\beta_0+\beta_1X_{1} + \ldots + \beta_pX_p}}{1+e^{\beta_0+\beta_1X_{1} + \ldots + \beta_pX_p}}\]</span></p>
<p>Equivalently:</p>
<p><span class="math display">\[\text{log}\left(\frac{{p_i}}{{1-p_i}}\right) =  \beta_0+\beta_1X_{1} + \ldots + \beta_pX_p \]</span></p>
<p>The function <span class="math inline">\(\text{log}\left(\frac{{p_i}}{{1-p_i}}\right)\)</span> is called <span class="math inline">\(\text{logit}(p_i)\)</span>. So, we can say:</p>
<p><span class="math display">\[\text{logit}(p_i) =  \beta_0+\beta_1X_{i1} + \ldots + \beta_pX_{ip}\]</span></p>
<p>The function <span class="math inline">\(f(p) = \text{logit}(p) = log\left(\frac{p}{1-p}\right)\)</span> is the link function.</p>
<p>Note: we could use different functions that map the real numbers into the interval (0,1), but the logit function works well and is frequently used.</p>
</div>
<div id="odds-and-odds-ratio" class="section level3 hasAnchor" number="7.1.10">
<h3><span class="header-section-number">7.1.10</span> Odds and Odds Ratio<a href="logistic-regression.html#odds-and-odds-ratio" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For an event with probability <span class="math inline">\(p\)</span>, the odds of the event occuring are <span class="math inline">\(\frac{p}{1-p}\)</span></p>
<p>For two events <span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_2\)</span> the odds ratio is defined as <span class="math inline">\(\frac{\text{Odds of Event 1}}{\text{Odds of Event 1}} = \frac{\frac{p_1}{1-p_1}}{\frac{p_2}{1-p_2}}\)</span></p>
</div>
<div id="interpreting-regression-coefficients" class="section level3 hasAnchor" number="7.1.11">
<h3><span class="header-section-number">7.1.11</span> Interpreting Regression Coefficients<a href="logistic-regression.html#interpreting-regression-coefficients" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s suppose we have one explanatory variable <span class="math inline">\(x\)</span>, so</p>
<p><span class="math display">\[\text{logit}(p_i) =  \frac{e^{\beta_0+\beta_1X_{1}}}{1+e^{\beta_0+\beta_1X_{1}}}, \]</span></p>
<p>Consider the odds ratio for a case <span class="math inline">\(j\)</span> with explanatory variable <span class="math inline">\(x + 1\)</span>, compared to case <span class="math inline">\(i\)</span> with explanatory variable <span class="math inline">\(x\)</span>.</p>
<p>That is <span class="math inline">\(\text{log}\left(\frac{p_i}{1-p_i}\right) = \beta_0+\beta_1x\)</span>, and
<span class="math inline">\(\text{log}\left(\frac{p_j}{1-p_j}\right) = \beta_0+\beta_1(x+1)\)</span>.</p>
<p><span class="math inline">\(\text{log}\left(\frac{\frac{p_j}{1-p_j}}{\frac{p_i}{1-p_i}}\right)=\text{log}\left(\frac{p_j}{1-p_j}\right)-\text{log}\left(\frac{p_i}{1-p_j}\right)=\beta_0+\beta_1(x+1)-(\beta_0+\beta_1(x))=\beta_1.\)</span></p>
<p>For each 1-unit increase in <span class="math inline">\(x\)</span> the log of the odds ratio of success to failure is expected to multiply by a factor of <span class="math inline">\(\beta_1\)</span>.</p>
<p>For each 1-unit increase in <span class="math inline">\(x\)</span> the odds ratio of success to failure is expected to multiply by a factor of <span class="math inline">\(e^{\beta_1}\)</span>.</p>
<p>For a categorical variable <span class="math inline">\(x_j\)</span> the odds success to failure in category <span class="math inline">\(j\)</span>, are expected to be <span class="math inline">\(e^{\beta_1}\)</span> times higher in category <span class="math inline">\(j\)</span> than in the baseline category.</p>
</div>
<div id="binomial-logistic-regression-assumptions" class="section level3 hasAnchor" number="7.1.12">
<h3><span class="header-section-number">7.1.12</span> Binomial Logistic Regression Assumptions<a href="logistic-regression.html#binomial-logistic-regression-assumptions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A logistic regression model relies on the following assumptions:</p>
<ol style="list-style-type: decimal">
<li><strong>Binary Response</strong> The response variable is dichotomous (two possible responses) or the sum of dichotomous responses.</li>
<li><strong>Independence</strong> The observations must be independent of one another.</li>
<li><strong>Variance Structure</strong> By definition, the variance of a binomial random variable is <span class="math inline">\(np(1-p)\)</span>, so that variability is highest when <span class="math inline">\(p=.5\)</span>.</li>
<li><strong>Linearity</strong> The log of the odds ratio, <span class="math inline">\(\text{log}(\frac{p}{1-p}) = \text{logit}(p)\)</span>, must be a linear function of <span class="math inline">\(x\)</span>.</li>
</ol>
</div>
</div>
<div id="model-for-wisconsin-vote" class="section level2 hasAnchor" number="7.2">
<h2><span class="header-section-number">7.2</span> Model for Wisconsin Vote<a href="logistic-regression.html#model-for-wisconsin-vote" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="an-initial-model" class="section level3 hasAnchor" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> An Initial Model<a href="logistic-regression.html#an-initial-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We’ll start by trying to model the relationship between number of votes for Biden and percentage of voters with a college degree.</p>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb350-1"><a href="logistic-regression.html#cb350-1" tabindex="-1"></a>M1 <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">cbind</span>(Dvotes, Rvotes) <span class="sc">~</span> College , <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link=</span><span class="st">&quot;logit&quot;</span>), <span class="at">data =</span> Wisconsin)</span>
<span id="cb350-2"><a href="logistic-regression.html#cb350-2" tabindex="-1"></a><span class="fu">summary</span>(M1)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(Dvotes, Rvotes) ~ College, family = binomial(link = &quot;logit&quot;), 
##     data = Wisconsin)
## 
## Coefficients:
##               Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept) -0.9521859  0.0035941  -264.9 &lt;0.0000000000000002 ***
## College      0.0319564  0.0001136   281.4 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 277052  on 71  degrees of freedom
## Residual deviance: 194994  on 70  degrees of freedom
## AIC: 195751
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>For each one percent increase in college education, the odds of voting for Biden are expected to multiply by a factor of <span class="math inline">\(e^{0.0320}=1.0325\)</span> (a 3% increase).</p>
<p>In a county where 25% of the population has a college degree, the probability of an individual voter voting for Biden is
<span class="math display">\[\frac{e^{-0.9521859 + 0.0319564\times25}}{1+ e^{ (-0.9521859 + 0.0319564\times25)}}=0.4618\]</span></p>
<p>In a county where 35% of the population has a college degree, the probability of an individual voter voting for Biden is</p>
<p><span class="math display">\[\frac{e^{-0.9521859 + 0.0319564\times35}}{1 + e^{ (-0.9521859 + 0.0319564\times35)}}=0.5415\]</span></p>
</div>
<div id="checking-linearity-assumption" class="section level3 hasAnchor" number="7.2.2">
<h3><span class="header-section-number">7.2.2</span> Checking Linearity Assumption<a href="logistic-regression.html#checking-linearity-assumption" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The model assumes that <span class="math inline">\(\text{log}\left(\frac{p}{1-p}\right) = \text{logit}(p)\)</span> is a linear function of <span class="math inline">\(x\)</span>. To check this, we calculate <span class="math inline">\(\hat{p}_i\)</span> for each county and plot <span class="math inline">\(\text{log}\left(\frac{\hat{p}_i}{1-\hat{p_i}}\right)\)</span> against percentage of college graduates.</p>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb352-1"><a href="logistic-regression.html#cb352-1" tabindex="-1"></a>phat <span class="ot">&lt;-</span> <span class="fu">with</span>(Wisconsin, (Dvotes)<span class="sc">/</span>(Dvotes<span class="sc">+</span>Rvotes))</span>
<span id="cb352-2"><a href="logistic-regression.html#cb352-2" tabindex="-1"></a>Wisconsin<span class="sc">$</span>elogit <span class="ot">&lt;-</span> <span class="fu">log</span>(phat<span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span>phat))</span>
<span id="cb352-3"><a href="logistic-regression.html#cb352-3" tabindex="-1"></a><span class="do">## Plots</span></span>
<span id="cb352-4"><a href="logistic-regression.html#cb352-4" tabindex="-1"></a><span class="fu">ggplot</span>(Wisconsin, <span class="fu">aes</span>(<span class="at">x=</span>College, <span class="at">y=</span>elogit))<span class="sc">+</span></span>
<span id="cb352-5"><a href="logistic-regression.html#cb352-5" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">shape=</span><span class="dv">1</span>) <span class="sc">+</span>    <span class="co"># Use hollow circles</span></span>
<span id="cb352-6"><a href="logistic-regression.html#cb352-6" tabindex="-1"></a>    <span class="fu">geom_smooth</span>(<span class="at">method=</span>lm,   <span class="co"># Add linear regression line</span></span>
<span id="cb352-7"><a href="logistic-regression.html#cb352-7" tabindex="-1"></a>                <span class="at">se=</span><span class="cn">FALSE</span>) <span class="sc">+</span> <span class="co"># Don&#39;t add shaded confidence region</span></span>
<span id="cb352-8"><a href="logistic-regression.html#cb352-8" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;College&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;empirical logits&quot;</span>) <span class="sc">+</span> </span>
<span id="cb352-9"><a href="logistic-regression.html#cb352-9" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title=</span><span class="st">&quot;Wisconsin Vote Empirical logits by College Pct.&quot;</span>)</span></code></pre></div>
<p><img src="Stat-455-Notes_files/figure-html/emplogits-1.png" width="60%" style="display: block; margin: auto;" /></p>
</div>
<div id="overdispersion-in-binomial-counts" class="section level3 hasAnchor" number="7.2.3">
<h3><span class="header-section-number">7.2.3</span> Overdispersion in Binomial Counts<a href="logistic-regression.html#overdispersion-in-binomial-counts" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The binomial model assumes that the variance is equal to <span class="math inline">\(np(1-p)\)</span>. Checking this using graphs or tables is challenging, since it involves both <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span>, but we can group together counties with similar <span class="math inline">\(n\)</span> and similar percentages of college graduates (hence similar <span class="math inline">\(p\)</span>), and calculate variance in each group.</p>
<div class="sourceCode" id="cb353"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb353-1"><a href="logistic-regression.html#cb353-1" tabindex="-1"></a>summarize <span class="ot">&lt;-</span> dplyr<span class="sc">::</span>summarize</span>
<span id="cb353-2"><a href="logistic-regression.html#cb353-2" tabindex="-1"></a>Wisconsin <span class="ot">&lt;-</span> Wisconsin <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">TotalVotes =</span> Dvotes<span class="sc">+</span>Rvotes)</span>
<span id="cb353-3"><a href="logistic-regression.html#cb353-3" tabindex="-1"></a>                                </span>
<span id="cb353-4"><a href="logistic-regression.html#cb353-4" tabindex="-1"></a>EdCuts <span class="ot">=</span> <span class="fu">cut</span>(Wisconsin<span class="sc">$</span>College,</span>
<span id="cb353-5"><a href="logistic-regression.html#cb353-5" tabindex="-1"></a>           <span class="at">breaks=</span><span class="fu">c</span>(<span class="dv">10</span>,<span class="dv">20</span>,<span class="dv">30</span>,<span class="dv">40</span>,<span class="dv">50</span>,<span class="dv">60</span>))</span>
<span id="cb353-6"><a href="logistic-regression.html#cb353-6" tabindex="-1"></a>PopCuts <span class="ot">=</span> <span class="fu">cut</span>(Wisconsin<span class="sc">$</span>TotalVotes,</span>
<span id="cb353-7"><a href="logistic-regression.html#cb353-7" tabindex="-1"></a>           <span class="at">breaks=</span><span class="fu">c</span>(<span class="fu">seq</span>(<span class="at">from=</span><span class="dv">0</span>, <span class="at">to =</span><span class="dv">100000</span>, <span class="at">by=</span><span class="dv">10000</span>), <span class="dv">500000</span>))</span>
<span id="cb353-8"><a href="logistic-regression.html#cb353-8" tabindex="-1"></a>WisconsinCuts <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(EdCuts, PopCuts, Wisconsin) </span>
<span id="cb353-9"><a href="logistic-regression.html#cb353-9" tabindex="-1"></a>WisconsinGrps <span class="ot">&lt;-</span> WisconsinCuts <span class="sc">%&gt;%</span> <span class="fu">group_by</span>(EdCuts, PopCuts) <span class="sc">%&gt;%</span> </span>
<span id="cb353-10"><a href="logistic-regression.html#cb353-10" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">NCounties =</span> <span class="fu">n</span>(),</span>
<span id="cb353-11"><a href="logistic-regression.html#cb353-11" tabindex="-1"></a>            <span class="at">phat =</span> <span class="fu">sum</span>(Dvotes)<span class="sc">/</span><span class="fu">sum</span>(TotalVotes),</span>
<span id="cb353-12"><a href="logistic-regression.html#cb353-12" tabindex="-1"></a>            <span class="at">mean_n =</span> <span class="fu">mean</span>(TotalVotes),</span>
<span id="cb353-13"><a href="logistic-regression.html#cb353-13" tabindex="-1"></a>            <span class="at">Theoretical_Variance =</span> mean_n<span class="sc">*</span>phat<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>phat),</span>
<span id="cb353-14"><a href="logistic-regression.html#cb353-14" tabindex="-1"></a>            <span class="at">Obs_Var =</span> <span class="fu">var</span>(Dvotes)) <span class="sc">%&gt;%</span></span>
<span id="cb353-15"><a href="logistic-regression.html#cb353-15" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(NCounties))</span>
<span id="cb353-16"><a href="logistic-regression.html#cb353-16" tabindex="-1"></a>WisconsinGrps                                                                 </span></code></pre></div>
<pre><code>## # A tibble: 24 × 7
## # Groups:   EdCuts [5]
##    EdCuts  PopCuts       NCounties  phat  mean_n Theoretical_Variance   Obs_Var
##    &lt;fct&gt;   &lt;fct&gt;             &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;                &lt;dbl&gt;     &lt;dbl&gt;
##  1 (10,20] (0,1e+04]            12 0.394   6359.                1518.  1233845.
##  2 (10,20] (1e+04,2e+04]        12 0.351  12366.                2817.  1137954.
##  3 (20,30] (2e+04,3e+04]         7 0.448  23677                 5855.  1662284 
##  4 (10,20] (2e+04,3e+04]         6 0.338  23962.                5359.  1454543.
##  5 (20,30] (1e+04,2e+04]         5 0.453  13037.                3231.  3059893.
##  6 (20,30] (3e+04,4e+04]         4 0.451  33628.                8325.  6968112.
##  7 (20,30] (1e+05,5e+05]         3 0.464 117357.               29187. 93383717.
##  8 (10,20] (4e+04,5e+04]         2 0.362  45874.               10589.   106722 
##  9 (20,30] (4e+04,5e+04]         2 0.413  43892.               10642.  6262260.
## 10 (20,30] (5e+04,6e+04]         2 0.384  56491                13362.  2422200.
## # ℹ 14 more rows</code></pre>
<p>In the groups where there are enough counties to compare, the observed variance in counts appears to be much higher than the binomial model assumes.</p>
<p>The data are heavily overdispersed.</p>
</div>
<div id="residuals-for-binomial-logistic-regression" class="section level3 hasAnchor" number="7.2.4">
<h3><span class="header-section-number">7.2.4</span> Residuals for Binomial Logistic Regression<a href="logistic-regression.html#residuals-for-binomial-logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We examine two kinds of residuals that are similar to those we saw in Poisson regression.</p>
<p><strong>Pearson Residual:</strong></p>
<p><span class="math display">\[
\begin{equation*}
\textrm{Pearson residual}_i = \frac{\textrm{actual count}-\textrm{predicted count}}{\textrm{SD of count}} =
\frac{Y_i-m_i\hat{p_i}}{\sqrt{m_i\hat{p_i}(1-\hat{p_i})}}
\end{equation*}
\]</span></p>
<p>where <span class="math inline">\(m_i\)</span> is the number of trials for the <span class="math inline">\(i^{th}\)</span> observation and <span class="math inline">\(\hat{p}_i\)</span> is the estimated probability of success for that same observation.</p>
<p><strong>Deviance Residual:</strong>
<span class="math display">\[
\begin{equation*}
\textrm{d}_i =
\textrm{sign}(Y_i-m_i\hat{p_i})\sqrt{2[Y_i \log\left(\frac{Y_i}{m_i \hat{p_i}}\right)+
(m_i - Y_i) \log\left(\frac{m_i - Y_i}{m_i - m_i \hat{p_i}}\right)]}
\end{equation*}
\]</span></p>
<p>When the number of trials is large for all of the observations and the models are appropriate, both sets of residuals should follow a standard normal distribution.</p>
</div>
<div id="quasi-binomial-model" class="section level3 hasAnchor" number="7.2.5">
<h3><span class="header-section-number">7.2.5</span> Quasi-Binomial Model<a href="logistic-regression.html#quasi-binomial-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Like in Poisson regression, we can address overdispersion by fitting quasi-binomial model that estimates a dispersion parameter <span class="math inline">\(\hat{\phi}=\frac{\sum(\textrm{Pearson residuals})^2}{n-p}\)</span> and multiplies standard error by <span class="math inline">\(\sqrt{\phi}\)</span>.</p>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb355-1"><a href="logistic-regression.html#cb355-1" tabindex="-1"></a>M1b <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">cbind</span>(Dvotes, Rvotes) <span class="sc">~</span> College , <span class="at">family =</span> <span class="fu">quasibinomial</span>(<span class="at">link=</span><span class="st">&quot;logit&quot;</span>), <span class="at">data =</span> Wisconsin)</span>
<span id="cb355-2"><a href="logistic-regression.html#cb355-2" tabindex="-1"></a><span class="fu">summary</span>(M1b)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(Dvotes, Rvotes) ~ College, family = quasibinomial(link = &quot;logit&quot;), 
##     data = Wisconsin)
## 
## Coefficients:
##              Estimate Std. Error t value   Pr(&gt;|t|)    
## (Intercept) -0.952186   0.188929  -5.040 0.00000350 ***
## College      0.031956   0.005969   5.353 0.00000104 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for quasibinomial family taken to be 2763.213)
## 
##     Null deviance: 277052  on 71  degrees of freedom
## Residual deviance: 194994  on 70  degrees of freedom
## AIC: NA
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>The estimate of the dispersion parameter <span class="math inline">\(\hat{\phi} = 2763\)</span> is large.</p>
<ul>
<li>Standard errors increase considerably.<br />
</li>
<li>The t-statistics associated with the quasi-binomial model are much smaller the z-statistics associated with the binomial model.<br />
</li>
<li>The p-values are bigger, but still small enough to provide evidence of a relationship between college education and voting for Biden.</li>
</ul>
</div>
<div id="model-with-all-explanatory-variables" class="section level3 hasAnchor" number="7.2.6">
<h3><span class="header-section-number">7.2.6</span> Model with All Explanatory Variables<a href="logistic-regression.html#model-with-all-explanatory-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb357-1"><a href="logistic-regression.html#cb357-1" tabindex="-1"></a>M2 <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">cbind</span>(Dvotes, Rvotes) <span class="sc">~</span> College <span class="sc">+</span> Unemployment <span class="sc">+</span> WhitePct <span class="sc">+</span> COVID_DeathRate <span class="sc">+</span> Income , <span class="at">family =</span> <span class="fu">quasibinomial</span>(<span class="at">link=</span><span class="st">&quot;logit&quot;</span>), <span class="at">data =</span> Wisconsin)</span>
<span id="cb357-2"><a href="logistic-regression.html#cb357-2" tabindex="-1"></a><span class="fu">summary</span>(M2)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(Dvotes, Rvotes) ~ College + Unemployment + 
##     WhitePct + COVID_DeathRate + Income, family = quasibinomial(link = &quot;logit&quot;), 
##     data = Wisconsin)
## 
## Coefficients:
##                     Estimate   Std. Error t value        Pr(&gt;|t|)    
## (Intercept)      4.009188399  0.580255296   6.909 0.0000000023471 ***
## College          0.046311576  0.005900290   7.849 0.0000000000493 ***
## Unemployment    -0.110233627  0.060376843  -1.826          0.0724 .  
## WhitePct        -0.029353000  0.004832728  -6.074 0.0000000690197 ***
## COVID_DeathRate -0.006583959  0.001535600  -4.288 0.0000601756542 ***
## Income          -0.000033277  0.000004613  -7.214 0.0000000006729 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for quasibinomial family taken to be 527.7059)
## 
##     Null deviance: 277052  on 71  degrees of freedom
## Residual deviance:  34757  on 66  degrees of freedom
## AIC: NA
## 
## Number of Fisher Scoring iterations: 3</code></pre>
<ul>
<li><p>For each one percentage point increase in college education odds of voting for Biden are estimated to multiply by <span class="math inline">\(e^{0.0463} = 1.047\)</span> ( a 5% increase), assuming all other variables are held constant.</p></li>
<li><p>For each one percentage point increase in unemployment rate, odds of voting for Biden is estimated to multiply by <span class="math inline">\(e^{-0.1102} = 0.8957\)</span> (a 10% decrease), assuming all other variables are held constant.</p></li>
<li><p>For each one percentage point increase in white residents, odds of voting for Biden is estimated to multiply by <span class="math inline">\(e^{-0.02935} = 0.97\)</span> (a 3% decrease), assuming all other variables are held constant.</p></li>
<li><p>For each one death increase per 100k residents, odds of voting for Biden is estimated to multiply by <span class="math inline">\(e^{-0.006584} = 0.993\)</span> (a 0.7% decrease), assuming all other variables are held constant.</p></li>
<li><p>For each 1000 dollar increase in median income, odds of voting for Biden is estimated to multiply by <span class="math inline">\(e^{-0.0000328\times1000} = 0.968\)</span> (a 3% decrease), assuming all other variables are held constant.</p></li>
</ul>
</div>
<div id="tests-for-significance-of-model-coefficients" class="section level3 hasAnchor" number="7.2.7">
<h3><span class="header-section-number">7.2.7</span> Tests for Significance of Model Coefficients<a href="logistic-regression.html#tests-for-significance-of-model-coefficients" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Wald test statistics and p-values for all variables provide evidence of relationships between these variables and percentage voting for Biden.</p>
<p>This is not surprising since the sample size is very large. In fact, confidence intervals and hypothesis tests don’t really make sense to talk about here, because we have the whole population of Wisconsin voters in 2020. We’re not trying to generalize from a sample to a population.</p>
<p>The model estimates still make sense, and are informative, so we should base our conclusions on percentage change estimates given on the previous slide.</p>
</div>
<div id="drop-in-deviance-test-2" class="section level3 hasAnchor" number="7.2.8">
<h3><span class="header-section-number">7.2.8</span> Drop in Deviance Test<a href="logistic-regression.html#drop-in-deviance-test-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We could perform a drop-in-deviance test to compare our two models so far.</p>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb359-1"><a href="logistic-regression.html#cb359-1" tabindex="-1"></a>drop_in_dev <span class="ot">&lt;-</span> <span class="fu">anova</span>(M1b, M2, <span class="at">test =</span> <span class="st">&quot;F&quot;</span>)</span>
<span id="cb359-2"><a href="logistic-regression.html#cb359-2" tabindex="-1"></a>drop_in_dev</span></code></pre></div>
<pre><code>Analysis of Deviance Table

Model 1: cbind(Dvotes, Rvotes) ~ College
Model 2: cbind(Dvotes, Rvotes) ~ College + Unemployment + WhitePct + COVID_DeathRate + 
    Income
  Resid. Df Resid. Dev Df Deviance      F                Pr(&gt;F)    
1        70     194994                                             
2        66      34757  4   160237 75.912 &lt; 0.00000000000000022 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>We see a large drop in residual deviance, providing strong evidence that the larger model is prefered. In this case, that makes sense, since it contains variables we expect to be helpful.</p>
<p>When we have very large sample sizes we’ll get small p-values even when the new variables don’t make a practical difference. So we should not base model choices on p-values alone, but should look at confidence intervals and measures of the size of the effect associated with each variable.</p>
</div>
<div id="deviance-residual-plot" class="section level3 hasAnchor" number="7.2.9">
<h3><span class="header-section-number">7.2.9</span> Deviance Residual Plot<a href="logistic-regression.html#deviance-residual-plot" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We plot deviance residuals against the predicted values and against our explanatory variables to test for lack of fit.</p>
<p><img src="Stat-455-Notes_files/figure-html/unnamed-chunk-227-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p><img src="Stat-455-Notes_files/figure-html/resid-1.png" width="960" style="display: block; margin: auto;" /></p>
</div>
<div id="llsr-vs-binomial-logistic-regression" class="section level3 hasAnchor" number="7.2.10">
<h3><span class="header-section-number">7.2.10</span> LLSR vs Binomial Logistic Regression<a href="logistic-regression.html#llsr-vs-binomial-logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="math display">\[\begin{gather*}
\underline{\textrm{Response}} \\
\mathbf{LLSR:}\textrm{ normal} \\
\mathbf{Binomial\ Regression:}\textrm{ number of successes in n trials} \\
\textrm{ } \\
\underline{\textrm{Variance}} \\
\mathbf{LLSR:}\textrm{ equal for each level of}\ X \\
\mathbf{Binomial\ Regression:}\ np(1-p)\textrm{ for each level of}\ X \\
\textrm{ } \\
\underline{\textrm{Model Fitting}} \\
\mathbf{LLSR:}\ \mu=\beta_0+\beta_1x \textrm{ using Least Squares}\\
\mathbf{Binomial\ Regression:}\ \log\left(\frac{p}{1-p}\right)=\beta_0+\beta_1x \textrm{ using Maximum Likelihood}\\
\textrm{ } \\
\underline{\textrm{EDA}} \\
\mathbf{LLSR:}\textrm{ plot $X$ vs. $Y$; add line} \\
\mathbf{Binomial\ Regression:}\textrm{ find $\log(\textrm{odds})$ for several subgroups; plot vs. $X$} \\
\end{gather*}\]</span></p>
<p><span class="math display">\[\begin{gather*}
\underline{\textrm{Comparing Models}} \\
\mathbf{LLSR:}\textrm{ extra sum of squares F-tests; AIC/BIC} \\
\mathbf{Binomial\ Regression:}\textrm{ drop-in-deviance tests; AIC/BIC} \\
\textrm{ } \\
\underline{\textrm{Interpreting Coefficients}} \\
\mathbf{LLSR:}\ \beta_1=\textrm{ change in mean response for unit change in $X$} \\
\mathbf{Binomial\ Regression:}\ e^{\beta_1}=\textrm{ percent change in odds for unit change in $X$}
\end{gather*}\]</span></p>
</div>
</div>
<div id="maximum-likelihood-estimation" class="section level2 hasAnchor" number="7.3">
<h2><span class="header-section-number">7.3</span> Maximum Likelihood Estimation<a href="logistic-regression.html#maximum-likelihood-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="parameter-estimation" class="section level3 hasAnchor" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> Parameter Estimation<a href="logistic-regression.html#parameter-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall that in ordinarly least squares regression, the estimates <span class="math inline">\(b_1, b_2, \ldots, b_p\)</span> of regression coefficients <span class="math inline">\(\beta_1, \beta_2, \ldots \beta_p\)</span> are chosen in a way that minimizes <span class="math inline">\(\displaystyle\sum_{i=1}^n(y_i-\hat{y_i})^2=\displaystyle\sum_{i=1}^n(y_i-(b_0+b_1x_{i1}+\ldots b_px_{ip}))^2\)</span>.</p>
<p>The validity of the least-squares regression process depends on the assumptions associated with a LLSR model, making it inappropriate for the kinds of models we’ve seen in this class (mixed effects models, generalized linear models, etc.). Instead, we use a process called <strong>maximum likelihood estimation.</strong></p>
<p>In fact, in an ordinary LLSR model, it can be shown that maximum likelihood estimation would produce the same estimates as least squares estimation.</p>
<p>In this section, we’ll work through a simple example to illustrate how maximum likelihood works in a logistic regression model.</p>
</div>
<div id="steph-curry-3-point-shooting" class="section level3 hasAnchor" number="7.3.2">
<h3><span class="header-section-number">7.3.2</span> Steph Curry 3-Point Shooting<a href="logistic-regression.html#steph-curry-3-point-shooting" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Stephen Curry of the Golden State Warriors is widely considered to be the best 3-point shooter in the NBA. So far during the current 2021-22 NBA season, Curry has made 251 out of 663 attempted 3 point shots (37.9%).</p>
<p>When playing at home, he has made 150 out of 397 3-point shots (37.8%).</p>
<p>When playing away, he has made 101 out of 266 4-point shots (38.0%).</p>
<p>We’ll use a logistic regression model to estimate the probability of Curry making a shot at home or away and test whether there is evidence of differences in his shooting based on location.</p>
</div>
<div id="model-for-currys-shooting" class="section level3 hasAnchor" number="7.3.3">
<h3><span class="header-section-number">7.3.3</span> Model for Curry’s Shooting<a href="logistic-regression.html#model-for-currys-shooting" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We’ll start with a very simple intercept-only model. This model assumes that Curry has a constant probability of success on any shot (<span class="math inline">\(p\)</span>), which is the same, regardless of where he is playing.</p>
<p>Our goal is to estimate <span class="math inline">\(p\)</span> and to find a confidence interval for the range <span class="math inline">\(p\)</span> could plausibly lie in.</p>
</div>
<div id="likelihood-function" class="section level3 hasAnchor" number="7.3.4">
<h3><span class="header-section-number">7.3.4</span> Likelihood Function<a href="logistic-regression.html#likelihood-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <strong>likelihood function</strong> is a function that tells us how likely we are to observe our data for a given parameter value.</p>
<p>Let <span class="math inline">\(p\)</span> represent the probability of a made basket.</p>
<p>Since the shots are independent, we can write the Likelihood function for Curry’s shots as:</p>
<p><span class="math display">\[Lik(p) \propto p^{\text{#Makes}}(1-p)^{\text{#Misses}} = (p)^{251}(1-p)^{412}\]</span></p>
<p>If our goal is just to esimate <span class="math inline">\(p\)</span>, we could simply find the value of <span class="math inline">\(p\)</span> that maximizes this function. Such a value is called a <strong>maximum likelihood estimate</strong>.</p>
</div>
<div id="plotting-likelihood-function" class="section level3 hasAnchor" number="7.3.5">
<h3><span class="header-section-number">7.3.5</span> Plotting Likelihood Function<a href="logistic-regression.html#plotting-likelihood-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb361"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb361-1"><a href="logistic-regression.html#cb361-1" tabindex="-1"></a><span class="fu">options</span>( <span class="at">scipen =</span> <span class="dv">0</span> )</span>
<span id="cb361-2"><a href="logistic-regression.html#cb361-2" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb361-3"><a href="logistic-regression.html#cb361-3" tabindex="-1"></a>p<span class="ot">=</span><span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="at">length=</span><span class="dv">1001</span>)</span>
<span id="cb361-4"><a href="logistic-regression.html#cb361-4" tabindex="-1"></a>lik<span class="ot">=</span>p<span class="sc">^</span><span class="dv">251</span> <span class="sc">*</span> (<span class="dv">1</span><span class="sc">-</span>p)<span class="sc">^</span>(<span class="dv">663-251</span>)      <span class="co"># likelihood of getting observed data</span></span>
<span id="cb361-5"><a href="logistic-regression.html#cb361-5" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(p,lik)</span>
<span id="cb361-6"><a href="logistic-regression.html#cb361-6" tabindex="-1"></a>plot<span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>df,<span class="fu">aes</span>(<span class="at">x=</span>p, <span class="at">y=</span>lik)) <span class="sc">+</span> </span>
<span id="cb361-7"><a href="logistic-regression.html#cb361-7" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color=</span><span class="st">&quot;blue&quot;</span>, <span class="at">size=</span><span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb361-8"><a href="logistic-regression.html#cb361-8" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;possible values of p&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Likelihood&quot;</span>) <span class="sc">+</span> </span>
<span id="cb361-9"><a href="logistic-regression.html#cb361-9" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title=</span><span class="st">&quot;Likelihood function for Curry&#39;s shots&quot;</span>) </span>
<span id="cb361-10"><a href="logistic-regression.html#cb361-10" tabindex="-1"></a>plot <span class="sc">+</span> <span class="fu">xlim</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span></code></pre></div>
<p><img src="Stat-455-Notes_files/figure-html/unnamed-chunk-228-1.png" width="576" /></p>
<p>It looks like the most likely value of <span class="math inline">\(p\)</span> is around 0.4.</p>
<p>We’ll write a function in R to calculate the value of <span class="math inline">\(p\)</span> that maximizes the function.</p>
</div>
<div id="numerical-maximization" class="section level3 hasAnchor" number="7.3.6">
<h3><span class="header-section-number">7.3.6</span> Numerical Maximization<a href="logistic-regression.html#numerical-maximization" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb362-1"><a href="logistic-regression.html#cb362-1" tabindex="-1"></a>Lik.f <span class="ot">&lt;-</span> <span class="cf">function</span>(nbasket,nmissed,nGrid){</span>
<span id="cb362-2"><a href="logistic-regression.html#cb362-2" tabindex="-1"></a>    p <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">length =</span> nGrid)   <span class="co"># create nGrid values of p between 0 and 1</span></span>
<span id="cb362-3"><a href="logistic-regression.html#cb362-3" tabindex="-1"></a>    lik <span class="ot">&lt;-</span> p<span class="sc">^</span>{nbasket} <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> p)<span class="sc">^</span>{nmissed} <span class="co"># calculate value of lik at each p</span></span>
<span id="cb362-4"><a href="logistic-regression.html#cb362-4" tabindex="-1"></a>    <span class="fu">return</span>(p[lik<span class="sc">==</span><span class="fu">max</span>(lik)])             <span class="co"># find and return the value of p that maximizes the likelihood function    </span></span>
<span id="cb362-5"><a href="logistic-regression.html#cb362-5" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb363"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb363-1"><a href="logistic-regression.html#cb363-1" tabindex="-1"></a><span class="fu">Lik.f</span>(<span class="at">nbasket =</span> <span class="dv">251</span>, <span class="at">nmissed =</span>  <span class="dv">663-251</span>, <span class="at">nGrid =</span> <span class="dv">10000</span>) </span></code></pre></div>
<pre><code>## [1] 0.3785379</code></pre>
<p>The maximum likelihood estimate is <span class="math inline">\(\hat{p} = 0.3785\)</span>.</p>
<p>In fact, this is equal to 251/663. In this case, the MLE is consistent with our intuition.</p>
</div>
<div id="mle-using-calculus" class="section level3 hasAnchor" number="7.3.7">
<h3><span class="header-section-number">7.3.7</span> MLE Using Calculus<a href="logistic-regression.html#mle-using-calculus" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can also use calculus to find the value of <span class="math inline">\(p\)</span> that maximizes the function <span class="math inline">\(\text{lik}(p)\)</span>.</p>
<p>In fact, it is usually easier to maximize the log of this function. We can do this since log is a non-decreasing function, ensuring that the value that maximizes <span class="math inline">\(\text{log}(\text{lik}(p))\)</span> will also maximize <span class="math inline">\(\text{lik}(p)\)</span>.</p>
<p><span class="math display">\[
\begin{align*}
\text{lik}(p)                      &amp;= p^{251}(1-p)^{412} \\
\text{log}(\text{lik}(p))                &amp;= 251\log(p)+412\log(1-p) \\
\frac{d}{dp} \log(\text{lik}(p)) &amp;= \frac{251}{p} - \frac{412}{1-p} = 0
\end{align*}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\frac{251}{p} = \frac{412}{1-p} \implies 251(1-p)=412p\implies p=\frac{251}{251+412}\approx0.3785
\]</span></p>
</div>
<div id="likelihood-in-a-logistic-regression-model" class="section level3 hasAnchor" number="7.3.8">
<h3><span class="header-section-number">7.3.8</span> Likelihood in a Logistic Regression Model<a href="logistic-regression.html#likelihood-in-a-logistic-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In a logistic regression model, we don’t try to estimate <span class="math inline">\(p\)</span> directly, but rather to estimate <span class="math inline">\(\beta_0, \beta_1, \beta_p\)</span>, which are then used to calculate <span class="math inline">\(p\)</span></p>
<p>In our simple intercept only example,</p>
<p><span class="math display">\[p =  \frac{e^{\beta_0}}{1+e^{\beta_0}}\]</span></p>
<p>and we need to estimate <span class="math inline">\(\beta_0\)</span>.</p>
<p>After removing constants, the new likelihood looks like:</p>
<p><span class="math display">\[
\begin{equation*}
\begin{gathered}
    Lik(\beta_0) \propto \\
    \left( \frac{e^{\beta_0}}{1+e^{\beta_0}}\right)^{251}\left(1- \frac{e^{\beta_0}}{1+e^{\beta_0}}\right)^{412}
\end{gathered}
\end{equation*}
\]</span></p>
</div>
<div id="plot-of-likelihood-function" class="section level3 hasAnchor" number="7.3.9">
<h3><span class="header-section-number">7.3.9</span> Plot of Likelihood Function<a href="logistic-regression.html#plot-of-likelihood-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb365-1"><a href="logistic-regression.html#cb365-1" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb365-2"><a href="logistic-regression.html#cb365-2" tabindex="-1"></a>b<span class="ot">=</span><span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="at">length=</span><span class="dv">1001</span>)</span>
<span id="cb365-3"><a href="logistic-regression.html#cb365-3" tabindex="-1"></a>lik<span class="ot">=</span> (<span class="fu">exp</span>(b)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(b)))<span class="sc">^</span><span class="dv">251</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>(<span class="fu">exp</span>(b)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(b))))<span class="sc">^</span>(<span class="dv">412</span>)       <span class="co"># likelihood of getting observed data</span></span>
<span id="cb365-4"><a href="logistic-regression.html#cb365-4" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(b,lik)</span>
<span id="cb365-5"><a href="logistic-regression.html#cb365-5" tabindex="-1"></a>plot<span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>df,<span class="fu">aes</span>(<span class="at">x=</span>b, <span class="at">y=</span>lik)) <span class="sc">+</span> </span>
<span id="cb365-6"><a href="logistic-regression.html#cb365-6" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color=</span><span class="st">&quot;blue&quot;</span>, <span class="at">size=</span><span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb365-7"><a href="logistic-regression.html#cb365-7" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;possible values of beta_0&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Likelihood&quot;</span>) <span class="sc">+</span> </span>
<span id="cb365-8"><a href="logistic-regression.html#cb365-8" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title=</span><span class="st">&quot;Likelihood function for Curry&#39;s shots&quot;</span>) </span>
<span id="cb365-9"><a href="logistic-regression.html#cb365-9" tabindex="-1"></a>plot <span class="sc">+</span> <span class="fu">xlim</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span></code></pre></div>
<p><img src="Stat-455-Notes_files/figure-html/unnamed-chunk-231-1.png" width="576" /></p>
</div>
<div id="numerical-maximization-1" class="section level3 hasAnchor" number="7.3.10">
<h3><span class="header-section-number">7.3.10</span> Numerical Maximization<a href="logistic-regression.html#numerical-maximization-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb366"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb366-1"><a href="logistic-regression.html#cb366-1" tabindex="-1"></a>Lik.f_logistic <span class="ot">&lt;-</span> <span class="cf">function</span>(nbasket,nmissed,nGrid){</span>
<span id="cb366-2"><a href="logistic-regression.html#cb366-2" tabindex="-1"></a>    b <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="at">length =</span> nGrid)   <span class="co"># create values between -1 and 1 at which to evaluate the function</span></span>
<span id="cb366-3"><a href="logistic-regression.html#cb366-3" tabindex="-1"></a>    lik <span class="ot">&lt;-</span> (<span class="fu">exp</span>(b)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(b)))<span class="sc">^</span>nbasket<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>(<span class="fu">exp</span>(b)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(b))))<span class="sc">^</span>nmissed  <span class="co"># calculate values at each b</span></span>
<span id="cb366-4"><a href="logistic-regression.html#cb366-4" tabindex="-1"></a>    <span class="fu">return</span>(b[lik<span class="sc">==</span><span class="fu">max</span>(lik)])    <span class="co"># find and return value of b that maximizes the function</span></span>
<span id="cb366-5"><a href="logistic-regression.html#cb366-5" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb367-1"><a href="logistic-regression.html#cb367-1" tabindex="-1"></a><span class="fu">Lik.f_logistic</span>(<span class="at">nbasket =</span> <span class="dv">251</span>, <span class="at">nmissed =</span> <span class="dv">412</span>, <span class="at">nGrid =</span> <span class="dv">10000</span>) </span></code></pre></div>
<pre><code>## [1] -0.4955496</code></pre>
<p>Our estimate is <span class="math inline">\(b_0 = -0.4955\)</span>.</p>
<p>From this we can calculate <span class="math display">\[\hat{p} =  \frac{e^{-0.4955}}{1+e^{-0.4955}}\approx0.3785\]</span></p>
</div>
<div id="comparison-to-r-output" class="section level3 hasAnchor" number="7.3.11">
<h3><span class="header-section-number">7.3.11</span> Comparison to R Output<a href="logistic-regression.html#comparison-to-r-output" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb369-1"><a href="logistic-regression.html#cb369-1" tabindex="-1"></a>Location <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Home&quot;</span>, <span class="st">&quot;Away&quot;</span>)</span>
<span id="cb369-2"><a href="logistic-regression.html#cb369-2" tabindex="-1"></a>Makes <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">150</span>, <span class="dv">101</span>)</span>
<span id="cb369-3"><a href="logistic-regression.html#cb369-3" tabindex="-1"></a>Misses <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">247</span>, <span class="dv">165</span>)</span>
<span id="cb369-4"><a href="logistic-regression.html#cb369-4" tabindex="-1"></a>Curry <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(Location, Makes, Misses)</span>
<span id="cb369-5"><a href="logistic-regression.html#cb369-5" tabindex="-1"></a><span class="fu">head</span>(Curry)</span></code></pre></div>
<pre><code>##   Location Makes Misses
## 1     Home   150    247
## 2     Away   101    165</code></pre>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb371-1"><a href="logistic-regression.html#cb371-1" tabindex="-1"></a>M <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="at">data =</span> Curry, <span class="fu">cbind</span>(Makes, Misses) <span class="sc">~</span> <span class="dv">1</span> , <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link=</span><span class="st">&quot;logit&quot;</span>))</span>
<span id="cb371-2"><a href="logistic-regression.html#cb371-2" tabindex="-1"></a><span class="fu">summary</span>(M)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(Makes, Misses) ~ 1, family = binomial(link = &quot;logit&quot;), 
##     data = Curry)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -0.49557    0.08007  -6.189 6.05e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 0.0023559  on 1  degrees of freedom
## Residual deviance: 0.0023559  on 1  degrees of freedom
## AIC: 14.355
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<p>Note that the estimates differ in the 5th decimal place due to issues with numerical approximation. We could get a more precise approximation by increasing the number of points in our grid search.</p>
<p>We could maximize this function using calculus, which is more involved, but still doable in this case. Calculus-based methods typically do not work for more complicated likelihood methods involving more than one parameter, so we usually rely on numerical approximation methods.</p>
</div>
<div id="model-for-homeaway" class="section level3 hasAnchor" number="7.3.12">
<h3><span class="header-section-number">7.3.12</span> Model for Home/Away<a href="logistic-regression.html#model-for-homeaway" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now let’s build a model that allows Curry’s probability of making a shot to differ for away games, compared to home games.</p>
<p>Recall that Curry made 150 out of 397 shots at home and 101 out of 265 away.</p>
<p>Let <span class="math inline">\(p_H\)</span> represent the probability of making a shot at home and <span class="math inline">\(p_A\)</span> represent the probability of making a shot in an away game.</p>
<p>We can write the likelihood function as:</p>
<p><span class="math display">\[Lik(p_H, p_A) \propto p_H^{150}(1-p_H)^{247}
p_A^{101}(1-p_A)^{165}\]</span></p>
<p>Our interest centers on estimating <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span>, not <span class="math inline">\(p_1\)</span> or <span class="math inline">\(p_0\)</span>. So we replace <span class="math inline">\(p_1\)</span> in the likelihood with an expression for <span class="math inline">\(p_1\)</span> in terms of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. Recall</p>
<p><span class="math display">\[p_i =  \frac{e^{\beta_0+\beta_1\text{Home}}}{1+e^{\beta_0+\beta_1\text{Home}}}\]</span></p>
<p>After removing constants, the new likelihood looks like:</p>
<p><span class="math display">\[
\begin{equation*}
\begin{gathered}
    Lik(\beta_0,\beta_1) \propto \\
    \left( \frac{e^{\beta_0+\beta_1}}{1+e^{\beta_0+\beta_1}}\right)^{150}\left(1- \frac{e^{\beta_0+\beta_1}}{1+e^{\beta_0+\beta_1}}\right)^{247}
    \left(\frac{e^{\beta_0}}{1+e^{\beta_0}}\right)^{101}\left(1-\frac{e^{\beta_0}}{1+e^{\beta_0}}\right)^{165}
\end{gathered}
\end{equation*}
\]</span></p>
</div>
<div id="numerical-optimization" class="section level3 hasAnchor" number="7.3.13">
<h3><span class="header-section-number">7.3.13</span> Numerical Optimization<a href="logistic-regression.html#numerical-optimization" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb373-1"><a href="logistic-regression.html#cb373-1" tabindex="-1"></a>Lik.f_logistic2 <span class="ot">&lt;-</span> <span class="cf">function</span>(nbasketH,nmissedH,nbasketA,nmissedA,nGrid){</span>
<span id="cb373-2"><a href="logistic-regression.html#cb373-2" tabindex="-1"></a>    b0 <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="at">length =</span> nGrid)  <span class="co"># values of b0 </span></span>
<span id="cb373-3"><a href="logistic-regression.html#cb373-3" tabindex="-1"></a>    b1 <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="at">length=</span>nGrid)  <span class="co"># values of b1</span></span>
<span id="cb373-4"><a href="logistic-regression.html#cb373-4" tabindex="-1"></a>    B <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(b0, b1)  <span class="co"># create all combinations of b0 and b1</span></span>
<span id="cb373-5"><a href="logistic-regression.html#cb373-5" tabindex="-1"></a>    <span class="fu">names</span>(B) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;b0&quot;</span>, <span class="st">&quot;b1&quot;</span>)  <span class="co"># give B the right names</span></span>
<span id="cb373-6"><a href="logistic-regression.html#cb373-6" tabindex="-1"></a>    B <span class="ot">&lt;-</span> B <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">Lik =</span> (<span class="fu">exp</span>(b0<span class="sc">+</span>b1)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(b0<span class="sc">+</span>b1)))<span class="sc">^</span>nbasketH<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>(<span class="fu">exp</span>(b0<span class="sc">+</span>b1)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(b0<span class="sc">+</span>b1))))<span class="sc">^</span>nmissedH<span class="sc">*</span></span>
<span id="cb373-7"><a href="logistic-regression.html#cb373-7" tabindex="-1"></a>                        (<span class="fu">exp</span>(b0)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(b0)))<span class="sc">^</span>nbasketA<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>(<span class="fu">exp</span>(b0)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(b0))))<span class="sc">^</span>nmissedA) <span class="co">#evaluate function</span></span>
<span id="cb373-8"><a href="logistic-regression.html#cb373-8" tabindex="-1"></a>    <span class="fu">return</span>(B[B<span class="sc">$</span>Lik<span class="sc">==</span><span class="fu">max</span>(B<span class="sc">$</span>Lik),]) <span class="co"># find and return combination of b0 and b1 that maximize B.     </span></span>
<span id="cb373-9"><a href="logistic-regression.html#cb373-9" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb374-1"><a href="logistic-regression.html#cb374-1" tabindex="-1"></a><span class="fu">Lik.f_logistic2</span>(<span class="at">nbasketH =</span> <span class="dv">150</span>, <span class="at">nmissedH =</span> <span class="dv">247</span>, <span class="at">nbasketA =</span> <span class="dv">101</span>, <span class="at">nmissedA =</span> <span class="dv">165</span>, <span class="at">nGrid =</span> <span class="dv">1000</span>) </span></code></pre></div>
<pre><code>##                b0           b1           Lik
## 496255 -0.4914915 -0.007007007 9.835399e-192</code></pre>
<p>Although we have worked with the likelihood function here, it is more common to work with the log of the likelihood function. Notice that the maximized log likelihood is very small, which can create numerical instability, though it doesn’t here.</p>
</div>
<div id="comparison-to-r-output-1" class="section level3 hasAnchor" number="7.3.14">
<h3><span class="header-section-number">7.3.14</span> Comparison to R Output<a href="logistic-regression.html#comparison-to-r-output-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb376-1"><a href="logistic-regression.html#cb376-1" tabindex="-1"></a>M <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="at">data =</span> Curry, <span class="fu">cbind</span>(Makes, Misses) <span class="sc">~</span> Location , <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link=</span><span class="st">&quot;logit&quot;</span>))</span>
<span id="cb376-2"><a href="logistic-regression.html#cb376-2" tabindex="-1"></a><span class="fu">summary</span>(M)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(Makes, Misses) ~ Location, family = binomial(link = &quot;logit&quot;), 
##     data = Curry)
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -0.490825   0.126339  -3.885 0.000102 ***
## LocationHome -0.007928   0.163330  -0.049 0.961286    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance:  2.3559e-03  on 1  degrees of freedom
## Residual deviance: -4.2188e-15  on 0  degrees of freedom
## AIC: 16.353
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<p>The estimates are close to those that we obtained. We can make them closer by using a finer grid search.</p>
</div>
<div id="applications-of-likelihood" class="section level3 hasAnchor" number="7.3.15">
<h3><span class="header-section-number">7.3.15</span> Applications of Likelihood<a href="logistic-regression.html#applications-of-likelihood" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Likelihood is at the heart of many of the model comparison tests we’ve worked with in this class.</p>
<p><strong>Likelihood Ratio Tests</strong></p>
<p>The ANOVA-type tests of reduced vs full models use likelihoods to calculate the improvement in fit, associated with adding additional variables to the model.</p>
<p>Our test statistic is</p>
<p><span class="math display">\[\begin{equation*}
\begin{split}    
\textrm{LRT} &amp;= 2[\max(\log(Lik(\textrm{larger model}))) - \max(\log(Lik(\textrm{reduced model})))] \\
     &amp;= 2\log\left(\frac{\max(Lik(\textrm{larger  model}))}{\max(Lik(\textrm{reduced model}))} \right)
\end{split}
\end{equation*}\]</span></p>
<p>Statistical theory tells us that this statistic follows <span class="math inline">\(\chi^2\)</span> distribution with the difference in number of parameters as its degrees of freedom.</p>
<p>In fact, it can be shown that the drop-in-deviance tests we’ve used for Poisson and logistic regression are special cases of this likelihood ratio test.</p>
<p><strong>AIC and BIC</strong></p>
<p>AIC and BIC are also calculated using the likelihood function.</p>
<ul>
<li><p><span class="math inline">\(\textrm{AIC} = -2 (\textrm{maximum log-likelihood }) + 2p\)</span>, where <span class="math inline">\(p\)</span> represents the number of parameters in the fitted model. AIC stands for Akaike Information Criterion. Because smaller AICs imply better models, we can think of the second term as a penalty for model complexity—the more variables we use, the larger the AIC.</p></li>
<li><p><span class="math inline">\(\textrm{BIC} = -2 (\textrm{maximum log-likelihood }) + p\log(n)\)</span>, where <span class="math inline">\(p\)</span> is the number of parameters and <span class="math inline">\(n\)</span> is the number of observations. BIC stands for Bayesian Information Criterion, also known as Schwarz’s Bayesian criterion (SBC).</p></li>
</ul>
</div>
<div id="summary-maximum-likelihood-estimation" class="section level3 hasAnchor" number="7.3.16">
<h3><span class="header-section-number">7.3.16</span> Summary Maximum Likelihood Estimation<a href="logistic-regression.html#summary-maximum-likelihood-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Maximum likelihood estimation is widely used to estimate parameters in many different kinds of statistical models</p></li>
<li><p>In LLSR, MLE and least-squares procedures yield the same estimates</p></li>
<li><p>Although they can be determined graphically, or using calculus in simple situations, MLE’s are usually approximated using numerical methods</p></li>
<li><p>It’s usually best, for reasons of numerical stability, to maximize the log of the likelihood function, rather than the likelihood function itself</p></li>
<li><p>In this section, we looked at a couple simple examples in logistic regression, but MLE’s are used in all of the models we’ve seen in this course (mixed effects, Poisson regression, etc.) and many more. It is the go-to technique for parameter estimation in classical frequentist statistics (which probably includes all statistics you’ve studied so far)</p></li>
<li><p>Maximum Likelihood estimation is taught in much more mathematical detail in STAT 445.</p></li>
<li><p>An alternative approach to Maximium Likelihood Estimation is Bayesian Estimation, which is taught in STAT 450</p></li>
</ul>
</div>
</div>
<div id="zero-inflated-poisson-model" class="section level2 hasAnchor" number="7.4">
<h2><span class="header-section-number">7.4</span> Zero-Inflated Poisson Model<a href="logistic-regression.html#zero-inflated-poisson-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="case-study-weekend-drinking" class="section level3 hasAnchor" number="7.4.1">
<h3><span class="header-section-number">7.4.1</span> Case Study: Weekend Drinking<a href="logistic-regression.html#case-study-weekend-drinking" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Students in an introductory statistics class at a large university were asked:</p>
<p>“How many alcoholic drinks did you consume last weekend?”.</p>
<p>This survey was conducted on a dry campus where no alcohol is officially allowed, even among students of drinking age, so we expect that some portion of the respondents never drink. The purpose of this survey is to explore factors related to drinking behavior on a dry campus.</p>
<div class="sourceCode" id="cb378"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb378-1"><a href="logistic-regression.html#cb378-1" tabindex="-1"></a><span class="co">#Getting started-weekenddrinks</span></span>
<span id="cb378-2"><a href="logistic-regression.html#cb378-2" tabindex="-1"></a><span class="co"># File: weekendDrinks</span></span>
<span id="cb378-3"><a href="logistic-regression.html#cb378-3" tabindex="-1"></a>drinks <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/proback/BeyondMLR/master/data/weekendDrinks.csv&quot;</span>) </span>
<span id="cb378-4"><a href="logistic-regression.html#cb378-4" tabindex="-1"></a>drinks <span class="ot">&lt;-</span> drinks <span class="sc">%&gt;%</span> </span>
<span id="cb378-5"><a href="logistic-regression.html#cb378-5" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">off.campus=</span><span class="fu">ifelse</span>(dorm<span class="sc">==</span><span class="st">&quot;off campus&quot;</span>,<span class="dv">1</span>,<span class="dv">0</span>), </span>
<span id="cb378-6"><a href="logistic-regression.html#cb378-6" tabindex="-1"></a>         <span class="at">firstYear=</span>dorm<span class="sc">%in%</span><span class="fu">c</span>(<span class="st">&quot;kildahl&quot;</span>,<span class="st">&quot;mohn&quot;</span>,<span class="st">&quot;kittlesby&quot;</span>)) <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span><span class="fu">c</span>(dorm))</span>
<span id="cb378-7"><a href="logistic-regression.html#cb378-7" tabindex="-1"></a><span class="fu">head</span>(drinks)</span></code></pre></div>
<pre><code>##   drinks sex off.campus firstYear
## 1      0   f          0      TRUE
## 2      5   f          0     FALSE
## 3     10   m          0     FALSE
## 4      0   f          0     FALSE
## 5      0   m          0     FALSE
## 6      3   f          0     FALSE</code></pre>
</div>
<div id="questions-of-interest-3" class="section level3 hasAnchor" number="7.4.2">
<h3><span class="header-section-number">7.4.2</span> Questions of Interest<a href="logistic-regression.html#questions-of-interest-3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>What proportion of students on this dry campus never drink?<br />
</li>
<li>Do upper class students drink more than first years?<br />
</li>
<li>What factors, such as off-campus living and sex, are related to whether students drink?<br />
</li>
<li>Among those who do drink, to what extent is moving off campus associated with the number of drinks in a weekend?<br />
</li>
<li>It is commonly assumed that males’ alcohol consumption is greater than females’; is this true on this campus?</li>
</ul>
</div>
<div id="distribution-of-number-of-drinks" class="section level3 hasAnchor" number="7.4.3">
<h3><span class="header-section-number">7.4.3</span> Distribution of Number of Drinks<a href="logistic-regression.html#distribution-of-number-of-drinks" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="logistic-regression.html#cb380-1" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>drinks, <span class="fu">aes</span>(<span class="at">x=</span>drinks)) <span class="sc">+</span> <span class="fu">geom_histogram</span>() <span class="sc">+</span> <span class="fu">facet_wrap</span>(<span class="sc">~</span>firstYear)</span></code></pre></div>
<p><img src="Stat-455-Notes_files/figure-html/unnamed-chunk-240-1.png" width="576" /></p>
<div class="sourceCode" id="cb381"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb381-1"><a href="logistic-regression.html#cb381-1" tabindex="-1"></a>drinks <span class="sc">%&gt;%</span> <span class="fu">group_by</span>(firstYear) <span class="sc">%&gt;%</span> <span class="fu">summarize</span>(<span class="at">mean_drinks=</span><span class="fu">mean</span>(drinks), </span>
<span id="cb381-2"><a href="logistic-regression.html#cb381-2" tabindex="-1"></a>                                             <span class="at">prop_zero =</span> <span class="fu">mean</span>(drinks<span class="sc">==</span><span class="dv">0</span>), </span>
<span id="cb381-3"><a href="logistic-regression.html#cb381-3" tabindex="-1"></a>                                             <span class="at">n=</span><span class="fu">n</span>())</span></code></pre></div>
<pre><code>## # A tibble: 2 × 4
##   firstYear mean_drinks prop_zero     n
##   &lt;lgl&gt;           &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;
## 1 FALSE           2.41      0.407    59
## 2 TRUE            0.722     0.667    18</code></pre>
</div>
<div id="number-of-drinks-comparisons" class="section level3 hasAnchor" number="7.4.4">
<h3><span class="header-section-number">7.4.4</span> Number of Drinks Comparisons<a href="logistic-regression.html#number-of-drinks-comparisons" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb383"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb383-1"><a href="logistic-regression.html#cb383-1" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> drinks) <span class="sc">+</span> </span>
<span id="cb383-2"><a href="logistic-regression.html#cb383-2" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> drinks)) <span class="sc">+</span> <span class="fu">facet_wrap</span>(<span class="sc">~</span>firstYear, <span class="at">nrow=</span><span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb383-3"><a href="logistic-regression.html#cb383-3" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Drinking by First Year Status&quot;</span>) </span>
<span id="cb383-4"><a href="logistic-regression.html#cb383-4" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> drinks) <span class="sc">+</span> </span>
<span id="cb383-5"><a href="logistic-regression.html#cb383-5" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> drinks)) <span class="sc">+</span> <span class="fu">facet_wrap</span>(<span class="sc">~</span>sex, <span class="at">nrow=</span><span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb383-6"><a href="logistic-regression.html#cb383-6" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Drinks by Sex&quot;</span>) </span>
<span id="cb383-7"><a href="logistic-regression.html#cb383-7" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> drinks) <span class="sc">+</span> </span>
<span id="cb383-8"><a href="logistic-regression.html#cb383-8" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> drinks)) <span class="sc">+</span> <span class="fu">facet_wrap</span>(<span class="sc">~</span>off.campus, <span class="at">nrow=</span><span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb383-9"><a href="logistic-regression.html#cb383-9" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Drinking by On/Off Campus&quot;</span>) </span>
<span id="cb383-10"><a href="logistic-regression.html#cb383-10" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1, p2, p3, <span class="at">nrow=</span><span class="dv">1</span>)</span></code></pre></div>
<p><img src="Stat-455-Notes_files/figure-html/unnamed-chunk-242-1.png" width="960" /></p>
</div>
<div id="proportion-of-drinkers" class="section level3 hasAnchor" number="7.4.5">
<h3><span class="header-section-number">7.4.5</span> Proportion of Drinkers<a href="logistic-regression.html#proportion-of-drinkers" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now, we compare proportions of students who reported drinking any drinks.</p>
<p>Drinks by First-Year Status:</p>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb384-1"><a href="logistic-regression.html#cb384-1" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> drinks) <span class="sc">+</span> </span>
<span id="cb384-2"><a href="logistic-regression.html#cb384-2" tabindex="-1"></a>  <span class="fu">stat_count</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> firstYear, <span class="at">fill=</span>drinks<span class="sc">&gt;</span><span class="dv">0</span>), <span class="at">position=</span><span class="st">&quot;fill&quot;</span> ) <span class="sc">+</span> </span>
<span id="cb384-3"><a href="logistic-regression.html#cb384-3" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Drinking by First Year Status&quot;</span>) </span>
<span id="cb384-4"><a href="logistic-regression.html#cb384-4" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> drinks) <span class="sc">+</span> </span>
<span id="cb384-5"><a href="logistic-regression.html#cb384-5" tabindex="-1"></a>  <span class="fu">stat_count</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> sex, <span class="at">fill=</span>drinks<span class="sc">&gt;</span><span class="dv">0</span>), <span class="at">position=</span><span class="st">&quot;fill&quot;</span> ) <span class="sc">+</span> </span>
<span id="cb384-6"><a href="logistic-regression.html#cb384-6" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Drinking by Sex&quot;</span>) </span>
<span id="cb384-7"><a href="logistic-regression.html#cb384-7" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> drinks) <span class="sc">+</span> </span>
<span id="cb384-8"><a href="logistic-regression.html#cb384-8" tabindex="-1"></a>  <span class="fu">stat_count</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> off.campus, <span class="at">fill=</span>drinks<span class="sc">&gt;</span><span class="dv">0</span>), <span class="at">position=</span><span class="st">&quot;fill&quot;</span> ) <span class="sc">+</span> </span>
<span id="cb384-9"><a href="logistic-regression.html#cb384-9" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Drinking by On/Off Campus&quot;</span>) </span>
<span id="cb384-10"><a href="logistic-regression.html#cb384-10" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1, p2, p3, <span class="at">nrow=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="Stat-455-Notes_files/figure-html/unnamed-chunk-243-1.png" width="960" /></p>
</div>
<div id="modeling-drinks" class="section level3 hasAnchor" number="7.4.6">
<h3><span class="header-section-number">7.4.6</span> Modeling Drinks<a href="logistic-regression.html#modeling-drinks" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A Poisson distribution seems like a good choice for modeling drinks, since they are a count, and there is no fixed number of “attempts”, as in a binomial distribution.</p>
<p><img src="Stat-455-Notes_files/figure-html/unnamed-chunk-244-1.png" width="960" /></p>
<p>Expected Proportion of Zeros:</p>
<div class="sourceCode" id="cb385"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb385-1"><a href="logistic-regression.html#cb385-1" tabindex="-1"></a><span class="fu">dpois</span>(<span class="dv">0</span>, <span class="fl">2.41</span>)</span></code></pre></div>
<pre><code>## [1] 0.08981529</code></pre>
<div class="sourceCode" id="cb387"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb387-1"><a href="logistic-regression.html#cb387-1" tabindex="-1"></a><span class="fu">dpois</span>(<span class="dv">0</span>, <span class="fl">0.72</span>)</span></code></pre></div>
<pre><code>## [1] 0.4867523</code></pre>
<p>The proportion of zeros in our data is much higher than expected under a Poisson model with means equal to those observed in the data. (0.41 compared to 0.09 for upperclass students and 0.67, compared to 0.49 for first-years).</p>
</div>
<div id="explaining-the-large-number-of-zeros" class="section level3 hasAnchor" number="7.4.7">
<h3><span class="header-section-number">7.4.7</span> Explaining the Large Number of Zeros<a href="logistic-regression.html#explaining-the-large-number-of-zeros" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The students who reported 0 drinks will fall into one of two categories:</p>
<ol style="list-style-type: decimal">
<li>Students who do not drink at all.<br />
</li>
<li>Students who do drink, but did not drink last weekend.</li>
</ol>
<p>Our data consist of a <strong>mixture</strong> of responses from these two different populations.</p>
<p>Among students who do drink, it is reasonable to model the number of drinks consumed on a given weekend using a Poisson distribution</p>
<p>Among students who do not drink at all, there is no need to model the number of drinks in a given weekend, since we know it’s zero.</p>
<p>Ideally, we’d like to sort out the non-drinkers and drinkers when performing our analysis.</p>
<p>Answering these questions would be a simple matter if we knew who was and was not a drinker in our sample. Unfortunately, the non-drinkers did not identify themselves as such, so we will need to use the data available with a model that allows us to estimate the proportion of drinkers and non-drinkers.</p>
</div>
<div id="zero-inflated-poisson-model-1" class="section level3 hasAnchor" number="7.4.8">
<h3><span class="header-section-number">7.4.8</span> Zero-Inflated Poisson Model<a href="logistic-regression.html#zero-inflated-poisson-model-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We’ll fit the model in two steps:</p>
<ol style="list-style-type: decimal">
<li>Estimate the probability that a person drinks at all, given information contained in the explanatory variables.<br />
</li>
<li>Model the number of drinks consumed in a given weekend, assuming the person does drink at all.</li>
</ol>
<p>In step 1, we use logistic regression to estimate <span class="math inline">\(p\)</span>, the probability that the person does not drink at all.</p>
<p>In step 2, we use a Poisson regression to estimate <span class="math inline">\(\lambda\)</span>, the expected number of drinks a person consumes, assumping they drink at all.</p>
</div>
<div id="developing-the-zero-inflated-poisson-model" class="section level3 hasAnchor" number="7.4.9">
<h3><span class="header-section-number">7.4.9</span> Developing the Zero-Inflated Poisson Model<a href="logistic-regression.html#developing-the-zero-inflated-poisson-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let</p>
<p><span class="math display">\[ \begin{cases}
     1 &amp; \text{if student i drinks at all} \\
      0 &amp; \text{if student i does not drink}
   \end{cases}
\]</span></p>
<p>First, we model <span class="math inline">\(D_i\)</span>:</p>
<p><span class="math display">\[D_i\sim\text{Ber}(p_i)
\]</span></p>
<p>and then <span class="math inline">\(Y_{i}\)</span></p>
<p><span class="math display">\[ \begin{cases}
     Y_i\sim\text{Pois}(\lambda_i) &amp; \text{if } D_i=1 \\
     Y_i=0 &amp; \text{if } D_i=0
   \end{cases}
\]</span></p>
<p>The variable <span class="math inline">\(D_i\)</span> is called a <strong>latent variable</strong>. It is a variable that is relevant to the process we are interested in studying, but is not directly measured or reported in our data.</p>
<p>The Zero-Inflated Poisson is an example of a <strong>mixture model</strong>, as the response variable is modeled using a mixture of Bernoulli and Poisson distributions.</p>
<p>Let <span class="math inline">\(p_i\)</span> represent <span class="math inline">\(P(D_i=0)\)</span>, the probability that person person does not drink.</p>
</div>
<div id="deriving-the-zip-pmf" class="section level3 hasAnchor" number="7.4.10">
<h3><span class="header-section-number">7.4.10</span> Deriving the ZIP PMF<a href="logistic-regression.html#deriving-the-zip-pmf" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We derive the probability mass function for the Poisson model by considering the two different ways we can observe count <span class="math inline">\(y\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
P(Y=0) &amp;= P(\text{Person Doesn&#39;t Drink at All}) + P(\text{Person drinks and didn&#39;t drink last week})\\
&amp; = P(\text{Person Doesn&#39;t Drink at All}) + P(\text{0 drinks in a given weekend given person drinks})P(\text{Person drinks}) \\
&amp; = P(D_i=0) + P(Y_i=0|D_i=1)P(D_i=1) \\
&amp; = p_i + \frac{\lambda_i^0e^{-\lambda_i}}{0!}(1-p) \\
&amp; = p_i + e^{-\lambda_i}(1-p_i)
\end{aligned}
\]</span></p>
<p>For <span class="math inline">\(y\neq 0\)</span>,</p>
<p><span class="math display">\[
\begin{aligned}
P(Y=y) &amp;= P(\text{Person drinks and drinks y drinks in a weekend})\\
&amp; =  P(\text{y drinks in a given weekend given person drinks})P(\text{Person drinks}) \\
&amp; = P(Y_i=y|D_i=1)P(D_i=1) \\
&amp; =  \frac{\lambda_i^ye^{-\lambda_i}}{y!}(1-p)
\end{aligned}
\]</span></p>
<p>Putting these together, we get the ZIP probability mass function:</p>
<p><span class="math display">\[ P(Y=y) = \begin{cases}
     p_i + e^{-\lambda_i}(1-p_i) &amp; \text{if } y=0 \\
     \frac{\lambda_i^ye^{-\lambda_i}}{y!}(1-p_i) &amp; \text{if } y&gt;0
   \end{cases}
\]</span></p>
</div>
<div id="examples-of-zip-pmfs" class="section level3 hasAnchor" number="7.4.11">
<h3><span class="header-section-number">7.4.11</span> Examples of ZIP PMF’s<a href="logistic-regression.html#examples-of-zip-pmfs" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="Stat-455-Notes_files/figure-html/unnamed-chunk-247-1.png" width="960" /></p>
<p>Mean: (<span class="math inline">\((1-p)\lambda\)</span>)</p>
<p>Variance: (<span class="math inline">\((1-p)\lambda(1+p\lambda)\)</span>)</p>
</div>
<div id="zip-model" class="section level3 hasAnchor" number="7.4.12">
<h3><span class="header-section-number">7.4.12</span> ZIP Model<a href="logistic-regression.html#zip-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We assume</p>
<p><span class="math display">\[
Y_i \sim\text{ZIP}(p_i, \lambda_i)
\]</span></p>
<p><span class="math inline">\(p_i\)</span> represents the probability that student <span class="math inline">\(i\)</span> drinks at all.<br />
<span class="math inline">\(\lambda_i\)</span> represents the average number of drinks student <span class="math inline">\(i\)</span> consumes in a weekend, assuming they do drink at all.</p>
<p>We want to estimate <span class="math inline">\(p_i\)</span> and <span class="math inline">\(\lambda_i\)</span>, using information contained in the explanatory variables.</p>
<p>We can use different explanatory variables to estimate <span class="math inline">\(p_i\)</span> and <span class="math inline">\(\lambda_i\)</span>.</p>
<p>Let <span class="math inline">\(Z_{1}, Z_2, \ldots, Z_p&#39;\)</span> be the explanatory variables used to estimate <span class="math inline">\(p\)</span>, and <span class="math inline">\(X_1, X_2, \ldots, X_p\)</span> be the explanatory variables used to estimate <span class="math inline">\(\lambda\)</span></p>
<p>We link <span class="math inline">\(p_i\)</span> and <span class="math inline">\(\lambda_i\)</span> to a linear combination of the explanatory variables, using the link functions:</p>
<p><span class="math display">\[
log(\lambda_i) = \beta_0+\beta_1X_{i1}+ \ldots +\beta_pX_{ip},
\]</span></p>
<p><span class="math display">\[
log\left(\frac{p_i}{1-p_i}\right) = \alpha_0+\alpha_1Z_{i1}+ \ldots +\alpha_pZ_{ip&#39;},
\]</span></p>
<p>We obtain estimates of <span class="math inline">\(\beta_0, \ldots{\beta_p}\)</span> and <span class="math inline">\(\alpha_0, \ldots, \alpha_p\)</span>, and from these obtain maximum likelihood etimates for <span class="math inline">\(p_i\)</span> and <span class="math inline">\(\lambda_i\)</span>.</p>
</div>
</div>
<div id="model-for-drinks-data" class="section level2 hasAnchor" number="7.5">
<h2><span class="header-section-number">7.5</span> Model for Drinks Data<a href="logistic-regression.html#model-for-drinks-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="zip-for-drinks-data" class="section level3 hasAnchor" number="7.5.1">
<h3><span class="header-section-number">7.5.1</span> ZIP for Drinks Data<a href="logistic-regression.html#zip-for-drinks-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A zero-inflated Poisson regression model to take non-drinkers into account consists of two parts:</p>
<ul>
<li>One part models the association, among drinkers, between number of drinks and the predictors of sex and off-campus residence.</li>
<li>The other part uses a predictor for first-year status to obtain an estimate of the proportion of non-drinkers based on the reported zeros.</li>
</ul>
<p>The form for each part of the model follows. The first part looks like an ordinary Poisson regression model:</p>
<p><span class="math display">\[
log(\lambda_i)=\beta_0+\beta_1\textrm{off.campus}_i+ \beta_2\textrm{sex}_i
\]</span>
where <span class="math inline">\(\lambda\)</span> is the mean number of drinks in a weekend <em>among those who drink</em>.
The second part has the form</p>
<p><span class="math display">\[
logit(p_i)=\alpha_0+\alpha_1\textrm{firstYear}_i
\]</span>
where <span class="math inline">\(\alpha\)</span> is the probability of being in the non-drinkers group and <span class="math inline">\(logit(p_i) = log( p_i/(1-p_i))\)</span>.</p>
</div>
<div id="zip-model-in-r" class="section level3 hasAnchor" number="7.5.2">
<h3><span class="header-section-number">7.5.2</span> ZIP Model in R<a href="logistic-regression.html#zip-model-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We will use the R function <code>zeroinfl</code> from the package <code>pscl</code> to fit a ZIP model. The terms before the <code>|</code> are used to model expected number of drinks, assuming the person really does drink at all.</p>
<p>The terms after the <code>|</code> are used to estimate the probability that the person drinks at all.</p>
<div class="sourceCode" id="cb389"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb389-1"><a href="logistic-regression.html#cb389-1" tabindex="-1"></a>zip.m <span class="ot">&lt;-</span> <span class="fu">zeroinfl</span>(drinks <span class="sc">~</span> off.campus <span class="sc">+</span> sex <span class="sc">|</span> firstYear, </span>
<span id="cb389-2"><a href="logistic-regression.html#cb389-2" tabindex="-1"></a>                   <span class="at">data =</span> drinks)</span>
<span id="cb389-3"><a href="logistic-regression.html#cb389-3" tabindex="-1"></a><span class="fu">summary</span>(zip.m)</span></code></pre></div>
<pre><code>
Call:
zeroinfl(formula = drinks ~ off.campus + sex | firstYear, data = drinks)

Pearson residuals:
    Min      1Q  Median      3Q     Max 
-1.1118 -0.8858 -0.5290  0.6367  5.2996 

Count model coefficients (poisson with log link):
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   0.7543     0.1440   5.238 1.62e-07 ***
off.campus    0.4159     0.2059   2.020   0.0433 *  
sexm          1.0209     0.1752   5.827 5.63e-09 ***

Zero-inflation model coefficients (binomial with logit link):
              Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)    -0.6036     0.3114  -1.938   0.0526 .
firstYearTRUE   1.1364     0.6095   1.864   0.0623 .
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 

Number of iterations in BFGS optimization: 8 
Log-likelihood: -140.8 on 5 Df</code></pre>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb391-1"><a href="logistic-regression.html#cb391-1" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">coef</span>(zip.m))   <span class="co"># exponentiated coefficients</span></span></code></pre></div>
<pre><code>##  count_(Intercept)   count_off.campus         count_sexm   zero_(Intercept) 
##          2.1260699          1.5157953          2.7756910          0.5468311 
## zero_firstYearTRUE 
##          3.1154950</code></pre>
<p><strong>Interpretations</strong></p>
<ul>
<li><p>For those who drink, the average number of drinks for males is <span class="math inline">\(e^{1.0209}\)</span> or 2.76 times the number for females (Z = 5.827, p &lt; 0.001) given that you are comparing people who live in comparable settings (on or off campus)</p></li>
<li><p>Among drinkers, the mean number of drinks for students living off campus is <span class="math inline">\(e^{0.4159}=1.52\)</span> times that of students living on campus for those of the same sex (Z = 2.021, p = 0.0433).</p></li>
<li><p>The odds that a first-year student is a non-drinker are 3.12 times the odds that an upper-class student is a non-drinker.</p></li>
<li><p>The estimated probability that a first-year student is a non-drinker is</p></li>
</ul>
<p><span class="math display">\[
\frac{e^{0.533}}{1+e^{0.533}} = 0.630
\]</span></p>
<p>or 63.0%, while for non-first-year students, the estimated probability of being a non-drinker is 0.354.</p>
</div>
<div id="residual-plot" class="section level3 hasAnchor" number="7.5.3">
<h3><span class="header-section-number">7.5.3</span> Residual Plot<a href="logistic-regression.html#residual-plot" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Fitted values (<span class="math inline">\(\hat{y}\)</span>) and residuals (<span class="math inline">\(y-\hat{y}\)</span>) can be computed for zero-inflation models and plotted. Figure <a href="logistic-regression.html#fig:poisRes">7.1</a> reveals that one observation appears to be extreme (Y=22 drinks during the past weekend). Is this a legitimate observation or was there a transcribing error? Without the original respondents, we cannot settle this question. It might be worthwhile to get a sense of how influential this extreme observation is by removing Y=22 and refitting the model.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:poisRes"></span>
<img src="Stat-455-Notes_files/figure-html/poisRes-1.png" alt="Residuals by fitted counts for ZIP model." width="60%" />
<p class="caption">
Figure 7.1: Residuals by fitted counts for ZIP model.
</p>
</div>
</div>
<div id="limitations" class="section level3 hasAnchor" number="7.5.4">
<h3><span class="header-section-number">7.5.4</span> Limitations<a href="logistic-regression.html#limitations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are several concerns and limitations we should think about related to this study.</p>
<p>What time period constitutes the “weekend”?</p>
<p>What constitutes a drink—a bottle of beer?</p>
<p>How many drinks will a respondent report for a bottle of wine?</p>
<p>There is also an issue related to confidentiality. If the data is collected in class, will the teacher be able to identify the respondent? Will respondents worry that a particular response will affect their grade in the class or lead to repercussions on a dry campus?</p>
<p>In addition to these concerns, there are a number of other limitations that should be noted. Following the concern of whether this data represents a random sample of any population (it doesn’t), we also must be concerned with the size of this data set (77). ZIP models are not appropriate for small samples and this data set is not impressively large.</p>
</div>
<div id="final-thoughts-on-zero-inflated-models" class="section level3 hasAnchor" number="7.5.5">
<h3><span class="header-section-number">7.5.5</span> Final Thoughts on Zero-Inflated Models<a href="logistic-regression.html#final-thoughts-on-zero-inflated-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>At times, a mixture of zeros occurs naturally. It may not come about because of neglecting to ask a critical question on a survey, but the information about the subpopulation may simply not be ascertainable. For example, visitors from a state park were asked as they departed how many fish they caught, but those who report 0 could be either non-fishers or fishers who had bad luck. These kinds of circumstances occur often enough that ZIP models are becoming increasingly common.</p>
<p>Actually, applications which extend beyond ordinary Poisson regression applications—ZIPs and other Poisson modeling approaches such as hurdle models and quasi-Poisson applications—are becoming increasingly common. So it is worth taking a look at these variations of Poisson regression models. Here we have only skimmed the surface of zero-inflated models, but we want you to be aware of models of this type. ZIP models demonstrate that modeling can be flexible and creative—a theme we hope you will see throughout this book.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="poisson-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multilevel-generalized-linear-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/STAT455-W22/stat455-w22-notes/edit/master/07-Logistic_Regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/STAT455-W22/stat455-w22-notes/blob/master/07-Logistic_Regression.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
