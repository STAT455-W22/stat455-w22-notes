[["index.html", "Stat 455: Advanced Statistical Modeling Notes Preface", " Stat 455: Advanced Statistical Modeling Notes 2023-04-16 Preface These notes are written to accompany the text Beyond Multiple Linear Regression by Roback and Legler. Much of the text is either directly from the book, or lightly modified/summarized. Most of the code originates from the book’s Github repository. These notes will guide our lectures and class discussion, but they are not sufficient as a stand-alone reference. It is important to complete the reading assignments from the full text by Roback and Legler in addition to studying these notes. This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["review-of-multiple-linear-regression.html", "Chapter 1 Review of Multiple Linear Regression 1.1 Exploratory Data Analysis 1.2 Simple Linear Regression Model 1.3 Multiple Linear Regression with Two Predictors 1.4 Building a Multiple Linear Regression Model", " Chapter 1 Review of Multiple Linear Regression This chapter provides an outline of Sections 1.4-1.7 of Beyond Multiple Linear Regression by Roback and Legler. Much of the text is either directly from the book, or lightly modified/summarized. Most of the code originates from the book’s Github repository. knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, fig.height = 3, fig.width = 6) # Packages required for Chapter 1 library(knitr) library(gridExtra) library(GGally) library(kableExtra) library(jtools) library(rsample) library(broom) library(tidyverse) library(ggformula) 1.1 Exploratory Data Analysis 1.1.1 Kentucky Derby Data We use data from the Kentucky Derby, a 1.25 mile race run annually at Churchill Downs race track in Louisville, Kentucky. Our data set derbyplus.csv contains data from 1896-2017, and includes the following variables: year of the race, winning horse (winner), condition of the track (fast, good, slow) , average speed (in feet per second) of the winner, number of starters (horses who raced) We would like to use least squares linear regression techniques to model the speed of the winning horse as a function of track condition, field size, and trends over time. derby.df &lt;- read.csv(&quot;https://raw.githubusercontent.com/proback/BeyondMLR/master/data/derbyplus.csv&quot;) head(derby.df) ## year winner condition speed starters ## 1 1896 Ben Brush good 51.66 8 ## 2 1897 Typhoon II slow 49.81 6 ## 3 1898 Plaudit good 51.16 4 ## 4 1899 Manuel fast 50.00 5 ## 5 1900 Lieut. Gibson fast 52.28 7 ## 6 1901 His Eminence fast 51.66 5 1.1.2 Some Data Wrangling We modify the data to create: * indicator (0-1) variables for whether the track was in fast or good condition * a factor variable (fastfactor) telling whether or not the track was fast * a variable giving years since 1896 (yearnew) derby.df &lt;- derby.df %&gt;% mutate( fast = ifelse(condition==&quot;fast&quot;,1,0), good = ifelse(condition==&quot;good&quot;,1,0), yearnew = year - 1896, fastfactor = ifelse(fast == 0, &quot;not fast&quot;, &quot;fast&quot;)) table1 &lt;- derby.df %&gt;% filter(row_number() &lt; 6 | row_number() &gt; 117) kable(table1, booktabs=T,caption=&quot;The first five and the last five observations from the Kentucky Derby case study.&quot;) %&gt;% kable_styling(latex_options = &quot;scale_down&quot;) Table 1.1: The first five and the last five observations from the Kentucky Derby case study. year winner condition speed starters fast good yearnew fastfactor 1896 Ben Brush good 51.66 8 0 1 0 not fast 1897 Typhoon II slow 49.81 6 0 0 1 not fast 1898 Plaudit good 51.16 4 0 1 2 not fast 1899 Manuel fast 50.00 5 1 0 3 fast 1900 Lieut. Gibson fast 52.28 7 1 0 4 fast 2013 Orb slow 53.71 19 0 0 117 not fast 2014 California Chrome fast 53.37 19 1 0 118 fast 2015 American Pharoah fast 53.65 18 1 0 119 fast 2016 Nyquist fast 54.41 20 1 0 120 fast 2017 Always Dreaming fast 53.40 20 1 0 121 fast 1.1.3 Univariate Graphical Summaries Distributions of winning speeds and number of starters # EDA graphs speed_hist &lt;- ggplot(data = derby.df, aes(x = speed)) + geom_histogram(binwidth = 0.5, fill = &quot;white&quot;, color = &quot;black&quot;) + xlab(&quot;Winning speed (ft/s)&quot;) + ylab(&quot;Frequency&quot;) + labs(title=&quot;(a)&quot;) starters_hist &lt;- ggplot(data = derby.df, aes(x = starters)) + geom_histogram(binwidth = 3, fill = &quot;white&quot;, color = &quot;black&quot;) + xlab(&quot;Number of starters&quot;) + ylab(&quot;Frequency&quot;) + labs(title=&quot;(b)&quot;) grid.arrange(speed_hist, starters_hist, ncol = 2) Figure 1.1: Histograms of key continuous variables. Plot (a) shows winning speeds, while plot (b) shows the number of starters. 1.1.4 Bivariate Graphical Summaries The ggpairs function creates a scatterplot matrix displaying relationships between all pairs of variables. gg &lt;- ggpairs(data = derby.df, columns = c(&quot;condition&quot;, &quot;year&quot;, &quot;starters&quot;, &quot;speed&quot;)) gg Figure 1.2: Relationships between pairs of variables in the Kentucky Derby data set. We see evidence of higher speeds on fast tracks and also a tendency for recent years to have more fast conditions. We examine how winning speeds have changed over time, when the track is fast and when it is not fast. # Coded scatterplot ggplot(derby.df, aes(x = year, y = speed, colour = fastfactor)) + geom_point(aes(shape = fastfactor)) + geom_smooth(aes(linetype = fastfactor), method = lm, se = FALSE) Figure 1.3: Linear trends in winning speeds over time, presented separately for fast conditions vs. good or slow conditions. It appears that winning speeds have increased more rapidly for tracks that are not fast. This suggests an interaction between year and track condition, since the relationship between speed and year appears to differ depending on whether or not the track was fast. 1.2 Simple Linear Regression Model 1.2.1 Model for Winning Time and Year We begin with a simple linear regression model for winning speed (\\(Y\\)), using year since 1896 as the explanatory variable. This model has the form: \\[\\begin{equation} Y_{i}=\\beta_{0}+\\beta_{1}\\textrm{Yearnew}_{i}+\\epsilon_{i} \\quad \\textrm{where} \\quad \\epsilon_{i}\\sim \\textrm{N}(0,\\sigma^2). \\end{equation}\\] We obtain estimates of \\(\\beta_0\\) and \\(\\beta_1\\), denoted (\\(\\hat{\\beta_0}\\) and \\(\\hat{\\beta_1}\\)) by minimizing the sum of squared residuals \\(SSR=\\displaystyle\\sum_{i=1}^{n}\\left(Y_i- (\\beta_{0}+\\beta_{1}\\textrm{Yearnew}_{i})\\right)^2.\\) 1.2.2 First Model R Output We fit the model in R. model2 &lt;- lm(speed ~ yearnew, data = derby.df) coef(summary(model2)) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 51.58839264 0.162549197 317.37095 2.474501e-177 ## yearnew 0.02612601 0.002322013 11.25145 1.716806e-20 cat(&quot; R squared = &quot;, summary(model2)$r.squared, &quot;\\n&quot;, &quot;Residual standard error = &quot;, summary(model2)$sigma) ## R squared = 0.5133724 ## Residual standard error = 0.9032317 Interpretations: The expected winning speed in 1896 is 51.59 ft/s. Winning speed is expected to increase by 0.026 ft./s on average for each year since 1896. The low p-value provides evidence that average winning speed has increased over time. 51% of the total variability in winning speed is explained by the simple linear regression model with year since 1896 as the explanatory variable. We estimate that the error standard deviation \\(\\sigma\\) is 0.90. 1.2.3 Checking Model Assumptions # Residual diagnostics for Model 2 par(mar=c(4,4,4,4)) par(mfrow=c(2,2)) plot(model2) Figure 1.4: Residual plots for Model 2. par(mfrow=c(1,1)) The residual plots help tell us what trends/relationships our model is missing, or leaving unexplained. The upper left plot, Residuals vs. Fitted, can be used to check the Linearity assumption. Residuals should be patternless around Y = 0; if not, there is a pattern in the data that is currently unaccounted for. The upper right plot, Normal Q-Q, can be used to check the Normality assumption. Deviations from a straight line indicate that the distribution of residuals does not conform to a theoretical normal curve. The lower left plot, Scale-Location, can be used to check the Equal Variance assumption. Positive or negative trends across the fitted values indicate variability that is not constant. The lower right plot, Residuals vs. Leverage, can be used to check for influential points. Points with high leverage (having unusual values of the predictors) and/or high absolute residuals can have an undue influence on estimates of model parameters. There is typically no residual plot, to evaluate the Independence assumption. Evidence for lack of independence comes from knowing about the study design and methods of data collection. In this case, with a new field of horses each year, the assumption of independence is pretty reasonable. In this case, the Residuals vs. Fitted plot indicates that a quadratic fit might be better than the linear fit of Model 2; other assumptions look reasonable. 1.2.4 Quadratic Term for Year Let’s add a quadratic term to the model \\[\\begin{equation*} Y_{i}=\\beta_{0}+\\beta_{1}\\textrm{Yearnew}_{i}+\\beta_{2}\\textrm{Yearnew}^2_{i}+\\epsilon_{i}\\quad \\textrm{where}\\quad \\epsilon_{i}\\sim \\textrm{N}(0,\\sigma^2). \\end{equation*}\\] 1.2.5 Quadratic Model in R derby.df &lt;- mutate(derby.df, yearnew2 = yearnew^2) model2q &lt;- lm(speed ~ yearnew + yearnew2, data = derby.df) coef(summary(model2q)) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 50.5874565658 2.081705e-01 243.009695 2.615174e-162 ## yearnew 0.0761728163 7.950413e-03 9.580989 1.838874e-16 ## yearnew2 -0.0004136099 6.358703e-05 -6.504628 1.920684e-09 cat(&quot; R squared = &quot;, summary(model2q)$r.squared, &quot;\\n&quot;, &quot;Residual standard error = &quot;, summary(model2q)$sigma) ## R squared = 0.6410103 ## Residual standard error = 0.7790385 # Fitted models for Model 2 and Model 2Q ggplot(derby.df, aes(x = year, y = speed)) + geom_point() + stat_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, linetype = 1) + stat_smooth(method = &quot;lm&quot;, formula = y ~ x + I(x^2), se = FALSE, linetype = 2) Figure 1.5: Linear (solid) vs. quadratic (dashed) fit. This model suggests that the rate of increase in winning speeds is slowing down over time. The low p-value on the quadratic term provides evidence that there is indeed a quadratic relationship between speed and year (as opposed to a linear one). Furthermore, the proportion of variation in winning speeds explained by the model has increased from 51.3% to 64.1%. 1.2.6 Quadratic Model Residual Plots # Residual diagnostics for Model 2 par(mar=c(4,4,4,4)) par(mfrow=c(2,2)) plot(model2q) Figure 1.6: Residual plots for Model 2Q. par(mfrow=c(1,1)) The quadratic trend in the residual vs fitted plot has disappeared, as the quadratic relationship is now explained in our model. 1.3 Multiple Linear Regression with Two Predictors 1.3.1 Model with Year and Fast Track We add an indicator variable for whether or not the track is fast in our model. Note that the text writes an indicator using the name of the 0-1 categorical variable, as opposed to the \\(\\text{I}_{\\text{Fast}}\\) notation I used in STAT 255. \\[ \\begin{equation} Y_{i}=\\beta_{0}+\\beta_{1}\\textrm{Yearnew}_{i}+\\beta_{2}\\textrm{Fast}_{i}+\\epsilon_{i}\\quad \\textrm{where}\\quad \\epsilon_{i}\\sim \\textrm{N}(0,\\sigma^2). \\end{equation} \\] 1.3.2 Multiple Regression Model in R model4 &lt;- lm(speed ~ yearnew + fast, data = derby.df) coef(summary(model4)) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 50.91782155 0.154601703 329.348388 5.360308e-178 ## yearnew 0.02258276 0.001918849 11.768907 1.116763e-21 ## fast 1.22684588 0.150721259 8.139833 4.393084e-13 cat(&quot; R squared = &quot;, summary(model4)$r.squared, &quot;\\n&quot;, &quot;Residual standard error = &quot;, summary(model4)$sigma) ## R squared = 0.6874141 ## Residual standard error = 0.7269468 Interpretations: winning speeds are, on average, 1.23 ft/s faster under fast conditions after accounting for time trends (i.e. assuming year is held constant). The low p-value provides evidence that winning speeds increase over time, after accounting for track condition. winning speeds are expected to increase by 0.023 ft/s per year, after accounting for track condition. The low p-value provides evidence that winning speeds are faster when the track is in fast condition, after accounting for year. This yearly effect is also smaller than the 0.026 ft/s per year we estimated the previous model, that did not account for track condition. The single-variable model appears to have slightly overestimated the average increase in speed. This is probably because track conditions have also improved over time (due to improvements in track maintenence). The single variable model cannot distinguish between improvements in track conditions and improvements in speed of the horses. The multiple regression model can estimate these effects separately. Based on the \\(R^2\\) value, Model 4 explains 68.7% of the year-to-year variability in winning speeds, a noticeable increase over using either explanatory variable alone. 1.3.3 Confidence Intervals from MLR Model Confidence Intervals for \\(\\beta_0, \\beta_1, \\beta_2\\). Under LINE assumptions, a confidence interval for \\(\\beta_j\\) is given by \\(\\hat{\\beta_j} \\pm t_{(n-p), (1-\\alpha/2)}^* \\text{SE}(\\beta_j)\\), where \\(t_{(n-p), (1-\\alpha/2)}^*\\) represents the \\((1-\\alpha/2)\\) quantile of a t-distribution with \\(n-p\\) degrees of freedom, \\(\\alpha\\) represents the level of significance (e.g. 0.05 for a 95% CI), and \\(p\\) represents the number of parameters \\(\\beta_0, \\beta_1, \\ldots...\\) confint(model4) ## 2.5 % 97.5 % ## (Intercept) 50.61169473 51.22394836 ## yearnew 0.01878324 0.02638227 ## fast 0.92840273 1.52528902 Interpretations: We can be 95% confident that average winning speeds increase between 0.019 and 0.026 ft/s each year, after accounting for track condition. We can be 95% confident that average winning speeds under fast conditions are between 0.93 and 1.53 ft/s higher than under non-fast conditions, after accounting for the effect of year. To make a prediction for a new case, such as the winning speed in 2017, we use a prediction interval: new.data &lt;- data.frame(yearnew = 2017 - 1896, fast = 1) predict(model4, new = new.data, interval = &quot;prediction&quot;) fit lwr upr 1 54.87718 53.4143 56.34006 Based on our model, we can be 95% confident that the winning speed in 2017 under fast conditions will be between 53.4 and 56.3 ft/s. Note that Always Dreaming’s actual winning speed (53.40) barely fit within this interval—the 2017 winning speed was a borderline outlier on the slow side. If we wanted to estimate the average value of Y among all cases with the given explanatory variable values, we would use interval=\"confidence\". This doesn’t really make sense in this context, since there is only one winning speed each year. 1.3.4 Slopes for Fast, non-Fast Tracks In model4, we assume that the expected rate of change in winning speed over time is the same, regardless of whether the track is fast or not. In either case, it is given by \\(\\beta_1\\). Thus, Model 4 produces a picture that looks like this: equation1 &lt;- function(x){coef(model4)[2]*x+coef(model4)[1]} equation2 &lt;- function(x){coef(model4)[2]*x+coef(model4)[1]+coef(model4)[3]} ggplot(data=derby.df, aes(x=yearnew, y=speed, color=fastfactor)) + geom_point()+ stat_function(fun=equation1,geom=&quot;line&quot;,color=scales::hue_pal()(3)[3]) + stat_function(fun=equation2,geom=&quot;line&quot;,color=scales::hue_pal()(3)[1]) Recall, however, that the data suggested that speeds have increased more rapidly for tracks that are not fast. # Coded scatterplot ggplot(derby.df, aes(x = year, y = speed, colour = fastfactor)) + geom_point(aes(shape = fastfactor)) + geom_smooth(aes(linetype = fastfactor), method = lm, se = FALSE) Figure 1.7: Linear trends in winning speeds over time, presented separately for fast conditions vs. good or slow conditions. 1.3.5 MLR Model with Interaction We want to build a model allows winning speeds to increase at different rates for fast tracks than for those that are not fast. (i.e. a model that includes an interaction between fast and yearnew) Thus, consider Model 5: \\[ \\begin{equation*} \\begin{split} Y_{i}&amp;= \\beta_{0}+\\beta_{1}\\textrm{Yearnew}_{i}+\\beta_{2}\\textrm{Fast}_{i} \\\\ &amp;{}+\\beta_{3}\\textrm{Yearnew}_{i}\\times\\textrm{Fast}_{i}+\\epsilon_{i}\\quad \\textrm{where}\\quad \\epsilon_{i}\\sim \\textrm{N}(0,\\sigma^2) \\end{split} \\end{equation*} \\] ### Interaction Model Estimates LLSR provides the following parameter estimates: We can do this using either of the following commands model5 &lt;- lm(speed ~ yearnew + fast + yearnew:fast, data=derby.df) model5 &lt;- lm(speed ~ yearnew*fast, data=derby.df) coef(summary(model5)) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 50.52862926 0.205072338 246.394174 6.988530e-162 ## yearnew 0.03075099 0.003470967 8.859489 9.838736e-15 ## fast 1.83352259 0.262174513 6.993520 1.729697e-10 ## yearnew:fast -0.01149034 0.004116733 -2.791129 6.127912e-03 cat(&quot; R squared = &quot;, summary(model5)$r.squared, &quot;\\n&quot;, &quot;Residual standard error = &quot;, summary(model5)$sigma) ## R squared = 0.7067731 ## Residual standard error = 0.7070536 1.3.6 Model Equations for Fast, Non-Fast Tracks According to our model, estimated winning speeds can be found by: \\[ \\begin{equation} \\hat{Y}_{i}=50.53+0.031\\textrm{Yearnew}_{i}+1.83\\textrm{Fast}_{i}-0.011\\textrm{Yearnew}_{i}\\times\\textrm{Fast}_{i}. \\end{equation} \\] \\[ \\begin{align*} \\textrm{Fast}=0: &amp; \\\\ \\hat{Y}_{i} &amp;= 50.53+0.031\\textrm{Yearnew}_{i} \\\\ \\textrm{Fast}=1: &amp; \\\\ \\hat{Y}_{i} &amp;= (50.53+1.83)+(0.031-0.011)\\textrm{Yearnew}_{i} \\end{align*} \\] Interpretations \\(\\hat{\\beta}_{0} = 50.53\\). The expected winning speed in 1896 under non-fast conditions was 50.53 ft/s. \\(\\hat{\\beta}_{1} = 0.031\\). The expected yearly increase in winning speeds under non-fast conditions is 0.031 ft/s. \\(\\hat{\\beta}_{2} = 1.83\\). The winning speed in 1896 was expected to be 1.83 ft/s faster under fast conditions compared to non-fast conditions. \\(\\hat{\\beta}_{3} = -0.011\\). The expected yearly increase in winning speeds under fast conditions is 0.020 ft/s, compared to 0.031 ft/s under non-fast conditions, a difference of 0.011 ft/s. 1.4 Building a Multiple Linear Regression Model 1.4.1 Model Building Considerations We now add additional variables, with the goal of building a final model that provides insight into relationships between winning speed and other variables. There is no single correct model, but a good model will have the following characteristics: explanatory variables allow one to address primary research questions explanatory variables control for important covariates potential interactions have been investigated variables are centered where interpretations can be enhanced (e.g. subtract 1896 from year) unnecessary terms have been removed LINE assumptions and the presence of influential points have both been checked using residual plots the model tells a “persuasive story parsimoniously” Most good models should lead to similar conclusions. 1.4.2 Model Diagnostics Several tests and measures of model performance can be used when comparing different models for model building: \\(R^2\\). Measures the variability in the response variable explained by the model. One problem is that \\(R^2\\) always increases with extra predictors, even if the predictors add very little information. adjusted \\(R^2\\). Adds a penalty for model complexity to \\(R^2\\) so that any increase in performance must outweigh the cost of additional complexity. We should ideally favor any model with higher adjusted \\(R^2\\), regardless of size, but the penalty for model complexity (additional terms) is fairly ad-hoc. AIC (Akaike Information Criterion). Again attempts to balance model performance with model complexity, with smaller AIC levels being preferable, regardless of model size. The BIC (Bayesian Information Criterion) is similar to the AIC, but with a greater penalty for additional model terms. extra sum of squares F test. This is a generalization of the t-test for individual model coefficients which can be used to perform significance tests on nested models, where one model is a reduced version of the other. 1.4.3 Three Possible Models We’ll consider three possible final models: Model A: \\[ \\begin{equation} \\begin{split} Y_{i}&amp;=\\beta_{0}+\\beta_{1}\\textrm{Yearnew}_{i}+\\beta_{2}\\textrm{Yearnew}^2_{i}+\\epsilon_{i}\\quad \\textrm{where}\\quad \\epsilon_{i}\\sim \\textrm{N}(0,\\sigma^2) \\end{split} \\end{equation} \\] Model B: \\[ \\begin{equation} \\begin{split} Y_{i}&amp;=\\beta_{0}+\\beta_{1}\\textrm{Yearnew}_{i}+\\beta_{2}\\textrm{Yearnew}^2_{i}+\\beta_{3}\\textrm{Fast}_{i}\\\\ &amp;{}+\\beta_{4}\\textrm{Good}_{i}+\\beta_{5}\\textrm{Starters}_{i}+\\epsilon_{i}\\quad \\textrm{where}\\quad \\epsilon_{i}\\sim \\textrm{N}(0,\\sigma^2) \\end{split} \\end{equation} \\] Note that this is equivalent to including the original track condition variable in a model. In this case, slow track is treated as the baseline variable, since we left the indicator for slow out of the model. Model C: \\[ \\begin{equation} \\begin{split} Y_{i}&amp;=\\beta_{0}+\\beta_{1}\\textrm{Yearnew}_{i}+\\beta_{2}\\textrm{Yearnew}^2_{i}+\\beta_{3}\\textrm{Fast}_{i}\\\\ &amp;{}+\\beta_{4}\\textrm{Good}_{i}+\\beta_{5}\\textrm{Starters}_{i} \\\\ &amp; + \\beta_6\\textrm{Yearnew}_{i}\\textrm{Fast}_{i}+ \\beta_7\\textrm{Yearnew}_{i}\\textrm{Good}_{i} \\\\ &amp; + \\beta_8\\textrm{Yearnew}^2_{i}\\textrm{Fast}_{i}+ \\beta_9\\textrm{Yearnew}^2_{i}\\textrm{Good}_{i} \\\\ &amp; + \\epsilon_{i}\\quad \\textrm{where}\\quad \\epsilon_{i}\\sim \\textrm{N}(0,\\sigma^2) \\end{split} \\end{equation} \\] 1.4.4 MLR Models Fit in R We fit each model in R. model0A &lt;- lm(speed ~ yearnew + yearnew2 , data = derby.df) model0B &lt;- lm(speed ~ yearnew + yearnew2 + fast + good + starters, data = derby.df) model0C &lt;- lm(speed ~ yearnew + yearnew2 + fast + good + starters + yearnew:fast + yearnew:good + yearnew2:fast + yearnew2:good, data = derby.df) 1.4.5 Model 0A Output coef(summary(model0A)) %&gt;% round(6) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 50.587457 0.208171 243.009695 0 ## yearnew 0.076173 0.007950 9.580989 0 ## yearnew2 -0.000414 0.000064 -6.504628 0 cat(&quot; R squared = &quot;, summary(model0A)$r.squared, &quot;\\n&quot;, &quot; Adjusted R squared = &quot;, summary(model0A)$adj.r.squared, &quot;\\n&quot;, &quot;Residual standard error = &quot;, summary(model0A)$sigma, &quot;\\n&quot;, &quot;AIC = &quot;, AIC(model0A)) ## R squared = 0.6410103 ## Adjusted R squared = 0.6349769 ## Residual standard error = 0.7790385 ## AIC = 290.258 1.4.6 Model 0B Output coef(summary(model0B))%&gt;% round(6) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 50.020315 0.194646 256.980337 0.000000 ## yearnew 0.070034 0.006130 11.423908 0.000000 ## yearnew2 -0.000370 0.000046 -8.041141 0.000000 ## fast 1.392666 0.130520 10.670102 0.000000 ## good 0.915698 0.207677 4.409248 0.000023 ## starters -0.025284 0.013602 -1.858827 0.065586 cat(&quot; R squared = &quot;, summary(model0B)$r.squared, &quot;\\n&quot;, &quot; Adjusted R squared = &quot;, summary(model0B)$adj.r.squared, &quot;\\n&quot;, &quot;Residual standard error = &quot;, summary(model0B)$sigma,&quot;\\n&quot;, &quot;AIC = &quot;, AIC(model0B)) ## R squared = 0.8266716 ## Adjusted R squared = 0.8192006 ## Residual standard error = 0.5482735 ## AIC = 207.4291 1.4.7 Model 0C Output coef(summary(model0C))%&gt;% round(6) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 49.703525 0.296614 167.569982 0.000000 ## yearnew 0.068568 0.013167 5.207395 0.000001 ## yearnew2 -0.000290 0.000102 -2.835528 0.005430 ## fast 1.697589 0.337378 5.031710 0.000002 ## good 1.704844 0.468469 3.639181 0.000415 ## starters -0.018592 0.013107 -1.418444 0.158838 ## yearnew:fast 0.004223 0.014398 0.293292 0.769841 ## yearnew:good -0.031672 0.021548 -1.469858 0.144404 ## yearnew2:fast -0.000128 0.000114 -1.124264 0.263305 ## yearnew2:good 0.000249 0.000213 1.168083 0.245254 cat(&quot; R squared = &quot;, summary(model0C)$r.squared, &quot;\\n&quot;, &quot; Adjusted R squared = &quot;, summary(model0C)$adj.r.squared, &quot;\\n&quot;, &quot;Residual standard error = &quot;, summary(model0C)$sigma, &quot;\\n&quot;, &quot;AIC = &quot;, AIC(model0C)) ## R squared = 0.8498007 ## Adjusted R squared = 0.8377311 ## Residual standard error = 0.5194172 ## AIC = 197.9556 1.4.8 Goodness of Fit Tests When two models are nested (that is, all the terms in the smaller model also appear in the larger model) we can compare them using a goodness of fit test. Reduced Model: \\(\\hat{y}_i = b_0 + b_1x_{i1} + b_2{x_i2} + \\ldots + b_{q-1}x_{iq-1}\\) Full Model: \\(\\hat{y}_i = b_0 + b_1x_{i1} + b_2{x_i2} + \\ldots + b_{q-1}x_{iq-1} + b_{q}x_{i{q}} \\ldots + b_{p}x_{i{p-1}}\\) p = # parameters in Full Model q = # parameters in Reduced Model \\((q&lt;p)\\) n = number of observations The hypothesis are: Null Hypothesis: Smaller model adequately explains variability in the response variable. Alternative Hypothesis: Larger model better explains variability in the response variable than the smaller one. 1.4.9 ANOVA F-Statistic We calculate an F-statistic using the formula: \\[ F = \\frac{\\frac{\\text{SSR}_{\\text{Reduced}}-\\text{SSR}_{\\text{Full}}}{p-q}}{\\frac{\\text{SSR}_{\\text{Full}}}{n-p}} \\] When the null hypothesis is true, this statistic follows an F-distribution with \\(p-q\\) and \\(n-p\\) degrees of freedom. # Compare model0A and model0B anova(model0A, model0B, test = &quot;F&quot;) Analysis of Variance Table Model 1: speed ~ yearnew + yearnew2 Model 2: speed ~ yearnew + yearnew2 + fast + good + starters Res.Df RSS Df Sum of Sq F Pr(&gt;F) 1 119 72.221 2 116 34.870 3 37.351 41.418 &lt; 0.00000000000000022 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 There is very strong evidence that track condition and number of starters help explain variability in winning speed. # Compare model0A and model0B anova(model0B, model0C, test = &quot;F&quot;) Analysis of Variance Table Model 1: speed ~ yearnew + yearnew2 + fast + good + starters Model 2: speed ~ yearnew + yearnew2 + fast + good + starters + yearnew:fast + yearnew:good + yearnew2:fast + yearnew2:good Res.Df RSS Df Sum of Sq F Pr(&gt;F) 1 116 34.870 2 112 30.217 4 4.6531 4.3117 0.002784 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 There is evidence of interaction between year and track conditions. Observations: There is strong evidence that model B is better than model A. Accounting for condition of track and number of starters helps explain variability in winning speeds. Models B and C both seem like reasonable fits. Adjusted R^2, AIC, and the F-test all favor model C over model B. Model C is, however, much harder to interpret. The p-values on any single interaction term were large, even though the model testing for significance of interactions collectively was small. When in doubt, it’s better to go with the simpler model, unless there is clear reason to choose the more complex one. It is important to consider intuition, domain area knowledge, and interpretability when choosing a model. Do not choose a model based on statistical tests alone! 1.4.10 Final Model Residual Plots We’ll go with model B. We use residual plots to check model assumptions. # Residual diagnostics for Model B par(mar=c(4,4,4,4)) par(mfrow=c(2,2)) plot(model0B) Figure 1.8: Residual plots for Model 0B. par(mfrow=c(1,1)) There do not appear to be any major model violations. Model B Coefficients Table: coef(summary(model0B))%&gt;% round(6) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 50.020315 0.194646 256.980337 0.000000 ## yearnew 0.070034 0.006130 11.423908 0.000000 ## yearnew2 -0.000370 0.000046 -8.041141 0.000000 ## fast 1.392666 0.130520 10.670102 0.000000 ## good 0.915698 0.207677 4.409248 0.000023 ## starters -0.025284 0.013602 -1.858827 0.065586 cat(&quot; R squared = &quot;, summary(model0B)$r.squared, &quot;\\n&quot;, &quot; Adjusted R squared = &quot;, summary(model0B)$adj.r.squared, &quot;\\n&quot;, &quot;Residual standard error = &quot;, summary(model0B)$sigma,&quot;\\n&quot;, &quot;AIC = &quot;, AIC(model0B)) ## R squared = 0.8266716 ## Adjusted R squared = 0.8192006 ## Residual standard error = 0.5482735 ## AIC = 207.4291 1.4.11 Overall Conclusions Conclusions: * The rate of increase in winning speeds is slowing over time (negative quadratic term) * The better the condition of the track, the faster the horses tend to run * larger field, with more starters, is associated with slower winning times Notice this last conclusion appears contradictory to our exploratory data analysis, which showed a positive relationship between starters and speed. gg &lt;- ggpairs(data = derby.df, columns = c(&quot;condition&quot;, &quot;year&quot;, &quot;starters&quot;, &quot;speed&quot;)) gg Figure 1.9: Relationships between pairs of variables in the Kentucky Derby data set. This happens because over time, the number of starters in the race has increased, as have winning speeds. So, it appears that having more starters is associated with faster winning speeds, but year is acting as a confounding variable. The multiple regression model is able to separate the effect of year from that of number of starters. The model tells us that assuming year is held constant, having more starters is actually associated with a slower winning speed. A situation like this, where adding a variable (such as year) to a model results in an apparent trend disappearing or reversing itself, is called Simpson’s Paradox. "],["introduction-to-correlated-data.html", "Chapter 2 Introduction to Correlated Data 2.1 Introduction to Correlated Data 2.2 Linear Mixed Effects Models 2.3 A Second Mice Experiment 2.4 A Multilevel Experiment", " Chapter 2 Introduction to Correlated Data library(tidyverse) library(lme4) library(lmerTest) library(knitr) 2.1 Introduction to Correlated Data 2.1.1 Weight Gain in Mice: Experiment Design #1 Consider an experiment designed to assess the impact of three different diets on weight gain in mice. We observe six different litters of mice, with six mice in each litter. Within each litter, two mice are randomly assigned to each of the three diets. Researchers recorded the mean weight gain in each mouse over a four-week period. Experimental Design 1: Figure 2.1: Mouse Experiment Version 1 2.1.2 Mice Experiment 1 Data The first 10 rows of the dataset look like this: head(mice,10) ## litter diet weight_gain ## 1 1 A -0.03526041 ## 2 1 B -0.06841666 ## 3 1 C -0.06351305 ## 4 1 A -0.05171452 ## 5 1 B -0.06917391 ## 6 1 C -0.05951775 ## 7 2 A 0.07584083 ## 8 2 B 0.04913527 ## 9 2 C 0.07958384 ## 10 2 A 0.07278071 2.1.3 A Naive Graphical Analysis Let’s temporarily ignore the fact that some mice came from the same litter, and treat all observations as independent. The plot below shows the weight gain (or loss) for each of the mice, by diet. The red dots and connecting lines show the mean weight gain for each diet. The ensuing table shows the mean and standard deviation in weight gain for each of the three diets. ggplot(data=mice, aes(x=factor(diet), y=weight_gain)) + geom_point() + stat_summary(fun=&quot;mean&quot;, geom=&quot;line&quot;, aes(group=factor(1))) + stat_summary(fun=&quot;mean&quot;, geom=&quot;point&quot;, color=&quot;red&quot;, size=2) Question: Based on this graph, do you think there is evidence of diets have an effect on weight gain in mice? Why or why not? 2.1.4 A More Informed Graphical Analysis So far, we’ve ignored the fact that some of the mice came from the same litter. Now, let’s take litter into account. The figure below colors the mice by litter. The lines represent the average weight gain (or loss) in each litter. ggplot(data=mice, aes(x=factor(diet), y=weight_gain, color=factor(litter))) + geom_point() + stat_summary(fun=&quot;mean&quot;, geom=&quot;line&quot;, aes(group=factor(litter))) It may be helpful to examine each litter individually. ggplot(data=mice, aes(x=factor(diet), y=weight_gain, color=factor(litter))) + geom_point() + facet_grid(.~litter, scales = &quot;free&quot;) + stat_summary(fun=&quot;mean&quot;, geom=&quot;line&quot;, aes(group=factor(litter))) Question: Based on the information about litters, do your thoughts about whether diets have an effect on weight gain in mice change? Does there appear to be stronger evidence of differences between groups? Weaker? Same? 2.1.5 Table of Mean Weight By Diet mouse_groups &lt;- mice %&gt;% group_by(diet)%&gt;% summarize(Mean_Weight=mean(weight_gain), SD_Weight = sd(weight_gain), N=n()) mouse_groups ## # A tibble: 3 × 4 ## diet Mean_Weight SD_Weight N ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 A 0.0580 0.0567 12 ## 2 B 0.0340 0.0583 12 ## 3 C 0.0471 0.0612 12 2.1.6 Table of Mean Weight By Diet and Litter mouse_groups &lt;- mice %&gt;% group_by(diet, litter)%&gt;% summarize(Mean_Weight=mean(weight_gain), SD_Weight = sd(weight_gain), N=n()) mouse_groups ## # A tibble: 18 × 5 ## # Groups: diet [3] ## diet litter Mean_Weight SD_Weight N ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 A 1 -0.0435 0.0116 2 ## 2 A 2 0.0743 0.00216 2 ## 3 A 3 0.0192 0.00282 2 ## 4 A 4 0.104 0.00487 2 ## 5 A 5 0.110 0.00145 2 ## 6 A 6 0.0833 0.00721 2 ## 7 B 1 -0.0688 0.000535 2 ## 8 B 2 0.0554 0.00881 2 ## 9 B 3 -0.0108 0.00781 2 ## 10 B 4 0.0731 0.00482 2 ## 11 B 5 0.0873 0.00890 2 ## 12 B 6 0.0682 0.00430 2 ## 13 C 1 -0.0615 0.00283 2 ## 14 C 2 0.0746 0.00711 2 ## 15 C 3 0.000839 0.00489 2 ## 16 C 4 0.0918 0.00638 2 ## 17 C 5 0.0979 0.0214 2 ## 18 C 6 0.0792 0.00310 2 Since each mouse in a litter received a different treatment, we can use the standard deviations between mice in the same litter to assess the amount of unexplained variability after accounting for litter and diet. Notice standard deviations are much smaller when we account for litter. Most of the unexplained variability in the first table is explained when we account for litter. When we fail to account for litter, variability thqt can be explained by differences between litters becomes conflated with unexplained variability. This causes us to overestimate unexplained variability and makes differences between groups look less meaningful than they really are. 2.1.7 Assessing Evidence of Differences Conceptually, we can assess whether there is evidence of differences between the diets by considering differences in mean weights, relative to the amount of unexplained variability between mice in the same litter and on the same diet. Recall that when testing for a difference between two groups, a t-statistic is calculated using the formula \\[ t= \\frac{\\bar{x}_1-\\bar{x}_2}{\\textrm{SE}(\\bar{x}_1-\\bar{x}_2)}=\\frac{\\bar{x}_1-\\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1}+\\frac{s_2^2}{n_2}}} \\] The numerator measures the size of the differences between the groups, and the denominator measures the amount of unexplained variability between individuals in the same group. 2.1.8 An Improper Statistical Analysis We’ve seen graphically, and in table form, how accounting for litter impacts our ability to discern differences between diets. Now, let’s look at how this happens in a statistical model. If we ignore the fact that some mice are from the same litter, and wrongly treat them as independent, we might use an ordinary linear least squares regression model. M_LLSR &lt;- lm(data=mice, weight_gain~factor(diet)) summary(M_LLSR)$coefficients ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.05798494 0.01696450 3.4180166 0.001693572 ## factor(diet)B -0.02394185 0.02399142 -0.9979334 0.325573272 ## factor(diet)C -0.01085590 0.02399142 -0.4524907 0.653876252 The p-values on line 2 is large, indicating that there is not evidence of differences in weight gain between mice on diet 2, and the baseline diet (diet 1). The same is true for a comparison of diets 3 and 1, as seen on the third line. 2.1.9 A More Appropriate Statistical Analysis The following command fits a linear mixed effects model (or multilevel model) that accounts for correlation between mice in the same litter. M_LME &lt;- lmer(data=mice, weight_gain~factor(diet) + (1 | factor(litter))) summary(M_LME)$coeff ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 0.05798494 0.025057550 5.046906 2.314071 0.068074390235216 ## factor(diet)B -0.02394185 0.002962717 28.000001 -8.081043 0.000000008464648 ## factor(diet)C -0.01085590 0.002962717 28.000001 -3.664169 0.001025965505479 Estimates are unchanged, but standard errors decrease by a factor of almost 10. t-statistics are now high, and p-values low, indicating differences between the diets Just as we saw graphically, and in tables, accounting for differences between litters allows us to accurately quantify unexplained variability, and assess whether there is evidence of differences in weight gain between the diets. 2.2 Linear Mixed Effects Models 2.2.1 LLSR Model for Mice Experiment Let \\(Y_{ij}\\) denote the weight gain of mouse \\(j\\) in litter \\(i\\). \\(j=1,2,\\ldots, 6\\), \\(j=1,2,\\ldots, 6\\). In an ordinary linear least squares regression model, we assume that: each diet has an expected (or average) weight gain individual mice vary from their expected weights randomly, according to normal distributions with constant variance \\(\\sigma^2\\) no two mice are any more or less alike than any others, except for diet (which is not true in this context) A model would have the form: \\[ Y_{ij} = \\beta_{0}+\\beta_{1}\\textrm{DietB}_{ij} +\\beta_{2}\\textrm{DietC}_{ij} + \\epsilon_{ij}, \\] where \\(\\epsilon_{ij} \\sim\\mathcal{N}(0, \\sigma^2)\\). Examples: Diet Expected Weight Random Deviation Litter 1, Mouse 1 A \\(\\beta_0\\) \\(\\epsilon_{11}\\) Litter 1, Mouse 3 B \\(\\beta_0 + \\beta_1\\) \\(\\epsilon_{13}\\) Litter 1, Mouse 5 C \\(\\beta_0 + \\beta_2\\) \\(\\epsilon_{15}\\) Litter 2, Mouse 1 A \\(\\beta_0\\) \\(\\epsilon_{21}\\) Litter 2, Mouse 3 B \\(\\beta_0 + \\beta_1\\) \\(\\epsilon_{23}\\) Litter 2, Mouse 5 C \\(\\beta_0 + \\beta_2\\) \\(\\epsilon_{25}\\) 2.2.2 Model Accounting For Correlation Let \\(Y_{ij}\\) denote the weight gain of mouse \\(j\\) in litter \\(i\\). \\(j=1,2,\\ldots, 6\\), \\(j=1,2,\\ldots, 6\\). We assume that: expected (or average) weight gain differs between diets individual litters vary from their expected weight randomly, according to normal distributions with constant variance \\(\\sigma^2_l\\) within each litter, individual mice vary from their expected weights randomly, according to normal distributions with constant variance \\(\\sigma^2\\) A model would have the form: \\[ Y_{ij} = \\beta_{0}+\\beta_{1}\\textrm{DietB}_{ij} +\\beta_{2}\\textrm{DietC}_{ij} + l_{i} + \\epsilon_{ij}, \\] where \\(l_i\\sim\\mathcal{N}(0, \\sigma^2_l)\\), and \\(\\epsilon_{ij} \\sim\\mathcal{N}(0, \\sigma^2)\\). Diet Expected Weight Random Deviation Litter 1, Mouse 1 A \\(\\beta_0\\) \\(l_1 + \\epsilon_{11}\\) Litter 1, Mouse 3 B \\(\\beta_0 + \\beta_1\\) \\(l_1 + \\epsilon_{13}\\) Litter 1, Mouse 5 C \\(\\beta_0 + \\beta_2\\) \\(l_1 + \\epsilon_{15}\\) Litter 2, Mouse 1 A \\(\\beta_0\\) \\(l_2 + \\epsilon_{21}\\) Litter 2, Mouse 3 B \\(\\beta_0 + \\beta_1\\) \\(l_2 + \\epsilon_{23}\\) Litter 2, Mouse 5 C \\(\\beta_0 + \\beta_2\\) \\(l_2 + \\epsilon_{25}\\) 2.2.3 Questions of Interest The model \\[ Y_{ij} = \\beta_{0}+\\beta_{1}\\textrm{DietB}_{ij} +\\beta_{2}\\textrm{DietC}_{ij} + l_{i} + \\epsilon_{ij}, \\] where \\(l_i\\sim\\mathcal{N}(0, \\sigma^2_l)\\), and \\(\\epsilon_{ij} \\sim\\mathcal{N}(0, \\sigma^2)\\) has 5 parameters: \\(\\beta_0\\) - average weight gain for mice on diet A. \\(\\beta_1\\) - difference in average weight gain for mice on diet B, compared to to diet A \\(\\beta_2\\) - difference in average weight gain for mice on diet C, compared to to diet A \\(\\sigma_l\\) - standard deviation in the distribution of differences between litters (i.e. variability explained by litter) \\(\\sigma\\) - standard deviation in the distribution of differences between individual mice in the same litter (i.e. unexplained variability) Thus, for a mouse on Diet A, the expected weight gain follows a normal distribution with mean \\(\\beta_0\\) and variance \\(\\sigma^2_l + \\sigma^2\\). For a mouse on Diet C, the expected weight gain follows a normal distribution with mean \\(\\beta_0 + \\beta_2\\) and variance \\(\\sigma^2_l + \\sigma^2\\) This is based on the fact that the sum of two independent normal random variables is normal, with mean equal to the sum of the means and variance equal to the sum of the variances. 2.2.4 Fixed and Random Effects In this case, we want to test for whether there are differences in weight gain between the diets. There is no reason to test for differences in weight gain between the litters. Differences between these specific litters of mice are not important to us. We’re not interested in drawing conclusions about these specific mice. They’re just a sample of participants, being used to investigate the diets. It’s likely that we’ll never acually see these specific litters of mice beyond this study. We still need to account for litter, though, because it helps explain, or account for, variability that would otherwise go unexplained. Variables for which we want to investigate differences or relationships are called fixed effects. We should build these into the “expectation structure” of the model, using \\(\\beta_j\\)’s. Variables that we are not interested in testing for differences or relationships between, but that we still want to include in our model in order to account for correlation and explain variability are called random effects. We should add these to the model as normally distributed error terms. Accounting for random effects allows us to accurately calculate standard errors associated with fixed effects. A model that involves both fixed and random effects is called a linear mixed effects model. 2.2.5 Fitting the Model in R To fit a linear mixed effects model in R, we use the lmer() command that is part of the lme4 package. It is also helpful to load the lmerTest package, in order to obtain p-values in the output. To add a random effect for a variable add (1 | variable_name) in the model. M_LME &lt;- lmer(data=mice, weight_gain~factor(diet) + (1 | factor(litter))) summary(M_LME) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: weight_gain ~ factor(diet) + (1 | factor(litter)) ## Data: mice ## ## REML criterion at convergence: -193.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.2468 -0.7088 0.0247 0.6028 1.9280 ## ## Random effects: ## Groups Name Variance Std.Dev. ## factor(litter) (Intercept) 0.00374095 0.061163 ## Residual 0.00005267 0.007257 ## Number of obs: 36, groups: factor(litter), 6 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 0.057985 0.025058 5.046906 2.314 0.06807 . ## factor(diet)B -0.023942 0.002963 28.000001 -8.081 0.00000000846 *** ## factor(diet)C -0.010856 0.002963 28.000001 -3.664 0.00103 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) fct()B ## factor(dt)B -0.059 ## factor(dt)C -0.059 0.500 Estimates and Interpretations \\(\\beta_0 = 0.058\\): We estimate that average weight gain for Diet A is 0.058 g. \\(\\beta_1 = -0.024\\): We estimate that mice on diet B gain 0.024 g. less than mice on diet A, on average. \\(\\beta_2 = -0.011\\): We estimate that mice on diet C gain 0.011 g. less than mice on diet A, on average. The “Random effects” table gives estimates of \\(\\sigma^2_l\\) (litters) and \\(\\sigma^2\\) (Residual). \\(\\sigma_l = 0.061\\): We estimate that the standard deviation in differences in weights between litters, after accounting for diet, is 0.061 g. \\(\\sigma = 0.007\\): We estimate that the standard deviation in differences in weights between mice within a litter, after accounting for diet, is 0.007 g. There is evidence of differences between the diets. There is more variability in weight between different litters than between mice in the same litter, after accounting for diet. 2.2.6 Why Not Fixed Effect for Litter? Why would a model like the following, which uses litter as an expanatory variable in Example 1, not be very useful? M_fixed_litter &lt;- lm(data=mice, weight_gain~ factor(diet) + factor(litter)) summary(M_fixed_litter) ## ## Call: ## lm(formula = weight_gain ~ factor(diet) + factor(litter), data = mice) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.0164273 -0.0051744 0.0001942 0.0044281 0.0138701 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.046333 0.003421 -13.544 0.0000000000000815 *** ## factor(diet)B -0.023942 0.002963 -8.081 0.0000000084646521 *** ## factor(diet)C -0.010856 0.002963 -3.664 0.00103 ** ## factor(litter)2 0.126011 0.004190 30.075 &lt; 0.0000000000000002 *** ## factor(litter)3 0.061021 0.004190 14.564 0.0000000000000136 *** ## factor(litter)4 0.147712 0.004190 35.254 &lt; 0.0000000000000002 *** ## factor(litter)5 0.156366 0.004190 37.320 &lt; 0.0000000000000002 *** ## factor(litter)6 0.134801 0.004190 32.173 &lt; 0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.007257 on 28 degrees of freedom ## Multiple R-squared: 0.9874, Adjusted R-squared: 0.9843 ## F-statistic: 314.5 on 7 and 28 DF, p-value: &lt; 0.00000000000000022 We’re now estimating 8 \\(\\beta&#39;s\\) instead of 3. Each time we estimate an additional parameter, we lose a degree of freedom, making estimates and predictions less precise. We don’t care about differences between the litters, so \\(\\beta_3, \\beta_4, \\ldots, \\beta_7\\) are not useful. Imagine if we had many more litters. Things would get really messy, and unnecessarily so. If, for some reason, we really wanted to test for differences in weight gain between these specific litters of mice, then we would treat them as fixed effects, but it’s hard to see why we would want to do that. 2.3 A Second Mice Experiment 2.3.1 Weight Gain in Mice: Experiment 2 Now consider a different structure of the mouse experiment. In this version of the experiment, the three diets were randomly assigned to six pregnant mice, so that two mice were assigned to each diet. Each of the six mice (dams), gave birth to six pups, creating six litters of six, as seen before. Researchers the observed the mean weight gain of the pups over a four week period. Now, each pup in a litter has necessarily been assigned to the same diet, since diets were assigned to the dams, before the pups were born. Experimental Design 2: Figure 2.2: Mouse Experiment Version 2 2.3.2 Mice Experiment 2 Data The first 15 rows of the dataset look like this: head(mice2,15) ## litter diet weight_gain ## 1 1 A -0.0352604099 ## 2 1 A -0.0474166604 ## 3 1 A -0.0545130532 ## 4 1 A -0.0517145212 ## 5 1 A -0.0481739132 ## 6 1 A -0.0505177486 ## 7 2 A 0.0758408263 ## 8 2 A 0.0701352749 ## 9 2 A 0.0885838352 ## 10 2 A 0.0727807107 ## 11 2 A 0.0826007925 ## 12 2 A 0.0785294998 ## 13 3 B 0.0002306143 ## 14 3 B -0.0163362762 ## 15 3 B -0.0146213462 2.3.3 A Naive Graphical Analysis for Experiment 2 Again, we’ll temporarily ignore the fact that mice come from the same litter and treat all observations as independent. ggplot(data=mice2, aes(x=factor(diet), y=weight_gain)) + geom_point() + stat_summary(fun=&quot;mean&quot;, geom=&quot;line&quot;, aes(group=factor(1)))+ stat_summary(fun=&quot;mean&quot;, geom=&quot;point&quot;, color=&quot;red&quot;, size=2) 2.3.4 A More Informed Graphical Analysis for Experiment 2 Now, we’ll account for the fact that mice in the same litter got the same diets. The plot below adds color to show litter. ggplot(data=mice2, aes(x=factor(diet), y=weight_gain, color=factor(litter))) + geom_point() Since diets were assigned to litters, not individual mice, it is the litters we should be comparing. When comparing diets, our observational units are litters, not individual mice. Since there are only 6 litters, our sample size is 6, rather than 36. Thus, the best graphical analysis would come from the following plot, which displays average weight for each litter: Litters &lt;- mice2 %&gt;% group_by(diet, litter)%&gt;% summarize(mean_weight_gain=mean(weight_gain), N=n()) head(Litters) ## # A tibble: 6 × 4 ## # Groups: diet [3] ## diet litter mean_weight_gain N ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 A 1 -0.0479 6 ## 2 A 2 0.0781 6 ## 3 B 3 -0.00791 6 ## 4 B 4 0.0788 6 ## 5 C 5 0.0994 6 ## 6 C 6 0.0779 6 ggplot(data=Litters, aes(x=factor(diet), y=mean_weight_gain, color=factor(litter))) + geom_point() 2.3.5 Table of Mean Weight By Diet for Experiment 2 mouse_groups &lt;- mice2 %&gt;% group_by(diet)%&gt;% summarize(Mean_Weight=mean(weight_gain), SD_Weight = sd(weight_gain), N=n()) mouse_groups ## # A tibble: 3 × 4 ## diet Mean_Weight SD_Weight N ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 A 0.0151 0.0661 12 ## 2 B 0.0354 0.0457 12 ## 3 C 0.0887 0.0137 12 This standard deviations in this table pertain to variability between the 12 mice that got each diet (6 from one litter and 6 from another). These are not useful here, since diets were assigned to litters, not individual mice. 2.3.6 Table Comparing Litters Means by Diet for Experiment 2 We now look at means and standard deviations between litter means, using the average rate in each litter as the response variable. litter_groups &lt;- Litters %&gt;% group_by(diet)%&gt;% summarize(Mean_Weight=mean(mean_weight_gain), SD_Weight = sd(mean_weight_gain), N=n()) litter_groups ## # A tibble: 3 × 4 ## diet Mean_Weight SD_Weight N ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 A 0.0151 0.0891 2 ## 2 B 0.0354 0.0613 2 ## 3 C 0.0887 0.0152 2 2.3.7 An Inappropriate Model for the Second Design An ordinarly linear least squares regression model fails to account for the fact that treatments were assigned to litters, not mice. It is based on the assumption that we have 36 independent mice (which is incorret). Such a model would have the form \\[ Y_{ij} = \\beta_{0}+\\beta_{1}\\textrm{DietB}_{ij} +\\beta_{2}\\textrm{DietC}_{ij} + \\epsilon_{ij}, \\] Output for such a model is shown below. M2_LLSR &lt;- lm(data=mice2, weight_gain~factor(diet)) summary(M2_LLSR) ## ## Call: ## lm(formula = weight_gain ~ factor(diet), data = mice2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.069586 -0.041328 -0.005675 0.041915 0.073511 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.01507 0.01359 1.109 0.275297 ## factor(diet)B 0.02036 0.01922 1.060 0.297007 ## factor(diet)C 0.07358 0.01922 3.829 0.000545 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.04707 on 33 degrees of freedom ## Multiple R-squared: 0.3215, Adjusted R-squared: 0.2804 ## F-statistic: 7.819 on 2 and 33 DF, p-value: 0.001662 2.3.8 A More Appropriate Model for Experiment 2 A linear mixed effects model with a random term for litter accounts for the fact that treatments were applied to litters, not individual mice. This model has the form: \\[ Y_{ij} = \\beta_{0}+\\beta_{1}\\textrm{DietB}_{ij} +\\beta_{2}\\textrm{DietC}_{ij} + l_{i} + \\epsilon_{ij}, \\] where \\(l_i\\sim\\mathcal{N}(0, \\sigma^2_l)\\), and \\(\\epsilon_{ij} \\sim\\mathcal{N}(0, \\sigma^2)\\) Output for a model that accounts for correlation between mice in the same litter is shown. M2_LME &lt;- lmer(data=mice2, weight_gain~factor(diet) + (1 | factor(litter))) summary(M2_LME) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: weight_gain ~ factor(diet) + (1 | factor(litter)) ## Data: mice2 ## ## REML criterion at convergence: -206.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.33470 -0.59248 0.03505 0.59073 1.91089 ## ## Random effects: ## Groups Name Variance Std.Dev. ## factor(litter) (Intercept) 0.00396804 0.062992 ## Residual 0.00005093 0.007136 ## Number of obs: 36, groups: factor(litter), 6 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 0.01507 0.04459 3.00000 0.338 0.758 ## factor(diet)B 0.02036 0.06306 3.00000 0.323 0.768 ## factor(diet)C 0.07358 0.06306 3.00000 1.167 0.328 ## ## Correlation of Fixed Effects: ## (Intr) fct()B ## factor(dt)B -0.707 ## factor(dt)C -0.707 0.500 Estimates are the same Standard errors are larger, due mostly to the fact that our sample size is 6, instead of 36 after accounting for diet, standard deviation in weights between litters is estimated to be 0.0629 g. (estimate of \\(\\sigma_l\\)) after accounting for diet, standard deviation in weights between mice in the same litter is estimated to be 0.0071 g. (estimate of \\(\\sigma\\)) 2.3.9 Model for Litter Means Alternatively, we could fit a model, using the 6 litters as our observations, with the mean weight in each litter as the response variable. If we now let \\(Y_i\\) represent the mean weight in litter i, our model has the form: \\[ Y_{i} = \\beta_{0}+\\beta_{1}\\textrm{DietB}_{i} +\\beta_{2}\\textrm{DietC}_{i} + \\epsilon_{i}, \\] where \\(\\epsilon_{i} \\sim\\mathcal{N}(0, \\sigma^2)\\) Since it is reasonable to assume that litters are independent, we could use an ordinary LLSR model in this context. M2_Means &lt;- lm(data=Litters, mean_weight_gain~factor(diet)) summary(M2_Means) ## ## Call: ## lm(formula = mean_weight_gain ~ factor(diet), data = Litters) ## ## Residuals: ## 1 2 3 4 5 6 ## -0.06301 0.06301 -0.04335 0.04335 0.01078 -0.01078 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.01507 0.04459 0.338 0.758 ## factor(diet)B 0.02036 0.06306 0.323 0.768 ## factor(diet)C 0.07358 0.06306 1.167 0.328 ## ## Residual standard error: 0.06306 on 3 degrees of freedom ## Multiple R-squared: 0.3261, Adjusted R-squared: -0.1231 ## F-statistic: 0.7259 on 2 and 3 DF, p-value: 0.5532 Estimates, standard errors, and p-values are identical to the ones seen in the mixed-effects model. 2.3.10 Fixed Effect for Litter in Experiment 2 If we try to treat litter as a fixed effect in Experiment 2, we would not even be able to estimate all of the parameters. M2_fixed_litter &lt;- lm(data=mice2, weight_gain~ factor(diet) + factor(litter)) summary(M2_fixed_litter) ## ## Call: ## lm(formula = weight_gain ~ factor(diet) + factor(litter), data = mice2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.0166840 -0.0041608 0.0003311 0.0042513 0.0136135 ## ## Coefficients: (2 not defined because of singularities) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.047933 0.002913 -16.453 &lt; 0.0000000000000002 *** ## factor(diet)B 0.126712 0.004120 30.755 &lt; 0.0000000000000002 *** ## factor(diet)C 0.125801 0.004120 30.533 &lt; 0.0000000000000002 *** ## factor(litter)2 0.126011 0.004120 30.585 &lt; 0.0000000000000002 *** ## factor(litter)3 -0.086691 0.004120 -21.041 &lt; 0.0000000000000002 *** ## factor(litter)4 NA NA NA NA ## factor(litter)5 0.021565 0.004120 5.234 0.000012 *** ## factor(litter)6 NA NA NA NA ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.007136 on 30 degrees of freedom ## Multiple R-squared: 0.9858, Adjusted R-squared: 0.9835 ## F-statistic: 417.2 on 5 and 30 DF, p-value: &lt; 0.00000000000000022 2.4 A Multilevel Experiment 2.4.1 Experiment 2 Illustration In example 2, we saw that treatments (diets) were assigned to litters (dams), but measurements were taken on the individual mice (pups). 2.4.2 Experiment with Variables Assigned at Different Levels Now imagine qn experimemt with the following setup diets are still assigned to dams, prior to the birth of the pups, so all mice in the same litter get the same diet within each litter three mice are given nutritional supplements after their birth and the other three are not We want to study the effect of diet and supplement on weight gain. One treatment (diet) is assigned to litters, while the other (supplement) is assigned to individual mice. For the purpose of comparing diets, our observational units are 6 independent litters. For the purpose of comparing supplements, our observational units are 36 individual mice (who are not independent) An experiment where treatments are assigned at different levels is called a multilevel experiment level 1 observational units are mice, and level 1 treatment is supplement level 2 observational units are litters, and level 2 treatment is diet 2.4.3 Experiment 3 Data head(mice3,15) ## litter diet supplement weight_gain ## 1 1 A 1 -0.033260410 ## 2 1 A 0 -0.047416660 ## 3 1 A 1 -0.052513053 ## 4 1 A 0 -0.051714521 ## 5 1 A 1 -0.046173913 ## 6 1 A 0 -0.050517749 ## 7 2 A 1 0.077840826 ## 8 2 A 0 0.070135275 ## 9 2 A 1 0.090583835 ## 10 2 A 0 0.072780711 ## 11 2 A 1 0.084600792 ## 12 2 A 0 0.078529500 ## 13 3 B 1 0.002230614 ## 14 3 B 0 -0.016336276 ## 15 3 B 1 -0.012621346 2.4.4 Graphical Analysis for Experiment 3 We use color to represent litter, and shape to represent supplement. We’ll use the argument position=position_jitterdodge() to stagger litters and supplement levels, which avoids overlap and makes the graph easier to read. ggplot(data=mice3, aes(x=factor(diet), y=weight_gain, color=factor(litter), shape=factor(supplement))) + geom_point(position=position_jitterdodge()) 2.4.5 An Inappropriate Model for the 3rd Design An ordinarly linear least squares regression model fails to account for the fact that treatments were assigned to litters, not mice. It is based on the assumption that we have 36 independent mice (which is incorret). The model has the form \\[ Y_{ij} = \\beta_{0} + \\alpha\\textrm{Supplement}_i + \\beta_{1}\\textrm{DietB}_{ij} +\\beta_{2}\\textrm{DietC}_{ij} + \\epsilon_{ij}, \\] where \\(\\epsilon_{ij} \\sim\\mathcal{N}(0, \\sigma^2)\\) Output for such a model is shown below. M3_LLSR &lt;- lm(data=mice3, weight_gain~supplement + factor(diet)) summary(M3_LLSR) ## ## Call: ## lm(formula = weight_gain ~ supplement + factor(diet), data = mice3) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.072685 -0.040982 -0.005618 0.040366 0.070412 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.011974 0.015895 0.753 0.456766 ## supplement 0.008198 0.015895 0.516 0.609538 ## factor(diet)B 0.020361 0.019467 1.046 0.303431 ## factor(diet)C 0.073578 0.019467 3.780 0.000648 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.04768 on 32 degrees of freedom ## Multiple R-squared: 0.3263, Adjusted R-squared: 0.2632 ## F-statistic: 5.167 on 3 and 32 DF, p-value: 0.005021 2.4.6 A More Appropriate Model for Experiment 3 We instead fit a linear mixed effects model. Since we want to study the effects of diet and supplement, we treat supplement and diet as fixed effects. Since we want to account for correlation due to mice being in the same litter, we treat litter as a random effect. Our model has the form \\[ Y_{ij} = \\beta_{0} + \\alpha\\textrm{Supplement}_i + \\beta_{1}\\textrm{DietB}_{ij} +\\beta_{2}\\textrm{DietC}_{ij} + l_{i} + \\epsilon_{ij}, \\] where \\(l_i\\sim\\mathcal{N}(0, \\sigma^2_l)\\), and \\(\\epsilon_{ij} \\sim\\mathcal{N}(0, \\sigma^2)\\) Output for a model that accounts for correlation between mice in the same litter is shown. M3_LME &lt;- lmer(data=mice3, weight_gain ~ supplement + factor(diet) + (1 | factor(litter))) summary(M3_LME) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: weight_gain ~ supplement + factor(diet) + (1 | factor(litter)) ## Data: mice3 ## ## REML criterion at convergence: -203.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.12499 -0.76119 0.06055 0.60135 1.64980 ## ## Random effects: ## Groups Name Variance Std.Dev. ## factor(litter) (Intercept) 0.00396973 0.063006 ## Residual 0.00004076 0.006384 ## Number of obs: 36, groups: factor(litter), 6 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 0.011974 0.044603 3.003417 0.268 0.805735 ## supplement 0.008198 0.002128 29.000000 3.853 0.000596 *** ## factor(diet)B 0.020361 0.063060 3.000000 0.323 0.767980 ## factor(diet)C 0.073578 0.063060 3.000000 1.167 0.327609 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) spplmn fct()B ## supplement -0.024 ## factor(dt)B -0.707 0.000 ## factor(dt)C -0.707 0.000 0.500 Interpretations Interpretations for fixed effects are the same as in LLSR. We expect mice on the supplement to gain 0.008 g. more than mice not on the supplement, assuming they get the same diet. We expect mice in diet B to gain 0.02 g. more than mice on diet A, assuming supplement is held constant. We expect mice in diet C to gain 0.07 g. more than mice on diet A, assuming supplement is held constant After accounting for differences in diet and supplement, the standard deviation in weights between litters is estimated to be 0.063 g. (an estimate of \\(\\sigma_l\\)). After accounting for differences in diet and supplement, the standard deviation in weights between mice in the same litter is estimated to be 0.00638 g. (an estimate of \\(\\sigma\\)). 2.4.7 Comparison of LLSR and LME Models Compared to the incorrect LLSR model, when we use the linear mixed effects model: estimates for fixed effects supplement and diet do not change standard error for supplement is smaller - we get a more precise comparison for supplements because the model has accounted for variability due to differences in litters standard error for diet is larger - since diets were assigned to litters, our sample size is 6, not 36, so standard errors are higher The mixed effects model suggests evidence of differences due to supplement, but not evidence of differences due to diet. This is the opposite of the incorrect LLSR model. "],["multilevel-models.html", "Chapter 3 Multilevel Models 3.1 Music Performance Anxiety Study: Data and Exploratory Analysis 3.2 Modeling the Musician Data 3.3 Random Slopes Model 3.4 Unconditional Means Model 3.5 Building A Multilevel Model 3.6 Conceptual Questions", " Chapter 3 Multilevel Models These notes provide a summary of Chapter 8 in Beyond Multiple Linear Regression by Roback and Legler. Much of the code that appears here comes from the textbook’s Github repository. # Packages required for Chapter 8 library(MASS) library(gridExtra) library(mnormt) library(lme4) library(lmerTest) library(knitr) library(kableExtra) library(tidyverse) 3.1 Music Performance Anxiety Study: Data and Exploratory Analysis 3.1.1 Description of the Study A study by Miller (2010) examined the emotional state of musicians before performances and factors that might affect their emotional state. data on 497 different performances by 37 different performers performers completed Positive Affect Negative Affect Schedule (PANAS) before each performance, measuring characteristics of anxiety and happiness before performing we are interested in whether there are relationships between performance anxiety and characteristics such as performance type (solo, large ensemble, or small ensemble); audience (instructor, public, students, or juried); if the piece was played from memory; age; gender; instrument (voice, orchestral, or keyboard); and, years studying the instrument also have information on personalities of musicians, obtained through through the Multidimensional Personality Questionnaire (MPQ), which provided scores for absorption positive emotionality (PEM—a composite of well-being, social potency, achievement, and social closeness); negative emotionality (NEM—a composite of stress reaction, alienation, and aggression); and, constraint (a composite of control, harm avoidance, and traditionalism). 3.1.2 Variables We focus on the following variables: id = unique musician identification number diary = cumulative total of diaries filled out by musician perf_type = type of performance (Solo, Large Ensemble, or Small Ensemble) audience = who attended (Instructor, Public, Students, or Juried) memory = performed from Memory, using Score, or Unspecified na = negative affect score from PANAS gender = musician gender instrument = Voice, Orchestral, or Piano mpqab = absorption subscale from MPQ mpqpem = positive emotionality (PEM) composite scale from MPQ mpqnem = negative emotionality (NEM) composite scale from MPQ 3.1.3 The Data #Getting started music = read.csv(&quot;https://raw.githubusercontent.com/proback/BeyondMLR/master/data/musicdata.csv&quot;) head(music,10) # examine first 10 rows ## X id diary previous perform_type memory audience pa na age ## 1 1 1 1 0 Solo Unspecified Instructor 40 11 18 ## 2 2 1 2 1 Large Ensemble Memory Public Performance 33 19 18 ## 3 3 1 3 2 Large Ensemble Memory Public Performance 49 14 18 ## 4 4 1 4 3 Solo Memory Public Performance 41 19 18 ## 5 5 1 5 4 Solo Memory Student(s) 31 10 18 ## 6 6 1 6 5 Solo Memory Student(s) 33 13 18 ## 7 7 1 7 6 Solo Memory Instructor 34 11 18 ## 8 8 1 8 7 Solo Memory Juried Recital 43 13 18 ## 9 9 1 9 8 Solo Score Instructor 34 10 18 ## 10 10 1 10 9 Solo Score Student(s) 45 10 18 ## gender instrument years_study mpqab mpqsr mpqpem mpqnem mpqcon ## 1 Female voice 3 16 7 52 16 30 ## 2 Female voice 3 16 7 52 16 30 ## 3 Female voice 3 16 7 52 16 30 ## 4 Female voice 3 16 7 52 16 30 ## 5 Female voice 3 16 7 52 16 30 ## 6 Female voice 3 16 7 52 16 30 ## 7 Female voice 3 16 7 52 16 30 ## 8 Female voice 3 16 7 52 16 30 ## 9 Female voice 3 16 7 52 16 30 ## 10 Female voice 3 16 7 52 16 30 dim(music) # should be 497 x 18 ## [1] 497 18 Full Dataset 3.1.4 Some Data Wrangling We’ll select variables we’re interested in working with. select &lt;- dplyr:: select keydata &lt;- music %&gt;% dplyr::select(id, diary, perform_type, memory, audience, na, gender, instrument, mpqab, mpqpem, mpqnem) head(keydata) ## id diary perform_type memory audience na gender instrument ## 1 1 1 Solo Unspecified Instructor 11 Female voice ## 2 1 2 Large Ensemble Memory Public Performance 19 Female voice ## 3 1 3 Large Ensemble Memory Public Performance 14 Female voice ## 4 1 4 Solo Memory Public Performance 19 Female voice ## 5 1 5 Solo Memory Student(s) 10 Female voice ## 6 1 6 Solo Memory Student(s) 13 Female voice ## mpqab mpqpem mpqnem ## 1 16 52 16 ## 2 16 52 16 ## 3 16 52 16 ## 4 16 52 16 ## 5 16 52 16 ## 6 16 52 16 3.1.5 Multilevel Structure Note that we have multiple observations on the same musicians Since observations on the same musician will be correlated, we need to use a multilevel model with a random effect for musician. Level One Variables: are those measured at the most frequently occurring observational unit (the 497 performances) - negative affect (our response variable) - performance characteristics (type, audience, if music was performed from memory) - number of previous performances with a diary entry Level Two Variables: are those measured on larger observational units (the musicians) - demographics (age and gender of musician) - instrument used and number of previous years spent studying that instrument - baseline personality assessment (MPQ measures of positive emotionality, negative emotionality, constraint, stress reaction, and absorption) 3.1.6 Questions of Interest Do musicians playing orchestral instruments experience different levels or performance anxiety than those playing keyboard instruments or vocalists? Does playing in a large ensemble (as opposed to a small group or solo performance) have an impact on performance anxiety? Does the type of audience impact performance anxiety? Does performance anxiety decrease with experience? Are measures of the musician’s attitude/personality, such as positive emotions, negative emotions, and absorption associated with performance anxiety? For a single musician, is the amount of performance anxiety consistent across performances, or does it vary from one performance to the next? 3.1.7 Number of Performances by Musician When creating graphical summaries of level one covariates (variables) it is helpful to plot both 1) the 497 observations individually, and 2) averages for each of the 37 individuals, averaging across performances. Number of performances by each musician: # number of diary entries for each subject music %&gt;% count(id) ## id n ## 1 1 13 ## 2 2 14 ## 3 3 15 ## 4 5 12 ## 5 6 15 ## 6 7 15 ## 7 8 14 ## 8 9 15 ## 9 10 15 ## 10 12 13 ## 11 13 15 ## 12 15 15 ## 13 16 6 ## 14 17 15 ## 15 18 15 ## 16 19 15 ## 17 20 2 ## 18 21 15 ## 19 22 15 ## 20 24 15 ## 21 25 15 ## 22 27 15 ## 23 28 15 ## 24 29 15 ## 25 30 14 ## 26 32 15 ## 27 33 6 ## 28 34 15 ## 29 35 15 ## 30 36 15 ## 31 37 15 ## 32 38 15 ## 33 39 15 ## 34 40 15 ## 35 41 11 ## 36 42 13 ## 37 43 4 3.1.8 Number of Performances of Each Type We summarize level one covariates, ignoring the fact that there are multiple observations on the same musicians. # Exploratory data analysis # Summarize Level 1 covariates (and responses) by # ignoring within subject correlation and pretending # all observations are independent music %&gt;% count(perform_type) ## perform_type n ## 1 Large Ensemble 136 ## 2 Small Ensemble 82 ## 3 Solo 279 music %&gt;% count(audience) ## audience n ## 1 Instructor 149 ## 2 Juried Recital 44 ## 3 Public Performance 204 ## 4 Student(s) 100 3.1.9 Distribution of Negative Affect for All Performances We display the distribution of the response variable (negative affect) across all 497 performances. # create ggplot theme for plots # theme with grid, grey background theme.1 &lt;- theme(axis.title.x = element_text(size = 14), axis.title.y = element_text(size = 14), plot.title=element_text(hjust=.9,face=&quot;italic&quot;,size=12)) ## Histogram of negative affect frequencies na.all &lt;- ggplot(data=music,aes(x=na)) + geom_histogram(binwidth = 2, fill = &quot;white&quot;,color = &quot;black&quot;) + theme.1 + xlim(10,35) + xlab(&quot;Negative Affect&quot;) + ylab(&quot;Frequency&quot;) + labs(title=&quot;(a)&quot;) na.all 3.1.10 Distribution of Average Negative Affect for each Musician We also create a level two dataset, containing the average negative affect across all of the musician’s performances. # Create Level2 data set by picking off one observation # per subject, which would be easier if every subject # had a diary entry labeled &#39;1&#39; - should be 37 rows # and 6 columns (one per L2 variable) music.lev2 &lt;- keydata %&gt;% group_by(id) %&gt;% filter(row_number() == 1) %&gt;% select(id, gender:mpqnem) # Add average across all performances for each subject # for EDA plots meanbysubj &lt;- music %&gt;% group_by(id) %&gt;% summarise(meanbysubj = mean(na, na.rm = TRUE)) music.lev2 &lt;- music.lev2 %&gt;% left_join(meanbysubj, by = &quot;id&quot;) head(music.lev2) ## # A tibble: 6 × 7 ## # Groups: id [6] ## id gender instrument mpqab mpqpem mpqnem meanbysubj ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 Female voice 16 52 16 12.3 ## 2 2 Female voice 25 28 21 13.8 ## 3 3 Female voice 12 23 21 13.6 ## 4 5 Female orchestral instrument 28 54 40 18 ## 5 6 Female voice 27 58 26 12.7 ## 6 7 Female orchestral instrument 11 41 44 17.5 We display the mean negative affect scores for each of the 37 musicians. na.mean &lt;- ggplot(data=music.lev2,aes(x=meanbysubj)) + geom_histogram(binwidth = 2, fill = &quot;white&quot;, color = &quot;black&quot;) + theme.1 + xlim(10,35) + xlab(&quot;Mean Negative Affect&quot;) + ylab(&quot;Frequency&quot;) + labs(title=&quot;(b)&quot;) na.mean 3.1.11 Distribution of Level Two Covariates We examine the distribution of level 2 covariate instrument type (obtained from first performance by each musician, since these will be the same for all performances). music.lev2 %&gt;% ungroup(id) %&gt;% count(instrument) ## # A tibble: 3 × 2 ## instrument n ## &lt;chr&gt; &lt;int&gt; ## 1 keyboard (piano or organ) 5 ## 2 orchestral instrument 17 ## 3 voice 15 3.1.12 Distributions of NEM, PEM, Absorption nem1 &lt;- ggplot(data=music.lev2,aes(x=mpqnem)) + geom_histogram(binwidth = 5, fill = &quot;white&quot;, color = &quot;black&quot;) + theme.1 + xlab(&quot;NEM&quot;) + ylab(&quot;Frequency&quot;) + labs(title=&quot;(a)&quot;) pem1 &lt;- ggplot(data=music.lev2,aes(x=mpqpem)) + geom_histogram(binwidth = 5, fill = &quot;white&quot;, color = &quot;black&quot;) + theme.1 + xlab(&quot;PEM&quot;) + ylab(&quot;&quot;) + labs(title=&quot;(b)&quot;) abs &lt;- ggplot(data=music.lev2,aes(x=mpqab)) + geom_histogram(binwidth = 5, fill = &quot;white&quot;, color = &quot;black &quot;) + theme.1 + xlab(&quot;Absorption&quot;) + ylab(&quot;&quot;) + labs(title=&quot;(c)&quot;) grid.arrange(nem1,pem1,abs,ncol=3) 3.1.13 Negative Affect by Performance Type, Audience Type, and Previous Performances Boxplots of two categorical Level One covariates (performance type (a) and audience type (b)) vs. model response, and scatterplot of one continuous Level One covariate (number of previous diary entries (c)) vs. model response (negative affect). Each plot contains one observation for each of the 497 performances. # Look at relationships among Level 1 covariates and # primary response (again ignoring correlation). # Boxplots for categorical covariates and # scatterplots and lattice plot for continuous covariates. # boxplot of negative affect by performance type box.perform &lt;- ggplot(data=music,aes(factor(perform_type),na)) + geom_boxplot() + theme.1 + coord_flip() + ylab(&quot;Negative affect&quot;) + xlab(&quot;&quot;) + labs(title=&quot;(a) Negative Affect by Instrument Type&quot;) # boxplot of negative affect by audience box.audience &lt;- ggplot(data=music,aes(factor(audience),na)) + geom_boxplot() + theme.1 + coord_flip() + ylab(&quot;Negative affect&quot;) + xlab(&quot;&quot;) + labs(title=&quot;(b) Negative Affect by Performance Type&quot;) # scatterplot of negative affect versus number of # previous performances scatter.previous &lt;- ggplot(data=music, aes(x=previous,y=na)) + geom_point() + theme.1 + geom_smooth(method=&quot;lm&quot;,color=&quot;black&quot;) + ylab(&quot;Negative affect&quot;) + xlab(&quot;Previous Performances&quot;) + labs(title=&quot;(c) Negative Affect by Number of Previous Performances&quot;) # all three together grid.arrange(box.perform,box.audience,scatter.previous,ncol=2) 3.1.14 Lattice Plot for Negative Affect by Performance Type We plot negative affect by type of performance for each musician individually. (Lattice plot) # Lattice plot for NA vs. Performance Type ggplot(music,aes(x=factor(perform_type),y=na)) + theme.1 + geom_dotplot(binaxis=&quot;y&quot;,stackdir=&quot;center&quot;,binwidth=25/30) + facet_wrap(~id,ncol=5) + theme(strip.text.x=element_blank()) + coord_flip() + labs(x=&quot;Performance Type&quot;,y=&quot;Negative Affect&quot;) 3.1.15 Lattice Plot for Negative Affect by Audience Type We plot negative affect by type of audience for each musician individually. # Lattice plot for NA vs. Audience ggplot(music,aes(x=factor(audience),y=na)) + theme.1 + geom_dotplot(binaxis=&quot;y&quot;,stackdir=&quot;center&quot;,binwidth=25/30) + facet_wrap(~id,ncol=5) + theme(strip.text.x=element_blank()) + coord_flip() + labs(x=&quot;Audience&quot;,y=&quot;Negative Affect&quot;) 3.1.16 Lattice Plot for Previous Performances vs Negative Affect We plot of previous performances vs. negative affect, with separate scatterplots with fitted lines by musician # Lattice plot for NA vs. Previous Performances ggplot(music,aes(x=previous,y=na)) + theme.1 + geom_point() + geom_smooth(method=&quot;lm&quot;,color=&quot;black&quot;) + facet_wrap(~id,ncol=5) + theme(strip.text.x=element_blank()) + ylim(10,35) + labs(x=&quot;Previous Performances&quot;,y=&quot;Negative Affect&quot;) 3.1.17 Negative Affect by Instrument Type Boxplots of the categorical Level Two covariate (instrument) vs. model response (negative affect). Plot (a) is based on all 497 observations from all 37 subjects, while plot (b) uses only one observation per subject. # Look at relationships among Level 2 covariates and # negative affect (again ignoring correlation) instr.all &lt;- ggplot(data=music,aes(factor(instrument),na)) + geom_boxplot() + coord_flip() + theme.1 + ylab(&quot;Negative Affect&quot;) + xlab(&quot;&quot;) + labs(title=&quot;(a)&quot;) + ylim(10,35) instr.mean &lt;- ggplot(data=music.lev2, aes(factor(instrument),meanbysubj)) + geom_boxplot() + coord_flip() + theme.1 + ylab(&quot;Mean Negative Affect&quot;) + xlab(&quot;&quot;) + labs(title=&quot;(b)&quot;) + ylim(10,35) grid.arrange(instr.all, instr.mean, ncol = 1) 3.1.18 More Data Wrangling We create variables for whether or not musician played an orchestral instrument (as opposed to playing piano or being a vocalist), and for whether performance was part of a large ensemble (as opposed to a small ensemble or solo). 3.1.19 Lattice Plot for Large Ensemble Effect # Lattice plot for NA vs. Performance Type ggplot(music,aes(x=large,y=na)) + theme.1 + geom_point() + geom_smooth(method=&quot;lm&quot;,color=&quot;black&quot;) + facet_wrap(~id,ncol=5) + theme(strip.text.x=element_blank()) + ylim(10,35) + labs(x=&quot;Large Ensemble Performance&quot;,y=&quot;Negative Affect&quot;) 3.1.20 Boxplots for Orchestral Instrument Effect # Look at relationships among Level 2 covariates and # negative affect (again ignoring correlation) instr.all &lt;- ggplot(data=music,aes(factor(orch),na)) + geom_boxplot() + coord_flip() + theme.1 + ylab(&quot;Negative Affect&quot;) + xlab(&quot;Orchestral Instrument&quot;) + labs(title=&quot;(a)&quot;) + ylim(10,35) instr.mean &lt;- ggplot(data=music.lev2, aes(factor(orch),meanbysubj)) + geom_boxplot() + coord_flip() + theme.1 + ylab(&quot;Mean Negative Affect&quot;) + xlab(&quot;Orchestral Instrument&quot;) + labs(title=&quot;(b)&quot;) + ylim(10,35) grid.arrange(instr.all, instr.mean, ncol = 1) 3.1.21 Negative Affect by PEM, NEM, Absorption Scatterplots of continuous Level Two covariates (positive emotionality (PEM), negative emotionality (NEM), and absorption) vs. model response (negative affect). The top plots (a1, b1, c1) are based on all 497 observations from all 37 subjects, while the bottom plots (a2, b2, c2) use only one observation per subject. pem2.all &lt;- ggplot(data=music,aes(x=mpqpem,y=na)) + geom_point() + geom_smooth(method=&quot;lm&quot;,color=&quot;black&quot;) + theme.1 + ylab(&quot;Negative Affect&quot;) + xlab(&quot;PEM&quot;) + labs(title=&quot;(a1)&quot;) nem2.all &lt;- ggplot(data=music,aes(x=mpqnem,y=na)) + geom_point() + geom_smooth(method=&quot;lm&quot;,color=&quot;black&quot;) + theme.1 + ylab(&quot;&quot;) + xlab(&quot;NEM&quot;) + labs(title=&quot;(b1)&quot;) abs2.all &lt;- ggplot(data=music,aes(x=mpqab,y=na)) + geom_point() + geom_smooth(method=&quot;lm&quot;,color=&quot;black&quot;) + theme.1 + ylab(&quot;&quot;) + xlab(&quot;Absorption&quot;) + labs(title=&quot;(c1)&quot;) pem2.mean &lt;- ggplot(data = music.lev2, aes(x = mpqpem, y = meanbysubj)) + geom_point() + geom_smooth(method = &quot;lm&quot;, color = &quot;black&quot;) + theme.1 + ylab(&quot;Mean Negative Affect&quot;) + xlab(&quot;PEM&quot;) + labs(title = &quot;(a2)&quot;) nem2.mean &lt;- ggplot(data = music.lev2, aes(x = mpqnem, y = meanbysubj)) + geom_point() + geom_smooth(method = &quot;lm&quot;, color = &quot;black&quot;) + theme.1 + ylab(&quot;&quot;) + xlab(&quot;NEM&quot;) + labs(title = &quot;(b2)&quot;) abs2.mean &lt;- ggplot(data = music.lev2, aes(x = mpqab, y = meanbysubj)) + geom_point() + geom_smooth(method = &quot;lm&quot;, color = &quot;black&quot;) + theme.1 + ylab(&quot;&quot;) + xlab(&quot;Absorption&quot;) + labs(title=&quot;(c2)&quot;) mli.scatmat1 &lt;- grid.arrange(pem2.all, nem2.all, abs2.all, pem2.mean, nem2.mean, abs2.mean, ncol = 3) grid.arrange(pem2.all, nem2.all, abs2.all, pem2.mean, nem2.mean, abs2.mean, ncol = 3) 3.2 Modeling the Musician Data 3.2.1 Model Notation Let \\(Y_{ij}\\) be the negative affect (na) score of the \\(i^{th}\\) subject before performance \\(j\\). head(music) ## X id diary previous perform_type memory audience pa na age ## 1 1 1 1 0 Solo Unspecified Instructor 40 11 18 ## 2 2 1 2 1 Large Ensemble Memory Public Performance 33 19 18 ## 3 3 1 3 2 Large Ensemble Memory Public Performance 49 14 18 ## 4 4 1 4 3 Solo Memory Public Performance 41 19 18 ## 5 5 1 5 4 Solo Memory Student(s) 31 10 18 ## 6 6 1 6 5 Solo Memory Student(s) 33 13 18 ## gender instrument years_study mpqab mpqsr mpqpem mpqnem mpqcon orch large ## 1 Female voice 3 16 7 52 16 30 0 0 ## 2 Female voice 3 16 7 52 16 30 0 1 ## 3 Female voice 3 16 7 52 16 30 0 1 ## 4 Female voice 3 16 7 52 16 30 0 0 ## 5 Female voice 3 16 7 52 16 30 0 0 ## 6 Female voice 3 16 7 52 16 30 0 0 For example \\(Y_{15}=10\\). We’ll investigate the relationship between negative affect and playing an orchestral instrument (level 2), and playing in a large ensemble (level 1), as well as a possible interaction between these explanatory variables. 3.2.2 LLSR Model (Clearly inappropriate) We treat the 497 observations as independent and run a linear least-squares regression model. The model is: \\[ \\begin{align*} Y_{ij} &amp; = \\alpha_{0}+\\alpha_{1}\\textrm{Orch}_{i}+\\beta_{0}\\textrm{LargeEns}_{ij}+\\beta_{1}\\textrm{Orch}_{i}\\textrm{LargeEns}_{ij} +\\epsilon_{ij}, \\end{align*} \\] where \\(\\epsilon_{ij} \\sim\\mathcal{N}(0,\\sigma^2)\\). 3.2.3 LLSR Model Output # Linear least square regression model with LINE conditions model0 &lt;- lm(na ~ orch + large + orch:large, data = music) summary(model0) Call: lm(formula = na ~ orch + large + orch:large, data = music) Residuals: Min 1Q Median 3Q Max -7.510 -3.721 -1.444 3.279 19.279 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 15.7212 0.3591 43.778 &lt; 0.0000000000000002 *** orch 1.7887 0.5516 3.243 0.00126 ** large -0.2767 0.7910 -0.350 0.72662 orch:large -1.7087 1.0621 -1.609 0.10831 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 5.179 on 493 degrees of freedom Multiple R-squared: 0.02782, Adjusted R-squared: 0.0219 F-statistic: 4.702 on 3 and 493 DF, p-value: 0.003012 Clear violation of independence assumption! Performances by same musician likely to have higher correlation than those by different musicians. Intuitively, this model is likely to: * overestimate uncertainty associated with the level one variable (large ensemble), since it will fail to account for variability that can be explained by differences between musicians * underestimate uncertainty associated with the level two variable (orchestral instrument), since it will act as if the sample size is 497 independent performances, instead of 37 independent musicians 3.2.4 Random vs. Fixed Effects Instead, we fit a linear mixed effect model to account for the multilevel structure in the data. We’re interested in comparing axiety between instrument types (instrumental, non-instrumental) and types of performance (solos, small ensembles, and large ensembles), so instrument type and performance type are fixed effects. We’re not interested in comparing the 37 musicians themselves, but we want to account for correlation due to having multiple performances by the same musicians. We can think of them as a sample from a larger population of all musicians. Including a random effect for musician in our model helps explain variability in performance anxiety, and allows us to draw more precise conclusions about performance type. Fixed effects tell us about the mean structure (expected response). Random effects tell us about the amount of variability associated with our estimates. 3.2.5 An Initial Linear Mixed Effect Model This model has the form: \\[ \\begin{align*} Y_{ij} &amp; = \\alpha_{0}+\\alpha_{1}\\textrm{Orch}_{i}+\\beta_{0}\\textrm{LargeEns}_{ij}+\\beta_{1}\\textrm{Orch}_{i}\\textrm{LargeEns}_{ij} + u_{i}+\\epsilon_{ij}, \\end{align*} \\] where \\(u_i \\sim\\mathcal{N}(0,\\sigma^2_u)\\), and \\(\\epsilon_{ij} \\sim\\mathcal{N}(0,\\sigma^2)\\). We assume \\(u_i\\) and \\(\\epsilon_{ij}\\) are independent. \\(u_i\\) is a random effect corresponding to musician id. 3.2.6 Initial Mixed Effects Model in R We fit the model using the lmer() function in the lme4 package. If the the lmerTest package is loaded, approximate p-values are returned. These are approximate, because the exact distribution of the t-statistics is unknown. Satterthwaite showed that these t-statistics approximately follow t-distributions, with non-integer degrees of freedom. model1 &lt;- lmer(data=music, na ~ orch + large + orch:large + (1 | id), REML=TRUE) summary(model1) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ orch + large + orch:large + (1 | id) Data: music REML criterion at convergence: 2987.4 Scaled residuals: Min 1Q Median 3Q Max -1.9216 -0.6688 -0.1564 0.5043 4.1699 Random effects: Groups Name Variance Std.Dev. id (Intercept) 5.131 2.265 Residual 21.882 4.678 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 15.9026 0.6187 41.4059 25.703 &lt;0.0000000000000002 *** orch 1.7100 0.9131 42.8467 1.873 0.0679 . large -0.8918 0.8415 473.6492 -1.060 0.2898 orch:large -1.4650 1.0880 488.6918 -1.347 0.1788 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) orch large orch -0.678 large -0.282 0.191 orch:large 0.218 -0.308 -0.773 3.2.7 Mixed Effects Model Interpretations For orch=0, the prediction equation is: \\[ \\hat{Y}_{ij} = \\alpha_{0}+\\beta_{0}\\textrm{LargeEns}_{ij} \\] we estimate that the average negative affect score for performers with non-orchestral instruments when playing a solo or with a small ensemble is \\(\\hat{\\alpha}_0 = 15.9\\). We estimate that for non-orchestral musicians, average negative affect is \\(\\hat{\\beta}_0 = -0.89\\) (i.e. 0.89 points lower) when performing in a large ensemble, compared with playing in a small ensemble or a solo. For orch=1, the prediction equation is: \\[ \\hat{Y}_{ij} = (\\alpha_{0}+\\alpha_{1})+(\\beta_{0} + \\beta_1)\\textrm{LargeEns}_{ij} \\] we estimate that the average negative affect score for performers with orchestral instruments when performing in solos or small ensembles is \\(\\hat{\\alpha}_0 + \\hat{\\alpha}_0 = 17.3\\). We estimate that for orchestral musicians, average negative affect is \\(\\hat{\\beta}_0 + \\hat{\\beta}_1 = -0.89 - 1.46 = -2.35\\) (i.e. 2.35 points lower) when performing in a large ensemble, compared with playing in a small ensemble or a solo. Negative affect score tends to be higher for orchestral musicians than non orchestral musicians when performing solos or in small ensembles, but that negative affect also decreases more for orchestral musicians than non-orchestral musicians, when playing in a large ensemble. The interaction term is not statistically significany, indicating it is plausible that the effect of playing in a large ensemble, compared to a solo or with a small ensemble is the same for orchestral and non-orchestral musicians. After accounting for performance type and instrument type, and their interaction, the standard deviation in negative affect scores between different musicians is estimated to be \\(\\hat{\\sigma}_u=2.265\\). After accounting for performance type, instrument type, and their interaction, the standard deviation in negative affect scores between different performances by the same musician is estimated to be \\(\\hat{\\sigma}_u=4.68\\). There is more variability in negative affect between different performances by the same musician than between performances by different musicians, after accounting for performance type, instrument type, and their interaction. Standard errors on level 1 variable orch goes up considerably, which is expected since the mixed effects model understands that the appropriate sampel size is the 37 musicians not the 497 performances. Standard errors on level 2 variable large and the interaction go up slightly as well. This is different than what we’ve seen before. Since there is more variability between individual performances, than between musicians (\\(\\sigma&gt;\\sigma_l\\)), accounting for variability explained by performers does not improve precision of estimates. 3.2.8 Mixed Effects Model Without Interaction We might drop the interaction term to make interpretation easier. This gives the model: \\[ \\begin{align*} Y_{ij} &amp; = \\alpha_{0}+\\alpha\\textrm{Orch}_{i}+\\beta\\textrm{LargeEns}_{ij} + u_{i}+\\epsilon_{ij}, \\end{align*} \\] where \\(u_i \\sim\\mathcal{N}(0,\\sigma_u^2)\\), and \\(\\epsilon_{ij} \\sim\\mathcal{N}(0,\\sigma^2)\\). We assume \\(u_i\\) and \\(\\epsilon_{ij}\\) are independent. model1b &lt;- lmer(data=music, na ~ orch + large + (1 | id), REML=TRUE) summary(model1b) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ orch + large + (1 | id) Data: music REML criterion at convergence: 2991.2 Scaled residuals: Min 1Q Median 3Q Max -1.9316 -0.6953 -0.1835 0.4684 4.1262 Random effects: Groups Name Variance Std.Dev. id (Intercept) 5.214 2.283 Residual 21.901 4.680 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 16.0853 0.6074 38.0476 26.482 &lt; 0.0000000000000002 *** orch 1.3317 0.8742 35.4893 1.523 0.136533 large -1.7707 0.5339 493.3004 -3.317 0.000978 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) orch orch -0.658 large -0.182 -0.077 3.2.9 Interpretations for Model without Interaction we estimate that the average negative affect score for performers with non-orchestral instruments when playing a solo or with a small ensemble is \\(\\hat{\\alpha}_0 = 16.09\\). We estimate that, average negative affect is \\(\\hat{\\alpha}_1 = 1.33\\) points higher for musicians playing an orchestral instrument, compared to those playing a keyboard or vocalists, assuming performance type is the same. We estimate that, average negative affect is \\(\\hat{\\beta}_0 = -1.77\\) points (i.e. 1.78 points lower) when performing in a large ensemble, compared with playing in a small ensemble or a solo, assuming instrumental type is the same. After accounting for performance type and instrument type there the standard deviation in negative affect scores between different musicians is estimated to be \\(\\hat{\\sigma}_u=2.28\\). After accounting for performance type, instrument type, there the standard deviation in negative affect scores between different performances by the same musician is estimated to be \\(\\hat{\\sigma}=4.68\\). There is more variability in negative affect between different performances by the same musician than between performances by different musicians, after accounting for performance type, instrument type. 3.2.10 Assumptions in First Mixed Effects Model This model assumes that: Expected negative affect differs between instrument types and performance types, and, in the case of the model with interaction, the effect of performing in a large ensemble is allowed to differ between musicians playing orchestral instruments and those playing and non-orchestral instruments . Negative affect scores for different musicians deviate from one another according to a normal distribution with mean 0 and standard deviation \\(\\sigma_u\\) (introducing correlation in error terms between performances by the same musician). For each musician, negative affect scores between performances deviate from each other according to a normal distribution with standard deviation \\(\\sigma\\). The random effect for musician, \\(u_i\\) is uncorrelated with random error term \\(\\epsilon_{ij}\\) and also with all fixed effects in the model. (That is, there is no relationship between musicians’ performance anxiety and instrument/ensemble type, beyond what is accounted for in the fixed-effect structure of the model. 3.3 Random Slopes Model 3.3.1 Differences in Large vs Small/Solo The random effect \\(u_i\\) in the previous model captures random deviations in negative affect score between individual musicians, after accounting for instrument type and performance type. The model assumes that the difference in negative affect, when performing in an ensemble compared to performing a solo or in a small ensemble is constant accross musicians. This difference can be estimated using fixed effects (e.g. \\(\\beta\\)). Alternatively, we might want to build a model that allows differences in negative affect between solos/small ensemble performances and large ensemble performances to vary randomly between performers. Recall the lattice plot: # Lattice plot for NA vs. Performance Type ggplot(music,aes(x=large,y=na)) + theme.1 + geom_point() + geom_smooth(method=&quot;lm&quot;,color=&quot;black&quot;) + facet_wrap(~id,ncol=5) + theme(strip.text.x=element_blank()) + ylim(10,35) + labs(x=&quot;Large Ensemble Performance&quot;,y=&quot;Negative Affect&quot;) 3.3.2 Illustration of Previous Model model1 allows base performance anxiety to vary between musicians, after accounting for fixed effects, but assumes that the effect of playing in a large ensemble is the same across musicians This is shown in the following illustration, which includes effects for the 20 musicians playing non-orchestral instruments. The thick black line shows the expected performance anxiety, given by \\(\\hat{Y} = 16.09 - 1.77\\textrm{LargeEns}_{ij}\\) Deviations from the line are due to performer effect \\(u_i\\). 3.3.3 Illustration of New (Random Slopes) Model An alternative model would allow not only base performance anxiety to vary between musicians, after accounting for fixed effects, but also allow the effect of playing in a large ensemble to vary between musicians. This is illustrated in the graphic below. Notice the lines are no longer parallel, and that musicians with larger negative affect scores to begin with tend to see bigger decreases when playing in a large ensemble. 3.3.4 Random Slopes Model We allow for differences in the effect of playing in a large ensemble, between musicians, by adding a random effect for the slope (or in this case difference) between performance types for each performer. Model: \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0}+\\alpha\\textrm{Orch}_{i}+\\beta\\textrm{LargeEns}_{ij}] \\textrm{} + [u_{i}+v_{i}\\textrm{LargeEns}_{ij}+\\epsilon_{ij}] \\end{align*} \\] The first set of brackets describes the fixed effects, or expectation structure, and the second set describes the random component, or variability associated with performances. \\(u_i\\) - (the random intercept) is a random effect pertaining to negative affect scores between musicians for solos/small ensembles (one \\(u\\) for each musician). \\(v_i\\) - (the random slope) is a random effect pertaining to changes in negative affect scores for large ensemble performances, compared to solo/small ensemble performances for individual musicians (one \\(v\\) for each musician). \\(\\epsilon_{ij}\\) - is a random error term pertaining to differences between individual performances by the same musician. (one \\(\\epsilon\\) per performance.) 3.3.5 Specifying Distribution of Random Effects We still assume all of the random effects, \\(u_i\\), \\(v_i\\), and \\(\\epsilon_{ij}\\) follow normal distributions. assume that the errors associated with each performance of a particular musician can be described as: \\(\\epsilon_{ij}\\sim N(0,\\sigma^2)\\). We allow for the possibility of correlation between intercept \\(u_i\\) and slope \\(v_i\\) for user i. This allows the for possibility that musicians with higher performance anxiety playing solos or in small ensembles might see a more (or less) decrease when playing in a large ensemble than those with less performance anxiety when playing solos or in small ensembles. To allow for this correlation, we assume that \\(u_i\\) and \\(v_i\\) follow a multivariate normal distribution Mathematically, we can express this as: \\[ \\begin{equation*} \\left[ \\begin{array}{c} u_{i} \\\\ v_{i} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{u}^{2} &amp; \\rho_{uv}\\sigma_{u}\\sigma_v \\\\ \\rho_{uv}\\sigma_{u}\\sigma_v &amp; \\sigma_{v}^{2} \\end{array} \\right] \\right) \\end{equation*} \\] where \\(\\sigma_{u}^{2}\\) is the variance of the \\(u_{i}\\) terms, \\(\\sigma_{v}^{2}\\) is the variance of the \\(v_{i}\\) terms, and \\[ \\begin{equation*} \\rho_{uv} = \\frac{\\sigma_{uv}}{\\sigma_{u}\\sigma_{v}} \\end{equation*} \\] represents the correlation between \\(u_i\\) and \\(v_i\\) \\((-1\\leq\\rho_{uv}\\leq1)\\). \\(\\sigma_{uv}\\) is the covariance between the \\(u_{i}\\) and the \\(v_{i}\\) terms (describing how those two terms vary together). We still assume \\(\\epsilon_{ij}\\) is independent of \\(u_i\\) and \\(v_i\\). 3.3.6 Random Slopes Model with Error Term Distributions Model: \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0}+\\alpha\\textrm{Orch}_{i}+\\beta\\textrm{LargeEns}_{ij}] \\textrm{} + [u_{i}+v_{i}\\textrm{LargeEns}_{ij}+\\epsilon_{ij}] \\end{align*} \\] \\(\\epsilon_{ij}\\sim N(0,\\sigma^2)\\), and \\[ \\begin{equation*} \\left[ \\begin{array}{c} u_{i} \\\\ v_{i} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{u}^{2} &amp; \\rho_{uv}\\sigma_{u}\\sigma_v \\\\ \\rho_{uv}\\sigma_{u}\\sigma_v &amp; \\sigma_{v}^{2} \\end{array} \\right] \\right) \\end{equation*} \\] 3.3.7 Random Slopes Model in R To fit the random slopes model in R, we write (large | id), instead of (1 | id). model2b &lt;- lmer(data=music, na ~ orch + large + (large | id), REML=TRUE) summary(model2b) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ orch + large + (large | id) Data: music REML criterion at convergence: 2990.7 Scaled residuals: Min 1Q Median 3Q Max -1.9563 -0.6808 -0.1900 0.4821 4.1544 Random effects: Groups Name Variance Std.Dev. Corr id (Intercept) 5.8311 2.4148 large 0.7198 0.8484 -0.59 Residual 21.7807 4.6670 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 16.1722 0.6210 36.3694 26.043 &lt; 0.0000000000000002 *** orch 1.1911 0.8710 35.6123 1.367 0.18005 large -1.7474 0.5485 28.6734 -3.186 0.00347 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) orch orch -0.642 large -0.253 -0.102 we estimate that the average negative affect score for performers with non-orchestral instruments when playing a solo or with a small ensemble is \\(\\hat{\\alpha}_0 = 16.17\\). We estimate that, average negative affect is \\(\\hat{\\alpha}_1 = 1.19\\) points higher for musicians playing an orchestral instrument, compared to those playing a keyboard or vocalists, assuming type of performance is the same. We estimate that, average negative affect is \\(\\hat{\\beta}_0 = -1.75\\) points (i.e. 1.75 points lower) when performing in a large ensemble, compared with playing in a small ensemble or a solo, assuming instrument type is the same. After accounting for performance type and instrument type the standard deviation in negative affect scores between different musicians for solos/small ensembles is estimated to be \\(\\hat{\\sigma}_u=2.41\\). After accounting for performance type and instrument type the standard deviation in changes in negative affect scores for large ensemble performances, compared to solo/small ensemble performances is estimated to be \\(\\hat{\\sigma}_v=0.85\\). After accounting for performance type, and instrument type, the standard deviation in negative affect scores between different performances by the same musician is estimated to be \\(\\hat{\\sigma}=4.67\\). The correlation between negative affect scores for solos/small ensembles and change in negative affect scores when playing in large ensembles is \\(\\rho_{uv}=-0.59\\), indicating a negative correlation. Musicians with larger negative effect scores for solo/small ensemble performances see tend to have greater decreases in performance anxiety for large ensemble performances. 3.3.8 More on Interpreting Parameters Both \\(\\beta=-1.75\\) and \\(\\rho_{uv}=-0.59\\) seem to suggest negative relationships involving performance anxiety associated with playing in a large ensemble. Let’s think carefully about what each of these tells us, and how they’re different. \\(\\beta=-1.75\\) tells us that on average, a musicians’s negative affect score for performance anxiety is expected to decrease by 1.74 points when playing in a large ensemble, compared to a solo or small ensemble performance. \\(\\rho_{uv} = -0.59\\) tells us that musicians who have higher performance anxiety than expected when playing a solo or small ensemble tend to see a bigger decrease in anxiety when playing in a large ensemble than those who have less anxiety playing in a solo or small ensemble. Illustration: Each line represents one of the 20 musicians who play nonorchestral instruments. The thick black line represents the expectation function \\(\\hat{Y} = 16.17 - 1.75\\textrm{LargeEns}_{ij}\\). \\(\\beta=1.74\\) is indicated by negative slope on thick black line \\(\\rho_{uv}=-0.59\\) is indicated by lines with bigger negative affects on left having steeper negative slopes. Thought Question: Why would it not make sense to add a random slope for instrument type? 3.3.9 Model Comparisons We can compare the models using AIC and BIC. AIC(model2b, model1b) ## df AIC ## model2b 7 3004.667 ## model1b 5 3001.200 BIC(model2b, model1b) ## df BIC ## model2b 7 3034.127 ## model1b 5 3022.243 parameter estimates for the remaining 6 fixed effects and variance components closely mirror the corresponding parameter estimates from the first model. Removing the error term on the slope has improved (reduced) both the AIC and BIC measures of overall model performance. Instead of assuming that the large ensemble effects, after accounting for instrument played, vary by individual, we’ll assume that large ensemble effect is fixed across subjects. It is often beneficial to use an error term on the intercept equation to account for differences between subjects, but with no random slope terms unless there is an a priori reason to allow effects to vary by subject or if the model performs better after building in those additional error terms. 3.3.10 Random Slopes Model with Interaction Model: \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0}+\\alpha_1\\textrm{Orch}_{i}+\\beta_0\\textrm{LargeEns}_{ij} + \\beta_1\\textrm{Orch}_{i}\\textrm{LargeEns}_{ij}] \\\\ \\textrm{} &amp;+ [u_{i}+v_{i}\\textrm{LargeEns}_{ij}+\\epsilon_{ij}] \\end{align*} \\] \\(\\epsilon_{ij}\\sim N(0,\\sigma^2)\\), and \\[ \\begin{equation*} \\left[ \\begin{array}{c} u_{i} \\\\ v_{i} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{u}^{2} &amp; \\rho_{uv}\\sigma_{u}\\sigma_v \\\\ \\rho_{uv}\\sigma_{u}\\sigma_v &amp; \\sigma_{v}^{2} \\end{array} \\right] \\right) \\end{equation*} \\] 3.3.11 Random Slopes Model with Interaction in R model2 &lt;- lmer(data=music, na ~ orch + large + orch:large + (large | id), REML=TRUE) summary(model2) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ orch + large + orch:large + (large | id) Data: music REML criterion at convergence: 2987 Scaled residuals: Min 1Q Median 3Q Max -1.9404 -0.6625 -0.1771 0.4796 4.1860 Random effects: Groups Name Variance Std.Dev. Corr id (Intercept) 5.655 2.3781 large 0.452 0.6723 -0.63 Residual 21.807 4.6698 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 15.9297 0.6415 32.2972 24.833 &lt;0.0000000000000002 *** orch 1.6926 0.9452 33.6207 1.791 0.0824 . large -0.9106 0.8452 41.5021 -1.077 0.2876 orch:large -1.4239 1.0992 31.6101 -1.295 0.2046 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) orch large orch -0.679 large -0.368 0.250 orch:large 0.283 -0.402 -0.769 3.3.12 Random Slope vs Interaction Term At first glance, a random slopes model might seem similar to a model with interaction. These are however, different things. An interaction model allows the average effect of an explanatory variable on the response to differ, depending on values of other explanatory variables. A random slopes model allows the effect of an explanatory variable on a single individual to differ from one individual to another. Illustration: Interaction is illustrated by the fact that the thick blue line is steeper than the thick red line, indicating that on average, musician playing orchestral instruments experience larger decreases in performance anxiety than vocalists or keyboard instrumentalists. The random effect for slope is illustrated by the fact that the thinner lines, representing individual musicians, have different slopes. Some musicians see greater decreases in performance anxiety than others when playing in a large ensemble. Often those with highest performance anxieties when playing solos or in small ensembles see the greatest decreses in anxiety when playing in a large ensemble. 3.4 Unconditional Means Model 3.4.1 Unconditional Means Model Formulation When building models, it is often helpful to start with a model that does not include any explatory variables. This model allows us to compare variability within subject to variability between subjects. This model is called an unconditional means model (or random intercepts model). Model: \\[ \\begin{equation*} Y_{ij}=\\alpha_{0}+u_{i}+\\epsilon_{ij} \\end{equation*} \\] where \\(u_i\\sim N(0, \\sigma^2_u)\\) and \\(\\epsilon_{ij}\\sim N(0, \\sigma^2)\\). the true mean response of all observations for subject \\(i\\) is \\(\\alpha_0 + u_i\\) \\(\\alpha_{0}\\) is the grand mean – the true mean of all observations across the entire population. \\(\\sigma^2\\) is the within-person variability \\(\\sigma_{u}^{2}\\) is the between-person variability. 3.4.2 Unconditional Means Model in R #Model A (Unconditional means model) model.a &lt;- lmer(na ~ 1 + (1 | id), REML = TRUE, data = music) summary(model.a) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ 1 + (1 | id) Data: music REML criterion at convergence: 3005.8 Scaled residuals: Min 1Q Median 3Q Max -1.9041 -0.6894 -0.2076 0.5284 4.1286 Random effects: Groups Name Variance Std.Dev. id (Intercept) 4.95 2.225 Residual 22.46 4.739 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 16.2370 0.4279 36.6717 37.94 &lt;0.0000000000000002 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 3.4.3 Unconditional Means Model Interpretations \\(\\hat{\\alpha}_{0}=16.2=\\) the estimated mean performance anxiety score across all performances and all subjects. \\(\\hat{\\sigma}_{u}=2.225=\\) the estimated standard deviation in average performance anxiety scores between different musicians (between-subject variability). \\(\\hat{\\sigma}=4.739=\\) the estimated standard deviation in performance anxiety scores between performances by the same musician (within-subject variability). The relative levels of between- and within-person variability can be compared through the intraclass correlation coefficient. \\[ \\begin{equation*} \\hat{\\rho}=\\frac{\\textrm{Between-person variability}}{\\textrm{Total variability}} = \\frac{\\hat{\\sigma}_{u}^{2}}{\\hat{\\sigma}_{u}^{2}+\\hat{\\sigma}^2} = \\frac{5.0}{5.0+22.5} = .182. \\end{equation*} \\] Thus, 18.2% of the total variability in performance anxiety scores are attributable to differences among musicians In this particular model, we can also say that the average correlation for any pair of responses from the same individual is a moderately low .182. 3.5 Building A Multilevel Model We now return to the multi-level model from section 8.5 that included orch and Large as explanatory variables, as well as random effects for the intercept and effect of playing in a large ensemble for each musician. We add negative emotionality (MPQnem) as a Level Two predictor. \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0}+\\alpha_{1}\\textrm{Orch}_{i}+\\alpha_{2}\\textrm{MPQnem}_{i}+\\beta_{0}\\textrm{LargeEns}_{ij} \\\\ &amp; \\textrm{} + \\beta_{1}\\textrm{Orch}_{i}\\textrm{LargeEns}_{ij}+\\beta_{2}\\textrm{MPQnem}_{i}\\textrm{LargeEns}_{ij}] \\\\ &amp; \\textrm{} + [u_{i}+v_{i}\\textrm{LargeEns}_{ij}+\\epsilon_{ij}] \\end{align*} \\] where error terms are defined as before. #Add negative emotionality as second L2 covariate model3 &lt;- lmer(na ~ orch + mpqnem + large + (1 | id), data = music, REML=TRUE) summary(model3) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ orch + mpqnem + large + (1 | id) Data: music REML criterion at convergence: 2981.4 Scaled residuals: Min 1Q Median 3Q Max -2.0473 -0.6655 -0.1542 0.4747 4.0114 Random effects: Groups Name Variance Std.Dev. id (Intercept) 2.991 1.730 Residual 21.884 4.678 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 11.79704 1.12576 33.69922 10.479 0.00000000000386 *** orch 0.77284 0.73202 34.29199 1.056 0.298462 mpqnem 0.14375 0.03406 33.93766 4.221 0.000172 *** large -1.83298 0.52531 480.85113 -3.489 0.000529 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) orch mpqnem orch -0.121 mpqnem -0.894 -0.183 large -0.031 -0.079 -0.073 3.5.1 Centering Covariates It makes no sense to draw conclusions about performance anxiety levels for subjects with MPQNEM scores of 0 at baseline (as in \\(\\hat{\\beta}_{0}\\)), since the minimum NEM composite score among subjects in this study was 11. We subtract the mean, so that a value of 0 now correspons to the average MPQnem. music &lt;- music %&gt;% mutate(cmpqnem = mpqnem - mean(mpqnem)) # Model E (Center baseline NEM in Model D) model3c &lt;- lmer(na ~ orch + cmpqnem + large + (1 | id), data = music, REML=TRUE) summary(model3c) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ orch + cmpqnem + large + (1 | id) Data: music REML criterion at convergence: 2981.4 Scaled residuals: Min 1Q Median 3Q Max -2.0473 -0.6655 -0.1542 0.4747 4.0114 Random effects: Groups Name Variance Std.Dev. id (Intercept) 2.991 1.730 Residual 21.884 4.678 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 16.34397 0.50861 37.71295 32.135 &lt; 0.0000000000000002 *** orch 0.77284 0.73202 34.29199 1.056 0.298462 cmpqnem 0.14375 0.03406 33.93766 4.221 0.000172 *** large -1.83298 0.52531 480.85113 -3.489 0.000529 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) orch cmpqnm orch -0.655 cmpqnem 0.139 -0.183 large -0.223 -0.079 -0.073 Notice that only the intercept changes, since this is the only interpretation that depends on setting the mpqnem value equal to 0. Interpretation of Intercept: \\(\\hat{\\alpha}_{0} = 16.34\\). The estimated mean performance anxiety for solos and small ensembles (large=0) is 16.34 for keyboard players and vocalists (orch=0) with an average level of negative emotionality at baseline (mpqnem=31.63). 3.5.2 A Possible Final Model We’ll add information about the following level 1 variables, pertaining to individual performances: * number of previous performances, * whether the audience is made up of students, * whether the performance is juried, * whether it is public, * whether it is a solo We’ll also consider the following level 2 variables, pertaining to musicians: * mpqpem (positive emotion) * mpqab (absorption) * orch (orchestral instument) * mpqnem (negative emotion) We consider three potential final models: Model A: A two-level model with random slopes and an interaction between solo and mpqnem. \\[ \\begin{equation*} Y_{ij} = a_{i}+b_{i}\\textrm{previous}_{ij}+c_{i}\\textrm{students}_{ij}+ d_{i}\\textrm{juried}_{ij}+e_{i}\\textrm{public}_{ij}+f_{i}\\textrm{solo}_{ij}+\\epsilon_{ij} \\end{equation*} \\] - Level Two: \\[ \\begin{align*} a_{i} &amp; = \\alpha_{0}+\\alpha_{1}\\textrm{mpqpem}_{i}+\\alpha_{2}\\textrm{mpqab}_{i} + \\alpha_{3}\\textrm{orch}_{i}+\\alpha_{4}\\textrm{mpqnem}_{i}+u_{i} \\\\ b_{i} &amp; = \\beta_{0}+v_{i}, \\\\ c_{i} &amp; = \\gamma_{0}+w_{i}, \\\\ d_{i} &amp; = \\delta_{0}+x_{i}, \\\\ e_{i} &amp; = \\varepsilon_{0}+y_{i}, \\\\ f_{i} &amp; = \\zeta_{0}+\\zeta_{1}\\textrm{mpqnem}_{i}+z_{i}, \\end{align*} \\] After substitution, this can be written in the form \\[ \\begin{align*} Y_{ij} &amp; = \\alpha_{0}+\\alpha_{1}\\textrm{mpqpem}_{i} + \\alpha_{2}\\textrm{mpqab}_{i} + \\alpha_{3}\\textrm{orch}_{i}+\\alpha_{4}\\textrm{mpqnem}_{i} + u_{i} \\\\ &amp; +\\beta_{0}\\textrm{previous}_{ij} + v_{i}\\textrm{previous}_{ij} + \\gamma_{0}\\textrm{students}+w_{i}\\textrm{students}_{ij} + \\delta_{0}\\textrm{juried}_{ij}+x_{i}\\textrm{juried}_{ij} \\\\ &amp; + \\varepsilon_{0}\\textrm{public}+y_{i}\\textrm{public}_{ij}+ \\zeta_{0}\\textrm{solo}_{ij}+\\zeta_{1}\\textrm{mpqnem}_{i}\\textrm{solo}_{ij} \\\\ &amp; + z_{i}\\textrm{solo}_{ij}+\\epsilon_{ij} \\end{align*} \\] Grouping fixed and random effects, we get \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0}+\\alpha_{1}\\textrm{mpqpem}_{i} + \\alpha_{2}\\textrm{mpqab}_{i} + \\alpha_{3}\\textrm{orch}_{i}+\\alpha_{4}\\textrm{mpqnem}_{i} \\\\ &amp; +\\beta_{0}\\textrm{previous}_{ij} + \\gamma_{0}\\textrm{students} + \\delta_{0}\\textrm{juried}_{ij} + \\varepsilon_{0}\\textrm{public} + \\zeta_{0}\\textrm{solo}_{ij} +\\zeta_{1}\\textrm{mpqnem}_{i}\\textrm{solo}_{ij}] \\\\ &amp; + [u_{i} + v_{i}\\textrm{previous}_{ij} +w_{i}\\textrm{students}_{ij} +x_{i}\\textrm{juried}_{ij} +y_{i}\\textrm{public}_{ij} \\\\ &amp; + z_{i}\\textrm{solo}_{ij}+\\epsilon_{ij} ] \\end{align*} \\] This model accounts for random differences in performance anxiety between musicians, and also allows for the way anxiety changes with respect to changes in level one variables (previous, students, juried, public, solo, mpqnem) to vary randomly between performers. In addition, we assume the following variance-covariance structure at Level Two: \\[ \\left[ \\begin{array}{c} u_{i} \\\\ v_{i} \\\\ w_{i} \\\\ x_{i} \\\\ y_{i} \\\\ z_{i} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cccccc} \\sigma_{u}^{2} &amp; &amp; &amp; &amp; &amp; \\\\ \\sigma_{uv} &amp; \\sigma_{v}^{2} &amp; &amp; &amp; &amp; \\\\ \\sigma_{uw} &amp; \\sigma_{vw} &amp; \\sigma_{w}^{2} &amp; &amp; &amp; \\\\ \\sigma_{ux} &amp; \\sigma_{vx} &amp; \\sigma_{wx} &amp; \\sigma_{x}^{2} &amp; &amp; \\\\ \\sigma_{uy} &amp; \\sigma_{vy} &amp; \\sigma_{wy} &amp; \\sigma_{xy} &amp; \\sigma_{y}^{2} &amp; \\\\ \\sigma_{uz} &amp; \\sigma_{vz} &amp; \\sigma_{wz} &amp; \\sigma_{xz} &amp; \\sigma_{yz} &amp; \\sigma_{z}^{2} \\end{array} \\right] \\right). \\] Being able to write out these mammoth variance-covariance matrices is less important than recognizing the number of variance components that must be estimated by our intended model. 3.5.3 More Data Wrangling # Add new indicators to music data set music &lt;- music %&gt;% mutate(students = ifelse(audience==&quot;Student(s)&quot;,1,0), juried = ifelse(audience==&quot;Juried Recital&quot;,1,0), public = ifelse(audience==&quot;Public Performance&quot;,1,0), solo = ifelse(perform_type==&quot;Solo&quot;,1,0), memory1 = ifelse(memory==&quot;Memory&quot;,1,0), female = ifelse(gender==&quot;Female&quot;,1,0), vocal = ifelse(instrument==&quot;voice&quot;,1,0) ) 3.5.4 Fitting Model A modelA &lt;- lmer(na ~ previous + students + juried + public + solo + mpqpem + mpqab + orch + mpqnem + mpqnem:solo + (previous + students + juried + public + solo | id), data = music, REML=TRUE) summary(modelA) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ previous + students + juried + public + solo + mpqpem + mpqab + orch + mpqnem + mpqnem:solo + (previous + students + juried + public + solo | id) Data: music REML criterion at convergence: 2882.3 Scaled residuals: Min 1Q Median 3Q Max -2.1919 -0.6058 -0.1118 0.5345 3.9995 Random effects: Groups Name Variance Std.Dev. Corr id (Intercept) 14.4566 3.8022 previous 0.0707 0.2659 -0.65 students 8.2131 2.8659 -0.63 0.00 juried 18.3331 4.2817 -0.64 -0.12 0.83 public 12.7857 3.5757 -0.83 0.33 0.66 0.57 solo 0.7663 0.8754 -0.67 0.47 0.49 0.20 0.90 Residual 15.2843 3.9095 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 8.37271 1.91346 63.87462 4.376 0.0000457 *** previous -0.14303 0.06247 37.27430 -2.290 0.027794 * students 3.61094 0.76792 32.20414 4.702 0.0000465 *** juried 4.07294 1.03152 36.39148 3.948 0.000346 *** public 3.06498 0.89233 36.54339 3.435 0.001492 ** solo 0.51323 1.39646 262.84884 0.368 0.713527 mpqpem -0.08315 0.02407 38.74755 -3.454 0.001352 ** mpqab 0.20382 0.04740 35.95499 4.300 0.000125 *** orch 1.53123 0.58387 42.87273 2.623 0.012034 * mpqnem 0.11453 0.03590 43.18022 3.190 0.002650 ** solo:mpqnem 0.08308 0.04158 171.42767 1.998 0.047323 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) previs stdnts juried public solo mpqpem mpqab orch previous -0.230 students -0.261 -0.027 juried -0.252 -0.084 0.543 public -0.350 0.156 0.583 0.434 solo -0.449 -0.014 0.084 -0.003 0.220 mpqpem -0.392 0.010 0.002 0.026 -0.003 -0.068 mpqab -0.397 -0.017 -0.010 -0.034 -0.061 -0.030 -0.259 orch 0.088 -0.036 0.000 0.026 0.035 0.111 -0.244 -0.065 mpqnem -0.556 -0.024 -0.017 0.053 -0.038 0.635 -0.061 0.065 -0.131 solo:mpqnem 0.345 0.052 0.034 0.033 0.045 -0.906 0.067 0.019 -0.056 mpqnem previous students juried public solo mpqpem mpqab orch mpqnem solo:mpqnem -0.698 optimizer (nloptwrap) convergence code: 0 (OK) Model failed to converge with max|grad| = 0.0157114 (tol = 0.002, component 1) 3.5.5 A Model Without Random Slopes We consider eliminating the random slope terms, resulting in a model of the form: \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0}+\\alpha_{1}\\textrm{mpqpem}_{i} + \\alpha_{2}\\textrm{mpqab}_{i} + \\alpha_{3}\\textrm{orch}_{i}+\\alpha_{4}\\textrm{mpqnem}_{i} \\\\ &amp; +\\beta_{0}\\textrm{previous}_{ij} + \\gamma_{0}\\textrm{students} + \\delta_{0}\\textrm{juried}_{ij} + \\varepsilon_{0}\\textrm{public} + \\zeta_{0}\\textrm{solo}_{ij} +\\zeta_{1}\\textrm{mpqnem}_{i}\\textrm{solo}_{ij}] \\\\ &amp; + [u_{i} +\\epsilon_{ij} ] \\end{align*} \\] This model accounts for random differences in performance anxiety between musicians, but assumes that the way anxiety changes with respect to changes in level one variables (previous, students, juried, public, solo, mpqnem) is the same for all performers. 3.5.6 Fitting Model B in R modelB &lt;- lmer(na ~ previous + students + juried + public + solo + mpqpem + mpqab + orch + mpqnem + mpqnem:solo + (1 | id), data = music, REML=TRUE) summary(modelB) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ previous + students + juried + public + solo + mpqpem + mpqab + orch + mpqnem + mpqnem:solo + (1 | id) Data: music REML criterion at convergence: 2920.3 Scaled residuals: Min 1Q Median 3Q Max -1.9919 -0.7026 -0.1252 0.5162 3.9367 Random effects: Groups Name Variance Std.Dev. id (Intercept) 1.848 1.36 Residual 19.272 4.39 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 7.70582 1.99554 51.87716 3.862 0.000314 *** previous -0.12817 0.04677 473.53232 -2.740 0.006368 ** students 3.75767 0.61372 485.24491 6.123 0.0000000019 *** juried 4.28176 0.78158 483.19106 5.478 0.0000000692 *** public 3.09805 0.66208 481.42142 4.679 0.0000037469 *** solo -0.26784 1.41139 469.85154 -0.190 0.849569 mpqpem -0.05917 0.02795 30.52940 -2.117 0.042531 * mpqab 0.19185 0.05610 33.15989 3.420 0.001678 ** orch 1.23579 0.65797 34.10231 1.878 0.068929 . mpqnem 0.10568 0.03743 69.85950 2.823 0.006188 ** solo:mpqnem 0.10640 0.04144 416.29568 2.567 0.010596 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) previs stdnts juried public solo mpqpem mpqab orch previous -0.120 students -0.157 -0.042 juried -0.103 -0.065 0.309 public -0.225 -0.015 0.526 0.315 solo -0.424 -0.060 0.073 0.010 0.220 mpqpem -0.398 0.000 -0.007 -0.004 -0.016 -0.023 mpqab -0.389 -0.001 -0.029 -0.036 -0.086 -0.040 -0.368 orch 0.089 -0.022 0.017 0.036 0.089 0.104 -0.259 -0.059 mpqnem -0.627 -0.042 -0.003 0.045 -0.006 0.591 -0.008 0.088 -0.124 solo:mpqnem 0.344 0.063 0.039 0.012 0.045 -0.912 0.017 0.019 -0.032 mpqnem previous students juried public solo mpqpem mpqab orch mpqnem solo:mpqnem -0.632 AIC(modelA, modelB) ## df AIC ## modelA 33 2948.349 ## modelB 13 2946.328 BIC(modelA, modelB) ## df BIC ## modelA 33 3087.232 ## modelB 13 3001.040 Both AIC and BIC favor Model B. 3.5.7 One More Possible Model Finally, we consider a simpler model that accounts for only positive and negative emotions at level two. \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0}+\\alpha_{1}\\textrm{mpqpem}_{i} + \\alpha_{2}\\textrm{mpqnem}_{i} \\\\ &amp; +\\beta_{0}\\textrm{previous}_{ij} + \\gamma_{0}\\textrm{students} + \\delta_{0}\\textrm{juried}_{ij} + \\varepsilon_{0}\\textrm{public} + \\zeta_{0}\\textrm{solo}_{ij} +\\zeta_{1}\\textrm{mpqnem}_{i}\\textrm{solo}_{ij}] \\\\ &amp; + [u_{i} +\\epsilon_{ij} ] \\end{align*} \\] modelC &lt;- lmer(na ~ previous + students + juried + public + solo + mpqpem + mpqnem + mpqnem:solo + (1 | id), data = music, REML=TRUE) summary(modelC) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ previous + students + juried + public + solo + mpqpem + mpqnem + mpqnem:solo + (1 | id) Data: music REML criterion at convergence: 2931.1 Scaled residuals: Min 1Q Median 3Q Max -2.0015 -0.7103 -0.1269 0.5231 4.0510 Random effects: Groups Name Variance Std.Dev. id (Intercept) 3.236 1.799 Residual 19.279 4.391 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 9.927921 2.093605 55.074190 4.742 0.000015371131 *** previous -0.127735 0.046943 471.743502 -2.721 0.00675 ** students 3.855901 0.618592 482.592236 6.233 0.000000000997 *** juried 4.320965 0.786379 480.880270 5.495 0.000000063545 *** public 3.211002 0.667621 487.490870 4.810 0.000002018574 *** solo -0.222631 1.429140 484.511985 -0.156 0.87627 mpqpem -0.006105 0.029535 34.036100 -0.207 0.83748 mpqnem 0.104837 0.041660 68.959080 2.517 0.01418 * solo:mpqnem 0.103699 0.042476 466.126985 2.441 0.01500 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) previs stdnts juried public solo mpqpem mpqnem previous -0.111 students -0.162 -0.041 juried -0.118 -0.069 0.308 public -0.256 -0.011 0.524 0.312 solo -0.434 -0.061 0.068 0.012 0.207 mpqpem -0.675 -0.006 -0.011 -0.007 -0.022 -0.010 mpqnem -0.634 -0.044 0.000 0.053 0.007 0.562 -0.006 solo:mpqnem 0.343 0.067 0.040 0.005 0.052 -0.915 0.016 -0.587 3.5.8 AIC and BIC Comparisons for Models B and C AIC(modelB, modelC) ## df AIC ## modelB 13 2946.328 ## modelC 11 2953.082 BIC(modelB, modelC) ## df BIC ## modelB 13 3001.040 ## modelC 11 2999.377 AIC favors model B, while BIC favors model C. 3.5.9 Likelihood Ratio Test Since all of the fixed effects in Model C also appear in Model B, (Model C is a nested version of Model B), we can use a likelihood ratio test (drop in deviance test), which is similar to the ANOVA F-Test, to compare the models. When using mixed effects models, the test statistic for this goodness of fit test follows a \\(\\chi^2\\) distribution, rather than an F-distribution, so we use test = \"Chisq\". # anova() automatically uses ML for LRT tests drop_in_dev &lt;- anova(modelB, modelC, test = &quot;Chisq&quot;) drop_in_dev Data: music Models: modelC: na ~ previous + students + juried + public + solo + mpqpem + mpqnem + mpqnem:solo + (1 | id) modelB: na ~ previous + students + juried + public + solo + mpqpem + mpqab + orch + mpqnem + mpqnem:solo + (1 | id) npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) modelC 11 2936.7 2983.0 -1457.4 2914.7 modelB 13 2925.6 2980.3 -1449.8 2899.6 15.182 2 0.0005049 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The small p-value provides evidence against the null hypothesis that model C is sufficient, suggesting that accounting for absorption and whether the musician plays an orchestral instrument does indeed help explain variability in performance anxiety. We’ll go with Model B as our final model. 3.5.10 Final Conclusions summary(modelB) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: na ~ previous + students + juried + public + solo + mpqpem + ## mpqab + orch + mpqnem + mpqnem:solo + (1 | id) ## Data: music ## ## REML criterion at convergence: 2920.3 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.9919 -0.7026 -0.1252 0.5162 3.9367 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 1.848 1.36 ## Residual 19.272 4.39 ## Number of obs: 497, groups: id, 37 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 7.70582 1.99554 51.87716 3.862 0.000314 *** ## previous -0.12817 0.04677 473.53232 -2.740 0.006368 ** ## students 3.75767 0.61372 485.24491 6.123 0.0000000019 *** ## juried 4.28176 0.78158 483.19106 5.478 0.0000000692 *** ## public 3.09805 0.66208 481.42142 4.679 0.0000037469 *** ## solo -0.26784 1.41139 469.85154 -0.190 0.849569 ## mpqpem -0.05917 0.02795 30.52940 -2.117 0.042531 * ## mpqab 0.19185 0.05610 33.15989 3.420 0.001678 ** ## orch 1.23579 0.65797 34.10231 1.878 0.068929 . ## mpqnem 0.10568 0.03743 69.85950 2.823 0.006188 ** ## solo:mpqnem 0.10640 0.04144 416.29568 2.567 0.010596 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) previs stdnts juried public solo mpqpem mpqab orch ## previous -0.120 ## students -0.157 -0.042 ## juried -0.103 -0.065 0.309 ## public -0.225 -0.015 0.526 0.315 ## solo -0.424 -0.060 0.073 0.010 0.220 ## mpqpem -0.398 0.000 -0.007 -0.004 -0.016 -0.023 ## mpqab -0.389 -0.001 -0.029 -0.036 -0.086 -0.040 -0.368 ## orch 0.089 -0.022 0.017 0.036 0.089 0.104 -0.259 -0.059 ## mpqnem -0.627 -0.042 -0.003 0.045 -0.006 0.591 -0.008 0.088 -0.124 ## solo:mpqnem 0.344 0.063 0.039 0.012 0.045 -0.912 0.017 0.019 -0.032 ## mpqnem ## previous ## students ## juried ## public ## solo ## mpqpem ## mpqab ## orch ## mpqnem ## solo:mpqnem -0.632 Key Findings: After controlling for other factors we have evidence that: performance anxiety is higher when a musician is performing in front of students, a jury, or the general public rather than their instructor performance anxiety is is lower for each additional diary the musician previously filled out musicians with lower levels of positive emotionality and higher levels of absorption tend to experience greater performance anxiety those who play orchestral instruments experience more performance anxiety than those who play keyboards or sing. musicians with higher levels of negative emotionality experience higher levels of performance anxiety, and that this association is even more pronounced when musicians are performing solos rather than as part of an ensemble group. Interpretations of key fixed effects: A one-point increase in baseline level of negative emotionality is associated with an estimated 0.11 mean increase in performance anxiety for musicians performing in an ensemble group (solo=0), after controlling for previous diary entries, audience, positive emotionality, absorption, and instrument. When musicians play solos, a one-point increase in baseline level of negative emotionality is associated with an estimated \\(0.10568+0.10640=0.21208\\) mean increase in performance anxiety, approximately twice as high st musicians playing in ensemble groups (0.10568), controlling for the effects of previous diary entries, audience, positive emotionality, absorption, and instrument. Interpretations of random effects: After accounting for the effects of previous diary entries, audience, positive emotionality, absorption, and instrument, there is more variability in performance anxiety between performances by the same musician (\\(\\sigma=4.39\\)), than in variability between performance anxiety of different musicians (\\(\\sigma=1.36\\)) 3.6 Conceptual Questions We now model performance anxiety, measured by na using the following model: \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0}+\\alpha_{1}\\textrm{Years_Study}_{i}+\\beta_{0}\\textrm{Juried}_{ij}+\\beta_{1}\\textrm{Years_Study}_{i}\\textrm{Juried}_{ij}] \\\\ &amp; \\textrm{} + [u_{i}+v_{i}\\textrm{Juried}_{ij}+\\epsilon_{ij}] \\end{align*} \\] where \\(\\epsilon_{ij}\\sim N(0,\\sigma^2)\\), and \\[ \\begin{equation*} \\left[ \\begin{array}{c} u_{i} \\\\ v_{i} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{u}^{2} &amp; \\rho_{uv}\\sigma_{u}\\sigma_v \\\\ \\rho_{uv}\\sigma_{u}\\sigma_v &amp; \\sigma_{v}^{2} \\end{array} \\right] \\right) \\end{equation*} \\] R output for the model is shown below. summary(lmer(data=music, na ~ years_study + juried + years_study:juried + (juried|id)), REML=TRUE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: na ~ years_study + juried + years_study:juried + (juried | id) ## Data: music ## ## REML criterion at convergence: 2994.2 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.9321 -0.6373 -0.2106 0.4715 4.2441 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 5.398 2.323 ## juried 3.560 1.887 -0.09 ## Residual 21.595 4.647 ## Number of obs: 497, groups: id, 37 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 15.51321 0.99765 35.89127 15.550 &lt;0.0000000000000002 *** ## years_study 0.05505 0.10990 34.88732 0.501 0.620 ## juried 4.16156 1.81640 24.07290 2.291 0.031 * ## years_study:juried -0.18238 0.21396 23.93772 -0.852 0.402 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) yrs_st juried ## years_study -0.894 ## juried -0.188 0.163 ## yrs_stdy:jr 0.152 -0.163 -0.880 Explain in words what we should conclude from each of the following facts: \\(\\hat{\\beta_0}\\) is positive and the associated p-value is small. \\(\\hat{\\beta_1}\\) is negative and the associated p-value is large. \\(\\hat{\\sigma} &gt; \\hat{\\sigma_u}\\) \\(\\hat{\\sigma_u}\\) is about the same as \\(\\hat{\\sigma_v}\\) \\(\\hat{\\rho}_{uv}\\) is slightly negative Answers There is evidence that expected performance anxiety for musicians with no prior years of study is higher when giving a juried performance than a non-juried one. While the gap in performance anxiety between juried and non-juried performances may decrease with a musician’s years of study, it is plausible that this gap does not change at all. There is more variability in residuals for performance anxiety between performances of the same type (juried or non-juried) by the same performer than there is in average residuals between different performers for non-juried performances, after accounting for years of study and whether the performance was juried. After accounting for years of study and whether the performance was juried, variation in average residuals between different performers, for non-juried performances, is about the same as variation in change in performance anxiety for juried vs non-juried performances between individuals. After accounting for years of study and whether the performance ws juried, people who experience higher than expected performance anxiety for nonjuried performances have less increase in anxiety (maybe even decrease) when playing in a juried performance. Explain in words what it would mean if the model parameter was equal to zero. \\(\\alpha_0\\) \\(\\alpha_1\\) \\(\\beta_0\\) \\(\\beta_1\\) \\(\\sigma_u\\) \\(\\sigma_v\\) \\(\\sigma\\) \\(\\rho_{uv}\\) Solution \\(\\alpha_0 =0\\) would imply that the average performance anxiety score for a musician with no prior study in a non-juried performance is 0. \\(\\alpha_1=0\\) would imply that for non-juried performances, average performance anxiety does not change as the muscician gains more years of study. \\(\\beta_0=0\\) would imply that a musician with no prior years of study has no difference, on average, between performance anxiety scores when playing in a juried performance, compared to a non-juried one. \\(\\beta_1=0\\) would imply that on average, the difference in a musician’s performance anxiety scores in juried performances compared to non-juried ones stays the same, regardless of how many prior years of study the musician has. \\(\\sigma_u=0\\) would imply that all musicians with the same amount of prior study would have the same average performance anxiety score in their non-juried performances. \\(\\sigma_v=0\\) would imply that all musicians with the same amount of prior study would, on average, have the same change in performance anxiety between juried and non-juried performances. \\(\\sigma=0\\) would imply that all performances of the same type (juried vs nonjuried), that are given by musicians with the same amount of prior study would have the same performance anxiety scores. \\(\\rho_{uv}=0\\) would imply that after accounting for age and whether a performance is juried, there is no relationship between a performer’s average performance anxiety in a non-juried performance, and their change in performance anxiety between juried and non-juried performances. (Another way to say is that, after accounting for years of prior study and type of performance, a musician who has a higher than expected performance anxiety score in non-juried performances is not expected to have any bigger, or smaller, change when playing in a juried performance than a musician who has lower than expected performance anxiety in a non-juried performance). Now consider a model with no interaction term. \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0}+\\alpha_{1}\\textrm{Years_Study}_{i}+\\beta_{0}\\textrm{Juried}_{ij}] \\\\ &amp; \\textrm{} + [u_{i}+v_{i}\\textrm{Juried}_{ij}+\\epsilon_{ij}] \\end{align*} \\] Sketch lattice plots, with juried on the x-axis and na on the y-axis, for 5 different musicians that illustrate each of the following scenarios: \\(\\beta_0 &gt; 0\\), \\(\\sigma_u\\) is large, and \\(\\sigma_v\\) is small \\(\\beta_0 &gt; 0\\), \\(\\sigma_u\\) is small, and \\(\\sigma_v\\) is large \\(\\beta_0 &gt; 0\\), \\(\\rho_{uv} &gt; 0\\) \\(\\beta_0 &gt; 0\\), \\(\\rho_{uv} &lt; 0\\) \\(\\beta_0 &lt; 0\\), \\(\\rho_{uv} &lt; 0\\) "],["longitudinal-data.html", "Chapter 4 Longitudinal Data 4.1 Charter Schools Exploratory Analysis 4.2 Multilevel Longitudinal Models 4.3 Quadratic and Piecewise Linear Models 4.4 Model for School Type 4.5 Covariance Structure among Observations", " Chapter 4 Longitudinal Data These notes provide a summary of Chapter 9 in Beyond Multiple Linear Regression by Roback and Legler. Much of the code that appears here comes from the textbook’s Github repository. # Packages required for Chapter 9 library(MASS) library(gridExtra) library(mnormt) library(lme4) library(lmerTest) library(knitr) library(kableExtra) library(tidyverse) library(Hmisc) library(nlme) In this chapter, we look at situations where data are collected on the same observational units over time. 4.1 Charter Schools Exploratory Analysis Charter schools emerged in the 1990’s as alternatives to traditional public schools. While they are publicly funded, charter schools are exempt from many regulations that traditional publics schools must follow. Thus, charters will often extend the school days or year and tend to offer non-traditional techniques and styles of instruction and learning. In this case study, we compare the performance of students in public schools and charter schools on the Minnesota Comprehensive Assessment, using data from 2008-2010. 4.1.1 Data Organization Key variables in chart_wide_condense.csv which we will examine to address the research questions above are: schoolid = includes district type, district number, and school number schoolName = name of school urban = is the school in an urban (1) or rural (0) location? charter = is the school a charter school (1) or a non-charter public school (0)? schPctsped = proportion of special education students in a school (based on 2010 figures) schPctfree = proportion of students who receive free or reduced lunches in a school (based on 2010 figures). This serves as a measure of poverty among school families. MathAvgScore.0 = average MCA-II math score for all sixth grade students in a school in 2008 MathAvgScore.1 = average MCA-II math score for all sixth grade students in a school in 2009 MathAvgScore.2 = average MCA-II math score for all sixth grade students in a school in 2010 This data is stored in WIDE format, with one row per school. #Getting started chart.wide = read_csv(&quot;https://raw.githubusercontent.com/proback/BeyondMLR/master/data/chart_wide_condense.csv&quot;) head(head(chart.wide)) ## # A tibble: 6 × 10 ## ...1 schoolid schoo…¹ urban charter schPc…² schPc…³ MathA…⁴ MathA…⁵ MathA…⁶ ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 Dtype 1 D… RIPPLE… 0 0 0.118 0.363 653. 657. 653. ## 2 4 Dtype 1 D… WRENSH… 0 0 0.152 0.424 647. 645. 652. ## 3 7 Dtype 1 D… CENTRA… 0 0 0.123 0.262 655. 658. 660. ## 4 10 Dtype 1 D… SANDBU… 1 0 0.0827 0.248 656. 657. 660. ## 5 13 Dtype 1 D… OAK VI… 1 0 0.0954 0.142 658. 658. 660. ## 6 16 Dtype 1 D… ROOSEV… 1 0 0.0886 0.241 656. 659. 660. ## # … with abbreviated variable names ¹​schoolName, ²​schPctsped, ³​schPctfree, ## # ⁴​MathAvgScore.0, ⁵​MathAvgScore.1, ⁶​MathAvgScore.2 Full Dataset 4.1.2 Missing Data summary(chart.wide) ## ...1 schoolid schoolName urban ## Min. : 1.0 Length:618 Length:618 Min. :0.0000 ## 1st Qu.: 446.8 Class :character Class :character 1st Qu.:0.0000 ## Median : 885.5 Mode :character Mode :character Median :1.0000 ## Mean : 885.8 Mean :0.6165 ## 3rd Qu.:1332.2 3rd Qu.:1.0000 ## Max. :1733.0 Max. :1.0000 ## ## charter schPctsped schPctfree MathAvgScore.0 ## Min. :0.0000 Min. :0.00000 Min. :0.0000 Min. :625.7 ## 1st Qu.:0.0000 1st Qu.:0.08815 1st Qu.:0.2694 1st Qu.:649.4 ## Median :0.0000 Median :0.12500 Median :0.4000 Median :652.8 ## Mean :0.1181 Mean :0.14356 Mean :0.4509 Mean :652.1 ## 3rd Qu.:0.0000 3rd Qu.:0.17032 3rd Qu.:0.5830 3rd Qu.:655.9 ## Max. :1.0000 Max. :1.00000 Max. :1.0000 Max. :667.6 ## NA&#39;s :61 ## MathAvgScore.1 MathAvgScore.2 ## Min. :621.4 Min. :619.6 ## 1st Qu.:649.0 1st Qu.:651.5 ## Median :653.1 Median :655.6 ## Mean :652.1 Mean :654.5 ## 3rd Qu.:656.9 3rd Qu.:658.8 ## Max. :666.4 Max. :673.3 ## NA&#39;s :46 NA&#39;s :14 There are 61 missing values for MathAvgScore.0, 46 for MathAvgScore.1, and 14 for MathAvgScore.2. sum(complete.cases(chart.wide)) ## [1] 540 540 of the schools have complete data on all variables, while 78 have at least one missing value. Approaches for Handling Missing Data Complete Case Analysis - Include only schools with complete data. While easy, this means throwing away 78 of 618 schools (12.6%). Also, schools with missing values could be systematicall different than those with observed data, so ignoring them might lead to improper conclusions. Last observation carried forward - Use only the last recorded score for each school. A conservative approach sometimes used in clinical trials. Assumes that a school’s most recent score is representative of later missing scores. Information about trajectories over time is thrown away. Imputation of missing observations - “fill in” missing observations, using information from observed data, then run analysis. Risks include misrepresenting missing observations and overstating precision in final results. Multilevel methods - use available data to estimate patterns over time by school and combine in a way that recognizes that time trends for schools with complete data are more precise than time trends for schools with fewer measurements. We will approach this problem using multilevel methods. 4.1.3 Convert to Tidy Form First, we will convert the data to long (or in this case tidy) form. #Getting started-2 # Create data frame in LONG form (one obs per school-year) # chart.long is 1854x10 with 121 NAs for MathAvgScore select &lt;- dplyr::select chart.long &lt;- chart.wide %&gt;% pivot_longer(cols=MathAvgScore.0:MathAvgScore.2, names_to = &quot;key&quot;, # years since 2008 values_to = &quot;MathAvgScore&quot;) %&gt;% separate(key, into = c(&quot;name&quot;, &quot;year08&quot;), sep = &quot;\\\\.&quot;) %&gt;% select(-c(&quot;name&quot;)) %&gt;% arrange(schoolid, year08) %&gt;% mutate(year08 = as.numeric(year08)) head(chart.long) ## # A tibble: 6 × 9 ## ...1 schoolid schoo…¹ urban charter schPc…² schPc…³ year08 MathA…⁴ ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 Dtype 1 Dnum 1 Snu… RIPPLE… 0 0 0.118 0.363 0 653. ## 2 1 Dtype 1 Dnum 1 Snu… RIPPLE… 0 0 0.118 0.363 1 657. ## 3 1 Dtype 1 Dnum 1 Snu… RIPPLE… 0 0 0.118 0.363 2 653. ## 4 4 Dtype 1 Dnum 100 S… WRENSH… 0 0 0.152 0.424 0 647. ## 5 4 Dtype 1 Dnum 100 S… WRENSH… 0 0 0.152 0.424 1 645. ## 6 4 Dtype 1 Dnum 100 S… WRENSH… 0 0 0.152 0.424 2 652. ## # … with abbreviated variable names ¹​schoolName, ²​schPctsped, ³​schPctfree, ## # ⁴​MathAvgScore 4.1.4 Exploratory Analyses for General Multilevel Models We have a total of 1733 observation on 618 schools, observed over 3 years. Thus, we can analyze the data at two different levels. Levels Level 2 - observations that pertain to a school and stay constant over time (charter or non-charter, urban or rural, percent free and reduced lunch, percent special education) Level 1 - observations that change over time (year and average math scores) We calculate the average math score across the three years, and also add indicator variables for whether the school was in an urban setting, and whether it was a charter school. #Getting started-3 # Add average across all years for each school for EDA plots chart.means &lt;- chart.long %&gt;% group_by(schoolid) %&gt;% summarise(mean3yr = mean(MathAvgScore, na.rm=T)) chart.wide &lt;- chart.wide %&gt;% mutate(urban0 = ifelse(urban==1, &quot;urban&quot;, &quot;rural&quot;), charter0 = ifelse(charter==1, &quot;charter&quot;, &quot;public non-charter&quot;)) %&gt;% left_join(chart.means, by=&quot;schoolid&quot;) Histogram of mean sixth grade MCA math test scores over the years 2008-2010 for 618 Minnesota schools. ###histogram of mean math scores (1 obs per school) ggplot(data=chart.wide,aes(x=mean3yr)) + geom_histogram(binwidth=5,color=&quot;black&quot;,fill=&quot;white&quot;) + xlab(&quot;Mean Math Scores by School&quot;) + ylab(&quot;Frequency&quot;) Boxplots of categorical Level Two covariates vs. average MCA math scores. Plot (a) shows charter vs. public non-charter schools, while plot (b) shows urban vs. rural schools. charter.school &lt;- ggplot(data = chart.wide, aes(x = factor(charter0), y = mean3yr)) + geom_boxplot() + coord_flip() + ylab(&quot;Mean Math Scores by School&quot;) + xlab(&quot;&quot;) + labs(title=&quot;(a)&quot;) urban.school &lt;- ggplot(data = chart.wide, aes(x = factor(urban0), y = mean3yr)) + geom_boxplot() + coord_flip() + ylab(&quot;Mean Math Scores by School&quot;) + xlab(&quot;&quot;) + labs(title=&quot;(b)&quot;) grid.arrange(charter.school,urban.school,ncol=1,nrow=2) Scatterplots of average MCA math scores by (a) percent free and reduced lunch, (b) percent special education. PctFree.school &lt;- ggplot(data = chart.wide, aes(x = schPctfree, y = mean3yr)) + geom_point() + geom_smooth(se=FALSE,method=&quot;lm&quot;,color=&quot;red&quot;) + xlab(&quot;Percent Free/Reduced Lunch&quot;) + ylab(&quot;Mean Math Scores\\nby School&quot;) + labs(title=&quot;(a)&quot;) PctSped.school &lt;- ggplot(data = chart.wide, aes(x = schPctsped, y = mean3yr)) + geom_point() + geom_smooth(se=FALSE,method=&quot;lm&quot;,color=&quot;red&quot;) + xlab(&quot;Percent Special Ed&quot;) + ylab(&quot;Mean Math Scores\\nby School&quot;) + labs(title=&quot;(b)&quot;) grid.arrange(PctFree.school, PctSped.school, ncol = 2) chart.wide %&gt;% group_by(charter) %&gt;% summarise(Percent_Free_Red_Lunch = mean(schPctfree), Percent_Special_Ed = mean(schPctsped), Mean_Math_Score = mean(mean3yr), N=n()) ## # A tibble: 2 × 5 ## charter Percent_Free_Red_Lunch Percent_Special_Ed Mean_Math_Score N ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 0 0.433 0.143 653. 545 ## 2 1 0.585 0.151 648. 73 4.1.5 Exploratory Analyses for Longitudinal Data We use lattice plots and spaghetti plots to examine the change in scores over time for various schools. smallchart.long &lt;- filter(chart.long, row_number() &lt;= 72) #Lattice plots # First change names of Central and Chaska smallchart.long$schoolName[7:9]=&quot;CENTRAL108&quot; smallchart.long$schoolName[37:39]=&quot;CHASKAEAST&quot; smallchart.long$schoolName[40:42]=&quot;CHASKAWEST&quot; smallchart.long$schoolName[64:66]=&quot;CENTRAL13&quot; Lattice plot by school of math scores over time with linear fit for the first 24 schools in the data set. ggplot(smallchart.long, aes(x = year08, y = MathAvgScore)) + geom_point() + geom_line() + facet_wrap(~schoolName,ncol=6) + scale_x_continuous(limits=c(0,2), breaks=c(0,1,2)) + scale_y_continuous(limits=c(640,665)) + theme(strip.text.x=element_blank()) + labs(x=&quot;Years since 2008&quot;,y=&quot;Math Scores&quot;) We select a sampe of 73 non-charter schools (the number of charter schools), and compare scores over time. set.seed(27) #pulls same random sample every time wide.charter &lt;- chart.wide %&gt;% filter(charter==1) #dataframe with just charter schools # select a sample of public schools with size equal to number of charter schools samp = sample(1:length(chart.wide$charter==0), size=dim(wide.charter)[1]) wide.public &lt;- chart.wide %&gt;% filter(charter == 0) %&gt;% sample_n( dim(wide.charter)[1] ) sampdata &lt;- bind_rows(wide.charter, wide.public) %&gt;% mutate(vars = row_number()) # Just use numbers 1-146 as school ids #convert to long form sampdata.l &lt;- sampdata %&gt;% pivot_longer(names_to = &quot;key&quot;, values_to = &quot;MathAvgScore&quot;, cols=MathAvgScore.0:MathAvgScore.2) %&gt;% separate(key, into = c(&quot;name&quot;, &quot;year08&quot;), sep = &quot;\\\\.&quot;) %&gt;% select(-name) %&gt;% arrange(charter, vars, year08) %&gt;% mutate(year08 = as.numeric(year08)) Spaghetti (or trellis) plots showing time trends for each school by school type, for a random sample of charter schools (left) and public non-charter schools (right), with overall fits using loess (bold). ##Spaghetti Plots #get rid of NA data newsampdata.l &lt;- sampdata.l %&gt;% na.omit() ggplot(newsampdata.l, aes(x = year08, y = MathAvgScore)) + geom_line(aes(group=schoolid),color=&quot;grey&quot;) + facet_grid(.~charter0) + geom_smooth(aes(group=1),color=&quot;black&quot;,size=1) + labs(x=&quot;Years since 2008&quot;,y=&quot;Math Scores&quot;) Spaghetti (or trellis) plots showing time trends for each school by quartiles of percent free and reduced lunch, with loess fits. # divide into quartiles newsampdata.l &lt;- newsampdata.l %&gt;% mutate(splitup = paste(&quot;Quartile&quot;, as.numeric(cut2(schPctfree, g=4)))) ggplot(newsampdata.l,aes(x=year08,y=MathAvgScore)) + geom_line(aes(group=schoolid),color=&quot;grey&quot;) + geom_smooth(method=&quot;loess&quot;,color=&quot;black&quot;,se=FALSE,size=.75) + facet_grid(~splitup) + labs(x=&quot;Years since 2008&quot;,y=&quot;Math Scores&quot;) + scale_x_continuous(limits=c(0,2), breaks=c(0,1,2)) charter schools had math scores that were lower on average than public non-charter schools and more variable. Public non-charter schools have higher scores across all years; both school types show little growth between 2008 and 2009, but greater growth between 2009 and 2010, especially charter schools. Schools with lower percentages of free and reduced lunch students tend to have higher math scores and less variability. Across all levels of free and reduced lunch, we see greater gains between 2009 and 2010 than between 2008 and 2009. 4.2 Multilevel Longitudinal Models 4.2.1 Unconditional Means Model begin with unconditional means model, (no predictors at any level). assess the amount of variation at each level, compare variability within school to variability between schools. Define \\(Y_{ij}\\) as the MCA-II math score from school \\(i\\) and year \\(j\\). \\[ \\begin{equation*} Y _{ij} = \\alpha_{0} + u_{i} + \\epsilon_{ij} \\textrm{ with } u_{i} \\sim N(0, \\sigma^2_u) \\textrm{ and } \\epsilon_{ij} \\sim N(0, \\sigma^2) \\end{equation*} \\] #Model A (Unconditional means model) model.a &lt;- lmer(MathAvgScore~ 1 + (1|schoolid), REML=T, data=chart.long) summary(model.a) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: MathAvgScore ~ 1 + (1 | schoolid) ## Data: chart.long ## ## REML criterion at convergence: 10530.1 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.1567 -0.4948 0.0137 0.5130 3.5689 ## ## Random effects: ## Groups Name Variance Std.Dev. ## schoolid (Intercept) 41.87 6.471 ## Residual 10.57 3.251 ## Number of obs: 1733, groups: schoolid, 618 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 652.7460 0.2726 591.6845 2395 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.2.2 Interpretations in Unconditional Means Model \\(\\widehat{\\alpha}_{0}\\) = 652.7 = the mean math score across all schools and all years \\(\\widehat{\\sigma}_u\\)= 6.47= the standard deviation in average math scores (averaging across the tree years), for different schools (tells us on average, how much do average scores differ between schools?) \\(\\widehat{\\sigma}\\)= 3.25 = the standard deviation in math scores for the same school between different years (tells us how much scores vary from year to year in the same school) 4.2.3 Intraclass Correlation Coefficient: \\[ \\begin{equation*} \\widehat{\\rho}=\\frac{\\widehat{\\sigma}^2_u}{\\widehat{\\sigma}^2_u + \\widehat{\\sigma}^2} = \\frac{41.869}{41.869+10.571}= 0.798 \\end{equation*} \\] 79.8% of the total variation in math scores is attributable to differences among schools rather than changes over time within schools. We can also say that the average correlation for any pair of responses from the same school is 0.798. 4.2.4 Unconditional Growth Model The second model in most multilevel contexts introduces a covariate at Level One. With longitudinal data, this covariate is time. There are still no predictors at Level Two. This model is then called the unconditional growth model, and allows us to assess how much of the within-school variability can be attributed to systematic changes over time. We include a random slope term to allow the change in scores from year to year to vary between schools. Let \\(Y_{ij}\\) be the math score of the \\(i^{th}\\) school in year \\(j\\). Then we can model the linear change in math test scores over time for School \\(i\\) according to Model B: \\[ \\begin{equation*} Y_{ij}=\\alpha_{0} + \\beta_{0}\\textrm{Year08}_{ij}+u_{i}+v_{i}\\textrm{Year08}_{ij} + \\epsilon_{ij} \\end{equation*} \\] where \\(\\epsilon_{ij}\\sim N(0,\\sigma^2)\\) and \\[ \\left[ \\begin{array}{c} u_{i} \\\\ v_{i} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{u}^{2} &amp; \\\\ \\rho_{uv}\\sigma_{u}\\sigma_{v} &amp; \\sigma_{v}^{2} \\end{array} \\right] \\right) . \\] \\(\\alpha_0\\) is the average math score in 2008. \\(\\beta_0\\) is the slope relating average math score to time, that is the mean change in math scores from one year to the next. \\(u_i\\) is a random effect capturing how individual schools 2008 scores vary from the overall average. \\(v_i\\) is a random effect capturing how slopes for individual schools vary from the average slope. \\(\\sigma_u\\) quantifies the amount of variability between scores in different schools in 2008. \\(\\sigma_v\\) quantifies the amount of variability in average year-to-year change between schools. \\(\\sigma\\) quantifies the variability in test scores within the same school #Model B (Unconditional growth) model.b &lt;- lmer(MathAvgScore~ year08 + (year08|schoolid), REML=T, data=chart.long) summary(model.b) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: MathAvgScore ~ year08 + (year08 | schoolid) Data: chart.long REML criterion at convergence: 10339.5 Scaled residuals: Min 1Q Median 3Q Max -3.1579 -0.4668 0.0180 0.4596 3.4972 Random effects: Groups Name Variance Std.Dev. Corr schoolid (Intercept) 39.4410 6.2802 year08 0.1105 0.3325 0.72 Residual 8.8200 2.9699 Number of obs: 1733, groups: schoolid, 618 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 651.40766 0.27934 565.22116 2331.96 &lt;0.0000000000000002 *** year08 1.26495 0.08997 537.98822 14.06 &lt;0.0000000000000002 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) year08 -0.234 4.2.5 Interpretations in Unconditional Growth Model From this output, we obtain estimates of our six model parameters: \\(\\widehat{\\alpha}_{0}\\) = 651.4 = the mean math score for the population of schools in 2008. \\(\\widehat{\\beta}_{0}\\) = 1.26 = the mean yearly change in math test scores for the population during the three-year observation period. \\(\\widehat{\\sigma}_u\\) = 6.28 = the standard deviation in math scores between schools in 2008 \\(\\widehat{\\sigma}_v\\) = 0.33 = the standard deviation in rates of change in math scores during the three-year observation period. \\(\\widehat{\\sigma}\\) = 2.97 = the standard deviation in scores within the same school. \\(\\widehat{\\rho}_{uv}\\) = 0.72 = the correlation in schools’ 2008 math score and their rate of change in scores between 2008 and 2010. Schools had a mean math test score of 651.4 in 2008 and their mean test scores tended to increase by 1.26 points per year over the three-year observation period. Since \\(\\widehat{\\beta}_{0}&gt;0\\) and \\(\\rho_{uv} &gt; 0\\), we can conclude that on average, math scores increased from 2008-2010, and that schools with higher math scores in 2008 saw bigger increases than those with lower scores in 2008. 4.3 Quadratic and Piecewise Linear Models 4.3.1 Quadratic Trend over Time Since our exploratory data analysis revealed a possible nonlinear trend, we might consider adding a quadratic term for year. When squaring a variable, it’s helpful to center it first. We create a centered variable yearc by subtracting 1 from year08. (So 2008 is denoted -1, 2009 is denoted 0, and 2010 is denoted 1). Then, we create a varaible yearc2 that is the square of this variable. #center year and calculate year^2 chart.long &lt;- chart.long %&gt;% mutate(yearc = year08 - 1, yearc2 = yearc ^ 2) 4.3.2 Quadratic Model We’ll include a random intercept term \\(u_i\\) modeling random differences between schools. Model: \\[ Y_{ij}=\\alpha_{0}+\\beta_{0}\\textrm{YearC}_{ij}+\\gamma_{0}\\textrm{YearC}^{2}_{ij} + u_i + \\epsilon_{ij} \\] where \\(u_i\\sim\\mathcal{N}(0, \\sigma^2_u)\\) and \\(\\epsilon_{ij}\\sim\\mathcal{N}(0, \\sigma^2)\\) 4.3.3 Quadratic Model in R # Modeling quadratic time trend model.b1 &lt;- lmer(MathAvgScore~ yearc + yearc2 + (1|schoolid), REML=T, data=chart.long) summary(model.b1) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: MathAvgScore ~ yearc + yearc2 + (1 | schoolid) Data: chart.long REML criterion at convergence: 10298.2 Scaled residuals: Min 1Q Median 3Q Max -3.2125 -0.4756 0.0088 0.4687 3.4954 Random effects: Groups Name Variance Std.Dev. schoolid (Intercept) 43.050 6.561 Residual 8.523 2.919 Number of obs: 1733, groups: schoolid, 618 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 651.94235 0.29229 768.06158 2230.448 &lt; 0.0000000000000002 *** yearc 1.26993 0.08758 1107.30220 14.501 &lt; 0.0000000000000002 *** yearc2 1.06841 0.15046 1098.25374 7.101 0.00000000000222 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) yearc yearc -0.011 yearc2 -0.350 -0.016 The small p-value on the yearc2 line provides evidence of a quadratic relationship between year and test scores. 4.3.4 Estimated Response Curve \\[E(Y)_{ij} = 652 + 1.27(\\textrm{YearC}) + 1.07(\\textrm{YearC})^2 \\] Where \\(\\textrm{YearC}=\\textrm{Year}-2009\\). ggplot(data=chart.long, aes(x=yearc, y=MathAvgScore)) + geom_point() + stat_smooth(method=&quot;lm&quot;, se=TRUE, fill=NA, formula=y ~ poly(x, 2, raw=TRUE),colour=&quot;red&quot;) There is more growth, on average, between 2009 and 2010, than between 2008 and 2009. 4.3.5 Linear and Quadratic Error Terms The previous model assumes that there are differences in average math scores between schools, but that year-to-year change in scores is the same between schools. If we wanted to allow year-to-year change to vary between schools, we could add random effects associated with linear and quadratic change. One option would be to assume the intercept, linear term, and quadratic term differ between schools, i.e.  Level One: \\[ \\begin{align*} Y_{ij} &amp; =(\\alpha_{0} + u_{i})+(\\beta_{0} + v_{i})\\textrm{Year08}_{ij}+ (\\gamma_{0} + w_{i})\\textrm{Year08}^{2}_{ij} + \\epsilon_{ij} \\\\ &amp; =\\alpha_{0} +\\beta_{0}\\textrm{Year08}_{ij}+ \\gamma_{0}\\textrm{Year08}^{2}_{ij} + u_{i} + v_{i}\\textrm{Year08}_{ij} + w_{i}\\textrm{Year08}^{2}_{ij} + \\epsilon_{ij} \\end{align*} \\] where \\(\\epsilon_{ij}\\sim N(0,\\sigma^2)\\) and \\[ \\left[ \\begin{array}{c} u_{i} \\\\ v_{i} \\\\ w_{i} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{ccc} \\sigma_{u}^{2} &amp; &amp; \\\\ \\rho_{uv}\\sigma_{u}\\sigma_{v} &amp; \\sigma_{v}^{2} &amp; \\\\ \\rho_{uw}\\sigma_{u}\\sigma_{w} &amp; \\rho_{vw}\\sigma_{v}\\sigma_{w} &amp; \\sigma_{w}^{2} \\end{array} \\right] \\right) . \\] 4.3.6 Model with Many Random Terms in R # Modeling quadratic time trend model.b2 &lt;- lmer(MathAvgScore~ yearc + yearc2 + ((yearc2 + yearc) |schoolid), REML=T, data=chart.long) Error: number of observations (=1733) &lt;= number of random effects (=1854) for term ((yearc2 + yearc) | schoolid); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable summary(model.b2) Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;summary&#39;: object &#39;model.b2&#39; not found We now have 6 variance components (\\(\\sigma_u\\), \\(\\sigma_v\\), \\(\\sigma_w\\), \\(\\rho_u\\), \\(\\rho_v\\), \\(\\rho_w\\)) and only three observations at level 2. In order to obtain estimates, we need at least as many observations as parameters being estimated. Hence, this model doesn’t work. 4.3.7 Only a Linear Random Term We could try a model of the form \\[ \\begin{equation*} Y_{ij}=\\alpha_{0} + \\beta_{0}\\textrm{Year08}_{ij} + \\gamma_{0}\\textrm{Year08}_{ij}^2 +u_{i}+v_{i}\\textrm{Year08}_{ij} + \\epsilon_{ij} \\end{equation*} \\] where \\(\\epsilon_{ij}\\sim N(0,\\sigma^2)\\) and \\[ \\left[ \\begin{array}{c} u_{i} \\\\ v_{i} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{u}^{2} &amp; \\\\ \\rho_{uv}\\sigma_{u}\\sigma_{v} &amp; \\sigma_{v}^{2} \\end{array} \\right] \\right) . \\] # Modeling quadratic time trend model.b3 &lt;- lmer(MathAvgScore~ yearc + yearc2 + ((yearc) |schoolid), REML=T, data=chart.long) summary(model.b3) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: MathAvgScore ~ yearc + yearc2 + ((yearc) | schoolid) Data: chart.long REML criterion at convergence: 10290.2 Scaled residuals: Min 1Q Median 3Q Max -3.1287 -0.4581 0.0137 0.4552 3.3694 Random effects: Groups Name Variance Std.Dev. Corr schoolid (Intercept) 42.8574 6.5466 yearc 0.5002 0.7073 0.36 Residual 8.0548 2.8381 Number of obs: 1733, groups: schoolid, 618 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 651.94300 0.29028 749.70652 2245.890 &lt; 0.0000000000000002 *** yearc 1.25402 0.09001 537.52786 13.933 &lt; 0.0000000000000002 *** yearc2 1.07136 0.14634 550.10553 7.321 0.000000000000879 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) yearc yearc 0.094 yearc2 -0.342 -0.017 4.3.8 Comments on Random Terms It’s unclear what including a random term for linear effect without a random term for quadratic effect would give us - how would we interpret this? In practice, we often use longitudinal models with higher order fixed effects, but only random intercepts. Such a model allows for a separate effect between schools (in this case), while minimizing parameters that must be estimated. 4.3.9 Model Comparison We compare the quadratic model with the random intercept to the quadratic model with random intercept and linear terms. # Intercept only BIC(model.b1) ## [1] 10335.45 # Intercept and linear term BIC(model.b3) ## [1] 10342.4 The model with only the random intercept term is preferred. 4.3.10 Piecewise Linear Model Another frequently used approach to modeling time effects is the piecewise linear model. This model assumes that average scores change linearly from year to year, but that the slope between the first and second years might be different than the slope between the second and third years We create a binary variables to indicate whether the score came from the 08-09 or 09-10 school years. # Modeling piecewise linear time trend with 3 time points # (won&#39;t work in general) chart.long &lt;- chart.long %&gt;% mutate(year0809 = ifelse(year08==1, 1, 0), year0810 = ifelse(year08==2, 1, 0)) head(chart.long) ## # A tibble: 6 × 13 ## ...1 schoolid schoo…¹ urban charter schPc…² schPc…³ year08 MathA…⁴ yearc ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 Dtype 1 Dnum… RIPPLE… 0 0 0.118 0.363 0 653. -1 ## 2 1 Dtype 1 Dnum… RIPPLE… 0 0 0.118 0.363 1 657. 0 ## 3 1 Dtype 1 Dnum… RIPPLE… 0 0 0.118 0.363 2 653. 1 ## 4 4 Dtype 1 Dnum… WRENSH… 0 0 0.152 0.424 0 647. -1 ## 5 4 Dtype 1 Dnum… WRENSH… 0 0 0.152 0.424 1 645. 0 ## 6 4 Dtype 1 Dnum… WRENSH… 0 0 0.152 0.424 2 652. 1 ## # … with 3 more variables: yearc2 &lt;dbl&gt;, year0809 &lt;dbl&gt;, year0810 &lt;dbl&gt;, and ## # abbreviated variable names ¹​schoolName, ²​schPctsped, ³​schPctfree, ## # ⁴​MathAvgScore 4.3.11 Piecewise Model Equation Let Year2 and Year3 denote indicators for the second and third years (09 and 10), respectively. We fit a model of the form: \\[ \\begin{equation*} Y_{ij}=\\beta{0} + \\beta_{1}\\textrm{Year2}_{ij} + \\beta_{2}\\textrm{Year3}_{ij} +u_{i} + \\epsilon_{ij} \\end{equation*} \\] where \\(u_i\\sim\\mathcal{N}(0, \\sigma^2_u)\\) and \\(\\epsilon_{ij}\\sim\\mathcal{N}(0, \\sigma^2)\\) \\(\\beta_0\\) represents the average math score in year 1 (2008) \\(\\beta_1\\) represents the average change in math score from year 1 to year 2 \\(\\beta_2\\) represents the average change in math score from year 1 to year 3 model.b4 &lt;- lmer(MathAvgScore~ year0809 + year0810 + (1|schoolid), REML=T, data=chart.long) summary(model.b4) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: MathAvgScore ~ year0809 + year0810 + (1 | schoolid) ## Data: chart.long ## ## REML criterion at convergence: 10296.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2125 -0.4756 0.0088 0.4687 3.4954 ## ## Random effects: ## Groups Name Variance Std.Dev. ## schoolid (Intercept) 43.050 6.561 ## Residual 8.523 2.919 ## Number of obs: 1733, groups: schoolid, 618 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 651.7408 0.2932 777.0126 2222.750 &lt;0.0000000000000002 *** ## year0809 0.2015 0.1753 1097.5936 1.149 0.251 ## year0810 2.5399 0.1752 1107.3022 14.501 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) yr0809 ## year0809 -0.304 ## year0810 -0.318 0.514 On average, scores improved by 0.20 points from 2008-2009. On average, scores improved by 2.54 points from 2009-2010. 4.3.12 Estimated Response Curve Red is quadratic estimate. Blue is piecewise linear estimate. ggplot(data=chart.long, aes(x=yearc, y=MathAvgScore)) + geom_point() + stat_smooth(method=&quot;lm&quot;, se=TRUE, fill=NA, formula=y ~ poly(x, 2, raw=TRUE),colour=&quot;red&quot;) + geom_segment(aes(x = -1 , y = fixef(model.b4)[1], xend = 0, yend = fixef(model.b4)[1] + fixef(model.b4)[2]), colour = &quot;blue&quot;)+ geom_segment(aes(x = 0 , y = fixef(model.b4)[1], xend = 1, yend = fixef(model.b4)[1] + fixef(model.b4)[3]), colour = &quot;blue&quot;) 4.3.13 Comparing Quadratic and Piecewise Models AIC(model.b1) # quadratic ## [1] 10308.16 AIC(model.b4) # piecewise ## [1] 10306.77 BIC(model.b1) #quadratic ## [1] 10335.45 BIC(model.b4) #piecewise ## [1] 10334.06 The performance of this model is very similar to the quadratic growth model by AIC and BIC measures, and the story told by fixed effects estimates is also very similar. While the mean yearly increase in math scores was 0.2 points between 2008 and 2009, it was 2.3 points between 2009 and 2010. Despite the good performances of the quadratic growth and piecewise linear models on our three-year window of data, we will continue to use linear growth assumptions in the remainder of this chapter. Not only is a linear model easier to interpret and explain, but it’s probably a more reasonable assumption in years beyond 2010. Predicting future performance is more risky by assuming a steep one-year rise or a non-linear rise will continue, rather than by using the average increase over two years. 4.4 Model for School Type 4.4.1 Uncontrolled Effects of School Type We’ll test for differences between charter and non-charter schools, by adding school type as a fixed effect. Model: \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0} + \\beta_{0}\\textrm{Year08}_{ij} +\\alpha_{1}\\textrm{Charter}_i+ \\beta_{1}\\textrm{Charter}_i\\textrm{Year08}_{ij}] + \\\\ &amp; \\quad [u_{i} + v_{i}\\textrm{Year08}_{ij} + \\epsilon_{ij}] \\end{align*} \\] where \\[ \\left[ \\begin{array}{c} u_{i} \\\\ v_{i} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{u}^{2} &amp; \\\\ \\rho_{uv}\\sigma_{u}\\sigma_{v} &amp; \\sigma_{v}^{2} \\end{array} \\right] \\right) . \\] #Model C (uncontrolled effects of school type on # intercept and slope) model.c &lt;- lmer(MathAvgScore~ charter + year08 + charter:year08 + (year08|schoolid), REML=T, data=chart.long) summary(model.c) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: MathAvgScore ~ charter + year08 + charter:year08 + (year08 | ## schoolid) ## Data: chart.long ## ## REML criterion at convergence: 10291.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.1935 -0.4710 0.0129 0.4660 3.4592 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## schoolid (Intercept) 35.8319 5.9860 ## year08 0.1311 0.3621 0.88 ## Residual 8.7845 2.9639 ## Number of obs: 1733, groups: schoolid, 618 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 652.05844 0.28449 554.58175 2291.998 &lt; 0.0000000000000002 *** ## charter -6.01843 0.86562 622.37343 -6.953 0.00000000000908 *** ## year08 1.19709 0.09427 526.23703 12.698 &lt; 0.0000000000000002 *** ## charter:year08 0.85571 0.31430 596.41970 2.723 0.00667 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) chartr year08 ## charter -0.329 ## year08 -0.203 0.067 ## chartr:yr08 0.061 -0.298 -0.300 4.4.2 Interpretations for School Type Model Fixed effects: \\(\\widehat{\\alpha}_{0} = 652.1.\\) The estimated mean test score for 2008 for non-charter public schools is 652.1. \\(\\widehat{\\alpha}_{1}= -6.02.\\) Charter schools have an estimated test score in 2008 which is 6.02 points lower than public non-charter schools. \\(\\widehat{\\beta}_{0}= 1.20.\\) Public non-charter schools have an estimated mean increase in test scores of 1.20 points per year. \\(\\widehat{\\beta}_{1}= 0.86.\\) Charter schools have an estimated mean increase in test scores of 2.06 points per year over the three-year observation period, 0.86 points higher than the mean yearly increase among public non-charter schools. Variance components: \\(\\widehat{\\sigma}_u= 5.99.\\) The estimated standard deviation of 2008 test scores is 5.99 points, after controlling for school type. \\(\\widehat{\\sigma}_v= 0.36.\\) The estimated standard deviation of yearly changes in test scores during the three-year observation period is 0.36 points, after controlling for school type. \\(\\widehat{\\rho}_{uv}= 0.88.\\) The estimated correlation between 2008 test scores and yearly changes in test scores is 0.88, after controlling for school type. \\(\\widehat{\\sigma}= 2.96.\\) The estimated standard deviation in residuals for the individual growth curves is 2.96 points. Based on t-values reported by R, the effects of year08 and charter both appear to be statistically significant, and there is also significant evidence of an interaction between year08 and charter. Public schools had a significantly higher mean math score in 2008, while charter schools had significantly greater improvement in scores between 2008 and 2010 (although the mean score of charter schools still lagged behind that of public schools in 2010, as indicated in the graphical comparison of Models B and C). 4.4.3 Illustration Section 9.6 of the text goes through several possible models, arriving at a final model with year, and four other covariates. See text for details. 4.5 Covariance Structure among Observations An important part of a longitudinal model is the covariance structure among observations. What does the model say about the correlation between scores at the same school one year apart? Two years apart? 4.5.1 Standard Covariance Structure We will use Model C (uncontrolled effects of school type) to illustrate covariance structure within subjects. Recall that, in composite form, Model C is: \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0}+\\alpha_{1}\\textrm{Charter}_i + \\beta_{0}\\textrm{Year08}_{ij} + \\beta_{1}\\textrm{Charter}_i\\textrm{Year08}_{ij}] \\\\ &amp; + [u_{i} + v_{i}\\textrm{Year08}_{ij} + \\epsilon_{ij}] \\end{align*} \\] where \\(\\epsilon_{ij}\\sim N(0,\\sigma^2)\\) and \\[ \\left[ \\begin{array}{c} u_{i} \\\\ v_{i} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{u}^{2} &amp; \\\\ \\rho_{uv}\\sigma_{u}\\sigma_{v} &amp; \\sigma_{v}^{2} \\end{array} \\right] \\right). \\] For School \\(i\\), the covariance structure for the three time points has general form: \\[ Cov(\\mathbf{Y}_i) = \\left[ \\begin{array}{cccc} Var(Y_{i0}) &amp; Cov(Y_{i0},Y_{i1}) &amp; Cov(Y_{i0},Y_{i2}) \\\\ Cov(Y_{i0},Y_{i1}) &amp; Var(Y_{i1}) &amp; Cov(Y_{i1},Y_{i2}) \\\\ Cov(Y_{i0},Y_{i2}) &amp; Cov(Y_{i1},Y_{i2}) &amp; Var(Y_{i2}) \\end{array} \\right] \\] where \\(Var(Y_{i0})\\) is the variability in 2008 test scores (time \\(j=0\\)), \\(Cov(Y_{i0},Y_{i1})\\) is the covariance between 2008 and 2009 test scores (times \\(j=0\\) and \\(j=1\\)), etc. \\(Cov(Y_{i0},Y_{i2})\\) is the covariance between 2008 and 2010 test scores (times \\(j=0\\) and \\(j=2\\)), etc. We expect positive values for all three covariance terms in \\(Cov(\\mathbf{Y}_i)\\), since schools with relatively high test scores in 2008 are likely to also have relatively high test scores in 2009 or 2010. We expect correlation coefficients between two years to be near 1. Note that the error structure at Level Two is not the same as the within-school covariance structure among observations. \\[ Cov(\\mathbf{Y}_i) \\neq \\left[ \\begin{array}{cc} \\sigma_{u}^{2} &amp; \\\\ \\rho_{uv}\\sigma_{u}\\sigma_{v} &amp; \\sigma_{v}^{2} \\end{array} \\right] . \\] \\(Cov(\\mathbf{Y}_i)\\) describes correlation between a school’s scores in different years. It is a 3x3 matrix, since there are 3 years of data. The second matrix describes correlation between the random intercept \\(u_i\\) and random slope \\(v_i\\). It is a 2x2 matrix, since there are 2 random effects. 4.5.2 Derivation of \\(Var(Y_{i1})\\) (optional) The material on this slide is intended for people who have taken Math 340:Probability. It will not be tested. The variance for individual observation \\(Y_{ij}\\) and covariance between two observations \\(Y_{ij}\\) and \\(Y_{ik}\\) (at school \\(i\\), with different time points \\(j\\) and \\(k\\)) can be derived as follows. Probability Fact: If \\(Y_1 = a_1 X_1 + a_2 X_2 + a_3\\) and \\(Y_2 = b_1 X_1 + b_2 X_2 + b_3\\) where \\(X_1\\) and \\(X_2\\) are random variables and \\(a_i\\) and \\(b_i\\) are constants for \\(i=1,2,3\\), then we know from probability theory that: \\[\\begin{align*} Var(Y_1) &amp; = a^{2}_{1} Var(X_1) + a^{2}_{2} Var(X_2) + 2 a_1 a_2 Cov(X_1,X_2) \\\\ Cov(Y_1,Y_2) &amp; = a_1 b_1 Var(X_1) + a_2 b_2 Var(X_2) + (a_1 b_2 + a_2 b_1) Cov(X_1,X_2) \\end{align*}\\] Applying these identities to Model C, we first see that we can ignore all fixed effects, since they do not contribute to the variability. Thus, \\[ \\begin{align*} Var(Y_{ij}) &amp; = Var(u_{i}+v_{i}\\textrm{Year08}_{ij}+\\epsilon_{ij}) \\\\ &amp; = Var(u_{i}) + \\textrm{Year08}^{2}_{ij} Var(v_{i}) + Var(\\epsilon_{ij}) + 2\\textrm{Year08}_{ij} Cov(u_{i},v_{i}) \\\\ &amp; = \\sigma_{u}^{2} + \\textrm{Year08}^{2}_{ij} \\sigma_{v}^{2} + \\sigma^{2} + 2\\textrm{Year08}_{ij}\\sigma_{uv} \\\\ &amp; = \\sigma_{u}^{2} + t^{2}_{j} \\sigma_{v}^{2} + \\sigma^{2} + 2t_{j}\\sigma_{uv} \\end{align*} \\] \\[ \\begin{align*} Cov(Y_{ij},Y_{ik}) &amp; = Cov(u_{i}+ v_{i}\\textrm{Year08}_{ij}+\\epsilon_{ij}, u_{i}+v_{i}\\textrm{Year08}_{ik}+\\epsilon_{ik}) \\\\ &amp; = Var(u_{i}) + \\textrm{Year08}_{ij}\\textrm{Year08}_{ik} Var(v_{i}) + \\\\ &amp; \\qquad (\\textrm{Year08}_{ij} + \\textrm{Year08}_{ik}) Cov(u_{i},v_{i}) \\\\ &amp; = \\sigma_{u}^{2} + t_{j}t_{k} \\sigma_{v}^{2} + (t_{j}+t_{k})\\sigma_{uv} \\end{align*} \\] Thus, the correlation between observations in consecutive years at school \\(i\\) is given by \\[ \\widehat{Cov}(Y_{i0},Y_{i1},Y_{i2}) = \\left[ \\begin{array}{cccc} \\sigma_u^2 + \\sigma^2 &amp; \\sigma_u^2 + (1)\\sigma_{uv} &amp; \\sigma_u^2 + (0+2)\\sigma_{uv} \\\\ \\sigma_u^2 + (1+0)\\sigma_{uv} &amp; \\sigma_u^2 + 1^2\\sigma_v^2 + \\sigma^2 + 2(1)\\sigma_{uv} &amp; \\sigma_u^2 + 2(1)\\sigma^2_{v} + (1+2)\\sigma_{uv} \\\\ \\sigma_u^2 + (2+0)\\sigma_{uv} &amp; \\sigma_u^2 + 1(2)\\sigma^2_{v} + (2+1)\\sigma_{uv} &amp; \\sigma_u^2 + 2^2\\sigma_v^2 + \\sigma^2 + 2(2)\\sigma_{uv} \\end{array} \\right] \\] 4.5.3 Interpretations of \\(Var(Y_{i1})\\) and \\(Cov(Y_{ij}, Y_{ik})\\) \\(Var(Y_{i0})\\), the uncertainty (variability) around a school’s score in 2008, increases as the uncertainty in intercepts (measured by \\(\\sigma^2_u\\)) and slopes (measured by \\(\\sigma^2_v\\)) increases, and as the uncertainty around that school’s linear time trend (measured by \\(\\sigma^2\\)) increases, and as covariance between intercept and slope residuals increases (measured by \\(\\sigma_{uv}\\)), since if one is off, the other one is likely off as well. \\(Cov(Y_{ij}, Y_{ik})\\) depends only on level two error terms(\\(\\sigma_u\\), \\(\\sigma_v\\), \\(\\sigma_{uv}\\)), not on year-to-year variability within the same school (\\(\\sigma\\)) 4.5.4 Variance and Covariance Estimates We plug into these equations to estimate variance and covariance between individual observations. \\[\\begin{align*} \\widehat{Var}(Y_{i0}) &amp; = 35.832 + 0^{2} 0.131 + 8.784 + 2(0)1.907 = 44.62 \\\\ \\widehat{Var}(Y_{i1}) &amp; = 35.832 + 1^{2} 0.131 + 8.784 + 2(1)1.907 = 48.56 \\\\ \\widehat{Var}(Y_{i2}) &amp; = 35.832 + 2^{2} 0.131 + 8.784 + 2(2)1.907 = 52.77 \\end{align*}\\] and our estimated within-school covariances between different time points would be: \\[\\begin{align*} \\widehat{Cov}(Y_{i0},Y_{i1}) &amp; = 35.832 + (0)(1)0.131 + (0+1)1.907 = 37.74 \\\\ \\widehat{Cov}(Y_{i0},Y_{i2}) &amp; = 35.832 + (0)(2)0.131 + (0+2)1.907 = 39.65 \\\\ \\widehat{Cov}(Y_{i1},Y_{i2}) &amp; = 35.832 + (1)(2)0.131 + (1+2)1.907 = 41.81 \\end{align*}\\] In fact, these values will be identical for every School \\(i\\), since scores were assessed at the same three time points. Thus, we will drop the subscript \\(i\\) moving forward. Written in matrix form, our two-level model implicitly imposes this estimated covariance structure on within-school observations for any specific School \\(i\\): \\[ \\widehat{Cov}(\\mathbf{Y}) = \\left[ \\begin{array}{cccc} 44.62 &amp; &amp; \\\\ 37.74 &amp; 48.56 &amp; \\\\ 39.65 &amp; 41.81 &amp; 52.77 \\end{array} \\right] \\] We can convert covariances to correlations using \\(Corr(Y_{0},Y_{1})=\\frac{Cov(Y_{0},Y_{1})}{\\sqrt{Var(Y_{0}) Var(Y_{1})}}\\): \\[ \\widehat{Corr}(\\mathbf{Y}) = \\left[ \\begin{array}{cccc} 1 &amp; &amp; \\\\ .811 &amp; 1 &amp; \\\\ .817 &amp; .826 &amp; 1 \\end{array} \\right] \\] Observations observations at the same school in different years are highly correlated This model required estimating four parameters associated with the variance-covariance structure: \\(\\sigma^2_u\\), \\(\\sigma^2_v\\), \\(\\sigma_{uv}\\), and \\(\\sigma^2\\). 4.5.5 Alternative Covariance Structure - Uncorrelated In a LLSR model, we assume observations to be independent and following an identical distribution with variance \\(\\sigma^2\\). \\[ \\widehat{Cov}(Y_{i0},Y_{i1},Y_{i2}) = \\left[ \\begin{array}{cccc} \\sigma^2 &amp; 0 &amp; 0 \\\\ 0 &amp; \\sigma^2 &amp; 0 \\\\ 0 &amp; 0 &amp; \\sigma^2 \\end{array} \\right] \\] 4.5.6 Alternative Covariance Structure - Unstructured There are other possible covariance structures that makes sense in certain situations. Unstructured - Every variance and covariance term for observations within a school is a separate parameter and is therefore estimated uniquely; no patterns among variances or correlations are assumed. This structure offers maximum flexibility but is most costly in terms of parameters estimated. \\[ \\widehat{Cov}(Y_{i0},Y_{i1},Y_{i2}) = \\left[ \\begin{array}{cccc} \\sigma^2_0 &amp; &amp; \\\\ \\sigma_{01} &amp; \\sigma^2_1 &amp; \\\\ \\sigma_{02} &amp; \\sigma_{12} &amp; \\sigma^2_2 \\end{array} \\right] \\] There are 6 parameters associated with the variance-covariance structure that need to be estimated: \\(\\sigma^2_0\\),\\(\\sigma^2_1\\),\\(\\sigma^2_2\\), \\(\\sigma_{01}\\), \\(\\sigma_{02}\\), \\(\\sigma_{12}\\). 4.5.7 Alternative Covariance Structure - Compound Symmetry Compound symmetry - Assume variance is constant across all time points and correlation is constant across all pairs of time points. This structure is highly restrictive but least costly in terms of parameters estimated. \\[ \\widehat{Cov}(Y_{i0},Y_{i1},Y_{i2}) = \\left[ \\begin{array}{cccc} \\sigma^2 &amp; &amp; \\\\ \\rho\\sigma &amp; \\sigma^2 &amp; \\\\ \\rho\\sigma &amp; \\rho\\sigma &amp; \\sigma^2 \\end{array} \\right] \\] There are 2 parameters associated with the variance-covariance structure that need to be estimated: \\(\\sigma^2\\), and \\(\\rho\\). 4.5.8 Alternative Covariance Structure - Autogregressive Autoregressive - Assume variance is constant across all time points, but correlation drops off in a systematic fashion as the gap in time increases. Autoregressive models expand compound symmetry by allowing for a common structure where points closest in time are most highly correlated. A common example of an autoregressive model is the AR(1) time series model. For \\(\\phi\\in(-1,1)\\), the covariance matrix is given by: \\[ \\widehat{Cov}(Y_{i0},Y_{i1},Y_{i2}) = \\left[ \\begin{array}{cccc} \\sigma^2 &amp; &amp; \\\\ \\phi\\sigma^2 &amp; \\sigma^2 &amp; \\\\ \\phi^2\\sigma^2 &amp; \\phi\\sigma^2 &amp; \\sigma^2 \\end{array} \\right]. \\] This model requires estimating two parameters \\(\\sigma^2\\), and \\(\\phi\\). This implies a correlation matrix \\[ \\widehat{Corr}(Y_{i0},Y_{i1},Y_{i2}) = \\left[ \\begin{array}{cccc} 1 &amp; &amp; \\\\ \\phi &amp; 1 &amp; \\\\ \\phi^2 &amp; \\phi &amp; 1 \\end{array} \\right]. \\] More generally, the correlation between observations at the same school, taken t years apart is given by \\(\\phi^{t}\\). Since \\(\\phi\\in(-1,1)\\), this correlation decays over time. 4.5.9 AR(1) Model on Schools Data This is not in the book. We fit an AR(1) time series model to the schools data. # keep only schools with observed scores for all 3 years chart.long1 &lt;- chart.long %&gt;% filter(schoolid %in% chart.wide[complete.cases(chart.wide),]$schoolid) AR1.sim = gls(MathAvgScore ~ charter + year08 + charter:year08, data = chart.long1, correlation = corAR1(form = ~ year08 | schoolid)) summary(AR1.sim) ## Generalized least squares fit by REML ## Model: MathAvgScore ~ charter + year08 + charter:year08 ## Data: chart.long1 ## AIC BIC logLik ## 9478.691 9511.017 -4733.346 ## ## Correlation Structure: AR(1) ## Formula: ~year08 | schoolid ## Parameter estimate(s): ## Phi ## 0.7825271 ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) 652.6150 0.2769250 2356.6485 0.0000 ## charter -5.4830 0.9592965 -5.7156 0.0000 ## year08 1.2117 0.1220596 9.9273 0.0000 ## charter:year08 0.6827 0.4228269 1.6147 0.1066 ## ## Correlation: ## (Intr) chartr year08 ## charter -0.289 ## year08 -0.441 0.127 ## charter:year08 0.127 -0.441 -0.289 ## ## Standardized residuals: ## Min Q1 Med Q3 Max ## -5.25884495 -0.53788943 0.06862807 0.59601366 2.96053326 ## ## Residual standard error: 6.16835 ## Degrees of freedom: 1620 total; 1616 residual The fixed effects estimates are very similar to those we saw in model.c. \\(\\widehat{\\phi}^t =0.78^t\\) gives the estimated correlation in measurements at the same school taken t years apart. The correlation in test scores at the same school, one year apart is estimated to be 0.78. The correlation in test scores at the same school, two year2 apart is estimated to be \\(0.78^2 \\approx 0.6084\\). Note that the fixed effects estimates and resulting standard errors and p-values are very similar to those seen in Model C. There are entire statistics courses and texts on Time Series. These are especially relevant in economics. For more information, see books such as this one. 4.5.10 Non-longitudinal Multilevel Models The variance-covariance structure seen here can be generalized to models that do not involve time as well. For example, in the musicians study from Chapter 8, Level One observational units are musical performances rather than time points. The standard model implies the following covariance structure for Musician \\(i\\) in Model C, which uses an indicator for large ensembles as a Level One predictor: \\[ \\begin{align*} Var(Y_{ij}) &amp; = \\sigma_{u}^{2} + \\textrm{Large}^{2}_{ij} \\sigma_{v}^{2} + \\sigma^{2} + 2\\textrm{Large}_{ij}\\sigma_{uv} \\\\ &amp; = \\left\\{ \\begin{array}{ll} \\sigma^{2} + \\sigma_{u}^{2} &amp; \\mbox{if $\\textrm{Large}_{ij}=0$} \\\\ \\sigma^{2} + \\sigma_{u}^{2} + \\sigma_{v}^{2} + 2\\sigma_{uv} &amp; \\mbox{if $\\textrm{Large}_{ij}=1$} \\end{array} \\right. \\end{align*} \\] and \\[ \\begin{align*} Cov(Y_{ij},Y_{ik}) &amp; = \\sigma_{u}^{2} + \\textrm{Large}_{ij}\\textrm{Large}_{ik} \\sigma_{v}^{2} + (\\textrm{Large}_{ij} + \\textrm{Large}_{ik}) \\sigma_{uv} \\\\ &amp; = \\left\\{ \\begin{array}{ll} \\sigma_{u}^{2} &amp; \\mbox{if $\\textrm{Large}_{ij}=\\textrm{Large}_{ik}=0$} \\\\ \\sigma_{u}^{2} + \\sigma_{uv} &amp; \\mbox{if $\\textrm{Large}_{ij}=0$, $\\textrm{Large}_{ik}=1$ or vice versa} \\\\ \\sigma_{u}^{2} + \\sigma_{v}^{2} + 2\\sigma_{uv} &amp; \\mbox{if $\\textrm{Large}_{ij}=\\textrm{Large}_{ik}=1$} \\end{array} \\right. \\end{align*} \\] 4.5.11 Final Thoughts Regarding Covariance Structures choice of covariance matrix does not greatly affect estimates of fixed effects. choice of covariance structure could potentially impact the standard errors of fixed effects, but does not appear to have much impact in this situation. If primary interest is in inference regarding fixed effects, and if the standard errors for the fixed effects appear robust to choice of covariance structure, then extensive time spent modeling the covariance structure is not advised. If researchers are interested in predicted random effects and estimated variance components in addition to estimated fixed effects, then choice of covariance structure can make a big difference. -For example, if researchers are interested in drawing conclusions about particular schools rather than charter schools in general, they may more carefully model the covariance structure in this study. "],["data-with-three-of-more-levels.html", "Chapter 5 Data with Three of More Levels 5.1 Three-Level Plants Experiment 5.2 Three-Level Model with Random Slopes 5.3 Longitudinal Component to Plants Data 5.4 Four-Level Longitudinal Model with Random Slopes", " Chapter 5 Data with Three of More Levels These notes accompany Chapter 10 in Beyond Multiple Linear Regression by Roback and Legler. # Packages required for Chapter 10 library(MASS) library(gridExtra) library(mnormt) library(lme4) library(lmerTest) library(knitr) library(kableExtra) library(tidyverse) library(Hmisc) library(nlme) 5.1 Three-Level Plants Experiment 5.1.1 Experimental Design Researchers are interested in comparing heights of plants of two different genotypes (A and B), with two different fertilizers (A and B), and also in assessing whether being close to window affects growth. Scientists obtained four trays and placed four pots in each tray. Two of the trays were placed close to windows and the other two were placed away from windows. Within each tray, two of the pots received fertilizer A and two received fertilizer B. Two plants of each phenotype were then planted in each plot. After 4 weeks, researchers recorded the height of each plant. Figure 5.1: Potted Plant Experimental Design 5.1.2 The Data The first 20 rows of the dataset are shown below. head(plants, 20) ## plantid tray pot window fertA phenoA height ## 1 1 1 1 1 1 1 5.59 ## 2 2 1 1 1 1 0 5.33 ## 3 3 1 1 1 1 1 5.70 ## 4 4 1 1 1 1 0 5.77 ## 5 5 1 2 1 0 1 2.93 ## 6 6 1 2 1 0 0 1.79 ## 7 7 1 2 1 0 1 2.57 ## 8 8 1 2 1 0 0 2.12 ## 9 9 1 3 1 1 1 4.86 ## 10 10 1 3 1 1 0 2.13 ## 11 11 1 3 1 1 1 3.24 ## 12 12 1 3 1 1 0 2.10 ## 13 13 1 4 1 0 1 1.10 ## 14 14 1 4 1 0 0 2.35 ## 15 15 1 4 1 0 1 1.79 ## 16 16 1 4 1 0 0 4.88 ## 17 17 2 5 0 1 1 1.51 ## 18 18 2 5 0 1 0 3.71 ## 19 19 2 5 0 1 1 2.30 ## 20 20 2 5 0 1 0 2.30 5.1.3 Questions Between plants B, C, and D, which would you expect to be most highly correlated with plant A? Which would you expect to be least highly correlated with plant A? What are the observational units at each level? What are the treatments or variables? 5.1.4 Three Level Model Let \\(Y_{ijk}\\) represent the height of plant \\(k\\) in pot \\(j\\) in tray \\(i\\). A possible model is: \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0}+\\alpha_{1}\\textrm{Window}_{i}+\\beta_{0}\\textrm{FertA}_{ij}+\\gamma_{0}\\textrm{PhenoA}_{ijk}] \\\\ &amp; \\textrm{} + [t_{i}+ p_{ij} + \\epsilon_{ijk}], \\end{align*} \\] where \\(t_i\\sim N(0, \\sigma^2_t)\\), \\(p_{ij}\\sim N(0, \\sigma^2_p)\\), and \\(\\epsilon_{ijk}\\sim N(0, \\sigma^2)\\) This model includes fixed effects for window, fertilizer, and phenotype, and random effects for tray and pot. We assume there are no interactions between the fixed effects. The model includes 3 random effects: \\(t_i\\) - deviations in average plant heights between trays, after accounting for the three fixed effects. \\(p_{ij}\\) - deviations in average plant height between pots in the same tray, after accounting for the three fixed effects. \\(\\epsilon_{ijk}\\) - deviations between individual plants in the same tray and pot after accounting for the three fixed effects. The model does not include any random slope effects. This means we are assuming the effect of phenotype is the same in each pot, and the effect of fertilizer is the same in each tray. 5.1.5 R Implementation of Three Level Model M &lt;- lmer(data=plants, height ~ window + fertA + phenoA + (1|pot) + (1|tray)) summary(M) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: height ~ window + fertA + phenoA + (1 | pot) + (1 | tray) ## Data: plants ## ## REML criterion at convergence: 201.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.35859 -0.61695 -0.06346 0.56342 2.27449 ## ## Random effects: ## Groups Name Variance Std.Dev. ## pot (Intercept) 0.4784 0.6917 ## tray (Intercept) 0.1336 0.3655 ## Residual 1.0775 1.0380 ## Number of obs: 64, groups: pot, 16; tray, 4 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 2.1178 0.4731 3.8400 4.476 0.0121 * ## window 1.1416 0.5662 2.0000 2.016 0.1813 ## fertA 0.7528 0.4324 11.0000 1.741 0.1095 ## phenoA 0.5997 0.2595 47.0000 2.311 0.0253 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) window fertA ## window -0.598 ## fertA -0.457 0.000 ## phenoA -0.274 0.000 0.000 \\(\\hat{\\sigma}_p=0.6917\\), \\(\\hat{\\sigma}_t=0.3655\\), \\(\\hat{\\sigma}=1.0380\\). After accounting for phenotype, fertilizer, and window, the greatest amount of remaining variability occurs between individual plants in the same pot, followed by average heights among pots in the same tray, followed by average heights between trays. 5.1.6 Inappropriate LLSR Model We compare this to an inappropriately fit LLSR model. M_LLSR &lt;- lm(data=plants, height ~ window + fertA + phenoA ) summary(M_LLSR) ## ## Call: ## lm(formula = height ~ window + fertA + phenoA, data = plants) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.7591 -0.9762 0.2752 0.8677 2.1381 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.1178 0.3126 6.775 0.00000000604 *** ## window 1.1416 0.3126 3.652 0.000548 *** ## fertA 0.7528 0.3126 2.408 0.019115 * ## phenoA 0.5997 0.3126 1.918 0.059814 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.25 on 60 degrees of freedom ## Multiple R-squared: 0.2755, Adjusted R-squared: 0.2393 ## F-statistic: 7.606 on 3 and 60 DF, p-value: 0.0002161 the LLSR model inappropriately assumes we have 64 independent observations Since the phenotype variable pertains to the 64 individual plants, the “effective” sample size for inference about phenotype is still 64. Since we are able to randomly assign phenotypes within pots, the multilevel model accounts for variability associated with pot and tray, taking \\(\\sigma^2_t\\) and \\(\\sigma^2_p\\) out of the calculation of \\(\\sigma^2\\) in the LSSR model, resulting in a smaller standard error associated with phenotype. Since fertilizer was assigned to pots, rather than plants, the “effective” sample size is 16. This smaller sample size leads to higher standard error associated with the effect of fertilizer. Since window was assigned to trays, the “effective” sample size is 4, resulting in the highest standard errors being associated with trays. 5.2 Three-Level Model with Random Slopes 5.2.1 Random Slope for PhenoA We could allow for the possibility that the effect of phenotype is different in different pots, by adding a random slope effect for phenotype. \\[ \\begin{align*} Y_{ijk} &amp; = [\\alpha_{0}+\\alpha_{1}\\textrm{Window}_{i}+\\beta_{0}\\textrm{FertA}_{ij}+\\gamma_{0}\\textrm{PhenoA}_{ijk}] \\\\ &amp; \\textrm{} + [t_i + p_{ij} + q_{ij}\\textrm{PhenoA}_{ij} + \\epsilon_{ijk}], \\end{align*} \\] where \\(t_i\\sim N(0, \\sigma^2_t)\\), and \\(\\epsilon_{ijk}\\sim N(0, \\sigma^2)\\) \\[ \\left[ \\begin{array}{c} p_{ij} \\\\q_{ij} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{p}^{2} &amp; \\rho_{pq}\\sigma_{p}\\sigma_q \\\\ \\rho_{pq}\\sigma_{p}\\sigma_q &amp; \\sigma_{q}^{2} \\end{array} \\right] \\right) \\] We assume random error terms on different levels are independent of each other. That is, \\(t_i\\) is independent of \\(p_{ij}\\) and \\(q_{ij}\\), and all of these are independent of \\(\\epsilon_{ijk}\\). 5.2.2 R Output for Random Slope for PhenoA M3 &lt;- lmer(data=plants, height ~ window + fertA + phenoA + (phenoA|pot) + (1|tray)) summary(M3) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: height ~ window + fertA + phenoA + (phenoA | pot) + (1 | tray) ## Data: plants ## ## REML criterion at convergence: 200.2 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.16998 -0.65343 -0.06843 0.67860 1.97927 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## pot (Intercept) 0.6371 0.7982 ## phenoA 0.5754 0.7586 -0.42 ## tray (Intercept) 0.1221 0.3494 ## Residual 0.8938 0.9454 ## Number of obs: 64, groups: pot, 16; tray, 4 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 2.1268 0.4719 3.5371 4.506 0.0142 * ## window 1.1380 0.5567 1.8497 2.044 0.1879 ## fertA 0.7384 0.4334 10.8398 1.704 0.1169 ## phenoA 0.5997 0.3030 15.0002 1.979 0.0665 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) window fertA ## window -0.590 ## fertA -0.459 0.000 ## phenoA -0.305 0.000 0.000 The negative estimate of correlation \\(\\rho_{pq}\\) indicates that differences between phenotypes are smaller in pots when plants of phenotype B are taller. 5.2.3 Random Slope for Fert What if we want to allow for the possibility that the effects of fertilizers varies between trays? The R code for such a model is shown below. M4 &lt;- lmer(data=plants, height ~ window + fertA + phenoA + (1|pot) + (fertA|tray)) How would we write this model mathematically? Include any distributional assumptions about the random effects and error terms. 5.2.4 R Output for Random Slope for Fert M4 &lt;- lmer(data=plants, height ~ window + fertA + phenoA + (1|pot) + (fertA|tray)) summary(M4) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: height ~ window + fertA + phenoA + (1 | pot) + (fertA | tray) ## Data: plants ## ## REML criterion at convergence: 201.1 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.34479 -0.62506 -0.01316 0.55385 2.38204 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## pot (Intercept) 0.3905 0.6249 ## tray (Intercept) 0.4759 0.6899 ## fertA 0.2731 0.5226 -1.00 ## Residual 1.0775 1.0380 ## Number of obs: 64, groups: pot, 16; tray, 4 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.9829 0.5404 3.0907 3.669 0.0333 * ## window 1.4115 0.5430 2.7821 2.599 0.0869 . ## fertA 0.7528 0.4830 3.8691 1.559 0.1964 ## phenoA 0.5997 0.2595 47.0000 2.311 0.0253 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) window fertA ## window -0.502 ## fertA -0.661 0.000 ## phenoA -0.240 0.000 0.000 ## optimizer (nloptwrap) convergence code: 0 (OK) ## boundary (singular) fit: see help(&#39;isSingular&#39;) 5.2.5 Boundary Constraints Recall that \\(-1\\leq\\rho\\leq1\\), where \\(\\rho\\) represents the correlation between random effects at the same level. When \\(\\hat{\\rho}=\\pm1\\), this indicates that the maximimum likelihood estimates are occuring along a boundary of this range, usually making them unreliable. In these situations, we should not draw conclusions basde on \\(\\rho\\) and should consider dropping this random effect from the model. We could also add interaction or nonlinear terms for fixed effects if we had reason to do so. 5.3 Longitudinal Component to Plants Data 5.3.1 Repeated Measures over Time Now suppose that in addition to this first measurement, the heights of the same plants were recorded again once per week for 4 weeks. head(plants, 20) ## plantid time tray pot window fertA phenoA height ## 1 1 1 1 1 1 1 1 5.593006 ## 2 1 2 1 1 1 1 1 6.588438 ## 3 1 3 1 1 1 1 1 7.483192 ## 4 1 4 1 1 1 1 1 8.889305 ## 5 2 1 1 1 1 1 0 5.330448 ## 6 2 2 1 1 1 1 0 6.350843 ## 7 2 3 1 1 1 1 0 7.380016 ## 8 2 4 1 1 1 1 0 8.442597 ## 9 3 1 1 1 1 1 1 5.700156 ## 10 3 2 1 1 1 1 1 6.549357 ## 11 3 3 1 1 1 1 1 7.742034 ## 12 3 4 1 1 1 1 1 8.892204 ## 13 4 1 1 1 1 1 0 5.770243 ## 14 4 2 1 1 1 1 0 6.550047 ## 15 4 3 1 1 1 1 0 7.632318 ## 16 4 4 1 1 1 1 0 8.796274 ## 17 5 1 1 2 1 0 1 2.925716 ## 18 5 2 1 2 1 0 1 3.626215 ## 19 5 3 1 2 1 0 1 4.687552 ## 20 5 4 1 2 1 0 1 5.433369 5.3.2 Levels and Variables Now, this is a 4-level dataset. Level Observational Unit Treatment or Variable Level 1 time points time Level 2 plants phenotype Level 3 pots fertilizer Level 4 trays window 5.3.3 Model for Longitudinal Plants Study Let \\(Y_{ijkl}\\) represent the height of plant \\(k\\) in pot \\(j\\) in tray \\(i\\) at time \\(l\\). A possible model is: \\[ \\begin{align*} Y_{ijkl} &amp; = [\\alpha_{0}+\\alpha_{1}\\textrm{Window}_{i}+\\beta_{0}\\textrm{FertA}_{ij}+\\gamma_{0}\\textrm{PhenoA}_{ijk} + \\delta_{0}\\textrm{Time}_{ijkl}] \\\\ &amp; \\textrm{} + [t_{i}+ p_{ij} + f_{ijk} + \\epsilon_{ijkl}], \\end{align*} \\] where \\(t_i\\sim N(0, \\sigma^2_t)\\), \\(p_{ij}\\sim N(0, \\sigma^2_p)\\), \\(f_{ijk}\\sim N(0, \\sigma^2_f)\\),and \\(\\epsilon_{ijkl}\\sim N(0, \\sigma^2)\\) This model involves random intercepts for each tray(\\(t_i\\)), pot(\\(p_{ij}\\)), plant (\\(f_{ijk}\\)), in addition to a random error term \\(\\epsilon{ijkl}\\) capturing random differences between measurements on the same plant over time. In addition to the assumptions of model 1, it assumes each plant grows at the same rate over time, after accounting for the fixed effects in the model. 5.3.4 R Output for Longitudinal Model M5 &lt;- lmer(data=plants, height ~ window + fertA + phenoA + time + (1|tray) + (1|pot) + (1|plantid)) summary(M5) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: height ~ window + fertA + phenoA + time + (1 | tray) + (1 | pot) + ## (1 | plantid) ## Data: plants ## ## REML criterion at convergence: 362.3 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.81419 -0.56459 -0.00598 0.56245 2.67726 ## ## Random effects: ## Groups Name Variance Std.Dev. ## plantid (Intercept) 1.10405 1.0507 ## pot (Intercept) 0.77702 0.8815 ## tray (Intercept) 0.07314 0.2704 ## Residual 0.08029 0.2834 ## Number of obs: 256, groups: plantid, 64; pot, 16; tray, 4 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.21075 0.50407 4.40526 2.402 0.0683 . ## window 1.47080 0.58108 2.00000 2.531 0.1270 ## fertA 0.90342 0.51431 11.00008 1.757 0.1068 ## phenoA 0.58651 0.26506 47.00103 2.213 0.0318 * ## time 0.66370 0.01584 190.99960 41.899 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) window fertA phenoA ## window -0.576 ## fertA -0.510 0.000 ## phenoA -0.263 0.000 0.000 ## time -0.079 0.000 0.000 0.000 We see that after accounting for time, phenotype, fertilizer, and window location, there is more variability between average heights of different plants in the same pot (\\(\\sigma_f=1.05\\)), and in average heights in different pots in the same tray (\\(\\sigma_p=0.88\\)), than between average heights in different trays(\\(\\sigma_t=0.27\\)), or between heights of the same plant at different times(\\(\\sigma=0.28\\)). There is evidence that plants grow over time, and evidence of differences between the phenotypes. 5.4 Four-Level Longitudinal Model with Random Slopes 5.4.1 Random Slope for Time We could add a random error term associated with the slope on time, to allow for the possibility that individual plants grow at different rates, even after accounting for the fixed effects in the model \\[ \\begin{align*} Y_{ijkl} &amp; = [\\alpha_{0}+\\alpha_{1}\\textrm{Window}_{i}+\\beta_{0}\\textrm{FertA}_{ij}+\\gamma_{0}\\textrm{PhenoA}_{ijk} + \\delta_{0}\\textrm{Time}_{ijkl}] \\\\ &amp; \\textrm{} + [t_{i}+ p_{ij} + f_{ijk} + g_{ijk}\\textrm{Time}_{ijk} + \\epsilon_{ijkl}], \\end{align*} \\] where \\(t_i\\sim N(0, \\sigma^2_t)\\), \\(p_{ij}\\sim N(0, \\sigma^2_p)\\), \\(\\epsilon_{ijkl}\\sim N(0, \\sigma^2)\\), and \\[ \\begin{equation*} \\left[ \\begin{array}{c} f_{ijk} \\\\g_{ijk} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{f}^{2} &amp; \\rho_{fg}\\sigma_{f}\\sigma_g \\\\ \\rho_{fg}\\sigma_{f}\\sigma_g &amp; \\sigma_{g}^{2} \\end{array} \\right] \\right) \\end{equation*} \\] M5 &lt;- lmer(data=plants, height ~ window + fertA + phenoA + time+ (time|plantid) + (1|pot) + (1|tray)) summary(M5) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: height ~ window + fertA + phenoA + time + (time | plantid) + ## (1 | pot) + (1 | tray) ## Data: plants ## ## REML criterion at convergence: 211.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.10148 -0.52521 -0.00405 0.46057 2.19928 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## plantid (Intercept) 1.15701 1.0756 ## time 0.03871 0.1967 0.22 ## pot (Intercept) 0.17876 0.4228 ## tray (Intercept) 0.20608 0.4540 ## Residual 0.01646 0.1283 ## Number of obs: 256, groups: plantid, 64; pot, 16; tray, 4 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.81814 0.45694 3.32508 3.979 0.0234 * ## window 0.73079 0.56786 1.99920 1.287 0.3270 ## fertA 0.47511 0.34115 7.96885 1.393 0.2013 ## phenoA 0.54007 0.26775 43.09443 2.017 0.0499 * ## time 0.66370 0.02562 63.00065 25.909 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) window fertA phenoA ## window -0.621 ## fertA -0.373 0.000 ## phenoA -0.293 0.000 0.000 ## time 0.051 0.000 0.000 0.000 The positive correlation between \\(s_{ijk}\\) and \\(r_{ijk}\\) tells us that taller plants tend to grow faster on average, even after accounting for fixed effects in the model. 5.4.2 More Random Slope Terms We could also allow the effect of phenotype to vary between pots and the effect of fertilizer to vary between trays. This gives a model of the form: \\[ \\begin{align*} Y_{ijk} &amp; = [\\beta_{0}+\\beta_{1}\\textrm{Window}_{i}+\\beta_{2}\\textrm{FertA}_{ij}+\\beta_{3}\\textrm{PhenoA}_{ijk} + \\beta_{3}\\textrm{Time}_{ijkl}] \\\\ &amp; \\textrm{} + [t_{i}+ s_i\\textrm{fertA}_i + p_{ij} + q_{ij}\\textrm{phenoA}_{ij} + f_{ijk} + g_{ijk}\\textrm{Time}_{ijk} + \\epsilon_{ijkl}], \\end{align*} \\] We again assume that random effects at different levels are independent. Thus, \\(\\epsilon_{ijkl}\\sim\\mathcal{N}(0, \\sigma^2)\\) \\[ \\begin{equation*} \\left[ \\begin{array}{c} t_{i} \\\\s_{i} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{t}^{2} &amp; \\rho_{ts}\\sigma_{t}\\sigma_s \\\\ \\rho_{ts}\\sigma_{t}\\sigma_s &amp; \\sigma_{s}^{2} \\end{array} \\right] \\right) \\end{equation*} \\] \\[ \\begin{equation*} \\left[ \\begin{array}{c} p_{ij} \\\\q_{ij} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{p}^{2} &amp; \\rho_{pq}\\sigma_{p}\\sigma_q \\\\ \\rho_{pq}\\sigma_{p}\\sigma_q &amp; \\sigma_{q}^{2} \\end{array} \\right] \\right) \\end{equation*} \\] \\[ \\begin{equation*} \\left[ \\begin{array}{c} f_{ijk} \\\\g_{ijk} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{f}^{2} &amp; \\rho_{fg}\\sigma_{f}\\sigma_g \\\\ \\rho_{fg}\\sigma_{f}\\sigma_g &amp; \\sigma_{g}^{2} \\end{array} \\right] \\right) \\end{equation*} \\] M5 &lt;- lmer(data=plants, height ~ window + fertA + phenoA + time+ (time|plantid) + (phenoA|pot) + (fertA|tray)) summary(M5) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: height ~ window + fertA + phenoA + time + (time | plantid) + ## (phenoA | pot) + (fertA | tray) ## Data: plants ## ## REML criterion at convergence: 210.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.09915 -0.51800 0.00304 0.44894 2.19798 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## plantid (Intercept) 0.96878 0.9843 ## time 0.03871 0.1967 0.22 ## pot (Intercept) 0.37653 0.6136 ## phenoA 0.55487 0.7449 -0.70 ## tray (Intercept) 0.35597 0.5966 ## fertA 0.13997 0.3741 -0.69 ## Residual 0.01646 0.1283 ## Number of obs: 256, groups: plantid, 64; pot, 16; tray, 4 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.71536 0.50375 1.46343 3.405 0.116 ## window 0.90369 0.57817 1.87488 1.563 0.266 ## fertA 0.50662 0.37849 2.69858 1.339 0.282 ## phenoA 0.54121 0.30820 14.50247 1.756 0.100 ## time 0.66370 0.02562 63.00080 25.909 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) window fertA phenoA ## window -0.574 ## fertA -0.484 0.000 ## phenoA -0.324 0.000 0.000 ## time 0.042 0.000 0.000 0.000 After accounting for window, fertilizer, phenotype, and time, plants that are taller initially tend to grow faster than those that are shorter initially (\\(\\hat{\\rho}_{fg} =0.22\\)) difference between phenotypes is smaller in pots where plants of phenotype B are taller difference between fertilizers is smaller in trays where plants receiving fertilizer B are taller 5.4.3 Additional Random Slopes In theory, we could add a random slope term that also allows plants in the same pot to change at different rates over time. We would write this model as: \\[ \\begin{align*} Y_{ij} &amp; = [\\beta_{0}+\\beta_{1}\\textrm{Window}_{i}+\\beta_{2}\\textrm{FertA}_{ij}+\\beta_{3}\\textrm{PhenoA}_{ijk} + \\beta_{3}\\textrm{Time}_{ijkl}] \\\\ &amp; \\textrm{} + [t_{i}+ s_i\\textrm{fertA}_i + p_{ij} + q_{ij}\\textrm{phenoA}_{ij} +r_{ij}\\textrm{Time}_{ijk}+ f_{ijk} + g_{ijk}\\textrm{Time}_{ijk} + \\epsilon_{ijkl}], \\end{align*} \\] We again assume that random effects at different levels are independent. Thus, \\(\\epsilon_{ijkl}\\sim\\mathcal{N}(0, \\sigma^2)\\) \\[ \\begin{equation*} \\left[ \\begin{array}{c} t_{i} \\\\s_{i} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{t}^{2} &amp; \\rho_{ts}\\sigma_{t}\\sigma_s \\\\ \\rho_{ts}\\sigma_{t}\\sigma_s &amp; \\sigma_{s}^{2} \\end{array} \\right] \\right) \\end{equation*} \\] \\[ \\begin{equation*} \\left[ \\begin{array}{c} p_{ij} \\\\q_{ij} \\\\ r_{ij} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{p}^{2} &amp; \\rho_{pq}\\sigma_{p}\\sigma_q &amp; \\rho_{pr}\\sigma_{p}\\sigma_r\\\\ \\rho_{pq}\\sigma_{p}\\sigma_q &amp; \\sigma_{q}^{2}&amp; \\rho_{qr}\\sigma_{q}\\sigma_r\\\\ \\rho_{pr}\\sigma_{p}\\sigma_r &amp; \\rho_{qr}\\sigma_{q}\\sigma_r &amp; \\sigma_r^2 \\\\ \\end{array} \\right] \\right) \\end{equation*} \\] \\[ \\begin{equation*} \\left[ \\begin{array}{c} f_{ijk} \\\\g_{ijk} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{f}^{2} &amp; \\rho_{fg}\\sigma_{f}\\sigma_g \\\\ \\rho_{fg}\\sigma_{f}\\sigma_g &amp; \\sigma_{g}^{2} \\end{array} \\right] \\right) \\end{equation*} \\] 5.4.4 R - Model with Additional Random Slopes M6 &lt;- lmer(data=plants, height ~ window + fertA + phenoA + time+ (time|plantid) + (time|pot) + (phenoA|pot) + (fertA|tray)) summary(M6) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: height ~ window + fertA + phenoA + time + (time | plantid) + ## (time | pot) + (phenoA | pot) + (fertA | tray) ## Data: plants ## ## REML criterion at convergence: 172.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.09129 -0.52578 0.03103 0.47586 2.20610 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## plantid (Intercept) 0.84586 0.9197 ## time 0.01242 0.1115 -0.03 ## pot (Intercept) 0.61408 0.7836 ## time 0.02760 0.1661 1.00 ## pot.1 (Intercept) 0.17413 0.4173 ## phenoA 0.58696 0.7661 -1.00 ## tray (Intercept) 0.05386 0.2321 ## fertA 0.29488 0.5430 1.00 ## Residual 0.01646 0.1283 ## Number of obs: 256, groups: plantid, 64; pot, 16; tray, 4 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 2.51518 0.40285 6.82721 6.244 0.000472 *** ## window -0.30245 0.45895 3.00925 -0.659 0.556822 ## fertA 0.09250 0.39111 3.17685 0.237 0.827477 ## phenoA 0.56183 0.30104 14.99004 1.866 0.081690 . ## time 0.66370 0.04439 15.03669 14.952 0.000000000196 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) window fertA phenoA ## window -0.570 ## fertA -0.052 0.000 ## phenoA -0.387 0.000 0.000 ## time 0.446 0.000 0.000 0.000 This model, however, leads to boundary contraint issues. 5.4.5 When Not to Add Random Slopes We can only add random slopes for variables measured at a lower level than the observational unit. Otherwise, the variable will not change within the observational unit. For example, we can’t add a random slope for effect of fertilizer (a level 3 variable) between pots (our level 3 observational units). All plants in the same pot have the same type of fertilizer, so we can’t estimate difference of fertilizer effects between pots. M7 &lt;- lmer(data=plants, height ~ window + fertA + phenoA + time+ (1|plantid) + (1|pot) + (fertA|pot) + (1|tray)) summary(M7) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: height ~ window + fertA + phenoA + time + (1 | plantid) + (1 | ## pot) + (fertA | pot) + (1 | tray) ## Data: plants ## ## REML criterion at convergence: 359.2 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.79063 -0.55735 -0.00856 0.57002 2.67333 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## plantid (Intercept) 1.0715982358 1.0351803 ## pot (Intercept) 0.0000001555 0.0003943 ## pot.1 (Intercept) 0.0000002716 0.0005211 ## fertA 1.5286919355 1.2364028 0.75 ## tray (Intercept) 0.6376007573 0.7984991 ## Residual 0.0802920056 0.2833584 ## Number of obs: 256, groups: plantid, 64; pot, 16; tray, 4 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.43322 0.63338 2.21644 2.263 0.1395 ## window 1.02587 0.86955 1.96345 1.180 0.3613 ## fertA 0.90342 0.50935 8.37031 1.774 0.1124 ## phenoA 0.58651 0.26121 50.12707 2.245 0.0292 * ## time 0.66370 0.01584 191.00264 41.900 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) window fertA phenoA ## window -0.686 ## fertA -0.106 0.000 ## phenoA -0.206 0.000 0.000 ## time -0.063 0.000 0.000 0.000 In this section, we have focused on random effects, but we can, of course, explore fixed effects (such as interactions) as we’ve done before. "],["poisson-regression.html", "Chapter 6 Poisson Regression 6.1 Modeling Counts 6.2 Poisson Regression Models 6.3 Poisson Model for Household Size 6.4 Poisson Model with Multiple Explanatory Variables 6.5 Deviance and Model Comparison 6.6 Overdisperson 6.7 Offsets in Poisson Regression 6.8 Summaries", " Chapter 6 Poisson Regression These notes provide a summary of Chapter 4 in Beyond Multiple Linear Regression by Roback and Legler. Much of the code that appears here comes from the textbook’s Github repository. 6.1 Modeling Counts 6.1.1 Case Study: Household Size in the Philippines From Roback &amp; Legler’s text: How many other people live with you in your home? The number of people sharing a house differs from country to country and often from region to region. International agencies use household size when determining needs of populations, and the household sizes determine the magnitude of the household needs. The Philippine Statistics Authority (PSA) spearheads the Family Income and Expenditure Survey (FIES) nationwide. The survey, which is undertaken every three years, is aimed at providing data on family income and expenditure, including levels of consumption by item of expenditure. Our data, from the 2015 FIES, is a subset of 1500 of the 40,000 observations. Our data set focuses on five regions: Central Luzon, Metro Manila, Ilocos, Davao, and Visayas. 6.1.2 Map of the Philippines Figure 6.1: Regions of the Philippines. 6.1.3 Questions of Interest Does household size vary between regions of the country? At what age are heads of households in the Philippines most likely to find the largest number of people in their household? Is this association similar for poorer households (measured by the presence of a roof made from predominantly light/salvaged materials)? 6.1.4 The Data fHH1 &lt;- read_csv(&quot;https://raw.githubusercontent.com/proback/BeyondMLR/master/data/fHH1.csv&quot;) The data include the following variables: location = where the house is located (Central Luzon, Davao Region, Ilocos Region, Metro Manila, or Visayas) age = the age of the head of household total = the number of people in the household other than the head numLT5 = the number in the household under 5 years of age roof = the type of roof in the household (either Predominantly Light/Salvaged Material, or Predominantly Strong Material, where stronger material can sometimes be used as a proxy for greater wealth) 6.1.5 First 5 Rows head(fHH1) # A tibble: 6 × 6 ...1 location age total numLT5 roof &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 1 1 CentralLuzon 65 0 0 Predominantly Strong Material 2 2 MetroManila 75 3 0 Predominantly Strong Material 3 3 DavaoRegion 54 4 0 Predominantly Strong Material 4 4 Visayas 49 3 0 Predominantly Strong Material 5 5 MetroManila 74 3 0 Predominantly Strong Material 6 6 Visayas 59 6 0 Predominantly Strong Material 6.1.6 Household Size by Region fHH1 %&gt;% group_by(location) %&gt;% summarise(mean=mean(total), sd=sd(total), var=var(total), n=n()) ## # A tibble: 5 × 5 ## location mean sd var n ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 CentralLuzon 3.40 2.04 4.15 224 ## 2 DavaoRegion 3.39 2.17 4.72 187 ## 3 IlocosRegion 3.59 2.32 5.40 191 ## 4 MetroManila 3.71 2.21 4.86 297 ## 5 Visayas 3.90 2.57 6.60 601 6.1.7 Household Size by Region Plots ggplot(fHH1, aes(total)) + geom_histogram(binwidth = .25, color = &quot;black&quot;, fill = &quot;white&quot;) + facet_wrap(~location) + xlab(&quot;Number in the house excluding head of household&quot;) + ylab(&quot;Count of households&quot;) responses range from 0 to 16 and are most often between 1 and 5 number of people in a house is right skewed and cannot be be negative 6.1.8 Modeling Household Size Let \\(Y_i\\) represent the size of household \\(i\\). We’ll use location as an explanatory variable. In this example, we’ll treat location as a fixed effect, since we’re interested in comparing and drawing conclusions about the five regions. 6.1.9 Inappropriate LLSR Model On first thought, we might consider an ordinary LLSR model of the form \\[ Y_i = \\beta_0 + \\beta_1\\textrm{locationDavao}_i + \\beta_2\\textrm{locationIlocos}_i + \\\\\\beta_3\\textrm{locationMetroManila}_i + \\beta_4\\textrm{locationVisayas}_i + \\epsilon_i \\] where \\(\\epsilon_i\\sim\\mathcal{N}(0,\\sigma^2)\\) 6.1.10 LLSR Model R Output M1 &lt;- lm(data=fHH1, total ~ location) summary(M1) ## ## Call: ## lm(formula = total ~ location, data = fHH1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.9018 -1.7071 -0.3904 1.2929 12.4136 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.40179 0.15678 21.698 &lt; 0.0000000000000002 *** ## locationDavaoRegion -0.01141 0.23243 -0.049 0.96085 ## locationIlocosRegion 0.18460 0.23110 0.799 0.42454 ## locationMetroManila 0.30528 0.20765 1.470 0.14172 ## locationVisayas 0.50004 0.18369 2.722 0.00656 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.346 on 1495 degrees of freedom ## Multiple R-squared: 0.00777, Adjusted R-squared: 0.005115 ## F-statistic: 2.927 on 4 and 1495 DF, p-value: 0.01999 6.1.11 LLSR Assumptions The LLSR model assumes that in region \\(j\\), household sizes are: Independent Normally distributed with mean \\(\\beta_0 + \\beta_j\\) and variance \\(\\sigma^2\\) Variance \\(\\sigma^2\\) is constant between regions The linearity assumption is not relevant here since the explanatory variable is categorical. 6.1.12 Distribution in Visayas Region According to the model, household sizes in the Visayas region are normally distributed with mean \\(\\hat{\\beta}_0 + \\hat{\\beta}_4 = 3.9\\) and standard deviation \\(\\hat{\\sigma} = 2.346\\). ggplot(fHH1 %&gt;% filter(location==&quot;Visayas&quot;), aes(total)) + geom_histogram(aes(y = ..density..), binwidth = 0.25, colour = &quot;black&quot;) + stat_function(fun = dnorm, args = list(mean = 3.9, sd = 2.346), size=1, color=&quot;red&quot;) + xlab(&quot;Number in the house excluding head of household&quot;) + ylab(&quot;Count of households&quot;) + xlim(c(-5,20)) Problems The normal distribution: allows for negative household sizes allows for non-integer household sizes underestimates probability of household sizes above 10 (fails to accunt for right-skewness) 6.1.13 Normal Quantile Quantile Plot A normal quantile-quantile plot graphs the quantiles of the model residuals against the expected quantiles from a normal distribution. If the normal distribution is appropriate, the points should lie close to a diagonal line. ggplot(data=data.frame(M1$residuals), aes(sample = scale(M1$residuals))) + stat_qq() + stat_qq_line() + xlab(&quot;Normal Quantiles&quot;) + ylab(&quot;Residual Quantiles&quot;) + ggtitle(&quot;QQ Plot&quot;) Residual quantiles are higher than expected on the left (since there are no negative household sizes), and on the right (since some households are larger than expected). The normal distribution is a poor fit. 6.2 Poisson Regression Models 6.2.1 The Poisson Distribution A Poisson random variable is a discrete random variable that takes on nonnegative integers. It depends on parameter \\(\\lambda &gt;0\\),representing the mean. Poisson random variables are useful when modeling counts. Notation: \\(Y\\sim Pois(\\lambda)\\),    Probability Mass Function: \\(\\text{P}(Y=y) = e^{-\\lambda}\\lambda^y/y!\\)    For \\(\\lambda=1\\), \\[ Pr(Y=0) = e^{-1}1^0/0! = e^{-1}\\approx(0.3679) \\] \\[ Pr(Y=1) = e^{-1}1^1/1! = e^{-1}\\approx(0.3679) \\] \\[ Pr(Y=2) = e^{-1}1^2/2! = e^{-1}/2\\approx(0.1839) \\] \\[ Pr(Y=3) = e^{-1}1^3/3! = e^{-1}/6\\approx(0.0613) \\] 6.2.2 Poisson Distribution for \\(\\lambda=1\\) df &lt;- data.frame(x = 0:10, y = dpois(0:10, 1)) ggplot(df, aes(x = x, y = y)) + geom_bar(stat = &quot;identity&quot;, col = &quot;white&quot;, fill = &quot;blue&quot;) + scale_y_continuous(expand = c(0.01, 0)) + scale_x_continuous(breaks=(0:10)) + xlab(&quot;x&quot;) + ylab(expression(paste(&quot;p(x|&quot;, theta, &quot;)&quot;))) + ggtitle(expression(paste(lambda, &quot;=1&quot;))) + theme_bw() + theme(plot.title = element_text(size = rel(1.2), vjust = 1.5)) Mean = 1 Variance = 1 6.2.3 Poisson Distribution for \\(\\lambda\\in\\{1,3,5\\}\\) Poisson distributions are right-skewed, especially when \\(\\lambda\\) is small. In a Poisson distribution, the mean is equivalent to its variance (both are equal to \\(\\lambda\\)). 6.2.4 Connecting Expected Response to Explatory Variables In a LLSR model, for a given set of values/categories for explanatory variables \\(X_1, \\ldots, X_p\\), the response variable is normally distributed with mean: \\[E(Y) = \\mu = \\beta_0+\\beta_1X_{1} + \\ldots + \\beta_pX_p\\] In a Poisson regression model, we don’t want to assume \\[E(Y) = \\lambda = \\beta_0+\\beta_1X_{1} + \\ldots + \\beta_pX_p\\] because this would allow \\(\\lambda\\) to be negative. Instead, we assume \\[E(Y) = \\lambda = e^{\\beta_0+\\beta_1X_{1} + \\ldots + \\beta_pX_p},\\] ensuring \\(\\lambda&gt;0\\). Equivalently, we assume \\[ \\text{log}(E(Y)) = \\text{log}(\\lambda) = \\beta_0+\\beta_1X_{1} + \\ldots + \\beta_pX_p\\]. To summarize: * a LLSR model assumes the expected response is a linear function of the explanatory variables. * a Poisson regression model assumes the log of the expected response is a linear function of the explanatory variables. 6.2.5 Poisson Regression Assumptions In a Poisson regression model, we assume: Poisson Response The response variable is a count per unit of time or space, described by a Poisson distribution. Independence The observations must be independent of one another, after accounting for fixed effects. Mean=Variance For given value(s) or category(ies) of the explanatory variable(s), the response variable must follow a distribution whose mean is equal to its variance. Linearity For numeric explanatory variable(s) x, the log of the mean rate, log(\\(\\lambda\\)), must be a linear function of x. 6.2.6 Poisson Regression Illustration Figure 6.2: Regression models: Linear regression (left) and Poisson regression (right). 6.3 Poisson Model for Household Size 6.3.1 Poisson Regression Model for Location MP1 = glm(total ~ location, family = poisson, data = fHH1) summary(MP1) Call: glm(formula = total ~ location, family = poisson, data = fHH1) Deviance Residuals: Min 1Q Median 3Q Max -2.7935 -0.9725 -0.2163 0.6373 4.7986 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 1.22430 0.03623 33.796 &lt; 0.0000000000000002 *** locationDavaoRegion -0.00336 0.05375 -0.063 0.95016 locationIlocosRegion 0.05285 0.05265 1.004 0.31554 locationMetroManila 0.08594 0.04712 1.824 0.06819 . locationVisayas 0.13714 0.04170 3.289 0.00101 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for poisson family taken to be 1) Null deviance: 2362.5 on 1499 degrees of freedom Residual deviance: 2344.9 on 1495 degrees of freedom AIC: 6727.8 Number of Fisher Scoring iterations: 5 6.3.2 Interpreting Model Parameters in Poisson Regression Given location, the expected household size is given by \\[ log(E(Y)) = log(\\lambda) = \\beta_0 + \\beta_1\\textrm{locationDavao}_i + \\beta_2\\textrm{locationIlocos}_i + \\\\ \\beta_3\\textrm{locationMetroManila}_i + \\beta_4\\textrm{locationVisayas}_i \\] In region CentralLuzon (CL) (the intercept): \\(log(E(Y)) = log(\\lambda_{CL}) = \\beta_0\\) In region Visayas (the intercept): \\(log(E(Y)) = log(\\lambda_{V}) = \\beta_0 + \\beta_4\\) \\[ \\begin{equation} \\begin{split} log(\\lambda_{CL}) &amp;= \\beta_0 \\\\ log(\\lambda_{V}) &amp;= \\beta_0 + \\beta_4 \\\\ log(\\lambda_{V})-log(\\lambda_{CL}) &amp;= \\beta_4 \\\\ log \\left(\\frac{\\lambda_{V}}{\\lambda_{CL}}\\right) &amp;= \\beta_4\\\\ \\frac{\\lambda_{V}}{\\lambda_{CL}} &amp;= e^{\\beta_4} \\end{split} \\end{equation} \\] The expected household size in region Visayas is \\(e^{\\beta_4}\\) times as great as in region CentralLuzon. We estimate that on average, households in the Visayas region have \\(e^{0.13714}=1.1469\\) times as many (or 14.7% more) people as households in the Central Luzon. region, excluding head of household. The small p-value provides strong evidence of differences in household size between the two regions. 6.3.3 Wald-Based Confidence Intervals for Difference In Poisson regression, assuming sample size is large enough, regression coefficients follow normal distributions, so we can calculate confidence intervals for \\(\\beta_j\\) using the formula \\(\\hat\\beta_j-Z^*\\cdot SE(\\hat\\beta_j)\\). Tests and intervals based on these estimates are called Wald-Based. A 95% CI provides a range of plausible values for \\(\\beta_4\\) and can be constructed: \\[(\\hat\\beta_4-Z^*\\cdot SE(\\hat\\beta_4), \\quad \\hat\\beta_4+Z^*\\cdot SE(\\hat\\beta_4))\\] \\[(0.13714-1.96*0.04170, \\quad 0.13714+1.96*0.04170)\\] \\[ (0.0554, 0.2189). \\] We are 95% confident that on average, households in the Visayas region have between \\(e^{0.0554}=1.056\\) and \\(e^{0.2189}=1.24\\) times as many people as households in the Central Luzon region, excluding head of household. Equivalently, households in Visayas are expected to have between 5.6% and 24% more people, on average, than those in Central Luzon. # CI for betas using profile likelihood confint(MP1) ## 2.5 % 97.5 % ## (Intercept) 1.152446927 1.2944708 ## locationDavaoRegion -0.108912941 0.1018527 ## locationIlocosRegion -0.050467957 0.1559685 ## locationMetroManila -0.006175889 0.1785772 ## locationVisayas 0.055973241 0.2194536 exp(confint(MP1)) ## 2.5 % 97.5 % ## (Intercept) 3.1659302 3.649064 ## locationDavaoRegion 0.8968085 1.107220 ## locationIlocosRegion 0.9507844 1.168789 ## locationMetroManila 0.9938431 1.195515 ## locationVisayas 1.0575694 1.245396 6.3.4 Mean = Variance Assumption Recall the Poisson regression model requires the assumption that \\(\\text{Mean} = \\text{Variance} = \\lambda\\). We can check whether this is reasonable by examining the mean and variance of household sizes in each region. fHH1 %&gt;% group_by(location) %&gt;% summarise(mean=mean(total), sd=sd(total), var=var(total), n=n()) ## # A tibble: 5 × 5 ## location mean sd var n ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 CentralLuzon 3.40 2.04 4.15 224 ## 2 DavaoRegion 3.39 2.17 4.72 187 ## 3 IlocosRegion 3.59 2.32 5.40 191 ## 4 MetroManila 3.71 2.21 4.86 297 ## 5 Visayas 3.90 2.57 6.60 601 We see that variances are slightly large than the mean, but not considerably larger, so this assumption might be reasonable. We’ll soon look at what to do when the mean = variance assumption is clearly violated. 6.4 Poisson Model with Multiple Explanatory Variables 6.4.1 Accounting for Age of Head of Household We add age of the head of household as an explanatory variable in the model. \\[ log(E(Y)) = log(\\lambda) = \\beta_0 + \\beta_1\\text{Age}_i + \\beta_2\\textrm{locationDavao}_i + \\\\ \\beta_3\\textrm{locationIlocos}_i + \\beta_4\\textrm{locationMetroManila}_i + \\beta_5\\textrm{locationVisayas}_i \\] 6.4.2 R Output for Model with Age MP2 = glm(total ~ age + location, family = poisson, data = fHH1) summary(MP2) Call: glm(formula = total ~ age + location, family = poisson, data = fHH1) Deviance Residuals: Min 1Q Median 3Q Max -2.9851 -0.9664 -0.1559 0.6194 4.8082 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 1.472332 0.061922 23.777 &lt; 0.0000000000000002 *** age -0.004598 0.000940 -4.891 0.000001 *** locationDavaoRegion -0.014191 0.053800 -0.264 0.79196 locationIlocosRegion 0.052387 0.052652 0.995 0.31975 locationMetroManila 0.072806 0.047195 1.543 0.12291 locationVisayas 0.127532 0.041742 3.055 0.00225 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for poisson family taken to be 1) Null deviance: 2362.5 on 1499 degrees of freedom Residual deviance: 2320.8 on 1494 degrees of freedom AIC: 6705.7 Number of Fisher Scoring iterations: 5 6.4.3 Interpreting Coefficients for Numeric Explanatory Variable Consider two heads of household in CL where the first person has age \\(a\\), and the second has age \\(a+1\\). Assume both live in Central Luzon, although region doesn’t matter as long as it’s the same. In region Central Luzon (CL): \\(log(E(Y)) = log(\\lambda_{CL}) = \\beta_0 + \\beta_1\\text{Age}\\). Age \\(a\\): \\(log(E(Y)) = log(\\lambda_{a}) = \\beta_0 + \\beta_1a\\) Age \\(a+1\\): \\(log(E(Y)) = log(\\lambda_{a+1}) = \\beta_0 + \\beta_1(a+1)\\) \\[ \\begin{equation} \\begin{split} log(\\lambda_{a+1})-log(\\lambda_a) &amp;= \\beta_1 \\\\ log \\left(\\frac{\\lambda_{a+1}}{\\lambda_a}\\right) &amp;= \\beta_1\\\\ \\frac{\\lambda_{a+1}}{\\lambda_a} &amp;= e^{\\beta_1} \\end{split} \\end{equation} \\] For each one-year increase in age of head of household, houshold size is expected to multipy by a factor of \\(e^{\\beta_1}\\), assuming region is held constant. Assuming we’re comparing households in the same region, for each one-year increase in age of head of household, average household size is expected to multiply be a factor of \\(e^{-0.004598} = 0.9954\\). Assuming we’re comparing households in the same region, for each y-year increase in age of head of household, average household size is expected to multiply be a factor of \\(e^{-0.004598y}\\). For example expected household size for a 50 year old head of house is expected to be \\(e^{-.004598*10}=0.9551\\) times that of a 40 year old head of house (an estimated 4.5% decrease), assuming region is held constant. 6.4.4 Mean = Variance Assumption This model depends on the assumption that for a given region and age, mean is equal to variance. We’ll examine whether this is reasonable, using the largest region, Visayas. Since we have limited obsevations for specific ages, we’ll group people in similar age ranges together. fHH1V &lt;- fHH1 %&gt;% filter(location==&quot;Visayas&quot;) cuts = cut(fHH1V$age, breaks=c(15,20,25,30,35,40,45,50,55,60,65,70)) ageGrps &lt;- data.frame(cuts,fHH1V) ggplot(data = ageGrps, aes(x = total)) + geom_histogram(binwidth = .25, color = &quot;black&quot;, fill = &quot;white&quot;) + facet_wrap(cuts) + xlab(&quot;Household size&quot;) Figure 6.3: Distribution of household sizes by age group of the household head. # Mean = Variance table1chp4&lt;- ageGrps %&gt;% group_by(cuts) %&gt;% summarise(mnNum= mean(total),varNum=var(total),n=n()) kable(table1chp4, booktabs=T, caption=&quot;Compare mean and variance of household size within each age group.&quot;, col.names = c(&quot;Age Groups&quot;, &quot;Mean&quot;, &quot;Variance&quot;, &quot;n&quot;)) %&gt;% kable_styling(full_width = F) Table 6.1: Compare mean and variance of household size within each age group. Age Groups Mean Variance n (15,20] 3.000000 NA 1 (20,25] 2.142857 2.1428571 7 (25,30] 3.260870 0.8379447 23 (30,35] 3.571429 2.3972125 42 (35,40] 4.423729 5.4208065 59 (40,45] 4.776316 5.6159649 76 (45,50] 4.690476 6.1921974 84 (50,55] 4.388889 7.8748044 72 (55,60] 3.590164 7.6792350 61 (60,65] 3.562500 7.2023810 64 (65,70] 3.609756 8.4439024 41 NA 2.436620 6.0209256 71 There is some concern about the validity of the assumption, as variance appears to increase as age increases. We’ll talk soon about ways to address, this but for now, since the violations are not too severe, we’ll proceed with the current model. 6.5 Deviance and Model Comparison 6.5.1 Accounting for Nonlinear Trend Recall that the Poisson regression model assumes that the log of the expected household counts is a linear function of region and head of household’s age. \\[ log(E(Y)) = log(\\lambda) = \\beta_0 + \\beta_1\\text{Age}_i + \\beta_2\\textrm{locationDavao}_i + \\\\ \\beta_3\\textrm{locationIlocos}_i + \\beta_4\\textrm{locationMetroManila}_i + \\beta_5\\textrm{locationVisayas}_i \\] We plot the relationship between log(count) and age for each region. ## Checking linearity assumption: Empirical log of the means plot sumStats &lt;- fHH1 %&gt;% group_by(age, location) %&gt;% summarise(mntotal = mean(total), logmntotal = log(mntotal), n=n()) ggplot(sumStats, aes(x=age, y=logmntotal)) + geom_point()+ geom_smooth(method = &quot;loess&quot;, size = 1.5)+ facet_wrap(~location) + xlab(&quot;Age of head of the household&quot;) + ylab(&quot;Log of the mean number in the house&quot;) The relationship appears to be quadratic, rather than linear. We should add a quadratic term to our model. The effect of age on log(count) appears to be roughly the same in each region. If it weren’t, we would need to add interaction terms to the model. 6.5.2 Quadratic Poisson Regresson Model fHH1 &lt;- fHH1 %&gt;% mutate(age2 = age*age) MP3 &lt;- glm(total ~ age + age2 + location, family = poisson, data = fHH1) summary(MP3) ## ## Call: ## glm(formula = total ~ age + age2 + location, family = poisson, ## data = fHH1) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.9781 -0.9278 -0.1149 0.5924 5.0424 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.3843338 0.1820919 -2.111 0.03480 * ## age 0.0703628 0.0069051 10.190 &lt; 0.0000000000000002 *** ## age2 -0.0007026 0.0000642 -10.944 &lt; 0.0000000000000002 *** ## locationDavaoRegion -0.0193872 0.0537827 -0.360 0.71849 ## locationIlocosRegion 0.0609820 0.0526598 1.158 0.24685 ## locationMetroManila 0.0544801 0.0472012 1.154 0.24841 ## locationVisayas 0.1121092 0.0417496 2.685 0.00725 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 2362.5 on 1499 degrees of freedom ## Residual deviance: 2187.8 on 1493 degrees of freedom ## AIC: 6574.7 ## ## Number of Fisher Scoring iterations: 5 We can assess the importance of the quadratic term in two ways. First, the p-value for the Wald-type statistic for age\\(^2\\) is statistically significant (Z = -11.058, p &lt; 0.001). Another approach is to perform a drop-in-deviance test. 6.5.3 Residuals for Poisson Models Residuals measure how far observations lie from their expectation, under the model. The residuals for linear least squares regression have the form: \\[ \\begin{align*} \\textrm{LLSR residual}_i &amp;= \\textrm{obs}_i - \\textrm{fit}_i \\nonumber \\\\ &amp;={Y_i-\\hat{\\mu}_i} \\nonumber \\\\ &amp;= Y_i-(\\hat{\\beta}_0 +\\hat{\\beta}_1 X_i) \\end{align*} \\] This calculation wouldn’t make sense in Poisson regression because it’s \\(log(E(Y))\\), rather than \\(E(Y)\\) that is a linear function of the explanatory variables. Instead, we use the following quantity, called deviance residual, to quantify the closeness of an observed value to its expectation under the model: \\[ \\textrm{deviance residual}_i = \\textrm{sign}(Y_i-\\hat{\\lambda}_i) \\sqrt{ 2 \\left[Y_i log\\left(\\frac{Y_i}{\\hat{\\lambda}_i}\\right) -(Y_i - \\hat{\\lambda}_i) \\right]} \\] where \\(\\textrm{sign}(x)\\) is defined such that: \\[ \\textrm{sign}(x) = \\begin{cases} 1 &amp; \\textrm{if }\\ x &gt; 0 \\\\ -1 &amp; \\textrm{if }\\ x &lt; 0 \\\\ 0 &amp; \\textrm{if }\\ x = 0\\end{cases}\\] When \\(Y_i\\) is close to \\(\\hat{\\lambda}_i\\), then \\(\\left(\\frac{Y_i}{\\hat{\\lambda}_i}\\right)\\) is close to 1 and \\(log\\left(\\frac{Y_i}{\\hat{\\lambda}_i}\\right)\\) is close to 0. Likewise \\((Y_i - \\hat{\\lambda}_i)\\) is close to 0. Thus, the deviance residual is small. As \\(Y_i\\) gets farther from \\(\\hat{\\lambda}_i\\), the deviance residual increases. 6.5.4 Plot of Deviance Residuals for First-Order Poisson Model # Residual plot for the first order model ## Log scale Pred = predict(MP2) # log scale Resid = resid(MP2) # linear model Residdf = data.frame(Pred,Resid) ggplot(Residdf,aes(x=Pred, y=Resid)) + geom_point(alpha = .25)+ geom_smooth(method = &quot;loess&quot;, size = 1.5, linetype = 2)+ geom_line(y=0, size=1.5, col=&quot;red&quot;)+ xlab(&quot;Fitted values&quot;) + ylab(&quot;Deviance Residuals&quot;) A plot of the deviance residuals versus predicted responses for the first order model exhibits curvature, supporting the idea that the model may improved by adding a quadratic term. 6.5.5 Plot of Deviance Residuals for Quadratic Poisson Model # Residual plot for the first order model ## Log scale Pred = predict(MP3) # log scale Resid = resid(MP3) # linear model Residdf = data.frame(Pred,Resid) ggplot(Residdf,aes(x=Pred, y=Resid)) + geom_point(alpha = .25)+ geom_smooth(method = &quot;loess&quot;, size = 1.5, linetype = 2)+ geom_line(y=0, size=1.5, col=&quot;red&quot;)+ xlab(&quot;Fitted values&quot;) + ylab(&quot;Deviance Residuals&quot;) The quadratic trend disappears when using the quadratic model, suggesting the model is better capturing the trend in the data. 6.5.6 Residual Deviance for a Model A model’s residual deviance is the sum of the squares of the deviance residuals. residual deviance \\(=\\sum (\\textrm{deviance residual})^2_i\\). We can use residual deviance to compare models in a manner similar to the ANOVA lack of fit tests we use in LLSR. 6.5.7 Drop-in-Deviance Test Assume that reduced is nested in larger model. That is, every term in the reduced model is also in the larger model. A drop-in-deviance test can be used to test the hypotheses: Null Hypothesis: Reduced model sufficienty explains variability in \\(Y\\). Alternative Hypothesis: Larger model better explains variability in \\(Y\\). We can calculate a test statistic by taking the difference in residual deviances between the two models, divided by the difference in the number of parameters. \\[ W=\\frac{\\text{Drop in Deviance}}{\\text{Difference in # Parameters}} \\] When the null hypothesis is true, W follows a \\(\\chi^2\\) distribution with degrees of freedom equal to the difference in number of parameters between the two models. We can compare the observed drop in deviance to the \\(\\chi^2\\) distribution to calculate a p-value. 6.5.8 Drop-in-Deviance Test anova(MP2, MP3, test = &quot;Chisq&quot;) Analysis of Deviance Table Model 1: total ~ age + location Model 2: total ~ age + age2 + location Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) 1 1494 2320.8 2 1493 2187.8 1 133.04 &lt; 0.00000000000000022 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 \\(H_0\\): log(\\(\\lambda\\))=\\(Y_i = \\beta_0 + \\beta_1\\text{Age} + \\beta_2\\textrm{locationDavao}_i + \\\\ \\beta_3\\textrm{locationIlocos}_i + \\beta_4\\textrm{locationMetroManila}_i + \\beta_5\\textrm{locationVisayas}_i\\) (reduced model) \\(H_A:\\) log(\\(\\lambda\\))=\\(Y_i = \\beta_0 + \\beta_1\\text{Age} + \\text{Age}^2 + \\beta_2\\textrm{locationDavao}_i + \\\\ \\beta_3\\textrm{locationIlocos}_i + \\beta_4\\textrm{locationMetroManila}_i + \\beta_5\\textrm{locationVisayas}_i\\) (larger model) The first order model has a residual deviance of 2320.8 with 1494 df The quadratic model has a residual deviance of 2187.8 with 1493 df. If the null hypothesis is correct, the drop in deviance would follow a \\(\\chi^2\\) distribution with 1 degree of freedom. The probability of observing a value as extreme as 133.04 on such a distribution is essentially 0, so the data provide significant support for including the quadratic term. 6.5.9 Visual of \\(\\chi^2\\) Test gf_dist(&quot;chisq&quot;, df = 1, geom = &quot;area&quot;, fill=&quot;turquoise&quot;) + geom_vline(xintercept=133.04, colour=&quot;red&quot;) + theme(legend.position=&quot;none&quot;) + ylim(c(0,0.1)) If the null hypothesis is correct, the drop in deviance would follow a \\(\\chi^2\\) distribution with 1 degree of freedom. The probability of observing a value as extreme as 133.04 on such a distribution is essentially 0, so the data provide significant support for including the quadratic term. 6.5.10 Adding Roofing Material to Model We also consider whether there is evidence of differences in household size between the two roofing material types, which might be used to measure household wealth. MP4 &lt;- glm(total ~ age + age2 + location + roof, family = poisson, data = fHH1) summary(MP4) ## ## Call: ## glm(formula = total ~ age + age2 + location + roof, family = poisson, ## data = fHH1) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.9900 -0.9281 -0.1070 0.5912 5.0255 ## ## Coefficients: ## Estimate Std. Error z value ## (Intercept) -0.42855992 0.18652834 -2.298 ## age 0.07040402 0.00690376 10.198 ## age2 -0.00070343 0.00006419 -10.958 ## locationDavaoRegion -0.01655038 0.05384310 -0.307 ## locationIlocosRegion 0.06298529 0.05269029 1.195 ## locationMetroManila 0.05321914 0.04721442 1.127 ## locationVisayas 0.11683456 0.04196452 2.784 ## roofPredominantly Strong Material 0.04751679 0.04358666 1.090 ## Pr(&gt;|z|) ## (Intercept) 0.02159 * ## age &lt; 0.0000000000000002 *** ## age2 &lt; 0.0000000000000002 *** ## locationDavaoRegion 0.75855 ## locationIlocosRegion 0.23194 ## locationMetroManila 0.25967 ## locationVisayas 0.00537 ** ## roofPredominantly Strong Material 0.27564 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 2362.5 on 1499 degrees of freedom ## Residual deviance: 2186.6 on 1492 degrees of freedom ## AIC: 6575.5 ## ## Number of Fisher Scoring iterations: 5 anova(MP3, MP4, test = &quot;Chisq&quot;) Analysis of Deviance Table Model 1: total ~ age + age2 + location Model 2: total ~ age + age2 + location + roof Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) 1 1493 2187.8 2 1492 2186.6 1 1.2024 0.2728 The drop in deviance is small when adding roof type to the model, and the large p-value does not provide evidence that roof type is associated with household size. 6.5.11 Visual of \\(\\chi^2\\) Test for Roof gf_dist(&quot;chisq&quot;, df = 1, geom = &quot;area&quot;, fill = ~ !(x &gt; 1.2)) + geom_vline(xintercept=1.2, colour=&quot;red&quot;) + theme(legend.position=&quot;none&quot;) + ylim(c(0,1)) 6.5.12 Goodness-of-Fit We can also use a model’s residual deviance to test whether it adequtely fits the data. Null Hypothesis: The model adequately fits the data Alternative Hypothesis: The model does not adequately fit the data When the null hypothesis is true, the model’s residual deviance follows a \\(\\chi^2\\) distribution with \\(n-p\\) degrees of freedom, where \\(p\\) is number of parameters in the model. MP3$deviance ## [1] 2187.8 MP3$df.residual ## [1] 1493 1-pchisq(MP3$deviance, MP3$df.residual) [1] 0 gf_dist(&quot;chisq&quot;, df = 1493, geom = &quot;area&quot;, fill = &quot;turquoise&quot;) + geom_vline(xintercept=2187.8, colour=&quot;red&quot;) + theme(legend.position=&quot;none&quot;) + ylim(c(0,0.01)) The small p-value indicates that the quadratic model does not adequately fit the data. We’ve already counted for the quadratic trend, and determined that roof material does not help explain variability in household size. It appears that the deficiency is not with the structure of the model’s estimated response, but rather with it’s ability to account for variability. Recall that variance appeared to increase with age, a violation of the Mean=Variance assumption. 6.6 Overdisperson 6.6.1 Quasi-Poisson Model Overdispersion occurs when there is more variability in the distribution of a response variable than a Poisson model would expect, given the value(s) and category(ies) of explanatory variable(s). Recall that the Poisson model assumes Mean=Variance. When data are overdispersed, a Poisson regression model will underestimate standard errors, producing confidence intervals that are too narrow, and p-values that are too small. We can estimate a dispersion parameter, \\[ \\hat{\\phi}=\\frac{\\displaystyle\\sum\\left(\\frac{Y_i-\\hat{\\lambda}_i}{\\sqrt{\\hat{\\lambda_i}}}\\right)^2}{n-p} \\] where \\(p\\) is the number of model parameters. We inflate the standard errors by multiplying the variance by \\(\\hat{\\phi}\\) i.e., \\(SE_Q(\\hat\\beta)=\\sqrt{\\hat\\phi}*SE(\\hat\\beta)\\), where \\(Q\\) stands for “quasi-Poisson” If there is no overdispersion, this estimate should be close to one. It will be larger than one in the presence of overdispersion. 6.6.2 Quasi-Poisson Model in R MQP &lt;- glm(total ~ age + age2 + location, family = quasipoisson, data = fHH1) summary(MQP) Call: glm(formula = total ~ age + age2 + location, family = quasipoisson, data = fHH1) Deviance Residuals: Min 1Q Median 3Q Max -2.9781 -0.9278 -0.1149 0.5924 5.0424 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -0.38433377 0.21660252 -1.774 0.0762 . age 0.07036283 0.00821374 8.566 &lt;0.0000000000000002 *** age2 -0.00070259 0.00007637 -9.200 &lt;0.0000000000000002 *** locationDavaoRegion -0.01938723 0.06397579 -0.303 0.7619 locationIlocosRegion 0.06098197 0.06264005 0.974 0.3304 locationMetroManila 0.05448007 0.05614687 0.970 0.3320 locationVisayas 0.11210920 0.04966211 2.257 0.0241 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for quasipoisson family taken to be 1.414965) Null deviance: 2362.5 on 1499 degrees of freedom Residual deviance: 2187.8 on 1493 degrees of freedom AIC: NA Number of Fisher Scoring iterations: 5 6.6.3 Standard Errors in Quasi-Poisson Model The dispersion parameter estimate is \\(\\hat{\\phi} = 1.414965\\). Example standard error calculation: \\(SE_Q(\\hat\\beta_6)=\\sqrt{1.414965}\\times0.0417496 = 0.04966211\\) Confidence intervals will be \\(\\sqrt{1.414965}\\) times as wide. confint(MP3) ## 2.5 % 97.5 % ## (Intercept) -0.7443966318 -0.0305771038 ## age 0.0569439548 0.0840125597 ## age2 -0.0008295514 -0.0005778801 ## locationDavaoRegion -0.1249936715 0.0858797829 ## locationIlocosRegion -0.0423469612 0.1641217501 ## locationMetroManila -0.0377905252 0.1472678216 ## locationVisayas 0.0308360654 0.1945162354 confint(MQP) ## 2.5 % 97.5 % ## (Intercept) -0.8133555745 0.0357651067 ## age 0.0544264830 0.0866258208 ## age2 -0.0008538719 -0.0005544976 ## locationDavaoRegion -0.1450589037 0.1058041117 ## locationIlocosRegion -0.0619628606 0.1836591347 ## locationMetroManila -0.0552277830 0.1649197466 ## locationVisayas 0.0155547017 0.2102682379 6.6.4 Drop-in-Deviance Tests for Quasi-Poisson Model When using a Quasi-Poisson Model the test statistic in a drop in deviance test is \\[ F=\\frac{\\frac{\\text{Drop in Deviance}}{\\text{Difference in # Parameters}}}{\\hat{\\phi}} \\] When the null hypothesis is true, this statistic follows an F-distribution with degrees of freedom equal to the difference in the number of parameters, and \\(n-p\\) respectively. 6.6.5 First vs Second Order Quasi-Poisson Models We compare first and second order quasi-Poisson models, using a drop-in-deviance test. MQP1 &lt;- glm(total ~ age + location, family = quasipoisson, data = fHH1) anova(MQP1, MQP, test = &quot;F&quot;) ## Analysis of Deviance Table ## ## Model 1: total ~ age + location ## Model 2: total ~ age + age2 + location ## Resid. Df Resid. Dev Df Deviance F Pr(&gt;F) ## 1 1494 2320.8 ## 2 1493 2187.8 1 133.04 94.025 &lt; 0.00000000000000022 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 After adjusting for overdispersion, we still have statistically significant evidence that the quadratic model is preferred. 6.7 Offsets in Poisson Regression 6.7.1 Case Study: Campus Crime We examine data on the number of crimes reported in a year on college campuses. Each row of c_data.csv contains crime information from a post secondary institution, either a college or university. The variables include: Enrollment = enrollment at the school type = college (C) or university (U) nv = the number of violent crimes for that institution for the given year nvrate = number of violent crimes per 1000 students enroll1000 = enrollment at the school, in thousands region = region of the country (C = Central, MW = Midwest, NE = Northeast, SE = Southeast, SW = Southwest, and W = West) #Getting started-Crime # Crime data for Universities and Colleges c.data &lt;- read_csv(&quot;https://raw.githubusercontent.com/proback/BeyondMLR/master/data/c_data.csv&quot;) head(c.data, n=10) ## # A tibble: 10 × 6 ## Enrollment type nv nvrate enroll1000 region ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 5590 U 30 5.37 5.59 SE ## 2 540 C 0 0 0.54 SE ## 3 35747 U 23 0.643 35.7 W ## 4 28176 C 1 0.0355 28.2 W ## 5 10568 U 1 0.0946 10.6 SW ## 6 3127 U 0 0 3.13 SW ## 7 20675 U 7 0.339 20.7 W ## 8 12548 C 0 0 12.5 W ## 9 30063 U 19 0.632 30.1 C ## 10 4429 C 4 0.903 4.43 C 6.7.2 Distribution of Number of Crimes Figure 6.4: Histogram of number of violent crimes by institution. Since crimes are nonnegative counts, a Poisson model seems reasonable. 6.7.3 Crimes by Type of Institution and Region Table 6.2: Proportion of colleges and universities within region in the campus crime data set. C MW NE SE SW W C 0.294 0.3 0.381 0.4 0.2 0.5 U 0.706 0.7 0.619 0.6 0.8 0.5 Counts are not directly comparable because they come from different size schools. Instead, we’ll display crimes per 1000 students. Table 6.3: The mean and variance of the violent crime rate by region and type of institution. region type MeanCount VarCount MeanRate VarRate n C C 1.6000000 3.3000000 0.3979518 0.2780913 5 C U 4.7500000 30.9318182 0.2219441 0.0349266 12 MW C 0.3333333 0.3333333 0.0162633 0.0007935 3 MW U 8.7142857 30.9047619 0.4019003 0.0620748 7 NE C 6.0000000 32.8571429 1.1249885 1.1821000 8 NE U 5.9230769 79.2435897 0.4359273 0.3850333 13 SE C 1.5000000 7.5000000 0.2487994 0.1280345 6 SE U 10.6250000 50.2678571 0.7171408 0.3508841 8 SW C 0.0000000 0.0000000 0.0000000 0.0000000 2 SW U 6.6250000 86.8392857 0.4254915 0.1958103 8 W C 0.5000000 0.3333333 0.0680164 0.0129074 4 W U 12.5000000 57.0000000 0.4679478 0.0246670 4 Figure 6.5: Boxplot of violent crime rate by region and type of institution (colleges (C) on the left, and universities (U) on the right). Mean violent crime rates that are generally lower at the colleges within a region (with the exception of the Northeast). Regional pattern of rates at universities appears to differ from that of the colleges. 6.7.4 Accounting for Enrollment Although we used rates (per 1000 students) for the plots, we want to use actual number of crimes when we fit the Poisson model (since a Poisson distribution requires integer counts). We account for enrollment by including an offset in our model. Rather than letting \\(log(\\lambda)\\) be a linear function of the explanatory variables, we use \\(log\\left(\\frac{\\lambda}{\\text{enroll1000}}\\right)\\). Thus, \\[ \\begin{align*} log(\\frac{\\lambda}{\\textrm{enroll1000}} )= \\beta_0 + \\beta_1(\\textrm{type}) \\nonumber \\\\ log(\\lambda)-log(\\textrm{enroll1000}) = \\beta_0 + \\beta_1(\\textrm{type}) \\nonumber \\\\ log(\\lambda) = \\beta_0 + \\beta_1(\\textrm{type}) + log(\\textrm{enroll1000}) \\end{align*} \\] So, the expected number of crimes at a school in a given year is: \\[ \\lambda = e^{\\beta_0 + \\beta_1(\\text{type}) + log(\\text{enroll1000})} = e^{\\beta_0 + \\beta_1(\\text{type})}(\\text{enroll1000}) \\] 6.7.5 Offset in R We model number of crimes using type of institution and region as explanatory variables. To do this, we add an argument called offset in the model. modeltr &lt;- glm(nv ~ type + region, family = poisson, offset = log(enroll1000), data = c.data) summary(modeltr) Call: glm(formula = nv ~ type + region, family = poisson, data = c.data, offset = log(enroll1000)) Deviance Residuals: Min 1Q Median 3Q Max -4.5430 -1.7879 -0.7442 1.0885 6.7443 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -1.54971 0.17117 -9.053 &lt; 0.0000000000000002 *** typeU 0.28172 0.13316 2.116 0.03438 * regionMW 0.09913 0.17752 0.558 0.57658 regionNE 0.77824 0.15307 5.084 0.000000369 *** regionSE 0.62997 0.16133 3.905 0.000094285 *** regionSW 0.50321 0.18508 2.719 0.00655 ** regionW 0.26313 0.18753 1.403 0.16056 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for poisson family taken to be 1) Null deviance: 392.76 on 79 degrees of freedom Residual deviance: 348.13 on 73 degrees of freedom AIC: 574.76 Number of Fisher Scoring iterations: 6 The Northeast and the South differ significantly from the Central region (p= 0.00000037 and p=0.0000924, respectively). The estimated coefficient of 0.778 means that the violent crime rate per 1,000 in the Northeast is nearly (\\(e^{0.778}=2.2\\)) times that of the Central region controlling for the type of school. A Wald-type confidence interval for this factor can be constructed by first calculating a CI for the coefficient (0.778 \\(\\pm\\) \\(1.96 \\cdot 0.153\\)) and then exponentiating (1.61 to 2.94). Expected number of crimes at a College in the Midwest with 1500 students. \\[ \\lambda = e^{-1.54971 + 0.09913 + log(1.5)} = 1.5e^{-1.54971 + 0.09913)}=0.35 \\] 6.7.6 Model with Interaction Our plots suggested the difference between colleges and universities might vary between regions. To allow for this, we add an interaction term in the model. modeli &lt;- glm(nv ~ type + region + region:type, family = poisson, offset = log(enroll1000), data = c.data) summary(modeli) Call: glm(formula = nv ~ type + region + region:type, family = poisson, data = c.data, offset = log(enroll1000)) Deviance Residuals: Min 1Q Median 3Q Max -3.7292 -1.5756 -0.7685 0.8346 4.8828 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -1.4741 0.3536 -4.169 0.0000305 *** typeU 0.1959 0.3775 0.519 0.60377 regionMW -1.9765 1.0607 -1.863 0.06239 . regionNE 1.5529 0.3819 4.066 0.0000477 *** regionSE 0.2508 0.4859 0.516 0.60577 regionSW -15.4630 736.9341 -0.021 0.98326 regionW -1.8337 0.7906 -2.319 0.02037 * typeU:regionMW 2.1965 1.0765 2.040 0.04132 * typeU:regionNE -1.0698 0.4200 -2.547 0.01086 * typeU:regionSE 0.4276 0.5152 0.830 0.40652 typeU:regionSW 16.0837 736.9341 0.022 0.98259 typeU:regionW 2.4106 0.8140 2.962 0.00306 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for poisson family taken to be 1) Null deviance: 392.76 on 79 degrees of freedom Residual deviance: 269.27 on 68 degrees of freedom AIC: 505.9 Number of Fisher Scoring iterations: 13 We have evidence that the difference between colleges and universities in violent crime rate differs by region. For example, our model estimates that violent crime rates are (\\(e^{.196+2.411}=13.6\\)) times higher in universities in the West compared to colleges, while in the Northeast we estimate that violent crime rates are (\\(\\frac{1}{e^{.196-1.070}}=2.4\\)) times higher in colleges. 6.7.7 Drop-in-Deviance Test for Interaction drop_in_dev &lt;- anova(modeltr, modeli, test = &quot;Chisq&quot;) drop_in_dev Analysis of Deviance Table Model 1: nv ~ type + region Model 2: nv ~ type + region + region:type Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) 1 73 348.13 2 68 269.27 5 78.866 0.000000000000001449 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We have statistically significant evidence (\\(\\chi^2=71.98, df=4, p&lt;.001\\)) that the difference between colleges and universities in violent crime rate differs by region. ResidDF ResidDev Deviance Df pval 1 73 348.1340 NA NA NA 2 68 269.2682 78.86585 5 0.000000000000001448983 6.7.8 Goodness of Fit Test We perform a goodness of fit test to test whether the interaction model adequately fits the data. 1-pchisq(modeli$deviance, modeli$df.residual) [1] 0 gf_dist(&quot;chisq&quot;, df = 70, geom = &quot;area&quot;, fill = &quot;turquoise&quot;) + geom_vline(xintercept=276.7038, colour=&quot;red&quot;) + theme(legend.position=&quot;none&quot;) + ylim(c(0,0.05)) There is strong evidence of a lack of fit. We don’t have any other explanatory variables, and nonlinear terms don’t make sense for categorical explanatory variables. The issue is likely due to overdispersion. 6.7.9 Quasi-Poisson Model modeliq &lt;- glm(nv ~ type + region + region:type, family = quasipoisson, offset = log(enroll1000), data = c.data) summary(modeliq) Call: glm(formula = nv ~ type + region + region:type, family = quasipoisson, data = c.data, offset = log(enroll1000)) Deviance Residuals: Min 1Q Median 3Q Max -3.7292 -1.5756 -0.7685 0.8346 4.8828 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -1.4741 0.7450 -1.979 0.0519 . typeU 0.1959 0.7956 0.246 0.8062 regionMW -1.9765 2.2350 -0.884 0.3796 regionNE 1.5529 0.8047 1.930 0.0578 . regionSE 0.2508 1.0239 0.245 0.8073 regionSW -15.4630 1552.8860 -0.010 0.9921 regionW -1.8337 1.6659 -1.101 0.2749 typeU:regionMW 2.1965 2.2685 0.968 0.3364 typeU:regionNE -1.0698 0.8849 -1.209 0.2309 typeU:regionSE 0.4276 1.0856 0.394 0.6949 typeU:regionSW 16.0837 1552.8861 0.010 0.9918 typeU:regionW 2.4106 1.7152 1.405 0.1644 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for quasipoisson family taken to be 4.440397) Null deviance: 392.76 on 79 degrees of freedom Residual deviance: 269.27 on 68 degrees of freedom AIC: NA Number of Fisher Scoring iterations: 13 The dispersion parameter of 4.45 suggests the data are highly overdispersed. Standard errors from the original Poisson model will be too low, making intervals and tests unreliable. 6.7.10 Test for Interaction We previously found evidence that the difference between colleges and universities in violent crime rate differs by region. That test, however, was based on a model that was not appropriate. We repeat the test, using the quasipoisson model, and associated F-test. modeltrq &lt;- glm(nv ~ type + region, family = quasipoisson, offset = log(enroll1000), data = c.data) drop_in_dev &lt;- anova(modeltrq, modeliq, test = &quot;F&quot;) drop_in_dev Analysis of Deviance Table Model 1: nv ~ type + region Model 2: nv ~ type + region + region:type Resid. Df Resid. Dev Df Deviance F Pr(&gt;F) 1 73 348.13 2 68 269.27 5 78.866 3.5522 0.006514 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Even after adjusting for overdispersion, we still have statistically significant evidence (\\(F=4.05, p=.0052\\)) that the difference between colleges and universities in violent crime rate differs by region. 6.8 Summaries 6.8.1 LLSR vs. Poisson Regression Comparison \\[\\begin{gather*} \\underline{\\textrm{Response}} \\\\ \\mathbf{LLSR:}\\textrm{ Normal} \\\\ \\mathbf{Poisson Regression:}\\textrm{ Counts} \\\\ \\textrm{ } \\\\ \\underline{\\textrm{Variance}} \\\\ \\mathbf{LLSR:}\\textrm{ Equal for each level of X} \\\\ \\mathbf{Poisson Regression:}\\textrm{ Equal to the mean for each level of X} \\\\ \\textrm{ } \\\\ \\underline{\\textrm{Model Fitting}} \\\\ \\mathbf{LLSR:}\\ \\mu=\\beta_0+\\beta_1x \\textrm{ using Least Squares}\\\\ \\mathbf{Poisson Regression:}\\ log(\\lambda)=\\beta_0+\\beta_1x \\textrm{ using Maximum Likelihood}\\\\ \\end{gather*}\\] \\[\\begin{gather*} \\underline{\\textrm{EDA}} \\\\ \\mathbf{LLSR:}\\textrm{ Plot X vs. Y; add line} \\\\ \\mathbf{Poisson Regression:}\\textrm{ Find }log(\\bar{y})\\textrm{ for several subgroups; plot vs. X} \\\\ \\textrm{ } \\\\ \\underline{\\textrm{Comparing Models}} \\\\ \\mathbf{LLSR:}\\textrm{ Extra sum of squares F-tests; AIC/BIC} \\\\ \\mathbf{Poisson Regression:}\\textrm{ Drop in Deviance tests; AIC/BIC} \\\\ \\textrm{ } \\\\ \\underline{\\textrm{Interpreting Coefficients}} \\\\ \\mathbf{LLSR:}\\ \\beta_1=\\textrm{ change in }\\mu_y\\textrm{ for unit change in X} \\\\ \\mathbf{Poisson Regression:}\\ e^{\\beta_1}=\\textrm{ percent change in }\\lambda\\textrm{ for unit change in X} \\end{gather*}\\] 6.8.2 Poisson vs Quasi-Poisson Inference Table 6.4: Comparison of Poisson and quasi-Poisson inference. Poisson quasi-Poisson Estimate \\(\\hat{\\beta}\\) \\(\\hat{\\beta}\\) Std error \\(SE(\\hat{\\beta})\\) \\(SE_Q(\\hat{\\beta}) = \\sqrt{\\hat{\\phi}} SE(\\hat{\\beta})\\) Wald-type test stat \\(Z = \\hat{\\beta} / SE(\\hat{\\beta})\\) \\(t = \\hat{\\beta} / SE_Q(\\hat{\\beta})\\) Confidence interval \\(\\hat{\\beta} \\pm z^{&#39;} SE(\\hat{\\beta})\\) \\(\\hat{\\beta} \\pm t^{&#39;} SE_Q(\\hat{\\beta})\\) Drop in deviance test \\(\\chi^2 = \\textrm{resid dev(reduced) - resid dev(full)}\\) \\(F = (\\chi^2 / \\textrm{difference in df}) / \\hat{\\phi}\\) "],["logistic-regression.html", "Chapter 7 Logistic Regression 7.1 Binomial Logistic Regression 7.2 Model for Wisconsin Vote 7.3 Maximum Likelihood Estimation 7.4 Zero-Inflated Poisson Model 7.5 Model for Drinks Data", " Chapter 7 Logistic Regression These notes provide a summary of Chapter 6 in Beyond Multiple Linear Regression by Roback and Legler. The dataset we work with is different than those in the text, but much of the code and analysis is based off the examples in the text. Github repository. # Packages required for Chapter 6 library(gridExtra) library(mnormt) library(lme4) library(knitr) library(pander) library(tidyverse) library(gridExtra) library(corrplot) 7.1 Binomial Logistic Regression In Stat 255, we learned about Logistic regression models for binary response data. Please review sections 6.1-6.3 in the Stat 255 notes prior to proceeding. 7.1.1 Binary Response Data We can use logistic regression to model binary responses, such as whether or not a student person defaults on a credit card payment, as in the dataset below. In this dataset, each row represents an individual with a single yes/no response. library(ISLR) data(Default) head(Default) ## default student balance income ## 1 No No 729.5265 44361.625 ## 2 No Yes 817.1804 12106.135 ## 3 No No 1073.5492 31767.139 ## 4 No No 529.2506 35704.494 ## 5 No No 785.6559 38463.496 ## 6 No Yes 919.5885 7491.559 7.1.2 Binomial Response Data We can also use logistic regression to model data where the rows represent the number of “successes” in a fixed number of trials. For example: Number of games won by a sports team in a given number of games. Number of people who survive for at least 10 years after being diagnosed with a disease. Number of people who vote for a candidate in election our of total number of voters. We’ll refer to this kind of regression as Binomial Logistic Regression, though the term logistic regression is used somewhat abmiguously and is sometimes applied to this context as well. 7.1.3 2020 Wisconsin Election Data We’ll work with data on the 2020 presidential election in the state of Wisconsin. Each row of the dataset represents a county in Wisconsin. Variables include: County - name of the county Rvotes - number of votes for Republican candidate (Donald Trump) Dvotes - number of votes for Democratic candidate (Joe Biden) PctD - percentage of 2-party vote that went to Biden (i.e. Rvotes/(Rvotes + Dvotes)) College - percentage of residents with a college degree Unemployment - unemployment rate WhitePct - percentage of white residents COVID_DeathRate - number of deaths from covid-19 per 100,000 residents Income - median household income All variables were recorded at the time of the election. Wisconsin &lt;- read_csv(&quot;WisconsinVote.csv&quot;) head(Wisconsin, 10) ## # A tibble: 10 × 10 ## ...1 County Rvotes Dvotes PctD College Unemp…¹ White…² COVID…³ Income ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 Adams County 7362 4329 37.0 12.4 5.2 93.8 29.7 53156 ## 2 2 Ashland Cou… 3841 4801 55.6 21.1 4.8 83.8 19.3 47202 ## 3 3 Barron Coun… 15803 9194 36.8 19.9 4 95.3 17.7 54372 ## 4 4 Bayfield Co… 4617 6147 57.1 30.5 5.6 85.4 13.3 58065 ## 5 5 Brown County 75871 65511 46.3 29.6 3.1 87.8 38.9 65494 ## 6 6 Buffalo Cou… 4834 2860 37.2 17.9 4.2 97.3 23.0 58407 ## 7 7 Burnett Cou… 6462 3569 35.6 20 5.3 91.5 38.9 51519 ## 8 8 Calumet Cou… 18156 12116 40.0 28.7 2.8 94.7 28.0 80354 ## 9 9 Chippewa Co… 21317 13983 39.6 20.1 3.8 94.7 37.1 60713 ## 10 10 Clark County 10002 4524 31.1 11.5 3.3 97.1 48.9 54296 ## # … with abbreviated variable names ¹​Unemployment, ²​WhitePct, ³​COVID_DeathRate P1 &lt;- ggplot(Wisconsin, aes(x=College, y=PctD, size=(Rvotes+Dvotes))) + geom_point() + geom_text(data=Wisconsin %&gt;% filter(County %in% c(&quot;Dane County&quot;, &quot;Door County&quot; , &quot;Milwaukee County&quot;, &quot;Menominee County&quot;, &quot;Outagamie County&quot;, &quot;Waukesha County&quot;)), aes(x=College, y=PctD, label=County, vjust=-1), size=3, color=&quot;red&quot;) + xlab(&quot;Percent with College Degree&quot;) + ylab(&quot;Percent Voting for Biden&quot;) + theme(legend.position=&quot;none&quot;) P2 &lt;- ggplot(Wisconsin, aes(x=Unemployment, y=PctD, size=(Rvotes+Dvotes))) + geom_point() + geom_text(data=Wisconsin %&gt;% filter(County %in% c(&quot;Dane County&quot;, &quot;Door County&quot; , &quot;Milwaukee County&quot;, &quot;Menominee County&quot;, &quot;Outagamie County&quot;, &quot;Waukesha County&quot;)), aes(x=Unemployment, y=PctD, label=County, vjust=-1), size=3, color=&quot;red&quot;) + xlab(&quot;Unemployment Rate&quot;) + ylab(&quot;Percent Voting for Biden&quot;) + theme(legend.position=&quot;none&quot;) P3 &lt;- ggplot(Wisconsin, aes(x=WhitePct, y=PctD, size=(Rvotes+Dvotes))) + geom_point() + geom_text(data=Wisconsin %&gt;% filter(County %in% c(&quot;Dane County&quot;, &quot;Door County&quot; , &quot;Milwaukee County&quot;, &quot;Menominee County&quot;, &quot;Outagamie County&quot;, &quot;Waukesha County&quot;)), aes(x=WhitePct, y=PctD, label=County, vjust=-1), size=3, color=&quot;red&quot;) + xlab(&quot;Percent of Population White&quot;) + ylab(&quot;Percent Voting for Biden&quot;) + theme(legend.position=&quot;none&quot;) P4 &lt;- ggplot(Wisconsin, aes(x=COVID_DeathRate, y=PctD, size=(Rvotes+Dvotes))) + geom_point() + geom_text(data=Wisconsin %&gt;% filter(County %in% c(&quot;Dane County&quot;, &quot;Door County&quot; , &quot;Milwaukee County&quot;, &quot;Menominee County&quot;, &quot;Outagamie County&quot;, &quot;Waukesha County&quot;)), aes(x=COVID_DeathRate, y=PctD, label=County, vjust=-1), size=3, color=&quot;red&quot;) + xlab(&quot;Covid Deaths Per 100k&quot;) + ylab(&quot;Percent Voting for Biden&quot;) + theme(legend.position=&quot;none&quot;) P5 &lt;- ggplot(Wisconsin, aes(x=Income, y=PctD, size=(Rvotes+Dvotes))) + geom_point() + geom_text(data=Wisconsin %&gt;% filter(County %in% c(&quot;Dane County&quot;, &quot;Door County&quot; , &quot;Milwaukee County&quot;, &quot;Menominee County&quot;, &quot;Outagamie County&quot;, &quot;Waukesha County&quot;)), aes(x=Income, y=PctD, label=County, vjust=-1), size=3, color=&quot;red&quot;) + xlab(&quot;Median Income&quot;) + ylab(&quot;Percent Voting for Biden&quot;) + theme(legend.position=&quot;none&quot;) grid.arrange(P1, P2, P3, P4, P5, nrow=3) + theme(legend.position=&quot;none&quot;) ## NULL 7.1.4 Correlation Between Explanatory Variables select &lt;- dplyr::select C &lt;- cor(Wisconsin %&gt;% select(&quot;College&quot;, &quot;Unemployment&quot;, &quot;WhitePct&quot;, &quot;COVID_DeathRate&quot;, &quot;Income&quot;)) P &lt;- corrplot(C, method=&quot;number&quot;) While there is some correlation between the explanatory variables, none of the correlations are strong enough to raise concerns about multicollinearity, so we’ll use all of them in our model. 7.1.5 Modeling Number of Votes Suppose we know the total number of votes in a county and the probability of a single voter choosing Biden. Since the response is a count, we might think to use a Poisson distribution. However, a Poisson distribution does not place an upper bound on the number of votes a candidate could receive in a county. This is unrealistic since we know that in reality, a candidate will never be able to get more votes than the total number of voters. 7.1.6 The Binomial Distribution A Binomial random variable is a discrete random variable that models the number of “successes” in a fixed number of independent trials. We let \\(n\\) represent the number of trials, and \\(p\\) represent the probability of success on any given trial. Notation: \\(Y\\sim Binom(n,p)\\),    Probability Mass Function: \\(\\text{P}(Y=y) = {n\\choose y}p^y(1-p)^{n-y}\\)    For \\(n = 4, p=0.6\\), \\[ Pr(Y=0) = {4\\choose 0}0.6^0(0.4)^{4} = 1(0.4)^4\\approx(0.0256) \\] \\[ Pr(Y=1) = {4\\choose 1}0.6^1(0.4)^{3} = 4(.6)(0.4)^3\\approx(0.1536) \\] \\[ Pr(Y=2) = {4\\choose 2}0.6^2(0.4)^{2} = 6(.6)^2(0.4)^2\\approx(0.3456) \\] \\[ Pr(Y=3) = {4\\choose 3}0.6^3(0.4)^{1} = 4(.6)^3(0.4)^1\\approx(0.3456) \\] \\[ Pr(Y=4) = {4\\choose 4}0.6^4(0.4)^{0} = 1(.6)^4(0.4)\\approx(0.1296) \\] In a binomial distribution, the mean is \\(np\\), and the variance is \\(np(1-p)\\). A binomial distribution with \\(n=1\\) is called a Bernoulli Distribution, denoted \\(Ber(p)\\). 7.1.7 Binomial Distribution for \\(n=4, p=0.6\\) df &lt;- data.frame(x = 0:4, y = dbinom(0:4, size = 4, prob=0.6)) ggplot(df, aes(x = x, y = y)) + geom_bar(stat = &quot;identity&quot;, col = &quot;white&quot;, fill = &quot;blue&quot;) + scale_y_continuous(expand = c(0.01, 0)) + scale_x_continuous(breaks=(0:4)) + xlab(&quot;x&quot;) + ylab(expression(paste(&quot;p(x|&quot;, p, &quot;)&quot;))) + ggtitle(&quot;n=4, p=0.6&quot;) + theme_bw() + theme(plot.title = element_text(size = rel(1.2), vjust = 1.5)) Mean = \\(0.6 \\times 4=2.4\\) Variance = \\(4\\times 0.6 \\times 0.4=0.96\\) 7.1.8 More Binomial Distributions We plot binomial distributions with \\(n=10\\), \\(p=0.25, 0.6, 0.9\\) 7.1.9 Connecting Expected Response to Explatory Variables set.seed(0) dat &lt;- tibble(x=runif(200, -5, 10), p=exp(-2+1*x)/(1+exp(-2+1*x)), y=rbinom(200, 1, p), y2=.3408+.0901*x, logit=log(p/(1-p))) dat2 &lt;- tibble(x = c(dat$x, dat$x), y = c(dat$y2, dat$p), `Regression model` = c(rep(&quot;linear&quot;, 200), rep(&quot;logistic&quot;, 200))) ggplot() + geom_point(data = dat, aes(x, y)) + geom_line(data = dat2, aes(x, y, linetype = `Regression model`)) + ylab(&quot;p&quot;) Let \\(p_i\\) represent the probability that a voter in county \\(i\\) votes for Biden. We want to connect \\(p_i\\) to our explanatory variables. Assuming \\[p_i = \\beta_0+\\beta_1X_{1} + \\ldots + \\beta_pX_p\\] is a bad idea since \\(p_1\\) must stay between -1 and 1. We’ll use a sigmoidal function of the form \\[p_i = \\frac{e^{\\beta_0+\\beta_1X_{1} + \\ldots + \\beta_pX_p}}{1+e^{\\beta_0+\\beta_1X_{1} + \\ldots + \\beta_pX_p}}\\] Equivalently: \\[\\text{log}\\left(\\frac{{p_i}}{{1-p_i}}\\right) = \\beta_0+\\beta_1X_{1} + \\ldots + \\beta_pX_p \\] The function \\(\\text{log}\\left(\\frac{{p_i}}{{1-p_i}}\\right)\\) is called \\(\\text{logit}(p_i)\\). So, we can say: \\[\\text{logit}(p_i) = \\beta_0+\\beta_1X_{1} + \\ldots + \\beta_pX_p\\] 7.1.10 Odds and Odds Ratio For an event with probability \\(p\\), the odds of the event occuring are \\(\\frac{p}{1-p}\\) For two events \\(p_1\\) and \\(p_2\\) the odds ratio is defined as \\(\\frac{\\text{Odds of Event 1}}{\\text{Odds of Event 1}} = \\frac{\\frac{p_1}{1-p_1}}{\\frac{p_2}{1-p_2}}\\) 7.1.11 Interpreting Regression Coefficients Let’s suppose we have one explanatory variable \\(x\\), so \\[\\text{logit}(p_i) = \\frac{e^{\\beta_0+\\beta_1X_{1}}}{1+e^{\\beta_0+\\beta_1X_{1}}}, \\] Consider the odds ratio for a case \\(j\\) with explanatory variable \\(x + 1\\), compared to case \\(i\\) with explanatory variable \\(x\\). That is \\(\\text{log}\\left(\\frac{p_i}{1-p_i}\\right) = \\beta_0+\\beta_1x\\), and \\(\\text{log}\\left(\\frac{p_j}{1-p_j}\\right) = \\beta_0+\\beta_1(x+1)\\). \\(\\text{log}\\left(\\frac{\\frac{p_j}{1-p_j}}{\\frac{p_i}{1-p_i}}\\right)=\\text{log}\\left(\\frac{p_j}{1-p_j}\\right)-\\text{log}\\left(\\frac{p_i}{1-p_j}\\right)=\\beta_0+\\beta_1(x+1)-(\\beta_0+\\beta_1(x))=\\beta_1.\\) For each 1-unit increase in \\(x\\) the log of the odds ratio of success to failure is expected to multiply by a factor of \\(\\beta_1\\). For each 1-unit increase in \\(x\\) the odds ratio of success to failure is expected to multiply by a factor of \\(e^{\\beta_1}\\). For a categorical variable \\(x_j\\) the odds success to failure in category \\(j\\), are expected to be \\(e^{\\beta_1}\\) times higher in category \\(j\\) than in the baseline category. 7.1.12 Binomial Logistic Regression Assumptions A logistic regression model relies on the following assumptions: Binary Response The response variable is dichotomous (two possible responses) or the sum of dichotomous responses. Independence The observations must be independent of one another. Variance Structure By definition, the variance of a binomial random variable is \\(np(1-p)\\), so that variability is highest when \\(p=.5\\). Linearity The log of the odds ratio, \\(\\text{log}(\\frac{p}{1-p}) = \\text{logit}(p)\\), must be a linear function of \\(x\\). 7.2 Model for Wisconsin Vote 7.2.1 An Initial Model We’ll start by trying to model the relationship between number of votes for Biden and percentage of voters with a college degree. M1 &lt;- glm(cbind(Dvotes, Rvotes) ~ College , family = binomial(link=&quot;logit&quot;), data = Wisconsin) summary(M1) ## ## Call: ## glm(formula = cbind(Dvotes, Rvotes) ~ College, family = binomial(link = &quot;logit&quot;), ## data = Wisconsin) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -223.41 -19.07 -11.05 7.52 268.69 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.9521859 0.0035941 -264.9 &lt;0.0000000000000002 *** ## College 0.0319564 0.0001136 281.4 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 277052 on 71 degrees of freedom ## Residual deviance: 194994 on 70 degrees of freedom ## AIC: 195751 ## ## Number of Fisher Scoring iterations: 4 For each one percent increase in college education, the odds of voting for Biden are expected to multiply by a factor of \\(e^{0.0320}=1.0325\\) (a 3% increase). In a county where 25% of the population has a college degree, the probability of an individual voter voting for Biden is \\[\\frac{e^{-0.9521859 + 0.0319564\\times25}}{1+ e^{ (-0.9521859 + 0.0319564\\times25)}}=0.4618\\] In a county where 35% of the population has a college degree, the probability of an individual voter voting for Biden is \\[\\frac{e^{-0.9521859 + 0.0319564\\times35}}{1 + e^{ (-0.9521859 + 0.0319564\\times35)}}=0.5415\\] 7.2.2 Checking Linearity Assumption The model assumes that \\(\\text{log}\\left(\\frac{p}{1-p}\\right) = \\text{logit}(p)\\) is a linear function of \\(x\\). To check this, we calculate \\(\\hat{p}_i\\) for each county and plot \\(\\text{log}\\left(\\frac{\\hat{p}_i}{1-\\hat{p_i}}\\right)\\) against percentage of college graduates. phat &lt;- with(Wisconsin, (Dvotes)/(Dvotes+Rvotes)) Wisconsin$elogit &lt;- log(phat/(1-phat)) ## Plots ggplot(Wisconsin, aes(x=College, y=elogit))+ geom_point(shape=1) + # Use hollow circles geom_smooth(method=lm, # Add linear regression line se=FALSE) + # Don&#39;t add shaded confidence region xlab(&quot;College&quot;) + ylab(&quot;empirical logits&quot;) + labs(title=&quot;Wisconsin Vote Empirical logits by College Pct.&quot;) 7.2.3 Overdispersion in Binomial Counts The binomial model assumes that the variance is equal to \\(np(1-p)\\). Checking this using graphs or tables is challenging, since it involves both \\(n\\) and \\(p\\), but we can group together counties with similar \\(n\\) and similar percentages of college graduates (hence similar \\(p\\)), and calculate variance in each group. summarize &lt;- dplyr::summarize Wisconsin &lt;- Wisconsin %&gt;% mutate(TotalVotes = Dvotes+Rvotes) EdCuts = cut(Wisconsin$College, breaks=c(10,20,30,40,50,60)) PopCuts = cut(Wisconsin$TotalVotes, breaks=c(seq(from=0, to =100000, by=10000), 500000)) WisconsinCuts &lt;- data.frame(EdCuts, PopCuts, Wisconsin) WisconsinGrps &lt;- WisconsinCuts %&gt;% group_by(EdCuts, PopCuts) %&gt;% summarize(NCounties = n(), phat = sum(Dvotes)/sum(TotalVotes), mean_n = mean(TotalVotes), Theoretical_Variance = mean_n*phat*(1-phat), Obs_Var = var(Dvotes)) %&gt;% arrange(desc(NCounties)) WisconsinGrps ## # A tibble: 24 × 7 ## # Groups: EdCuts [5] ## EdCuts PopCuts NCounties phat mean_n Theoretical_Variance Obs_Var ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (10,20] (0,1e+04] 12 0.394 6359. 1518. 1233845. ## 2 (10,20] (1e+04,2e+04] 12 0.351 12366. 2817. 1137954. ## 3 (20,30] (2e+04,3e+04] 7 0.448 23677 5855. 1662284 ## 4 (10,20] (2e+04,3e+04] 6 0.338 23962. 5359. 1454543. ## 5 (20,30] (1e+04,2e+04] 5 0.453 13037. 3231. 3059893. ## 6 (20,30] (3e+04,4e+04] 4 0.451 33628. 8325. 6968112. ## 7 (20,30] (1e+05,5e+05] 3 0.464 117357. 29187. 93383717. ## 8 (10,20] (4e+04,5e+04] 2 0.362 45874. 10589. 106722 ## 9 (20,30] (4e+04,5e+04] 2 0.413 43892. 10642. 6262260. ## 10 (20,30] (5e+04,6e+04] 2 0.384 56491 13362. 2422200. ## # … with 14 more rows In the groups where there are enough counties to compare, the observed variance in counts appears to be much higher than the binomial model assumes. The data are heavily overdispersed. 7.2.4 Residuals for Binomial Logistic Regression We examine two kinds of residuals that are similar to those we saw in Poisson regression. Pearson Residual: \\[ \\begin{equation*} \\textrm{Pearson residual}_i = \\frac{\\textrm{actual count}-\\textrm{predicted count}}{\\textrm{SD of count}} = \\frac{Y_i-m_i\\hat{p_i}}{\\sqrt{m_i\\hat{p_i}(1-\\hat{p_i})}} \\end{equation*} \\] where \\(m_i\\) is the number of trials for the \\(i^{th}\\) observation and \\(\\hat{p}_i\\) is the estimated probability of success for that same observation. Deviance Residual: \\[ \\begin{equation*} \\textrm{d}_i = \\textrm{sign}(Y_i-m_i\\hat{p_i})\\sqrt{2[Y_i \\log\\left(\\frac{Y_i}{m_i \\hat{p_i}}\\right)+ (m_i - Y_i) \\log\\left(\\frac{m_i - Y_i}{m_i - m_i \\hat{p_i}}\\right)]} \\end{equation*} \\] When the number of trials is large for all of the observations and the models are appropriate, both sets of residuals should follow a standard normal distribution. 7.2.5 Quasi-Binomial Model Like in Poisson regression, we can address overdispersion by fitting quasi-binomial model that estimates a dispersion parameter \\(\\hat{\\phi}=\\frac{\\sum(\\textrm{Pearson residuals})^2}{n-p}\\) and multiplies standard error by \\(\\sqrt{\\phi}\\). M1b &lt;- glm(cbind(Dvotes, Rvotes) ~ College , family = quasibinomial(link=&quot;logit&quot;), data = Wisconsin) summary(M1b) ## ## Call: ## glm(formula = cbind(Dvotes, Rvotes) ~ College, family = quasibinomial(link = &quot;logit&quot;), ## data = Wisconsin) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -223.41 -19.07 -11.05 7.52 268.69 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.952186 0.188929 -5.040 0.00000350 *** ## College 0.031956 0.005969 5.353 0.00000104 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for quasibinomial family taken to be 2763.213) ## ## Null deviance: 277052 on 71 degrees of freedom ## Residual deviance: 194994 on 70 degrees of freedom ## AIC: NA ## ## Number of Fisher Scoring iterations: 4 The estimate of the dispersion parameter \\(\\hat{\\phi} = 2763\\) is large. Standard errors increase considerably. The t-statistics associated with the quasi-binomial model are much smaller the z-statistics associated with the binomial model. The p-values are bigger, but still small enough to provide evidence of a relationship between college education and voting for Biden. 7.2.6 Model with All Explanatory Variables M2 &lt;- glm(cbind(Dvotes, Rvotes) ~ College + Unemployment + WhitePct + COVID_DeathRate + Income , family = quasibinomial(link=&quot;logit&quot;), data = Wisconsin) summary(M2) ## ## Call: ## glm(formula = cbind(Dvotes, Rvotes) ~ College + Unemployment + ## WhitePct + COVID_DeathRate + Income, family = quasibinomial(link = &quot;logit&quot;), ## data = Wisconsin) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -48.582 -14.059 0.227 9.791 72.837 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.009188399 0.580255296 6.909 0.0000000023471 *** ## College 0.046311576 0.005900290 7.849 0.0000000000493 *** ## Unemployment -0.110233627 0.060376843 -1.826 0.0724 . ## WhitePct -0.029353000 0.004832728 -6.074 0.0000000690197 *** ## COVID_DeathRate -0.006583959 0.001535600 -4.288 0.0000601756542 *** ## Income -0.000033277 0.000004613 -7.214 0.0000000006729 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for quasibinomial family taken to be 527.7059) ## ## Null deviance: 277052 on 71 degrees of freedom ## Residual deviance: 34757 on 66 degrees of freedom ## AIC: NA ## ## Number of Fisher Scoring iterations: 3 For each one percentage point increase in college education odds of voting for Biden are estimated to multiply by \\(e^{0.0463} = 1.047\\) ( a 5% increase), assuming all other variables are held constant. For each one percentage point increase in unemployment rate, odds of voting for Biden is estimated to multiply by \\(e^{-0.1102} = 0.8957\\) (a 10% decrease), assuming all other variables are held constant. For each one percentage point increase in white residents, odds of voting for Biden is estimated to multiply by \\(e^{-0.02935} = 0.97\\) (a 3% decrease), assuming all other variables are held constant. For each one death increase per 100k residents, odds of voting for Biden is estimated to multiply by \\(e^{-0.006584} = 0.993\\) (a 0.7% decrease), assuming all other variables are held constant. For each 1000 dollar increase in median income, odds of voting for Biden is estimated to multiply by \\(e^{-0.0000328\\times1000} = 0.968\\) (a 3% decrease), assuming all other variables are held constant. 7.2.7 Tests for Significance of Model Coefficients Wald test statistics and p-values for all variables provide evidence of relationships between these variables and percentage voting for Biden. This is not surprising since the sample size is very large. In fact, confidence intervals and hypothesis tests don’t really make sense to talk about here, because we have the whole population of Wisconsin voters in 2020. We’re not trying to generalize from a sample to a population. The model estimates still make sense, and are informative, so we should base our conclusions on percentage change estimates given on the previous slide. 7.2.8 Drop in Deviance Test We could perform a drop-in-deviance test to compare our two models so far. drop_in_dev &lt;- anova(M1b, M2, test = &quot;F&quot;) drop_in_dev Analysis of Deviance Table Model 1: cbind(Dvotes, Rvotes) ~ College Model 2: cbind(Dvotes, Rvotes) ~ College + Unemployment + WhitePct + COVID_DeathRate + Income Resid. Df Resid. Dev Df Deviance F Pr(&gt;F) 1 70 194994 2 66 34757 4 160237 75.912 &lt; 0.00000000000000022 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We see a large drop in residual deviance, providing strong evidence that the larger model is prefered. In this case, that makes sense, since it contains variables we expect to be helpful. When we have very large sample sizes we’ll get small p-values even when the new variables don’t make a practical difference. So we should not base model choices on p-values alone, but should look at confidence intervals and measures of the size of the effect associated with each variable. 7.2.9 Deviance Residual Plot We plot deviance residuals against the predicted values and against our explanatory variables to test for lack of fit. 7.2.10 LLSR vs Binomial Logistic Regression \\[\\begin{gather*} \\underline{\\textrm{Response}} \\\\ \\mathbf{LLSR:}\\textrm{ normal} \\\\ \\mathbf{Binomial\\ Regression:}\\textrm{ number of successes in n trials} \\\\ \\textrm{ } \\\\ \\underline{\\textrm{Variance}} \\\\ \\mathbf{LLSR:}\\textrm{ equal for each level of}\\ X \\\\ \\mathbf{Binomial\\ Regression:}\\ np(1-p)\\textrm{ for each level of}\\ X \\\\ \\textrm{ } \\\\ \\underline{\\textrm{Model Fitting}} \\\\ \\mathbf{LLSR:}\\ \\mu=\\beta_0+\\beta_1x \\textrm{ using Least Squares}\\\\ \\mathbf{Binomial\\ Regression:}\\ \\log\\left(\\frac{p}{1-p}\\right)=\\beta_0+\\beta_1x \\textrm{ using Maximum Likelihood}\\\\ \\textrm{ } \\\\ \\underline{\\textrm{EDA}} \\\\ \\mathbf{LLSR:}\\textrm{ plot $X$ vs. $Y$; add line} \\\\ \\mathbf{Binomial\\ Regression:}\\textrm{ find $\\log(\\textrm{odds})$ for several subgroups; plot vs. $X$} \\\\ \\end{gather*}\\] \\[\\begin{gather*} \\underline{\\textrm{Comparing Models}} \\\\ \\mathbf{LLSR:}\\textrm{ extra sum of squares F-tests; AIC/BIC} \\\\ \\mathbf{Binomial\\ Regression:}\\textrm{ drop-in-deviance tests; AIC/BIC} \\\\ \\textrm{ } \\\\ \\underline{\\textrm{Interpreting Coefficients}} \\\\ \\mathbf{LLSR:}\\ \\beta_1=\\textrm{ change in mean response for unit change in $X$} \\\\ \\mathbf{Binomial\\ Regression:}\\ e^{\\beta_1}=\\textrm{ percent change in odds for unit change in $X$} \\end{gather*}\\] 7.3 Maximum Likelihood Estimation 7.3.1 Parameter Estimation Recall that in ordinarly least squares regression, the estimates \\(b_1, b_2, \\ldots, b_p\\) of regression coefficients \\(\\beta_1, \\beta_2, \\ldots \\beta_p\\) are chosen in a way that minimizes \\(\\displaystyle\\sum_{i=1}^n(y_i-\\hat{y_i})^2=\\displaystyle\\sum_{i=1}^n(y_i-(b_0+b_1x_{i1}+\\ldots b_px_{ip}))^2\\). The validity of the least-squares regression process depends on the assumptions associated with a LLSR model, making it inappropriate for the kinds of models we’ve seen in this class (mixed effects models, generalized linear models, etc.). Instead, we use a process called maximum likelihood estimation. In fact, in an ordinary LLSR model, it can be shown that maximum likelihood estimation would produce the same estimates as least squares estimation. In this section, we’ll work through a simple example to illustrate how maximum likelihood works in a logistic regression model. 7.3.2 Steph Curry 3-Point Shooting Stephen Curry of the Golden State Warriors is widely considered to be the best 3-point shooter in the NBA. So far during the current 2021-22 NBA season, Curry has made 251 out of 663 attempted 3 point shots (37.9%). When playing at home, he has made 150 out of 397 3-point shots (37.8%). When playing away, he has made 101 out of 266 4-point shots (38.0%). We’ll use a logistic regression model to estimate the probability of Curry making a shot at home or away and test whether there is evidence of differences in his shooting based on location. 7.3.3 Model for Curry’s Shooting We’ll start with a very simple intercept-only model. This model assumes that Curry has a constant probability of success on any shot (\\(p\\)), which is the same, regardless of where he is playing. Our goal is to estimate \\(p\\) and to find a confidence interval for the range \\(p\\) could plausibly lie in. 7.3.4 Likelihood Function A likelihood function is a function that tells us how likely we are to observe our data for a given parameter value. Let \\(p\\) represent the probability of a made basket. Since the shots are independent, we can write the Likelihood function for Curry’s shots as: \\[Lik(p) \\propto p^{\\text{#Makes}}(1-p)^{\\text{#Misses}} = (p)^{251}(1-p)^{412}\\] If our goal is just to esimate \\(p\\), we could simply find the value of \\(p\\) that maximizes this function. Such a value is called a maximum likelihood estimate. 7.3.5 Plotting Likelihood Function options( scipen = 0 ) library(ggplot2) p=seq(0,1,length=1001) lik=p^251 * (1-p)^(663-251) # likelihood of getting observed data df &lt;- data.frame(p,lik) plot&lt;- ggplot(data=df,aes(x=p, y=lik)) + geom_line(color=&quot;blue&quot;, size=2) + xlab(&quot;possible values of p&quot;) + ylab(&quot;Likelihood&quot;) + labs(title=&quot;Likelihood function for Curry&#39;s shots&quot;) plot + xlim(c(0, 1)) It looks like the most likely value of \\(p\\) is around 0.4. We’ll write a function in R to calculate the value of \\(p\\) that maximizes the function. 7.3.6 Numerical Maximization Lik.f &lt;- function(nbasket,nmissed,nGrid){ p &lt;- seq(0, 1, length = nGrid) # create nGrid values of p between 0 and 1 lik &lt;- p^{nbasket} * (1 - p)^{nmissed} # calculate value of lik at each p return(p[lik==max(lik)]) # find and return the value of p that maximizes the likelihood function } Lik.f(nbasket = 251, nmissed = 663-251, nGrid = 10000) ## [1] 0.3785379 The maximum likelihood estimate is \\(\\hat{p} = 0.3785\\). In fact, this is equal to 251/663. In this case, the MLE is consistent with our intuition. 7.3.7 MLE Using Calculus We can also use calculus to find the value of \\(p\\) that maximizes the function \\(\\text{lik}(p)\\). In fact, it is usually easier to maximize the log of this function. We can do this since log is a non-decreasing function, ensuring that the value that maximizes \\(\\text{log}(\\text{lik}(p))\\) will also maximize \\(\\text{lik}(p)\\). \\[ \\begin{align*} \\text{lik}(p) &amp;= p^{251}(1-p)^{412} \\\\ \\text{log}(\\text{lik}(p)) &amp;= 251\\log(p)+412\\log(1-p) \\\\ \\frac{d}{dp} \\log(\\text{lik}(p)) &amp;= \\frac{251}{p} - \\frac{412}{1-p} = 0 \\end{align*} \\] and \\[ \\frac{251}{p} = \\frac{412}{1-p} \\implies 251(1-p)=412p\\implies p=\\frac{251}{251+412}\\approx0.3785 \\] 7.3.8 Likelihood in a Logistic Regression Model In a logistic regression model, we don’t try to estimate \\(p\\) directly, but rather to estimate \\(\\beta_0, \\beta_1, \\beta_p\\), which are then used to calculate \\(p\\) In our simple intercept only example, \\[p = \\frac{e^{\\beta_0}}{1+e^{\\beta_0}}\\] and we need to estimate \\(\\beta_0\\). After removing constants, the new likelihood looks like: \\[ \\begin{equation*} \\begin{gathered} Lik(\\beta_0) \\propto \\\\ \\left( \\frac{e^{\\beta_0}}{1+e^{\\beta_0}}\\right)^{251}\\left(1- \\frac{e^{\\beta_0}}{1+e^{\\beta_0}}\\right)^{412} \\end{gathered} \\end{equation*} \\] 7.3.9 Plot of Likelihood Function library(ggplot2) b=seq(-1,1,length=1001) lik= (exp(b)/(1+exp(b)))^251*(1-(exp(b)/(1+exp(b))))^(412) # likelihood of getting observed data df &lt;- data.frame(b,lik) plot&lt;- ggplot(data=df,aes(x=b, y=lik)) + geom_line(color=&quot;blue&quot;, size=2) + xlab(&quot;possible values of beta_0&quot;) + ylab(&quot;Likelihood&quot;) + labs(title=&quot;Likelihood function for Curry&#39;s shots&quot;) plot + xlim(c(-1, 1)) 7.3.10 Numerical Maximization Lik.f_logistic &lt;- function(nbasket,nmissed,nGrid){ b &lt;- seq(-1, 1, length = nGrid) # create values between -1 and 1 at which to evaluate the function lik &lt;- (exp(b)/(1+exp(b)))^nbasket*(1-(exp(b)/(1+exp(b))))^nmissed # calculate values at each b return(b[lik==max(lik)]) # find and return value of b that maximizes the function } Lik.f_logistic(nbasket = 251, nmissed = 412, nGrid = 10000) ## [1] -0.4955496 Our estimate is \\(b_0 = -0.4955\\). From this we can calculate \\[\\hat{p} = \\frac{e^{-0.4955}}{1+e^{-0.4955}}\\approx0.3785\\] 7.3.11 Comparison to R Output Location &lt;- c(&quot;Home&quot;, &quot;Away&quot;) Makes &lt;- c(150, 101) Misses &lt;- c(247, 165) Curry &lt;- data.frame(Location, Makes, Misses) head(Curry) ## Location Makes Misses ## 1 Home 150 247 ## 2 Away 101 165 M &lt;- glm(data = Curry, cbind(Makes, Misses) ~ 1 , family = binomial(link=&quot;logit&quot;)) summary(M) ## ## Call: ## glm(formula = cbind(Makes, Misses) ~ 1, family = binomial(link = &quot;logit&quot;), ## data = Curry) ## ## Deviance Residuals: ## 1 2 ## -0.03075 0.03755 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.49557 0.08007 -6.189 6.05e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 0.0023559 on 1 degrees of freedom ## Residual deviance: 0.0023559 on 1 degrees of freedom ## AIC: 14.355 ## ## Number of Fisher Scoring iterations: 2 Note that the estimates differ in the 5th decimal place due to issues with numerical approximation. We could get a more precise approximation by increasing the number of points in our grid search. We could maximize this function using calculus, which is more involved, but still doable in this case. Calculus-based methods typically do not work for more complicated likelihood methods involving more than one parameter, so we usually rely on numerical approximation methods. 7.3.12 Model for Home/Away Now let’s build a model that allows Curry’s probability of making a shot to differ for away games, compared to home games. Recall that Curry made 150 out of 397 shots at home and 101 out of 265 away. Let \\(p_H\\) represent the probability of making a shot at home and \\(p_A\\) represent the probability of making a shot in an away game. We can write the likelihood function as: \\[Lik(p_H, p_A) \\propto p_H^{150}(1-p_H)^{247} p_A^{101}(1-p_A)^{165}\\] Our interest centers on estimating \\(\\hat{\\beta_0}\\) and \\(\\hat{\\beta_1}\\), not \\(p_1\\) or \\(p_0\\). So we replace \\(p_1\\) in the likelihood with an expression for \\(p_1\\) in terms of \\(\\beta_0\\) and \\(\\beta_1\\). Recall \\[p_i = \\frac{e^{\\beta_0+\\beta_1\\text{Home}}}{1+e^{\\beta_0+\\beta_1\\text{Home}}}\\] After removing constants, the new likelihood looks like: \\[ \\begin{equation*} \\begin{gathered} Lik(\\beta_0,\\beta_1) \\propto \\\\ \\left( \\frac{e^{\\beta_0+\\beta_1}}{1+e^{\\beta_0+\\beta_1}}\\right)^{150}\\left(1- \\frac{e^{\\beta_0+\\beta_1}}{1+e^{\\beta_0+\\beta_1}}\\right)^{247} \\left(\\frac{e^{\\beta_0}}{1+e^{\\beta_0}}\\right)^{101}\\left(1-\\frac{e^{\\beta_0}}{1+e^{\\beta_0}}\\right)^{165} \\end{gathered} \\end{equation*} \\] 7.3.13 Numerical Optimization Lik.f_logistic2 &lt;- function(nbasketH,nmissedH,nbasketA,nmissedA,nGrid){ b0 &lt;- seq(-1, 1, length = nGrid) # values of b0 b1 &lt;- seq(-1, 1, length=nGrid) # values of b1 B &lt;- expand.grid(b0, b1) # create all combinations of b0 and b1 names(B) &lt;- c(&quot;b0&quot;, &quot;b1&quot;) # give B the right names B &lt;- B %&gt;% mutate(Lik = (exp(b0+b1)/(1+exp(b0+b1)))^nbasketH*(1-(exp(b0+b1)/(1+exp(b0+b1))))^nmissedH* (exp(b0)/(1+exp(b0)))^nbasketA*(1-(exp(b0)/(1+exp(b0))))^nmissedA) #evaluate function return(B[B$Lik==max(B$Lik),]) # find and return combination of b0 and b1 that maximize B. } Lik.f_logistic2(nbasketH = 150, nmissedH = 247, nbasketA = 101, nmissedA = 165, nGrid = 1000) ## b0 b1 Lik ## 496255 -0.4914915 -0.007007007 9.835399e-192 Although we have worked with the likelihood function here, it is more common to work with the log of the likelihood function. Notice that the maximized log likelihood is very small, which can create numerical instability, though it doesn’t here. 7.3.14 Comparison to R Output M &lt;- glm(data = Curry, cbind(Makes, Misses) ~ Location , family = binomial(link=&quot;logit&quot;)) summary(M) ## ## Call: ## glm(formula = cbind(Makes, Misses) ~ Location, family = binomial(link = &quot;logit&quot;), ## data = Curry) ## ## Deviance Residuals: ## [1] 0 0 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.490825 0.126339 -3.885 0.000102 *** ## LocationHome -0.007928 0.163330 -0.049 0.961286 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 2.3559e-03 on 1 degrees of freedom ## Residual deviance: -4.1300e-14 on 0 degrees of freedom ## AIC: 16.353 ## ## Number of Fisher Scoring iterations: 2 The estimates are close to those that we obtained. We can make them closer by using a finer grid search. 7.3.15 Applications of Likelihood Likelihood is at the heart of many of the model comparison tests we’ve worked with in this class. Likelihood Ratio Tests The ANOVA-type tests of reduced vs full models use likelihoods to calculate the improvement in fit, associated with adding additional variables to the model. Our test statistic is \\[\\begin{equation*} \\begin{split} \\textrm{LRT} &amp;= 2[\\max(\\log(Lik(\\textrm{larger model}))) - \\max(\\log(Lik(\\textrm{reduced model})))] \\\\ &amp;= 2\\log\\left(\\frac{\\max(Lik(\\textrm{larger model}))}{\\max(Lik(\\textrm{reduced model}))} \\right) \\end{split} \\end{equation*}\\] Statistical theory tells us that this statistic follows \\(\\chi^2\\) distribution with the difference in number of parameters as its degrees of freedom. In fact, it can be shown that the drop-in-deviance tests we’ve used for Poisson and logistic regression are special cases of this likelihood ratio test. AIC and BIC AIC and BIC are also calculated using the likelihood function. \\(\\textrm{AIC} = -2 (\\textrm{maximum log-likelihood }) + 2p\\), where \\(p\\) represents the number of parameters in the fitted model. AIC stands for Akaike Information Criterion. Because smaller AICs imply better models, we can think of the second term as a penalty for model complexity—the more variables we use, the larger the AIC. \\(\\textrm{BIC} = -2 (\\textrm{maximum log-likelihood }) + p\\log(n)\\), where \\(p\\) is the number of parameters and \\(n\\) is the number of observations. BIC stands for Bayesian Information Criterion, also known as Schwarz’s Bayesian criterion (SBC). 7.3.16 Summary Maximum Likelihood Estimation Maximum likelihood estimation is widely used to estimate parameters in many different kinds of statistical models In LLSR, MLE and least-squares procedures yield the same estimates Although they can be determined graphically, or using calculus in simple situations, MLE’s are usually approximated using numerical methods It’s usually best, for reasons of numerical stability, to maximize the log of the likelihood function, rather than the likelihood function itself In this section, we looked at a couple simple examples in logistic regression, but MLE’s are used in all of the models we’ve seen in this course (mixed effects, Poisson regression, etc.) and many more. It is the go-to technique for parameter estimation in classical frequentist statistics (which probably includes all statistics you’ve studied so far) Maximum Likelihood estimation is taught in much more mathematical detail in STAT 445. An alternative approach to Maximium Likelihood Estimation is Bayesian Estimation, which is taught in STAT 450 7.4 Zero-Inflated Poisson Model 7.4.1 Case Study: Weekend Drinking Students in an introductory statistics class at a large university were asked: “How many alcoholic drinks did you consume last weekend?”. This survey was conducted on a dry campus where no alcohol is officially allowed, even among students of drinking age, so we expect that some portion of the respondents never drink. The purpose of this survey is to explore factors related to drinking behavior on a dry campus. #Getting started-weekenddrinks # File: weekendDrinks drinks &lt;- read.csv(&quot;https://raw.githubusercontent.com/proback/BeyondMLR/master/data/weekendDrinks.csv&quot;) drinks &lt;- drinks %&gt;% mutate(off.campus=ifelse(dorm==&quot;off campus&quot;,1,0), firstYear=dorm%in%c(&quot;kildahl&quot;,&quot;mohn&quot;,&quot;kittlesby&quot;)) %&gt;% select(-c(dorm)) head(drinks) ## drinks sex off.campus firstYear ## 1 0 f 0 TRUE ## 2 5 f 0 FALSE ## 3 10 m 0 FALSE ## 4 0 f 0 FALSE ## 5 0 m 0 FALSE ## 6 3 f 0 FALSE 7.4.2 Questions of Interest What proportion of students on this dry campus never drink? Do upper class students drink more than first years? What factors, such as off-campus living and sex, are related to whether students drink? Among those who do drink, to what extent is moving off campus associated with the number of drinks in a weekend? It is commonly assumed that males’ alcohol consumption is greater than females’; is this true on this campus? 7.4.3 Distribution of Number of Drinks ggplot(data=drinks, aes(x=drinks)) + geom_histogram() + facet_wrap(~firstYear) drinks %&gt;% group_by(firstYear) %&gt;% summarize(mean_drinks=mean(drinks), prop_zero = mean(drinks==0), n=n()) ## # A tibble: 2 × 4 ## firstYear mean_drinks prop_zero n ## &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 FALSE 2.41 0.407 59 ## 2 TRUE 0.722 0.667 18 7.4.4 Number of Drinks Comparisons p1 &lt;- ggplot(data = drinks) + geom_histogram(mapping = aes(x = drinks)) + facet_wrap(~firstYear, nrow=2) + ggtitle(&quot;Drinking by First Year Status&quot;) p2 &lt;- ggplot(data = drinks) + geom_histogram(mapping = aes(x = drinks)) + facet_wrap(~sex, nrow=2) + ggtitle(&quot;Drinks by Sex&quot;) p3 &lt;- ggplot(data = drinks) + geom_histogram(mapping = aes(x = drinks)) + facet_wrap(~off.campus, nrow=2) + ggtitle(&quot;Drinking by On/Off Campus&quot;) grid.arrange(p1, p2, p3, nrow=1) 7.4.5 Proportion of Drinkers Now, we compare proportions of students who reported drinking any drinks. Drinks by First-Year Status: p1 &lt;- ggplot(data = drinks) + stat_count(mapping = aes(x = firstYear, fill=drinks&gt;0), position=&quot;fill&quot; ) + ggtitle(&quot;Drinking by First Year Status&quot;) p2 &lt;- ggplot(data = drinks) + stat_count(mapping = aes(x = sex, fill=drinks&gt;0), position=&quot;fill&quot; ) + ggtitle(&quot;Drinking by Sex&quot;) p3 &lt;- ggplot(data = drinks) + stat_count(mapping = aes(x = off.campus, fill=drinks&gt;0), position=&quot;fill&quot; ) + ggtitle(&quot;Drinking by On/Off Campus&quot;) grid.arrange(p1, p2, p3, nrow=3) 7.4.6 Modeling Drinks A Poisson distribution seems like a good choice for modeling drinks, since they are a count, and there is no fixed number of “attempts”, as in a binomial distribution. Expected Proportion of Zeros: dpois(0, 2.41) ## [1] 0.08981529 dpois(0, 0.72) ## [1] 0.4867523 The proportion of zeros in our data is much higher than expected under a Poisson model with means equal to those observed in the data. (0.41 compared to 0.09 for upperclass students and 0.67, compared to 0.49 for first-years). 7.4.7 Explaining the Large Number of Zeros The students who reported 0 drinks will fall into one of two categories: Students who do not drink at all. Students who do drink, but did not drink last weekend. Our data consist of a mixture of responses from these two different populations. Among students who do drink, it is reasonable to model the number of drinks consumed on a given weekend using a Poisson distribution Among students who do not drink at all, there is no need to model the number of drinks in a given weekend, since we know it’s zero. Ideally, we’d like to sort out the non-drinkers and drinkers when performing our analysis. Answering these questions would be a simple matter if we knew who was and was not a drinker in our sample. Unfortunately, the non-drinkers did not identify themselves as such, so we will need to use the data available with a model that allows us to estimate the proportion of drinkers and non-drinkers. 7.4.8 Zero-Inflated Poisson Model We’ll fit the model in two steps: Estimate the probability that a person drinks at all, given information contained in the explanatory variables. Model the number of drinks consumed in a given weekend, assuming the person does drink at all. In step 1, we use logistic regression to estimate \\(p\\), the probability that the person does not drink at all. In step 2, we use a Poisson regression to estimate \\(\\lambda\\), the expected number of drinks a person consumes, assumping they drink at all. 7.4.9 Developing the Zero-Inflated Poisson Model Let \\[ \\begin{cases} 1 &amp; \\text{if student i drinks at all} \\\\ 0 &amp; \\text{if student i does not drink} \\end{cases} \\] First, we model \\(D_i\\): \\[D_i\\sim\\text{Ber}(p_i) \\] and then \\(Y_{i}\\) \\[ \\begin{cases} Y_i\\sim\\text{Pois}(\\lambda_i) &amp; \\text{if } D_i=1 \\\\ Y_i=0 &amp; \\text{if } D_i=0 \\end{cases} \\] The variable \\(D_i\\) is called a latent variable. It is a variable that is relevant to the process we are interested in studying, but is not directly measured or reported in our data. The Zero-Inflated Poisson is an example of a mixture model, as the response variable is modeled using a mixture of Bernoulli and Poisson distributions. Let \\(p_i\\) represent \\(P(D_i=0)\\), the probability that person person does not drink. 7.4.10 Deriving the ZIP PMF We derive the probability mass function for the Poisson model by considering the two different ways we can observe count \\(y\\). \\[ \\begin{aligned} P(Y=0) &amp;= P(\\text{Person Doesn&#39;t Drink at All}) + P(\\text{Person drinks and didn&#39;t drink last week})\\\\ &amp; = P(\\text{Person Doesn&#39;t Drink at All}) + P(\\text{0 drinks in a given weekend given person drinks})P(\\text{Person drinks}) \\\\ &amp; = P(D_i=0) + P(Y_i=0|D_i=1)P(D_i=1) \\\\ &amp; = p_i + \\frac{\\lambda_i^0e^{-\\lambda_i}}{0!}(1-p) \\\\ &amp; = p_i + e^{-\\lambda_i}(1-p_i) \\end{aligned} \\] For \\(y\\neq 0\\), \\[ \\begin{aligned} P(Y=y) &amp;= P(\\text{Person drinks and drinks y drinks in a weekend})\\\\ &amp; = P(\\text{y drinks in a given weekend given person drinks})P(\\text{Person drinks}) \\\\ &amp; = P(Y_i=y|D_i=1)P(D_i=1) \\\\ &amp; = \\frac{\\lambda_i^ye^{-\\lambda_i}}{y!}(1-p) \\end{aligned} \\] Putting these together, we get the ZIP probability mass function: \\[ P(Y=y) = \\begin{cases} p_i + e^{-\\lambda_i}(1-p_i) &amp; \\text{if } y=0 \\\\ \\frac{\\lambda_i^ye^{-\\lambda_i}}{y!}(1-p_i) &amp; \\text{if } y&gt;0 \\end{cases} \\] 7.4.11 Examples of ZIP PMF’s Mean: (\\((1-p)\\lambda\\)) Variance: (\\((1-p)\\lambda(1+p\\lambda)\\)) 7.4.12 ZIP Model We assume \\[ Y_i \\sim\\text{ZIP}(p_i, \\lambda_i) \\] \\(p_i\\) represents the probability that student \\(i\\) drinks at all. \\(\\lambda_i\\) represents the average number of drinks student \\(i\\) consumes in a weekend, assuming they do drink at all. We want to estimate \\(p_i\\) and \\(\\lambda_i\\), using information contained in the explanatory variables. We can use different explanatory variables to estimate \\(p_i\\) and \\(\\lambda_i\\). Let \\(Z_{1}, Z_2, \\ldots, Z_p&#39;\\) be the explanatory variables used to estimate \\(p\\), and \\(X_1, X_2, \\ldots, X_p\\) be the explanatory variables used to estimate \\(\\lambda\\) We link \\(p_i\\) and \\(\\lambda_i\\) to a linear combination of the explanatory variables, using the link functions: \\[ log(\\lambda_i) = \\beta_0+\\beta_1X_{i1}+ \\ldots +\\beta_pX_{ip}, \\] \\[ log\\left(\\frac{p_i}{1-p_i}\\right) = \\alpha_0+\\alpha_1Z_{i1}+ \\ldots +\\alpha_pZ_{ip&#39;}, \\] We obtain estimates of \\(\\beta_0, \\ldots{\\beta_p}\\) and \\(\\alpha_0, \\ldots, \\alpha_p\\), and from these obtain maximum likelihood etimates for \\(p_i\\) and \\(\\lambda_i\\). 7.5 Model for Drinks Data 7.5.1 ZIP for Drinks Data A zero-inflated Poisson regression model to take non-drinkers into account consists of two parts: One part models the association, among drinkers, between number of drinks and the predictors of sex and off-campus residence. The other part uses a predictor for first-year status to obtain an estimate of the proportion of non-drinkers based on the reported zeros. The form for each part of the model follows. The first part looks like an ordinary Poisson regression model: \\[ log(\\lambda)=\\beta_0+\\beta_1\\textrm{off.campus}+ \\beta_2\\textrm{sex} \\] where \\(\\lambda\\) is the mean number of drinks in a weekend among those who drink. The second part has the form \\[ logit(\\alpha)=\\beta_0+\\beta_1\\textrm{firstYear} \\] where \\(\\alpha\\) is the probability of being in the non-drinkers group and \\(logit(\\alpha) = log( \\alpha/(1-\\alpha))\\). 7.5.2 ZIP Model in R We will use the R function zeroinfl from the package pscl to fit a ZIP model. The terms before the | are used to model expected number of drinks, assuming the person really does drink at all. The terms after the | are used to estimate the probability that the person drinks at all. zip.m &lt;- zeroinfl(drinks ~ off.campus + sex | firstYear, data = drinks) summary(zip.m) Call: zeroinfl(formula = drinks ~ off.campus + sex | firstYear, data = drinks) Pearson residuals: Min 1Q Median 3Q Max -1.1118 -0.8858 -0.5290 0.6367 5.2996 Count model coefficients (poisson with log link): Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 0.7543 0.1440 5.238 1.62e-07 *** off.campus 0.4159 0.2059 2.020 0.0433 * sexm 1.0209 0.1752 5.827 5.63e-09 *** Zero-inflation model coefficients (binomial with logit link): Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -0.6036 0.3114 -1.938 0.0526 . firstYearTRUE 1.1364 0.6095 1.864 0.0623 . --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Number of iterations in BFGS optimization: 8 Log-likelihood: -140.8 on 5 Df exp(coef(zip.m)) # exponentiated coefficients ## count_(Intercept) count_off.campus count_sexm zero_(Intercept) ## 2.1260699 1.5157953 2.7756910 0.5468311 ## zero_firstYearTRUE ## 3.1154950 Interpretations For those who drink, the average number of drinks for males is \\(e^{1.0209}\\) or 2.76 times the number for females (Z = 5.827, p &lt; 0.001) given that you are comparing people who live in comparable settings (on or off campus) Among drinkers, the mean number of drinks for students living off campus is \\(e^{0.4159}=1.52\\) times that of students living on campus for those of the same sex (Z = 2.021, p = 0.0433). The odds that a first-year student is a non-drinker are 3.12 times the odds that an upper-class student is a non-drinker. The estimated probability that a first-year student is a non-drinker is \\[ \\frac{e^{0.533}}{1+e^{0.533}} = 0.630 \\] or 63.0%, while for non-first-year students, the estimated probability of being a non-drinker is 0.354. 7.5.3 Residual Plot Fitted values (\\(\\hat{y}\\)) and residuals (\\(y-\\hat{y}\\)) can be computed for zero-inflation models and plotted. Figure 7.1 reveals that one observation appears to be extreme (Y=22 drinks during the past weekend). Is this a legitimate observation or was there a transcribing error? Without the original respondents, we cannot settle this question. It might be worthwhile to get a sense of how influential this extreme observation is by removing Y=22 and refitting the model. Figure 7.1: Residuals by fitted counts for ZIP model. 7.5.4 Limitations There are several concerns and limitations we should think about related to this study. What time period constitutes the “weekend”? What constitutes a drink—a bottle of beer? How many drinks will a respondent report for a bottle of wine? There is also an issue related to confidentiality. If the data is collected in class, will the teacher be able to identify the respondent? Will respondents worry that a particular response will affect their grade in the class or lead to repercussions on a dry campus? In addition to these concerns, there are a number of other limitations that should be noted. Following the concern of whether this data represents a random sample of any population (it doesn’t), we also must be concerned with the size of this data set (77). ZIP models are not appropriate for small samples and this data set is not impressively large. 7.5.5 Final Thoughts on Zero-Inflated Models At times, a mixture of zeros occurs naturally. It may not come about because of neglecting to ask a critical question on a survey, but the information about the subpopulation may simply not be ascertainable. For example, visitors from a state park were asked as they departed how many fish they caught, but those who report 0 could be either non-fishers or fishers who had bad luck. These kinds of circumstances occur often enough that ZIP models are becoming increasingly common. Actually, applications which extend beyond ordinary Poisson regression applications—ZIPs and other Poisson modeling approaches such as hurdle models and quasi-Poisson applications—are becoming increasingly common. So it is worth taking a look at these variations of Poisson regression models. Here we have only skimmed the surface of zero-inflated models, but we want you to be aware of models of this type. ZIP models demonstrate that modeling can be flexible and creative—a theme we hope you will see throughout this book. "],["multilevel-generalized-linear-models.html", "Chapter 8 Multilevel Generalized Linear Models 8.1 Basketball Referees Dataset 8.2 Multilevel Generalized Linear Model 8.3 Crossed Random Effects 8.4 Parametric Bootstrapping", " Chapter 8 Multilevel Generalized Linear Models These notes provide a summary of Chapter 11 in Beyond Multiple Linear Regression by Roback and Legler. Much of the code that appears here comes from the textbook’s Github repository. # Packages required for Chapter 11 library(gridExtra) library(lme4) library(pander) library(ggmosaic) library(knitr) library(kableExtra) library(broom) library(tidyverse) In basketball, do referees tend to “even out” calls over the course of a game? Is a team more likely to have a foul called on them if the last foul was called on the other team, or if the other team has had more fouls called in the game up to that point? 8.1 Basketball Referees Dataset 8.1.1 Data Overview Data was collected for 4972 fouls over 340 college basketball games during the 2009-2010 season. We focus on fouls called during the first half to avoid the issue of intentional fouls by the trailing team at the end of games. The dataset includes the following variables. game = unique game identification number date = date game was played (YYYYMMDD) visitor = visiting team abbreviation hometeam = home team abbreviation foul.num = cumulative foul number within game foul.home = indicator if foul was called on the home team foul.diff = the difference in fouls before the current foul was called (home - visitor) score.diff = the score differential before the current foul was called (home - visitor) lead.home = indicator if home team has the lead previous.foul.home = indicator if previous foul was called on the home team foul.type = categorical variable if current foul was offensive, personal, or shooting time = number of minutes left in the first half when foul called refdata &lt;- read.csv(&quot;https://raw.githubusercontent.com/proback/BeyondMLR/master/data/basketball0910.csv&quot;) refdata &lt;- refdata %&gt;% select(game, visitor, hometeam, foul.num, foul.home, foul.diff, score.diff, lead.home, previous.foul.home, foul.type, time) head(refdata) # examine first 6 rows ## game visitor hometeam foul.num foul.home foul.diff score.diff lead.home ## 1 1 IA MN 1 0 0 7 1 ## 2 1 IA MN 2 1 -1 10 1 ## 3 1 IA MN 3 1 0 11 1 ## 4 1 IA MN 4 0 1 11 1 ## 5 1 IA MN 5 0 0 14 1 ## 6 1 IA MN 6 0 -1 22 1 ## previous.foul.home foul.type time ## 1 0 Personal 14.166667 ## 2 0 Personal 11.433333 ## 3 1 Personal 10.233333 ## 4 1 Personal 9.733333 ## 5 0 Shooting 7.766667 ## 6 0 Shooting 5.566667 For our initial analysis, our primary response variable is the binary variable foul.home. Our hypothesis is that the probability a foul is called on the home team is inversely related to the foul differential; that is, if more fouls have been called on the home team than the visiting team, the next foul is less likely to be on the home team. Our data are measured at multiple levels: Level 1 Observational Unit: Individual fouls Level 1 Explanatory Variables: foul.num, foul.diff, score.diff, lead.home, previous.foul.home, time, Level 2 Observational Unit: Games Level 2 Variables: Home and Visiting Teams We don’t have data on these, but other potentially relevant level 2 variables might include attendance, or teams rankings. Our response variable (whether or not the fouls was on the home team) is a binary variable that might be modeled using logistic regression. We have not yet worked with logistic regression, or other generalized linear models, with multilevel datasets. 8.1.2 Histograms for Level One Covariates Histograms for the continuous Level One covariates (time remaining, foul differential, and score differential). # Summarize Level 1 covariates (and responses) by ignoring # within subject correlation and pretending all observations # are independent time.hist &lt;- ggplot(data = refdata, aes(x = time)) + geom_histogram(binwidth = 2, color = &quot;black&quot;, fill = &quot;white&quot;) + xlab(&quot;Time left in first half&quot;) + ylab(&quot;Frequency&quot;) + labs(title = &quot;(a)&quot;) score.hist &lt;- ggplot(data = refdata, aes(x = score.diff)) + geom_histogram(binwidth = 5, color = &quot;black&quot;, fill = &quot;white&quot;) + xlab(&quot;Score difference (home-visitor)&quot;) + ylab(&quot;Frequency&quot;) + labs(title = &quot;(b)&quot;) foul.hist &lt;- ggplot(data = refdata, aes(x = foul.diff)) + geom_histogram(binwidth = 1.5, color = &quot;black&quot;, fill = &quot;white&quot;) + xlab(&quot;Foul difference (home-visitor)&quot;) + ylab(&quot;Frequency&quot;) + labs(title = &quot;(c)&quot;) Figure 8.1: Histograms showing distributions of the 3 continuous Level One covariates: (a) time remaining, (b) score difference, and (c) foul difference. refdata %&gt;% summarize(Mean_Score_Diff=mean(score.diff), Home_Ahead = mean(score.diff&gt;0), Mean_Foul_Diff = mean(foul.diff), Prop_Fouls_Home=mean(foul.home) ) ## Mean_Score_Diff Home_Ahead Mean_Foul_Diff Prop_Fouls_Home ## 1 2.038013 0.5711987 -0.3596138 0.4794851 On average, the home team is ahead by 2 points averaging across all observations. The home team is ahead in 57% of all observations. 48% of fouls called were against the home team. On average, the home team had 0.35 fewer fouls than the visitor at any given time. 8.1.3 Average Fouls by Team Accounting for the effect of home and visiting team will likely be an important part of our model, since some teams tend to play in games with twice as many fouls called as others, and other teams see a noticeable disparity in the total number of fouls depending on if they are home or away. Home Visitor Difference Team Fouls Team Fouls Team Fouls Top 3 Duke 20.0 WVa 21.4 Duke 4.0 VaTech 19.4 Nova 19.0 Wisc 2.6 Nova 19.1 Wake 18.6 Pitt 2.3 Bottom 3 Mich 10.6 Wisc 10.4 WVa -6.9 Ill 11.6 Mich 11.1 Mia -2.7 MN 12.1 PSU 11.3 Clem -2.6 Lots of fouls are called in games where Duke, VaTech, and Nova are the home team, or when WVa, Nova, or Wake are the away team. Few fouls are called when Mich, Ill, and MN are the home team, or when Wisc, Mich, and PSU are the away team. There are more total fouls called in games where Duke, Wisc, and Pitt are home than when they are away. The opposite is true of WVa, Mia, and Clem. 8.1.4 Examining Bivariate Relationships We begin by observing broad trends involving all 4972 fouls called, even though fouls from the same game may be correlated. The conditional density plots in the first row examine continuous Level One covariates. foul.df &lt;- refdata %&gt;% filter(foul.diff &gt;= -7 &amp; foul.diff &lt;= 5) %&gt;% group_by(foul.diff) %&gt;% summarise(foul.phats = mean(foul.home)) %&gt;% mutate(foul.elogits = log(foul.phats/(1 - foul.phats)) ) score.df &lt;- refdata %&gt;% filter(score.diff &gt;= -11 &amp; score.diff &lt;= 18) %&gt;% group_by(score.diff) %&gt;% summarise(score.phats = mean(foul.home)) %&gt;% mutate(score.elogits = log(score.phats/(1 - score.phats)) ) time.df &lt;- refdata %&gt;% mutate(group = cut(time, breaks = c(-Inf, 2, 4, 6, 8, 10, 12, 14, 16, 18, Inf), labels = c(1, 3, 5, 7, 9, 11, 13, 15, 17, 19))) %&gt;% mutate(times = as.numeric(levels(group))[group]) %&gt;% select(-group) %&gt;% group_by(times) %&gt;% summarise(time.phats = mean(foul.home)) %&gt;% mutate(time.elogits = log(time.phats/(1 - time.phats)) ) refdata &lt;- refdata %&gt;% mutate(foul.factor = as.factor(ifelse(foul.home == 1, &quot;Home&quot;, &quot;Visitor&quot;)) ) foul.cd &lt;- ggplot(data = refdata, aes(x = foul.diff)) + theme(legend.title = element_blank()) + geom_density(aes(fill = foul.factor), position = &quot;fill&quot;, adjust = 2, alpha = 0.5) + xlab(&quot;Foul difference (H-V)&quot;) + ylab(&quot;Probability of Home Foul&quot;) + labs(title=&quot;(a)&quot;) + scale_fill_manual(values = c(&quot;grey20&quot;, &quot;grey80&quot;)) score.cd &lt;- ggplot(data = refdata, aes(x = score.diff)) + theme(legend.title = element_blank()) + geom_density(aes(fill = foul.factor), position = &quot;fill&quot;, adjust = 2, alpha = 0.5) + xlab(&quot;Score difference (H-V)&quot;) + ylab(&quot;Probability of Home Foul&quot;) + labs(title=&quot;(b)&quot;) + scale_fill_manual(values = c(&quot;grey20&quot;, &quot;grey80&quot;)) time.cd &lt;- ggplot(data = refdata, aes(x = time)) + theme(legend.title = element_blank()) + geom_density(aes(fill = foul.factor), position = &quot;fill&quot;, adjust = 2, alpha = 0.5) + xlab(&quot;Time left in half&quot;) + ylab(&quot;Probability of Home Foul&quot;) + labs(title=&quot;(c)&quot;) + scale_fill_manual(values = c(&quot;grey20&quot;, &quot;grey80&quot;)) foul.el &lt;- ggplot(data = foul.df, aes(x = foul.diff, y = foul.elogits)) + geom_point(color=&quot;dark grey&quot;) + xlab(&quot;Foul difference (H-V)&quot;) + ylab(&quot;Empirical Log-odds of Home Foul&quot;) + labs(title = &quot;(d)&quot;) + geom_smooth(se = FALSE, method = &quot;lm&quot;, color = &quot;black&quot;) score.el &lt;- ggplot(data = score.df, aes(x = score.diff, y = score.elogits)) + geom_point(color=&quot;dark grey&quot;) + xlab(&quot;Score difference (H-V)&quot;) + ylab(&quot;Empirical Log-odds of Home Foul&quot;) + labs(title = &quot;(e)&quot;) + geom_smooth(se = FALSE, method = &quot;lm&quot;, color = &quot;black&quot;) time.el &lt;- ggplot(data = time.df, aes(x = times, y = time.elogits)) + geom_point(color=&quot;dark grey&quot;) + xlab(&quot;Time left in half&quot;) + ylab(&quot;Empirical Log-odds of Home Foul&quot;) + labs(title = &quot;(f)&quot;) + geom_smooth(se = FALSE, method = &quot;lm&quot;, color = &quot;black&quot;) Figure 8.2: Conditional density and empirical logit plots of the binary model response (foul called on home or visitor) vs. the three continuous Level One covariates (foul differential, score differential, and time remaining). The dark shading in a conditional density plot shows the proportion of fouls called on the home team for a fixed value of (a) foul differential, (b) score differential, and (c) time remaining. In empirical logit plots, estimated log odds of a home team foul are calculated for each distinct foul (d) and score (e) differential, except for differentials at the high and low extremes with insufficient data; for time (f), estimated log odds are calculated for two-minute time intervals and plotted against the midpoints of those intervals. Figure (a) provides support for our primary hypothesis about evening out foul calls, indicating a very strong trend for fouls to be more often called on the home team at points in the game when more fouls had previously been called on the visiting team. Figures (b) and (c) then show that fouls were somewhat more likely to be called on the home team when the home team’s lead was greater and (very slightly) later in the half. Conclusions from the conditional density plots in Figures (a)-(c) are supported with associated empirical logit plots in Figures (d)-(f). If a logistic link function is appropriate, these plots should be linear, and the stronger the linear association, the more promising the predictor. We see in Figure (d) further confirmation of our primary hypothesis, with lower log-odds of a foul called on the home team associated with a greater number of previous fouls the home team had accumulated compared to the visiting team. Figure (e) shows that game score may play a role in foul trends, as the log-odds of a foul on the home team grows as the home team accumulates a bigger lead on the scoreboard. Figure (f) shows a very slight tendency for greater log-odds of a foul called on the home team as the half proceeds (since points on the right are closer to the beginning of the game). 8.1.5 Tabular Summary by Fouling Team refdata %&gt;% group_by(foul.home) %&gt;% summarize(Mean_foul.diff=mean(foul.diff), Mean_diff=mean(score.diff), Mean_time=mean(time)) ## # A tibble: 2 × 4 ## foul.home Mean_foul.diff Mean_diff Mean_time ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 -0.102 1.41 9.50 ## 2 1 -0.639 2.72 9.23 Conclusions about continuous Level One covariates are further supported by summary statistics calculated separately for fouls called on the home team and those called on the visiting team. For instance, when a foul is called on the home team, there is an average of 0.64 additional fouls on the visitors at that point in the game, compared to an average of 0.10 additional fouls on the visitors when a foul is called on the visiting team. Similarly, when a foul is called on the home team, they are in the lead by an average of 2.7 points, compared to an average home lead of 1.4 points when a foul is called on the visiting team. As expected, the average time remaining in the first half at the time of the foul is very similar for home teams and visitors (9.2 vs. 9.5 minutes, respectively). 8.1.6 Mosaic Plots refdata &lt;- refdata %&gt;% mutate(leadyes = ifelse(lead.home == 0, &quot;No&quot;, &quot;Yes&quot;), prevyes = ifelse(previous.foul.home == 0, &quot;No&quot;, &quot;Yes&quot;)) %&gt;% rename(whofoul = foul.factor) barplot2 &lt;- ggplot(data = refdata) + geom_mosaic(aes(weight = 1, x = product(whofoul, leadyes), fill = whofoul)) + xlab(&quot;Home Team in Lead&quot;) + ylab(&quot;Proportion within Leading Team&quot;) + labs(title = &quot;(a)&quot;) + scale_fill_grey() + theme(legend.title = element_blank()) barplot3 &lt;- ggplot(data = refdata) + geom_mosaic(aes(weight = 1, x = product(whofoul, prevyes), fill = whofoul)) + xlab(&quot;Previous Foul on Home Team&quot;) + ylab(&quot;Proportion within Previous Foul&quot;) + labs(title = &quot;(b)&quot;) + scale_fill_grey() + theme(legend.title = element_blank()) Figure 8.3: Mosaic plots of the binary model response (foul called on home or visitor) vs. the categorical Level One covariates (team in the lead (a), and team called for the previous foul (b)). Each bar shows the percentage of fouls called on the home team vs. the percentage of fouls called on the visiting team for a particular category of the covariate. The bar width shows the proportion of fouls at each of the covariate levels. Fouls were more likely to be called on the home team when the home team was leading, when the previous foul was on the visiting team 8.2 Multilevel Generalized Linear Model 8.2.1 Motivation for a Statistical Model The exploratory analyses presented above are an essential first step in understanding our data, seeing univariate trends, and noting bivariate relationships between variable pairs. However, our important research questions (a) involve the effect of foul differential after adjusting for other significant predictors of which team is called for a foul, (b) account for potential correlation between foul calls within a game (or within a particular home or visiting team), and (c) determine if the effect of foul differential is constant across game conditions. In order to address research questions such as these, we need to consider multilevel, multivariate statistical models for a binary response variable. We’ll begin by modeling the probability of a foul on the home team, using foul difference as the explanatory variable. Let \\(Y_{ij}\\) represent an indicator variable for whether the \\(j\\)th foul in game \\(i\\) was on the home team. That is \\[ Y_{ij} =\\begin{cases} 1 &amp; \\text{if $j$th foul in game $i$ was on home team} \\\\ 0 &amp; \\text{if $j$th foul in game $i$ was on away team } \\end{cases} \\] We assume: \\[ Y_{ij}\\sim\\text{Ber}(p_{ij}) \\] In an ordinary logistic regression model, we would say \\[ \\log\\bigg(\\frac{p_{ij}}{1-p_{ij}}\\bigg)=\\beta_0+\\beta_1\\text{foul.diff}_{ij} \\] 8.2.2 A GLM Approach We fit the logistic regression model in R # Logistic regression model (not multilevel) M0 = glm(foul.home ~ foul.diff, family = binomial, data = refdata) summary(M0) Call: glm(formula = foul.home ~ foul.diff, family = binomial, data = refdata) Deviance Residuals: Min 1Q Median 3Q Max -1.5817 -1.1227 -0.9654 1.1772 1.5225 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -0.13005 0.02912 -4.466 7.98e-06 *** foul.diff -0.13047 0.01426 -9.148 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 6884.3 on 4971 degrees of freedom Residual deviance: 6798.1 on 4970 degrees of freedom AIC: 6802.1 Number of Fisher Scoring iterations: 4 8.2.3 Adding Random Effect for Game The ordinary logistic regression model, treats observations (fouls) as independent. We might expect fouls in the same game to be correlated. To account for this, we’ll add a random effect \\(u_i\\) for games. This gives the link function: \\[ \\log\\bigg(\\frac{p_{ij}}{1-p_{ij}}\\bigg)=\\beta_0+\\beta_1\\text{foul.diff}_{ij} + u_i, \\] where \\(u_i\\sim\\mathcal{N}(0,\\sigma_u^2)\\). 8.2.4 Two Level Logistic Model Let \\(Y_{ij}\\) represent an indicator variable for whether the \\(j\\)th foul in game \\(i\\) was on the home team. That is \\[ Y_{ij} =\\begin{cases} 1 &amp; \\text{if $j$th foul in game $i$ was on home team} \\\\ 0 &amp; \\text{if $j$th foul in game $i$ was on away team } \\end{cases} \\] We assume: \\[ Y_{ij}\\sim\\text{Ber}(p_{ij}) \\] where, \\[ \\log\\bigg(\\frac{p_{ij}}{1-p_{ij}}\\bigg)=\\beta_0+\\beta_1\\text{foul.diff}_{ij} + u_i, \\] and \\(u_i\\sim\\mathcal{N}(0,\\sigma_u^2)\\). 8.2.5 Multilevel GLM in R We fit a multilevel generalized linear model in R using the glmer() function. M1 &lt;- glmer(foul.home ~ foul.diff + (1|game), family = binomial(link=&quot;logit&quot;), data = refdata) summary(M1) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: binomial ( logit ) ## Formula: foul.home ~ foul.diff + (1 | game) ## Data: refdata ## ## AIC BIC logLik deviance df.resid ## 6792.5 6812.1 -3393.3 6786.5 4969 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.6995 -0.9055 -0.6518 0.9655 1.6849 ## ## Random effects: ## Groups Name Variance Std.Dev. ## game (Intercept) 0.273 0.5225 ## Number of obs: 4972, groups: game, 340 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.18886 0.04434 -4.259 2.05e-05 *** ## foul.diff -0.26821 0.03895 -6.887 5.71e-12 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## foul.diff 0.368 Assuming the foul differential is even, the odds of a foul being called on the home team are: \\(e^{-0.18886} = 0.83:1\\) Equivalently, the probability of a foul called going against the home team when the foul differential is even is \\(\\frac{e^{-0.18886}}{1+e^{-0.18886}}\\approx0.45\\). Considering foul differential, for each additional fouls that the home team has, compared to the away team, the odds of the next foul going against the home team multiply by a factor of \\(e^{-0.26821} = 0.76\\), on average. The estimate of \\(\\sigma_u\\) is 0.5225. This is the standard deviation in game level random effects. This is difficult to interpret in a meaningful way. (Why does it not represent the standard deviation in number of fouls called between different games?) Notice that estimates change after accounting for in-game correlation, and standard errors increase. 8.2.6 Add Random Slope The previous model assumes that the effect of foul differential on the probability of the next foul going on the home team is the same across games. We might add a random slope term to allow this effect to vary between games. Model: \\[ Y_{ij}\\sim\\text{Ber}(p_{ij}) \\] where, \\[ \\log\\bigg(\\frac{p_{ij}}{1-p_{ij}}\\bigg)=\\beta_0+\\beta_1\\text{foul.diff}_{ij} + u_i + v_i\\text{foul.diff}_{ij}, \\] and \\[ \\left[ \\begin{array}{c} u_i \\\\ v_i \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{u}^{2} &amp; \\\\ \\sigma_{uv} &amp; \\sigma_{v}^{2} \\end{array} \\right] \\right) \\] 8.2.7 Random Slopes Model in R M2 &lt;- glmer(foul.home ~ foul.diff + (foul.diff|game), family = binomial(link=&quot;logit&quot;), data = refdata) summary(M2) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: binomial ( logit ) ## Formula: foul.home ~ foul.diff + (foul.diff | game) ## Data: refdata ## ## AIC BIC logLik deviance df.resid ## 6791.1 6823.6 -3390.5 6781.1 4967 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.6399 -0.9087 -0.6349 0.9528 1.7687 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## game (Intercept) 0.294144 0.54235 ## foul.diff 0.001235 0.03514 -1.00 ## Number of obs: 4972, groups: game, 340 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.15684 0.04637 -3.382 0.000719 *** ## foul.diff -0.28533 0.03835 -7.440 1.01e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## foul.diff 0.192 ## optimizer (Nelder_Mead) convergence code: 0 (OK) ## boundary (singular) fit: see help(&#39;isSingular&#39;) 8.2.8 AIC, BIC Comparison AIC(M1) ## [1] 6792.54 AIC(M2) ## [1] 6791.072 BIC(M1) ## [1] 6812.075 BIC(M2) ## [1] 6823.63 It’s not clear that adding the random slope makes much difference or is warranted. 8.2.9 Random Error Terms \\[ Y_{ij} =\\begin{cases} 1 &amp; \\text{if $j$th foul in game $i$ was on home team} \\\\ 0 &amp; \\text{if $j$th foul in game $i$ was on away team } \\end{cases} \\] We assume: \\[ Y_{ij}\\sim\\text{Ber}(p_{ij}) \\] where, \\[ \\log\\bigg(\\frac{p_{ij}}{1-p_{ij}}\\bigg)=\\beta_0+\\beta_1\\text{foul.diff}_{ij} + u_i, \\] and \\(u_i\\sim\\mathcal{N}(0,\\sigma_u^2)\\). Thought Question Why is there no \\(\\epsilon_{ij}\\) term in the link function? 8.3 Crossed Random Effects 8.3.1 Random Effects for Teams Our exploratory analysis showed evidence that the probability a foul is called on the home team changes if we know precisely who the home and visiting teams are. However, if we were to include an indicator variable for each distinct team, we would need 38 indicator variables for home teams and 38 more for visiting teams. This complicates the model and gives a lot of estimates we don’t really care about (since we’re not interested in comparing individual teams). It also means spending 38 degrees of freedom, which reduces precision of intervals and power of tests. Instead, we can treat home and away team as random effects. 8.3.2 Crossed vs Nested Random Effects Besides the fact that our response variable is binary, there’s a fundamental difference in the nature of this model compared to prior random effects models we’ve seen. Recall previous random effects models we’ve seen. For example, the plants in pots and trays. In that study, we used random effects for trays, and for pots, but an individual pot could only be within one tray. Thus, all plants in the same pot were necessarily in the same tray. This is an example of nested random effects. All other random effects models we’ve seen to this point have involved nested random effects. By contrast, the same home team (an visiting team), appears in different games. Thus, the random effect for team is not nested within games. Game, home team, and visiting team are all level two variables, and none is nested in another. These are examples of crossed random effects. 8.3.3 Models for Crossed Random Effects When using notation like \\(Y_{ijk}\\), we’re used to having the observational unit indexed by \\(k\\) nested within the observational unit indexed by \\(j\\), which is in turn nested within the observational unit indexed by \\(i\\). We need a new notation to make sense of crossed random effects. Let \\(Y_{i[vh]j}\\) denote the \\(j\\) foul in the \\(i\\)th game involving visiting team \\(v\\) and home team \\(h\\). We list \\(v\\) and \\(h\\) after \\(i\\), since they are on the same level as game, but place them inside brackets. Then, \\[ Y_{i[vh]j}\\sim\\text{Ber}(p_{i[vh]j}) \\] where, \\[ \\log\\bigg(\\frac{p_{i[vh]j}}{1-p_{i[vhj}}\\bigg)=\\beta_0+\\beta_1\\text{foul.diff}_{ij} + u_i + w_h+z_v. \\] We assume that the error terms are independent and normally distributed. \\(u_i\\sim\\mathcal{N}(0,\\sigma_u^2), w_h\\sim\\mathcal{N}(0,\\sigma_w^2), z_v\\sim\\mathcal{N}(0,\\sigma_z^2)\\). \\(\\beta_{0}\\) is the average log odds of a foul on the home team when the foul differential is 0 (fixed) \\(\\beta_{0}\\) is the average multiplicative increase in log odds of the next foul being on the home team, for every additional one foul differential in the home team’s favor \\(u_{i}\\) is the effect of Game \\(i\\) (random) \\(w_{h}\\) is the effect of Home Team \\(h\\) (random) \\(z_{v}\\) is the effect of Visiting Team \\(v\\) (random) 8.3.4 Fitting Model with Crossed Random Effects in R M3 &lt;- glmer(foul.home ~ foul.diff + (1|game) + (1|hometeam) + (1|visitor), family = binomial(link=&quot;logit&quot;), data = refdata) summary(M3) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: binomial ( logit ) ## Formula: foul.home ~ foul.diff + (1 | game) + (1 | hometeam) + (1 | visitor) ## Data: refdata ## ## AIC BIC logLik deviance df.resid ## 6780.5 6813.0 -3385.2 6770.5 4967 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.6589 -0.9056 -0.6522 0.9679 1.7952 ## ## Random effects: ## Groups Name Variance Std.Dev. ## game (Intercept) 0.17164 0.4143 ## hometeam (Intercept) 0.06809 0.2609 ## visitor (Intercept) 0.02323 0.1524 ## Number of obs: 4972, groups: game, 340; hometeam, 39; visitor, 39 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.18780 0.06331 -2.967 0.00301 ** ## foul.diff -0.26385 0.03883 -6.795 1.09e-11 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## foul.diff 0.256 Interpretations \\(\\hat{\\alpha}_{0}=-0.188=\\) the mean log odds of a home foul at the point where total fouls are equal between teams. In other words, when fouls are balanced between teams, the probability that a foul is called on the visiting team (.547) is 20.7% (\\(1/e^{-.188}=1.207\\)) higher than the probability a foul is called on the home team (.453). \\(\\hat{\\beta}_{0}=-0.264=\\) the decrease in mean log odds of a home foul for each 1 foul increase in the foul differential. More specifically, the odds the next foul is called on the visiting team rather than the home team increases by 30.2% with each additional foul called on the home team (\\(1/e^{-.264}=1.302\\)). \\(\\hat{\\sigma}_{u}^{2}=0.172=\\) the variance in log odds of foul going against home team from game-to-game. \\(\\hat{\\sigma}_{w}^{2}=0.068=\\) the variance in log odds of foul going against home team among different home teams. \\(\\hat{\\sigma}_{z}^{2}=0.023=\\) the variance in log odds of foul going against home team among different visiting teams. Based on the t-value (-6.80) and p-value (\\(p&lt;.001\\)) associated with foul differential in this model, we have significant evidence of a negative association between foul differential and the odds of a home team foul. That is, we have significant evidence that the odds that a foul is called on the home team shrinks as the home team has more total fouls compared with the visiting team. Thus, there seems to be preliminary evidence in the 2009-2010 data that college basketball referees tend to even out foul calls over the course of the first half. Of course, we have yet to adjust for other significant covariates. An estimated 65.4% of variability in the log odds of foul going against home team is due to differences from game-to-game, while 25.9% is due to differences among home teams, and 8.7% is due to differences among visiting teams. 8.3.5 More on Crossed Effects Although this was the only time we saw crossed random effects in this course, they are not unique to models with a binomial response. They could have come up in the linear mixed effects models we considered in the first half of the course. 8.3.6 A Final Model for Examining Referee Bias Section 11.7 in the Roback and Legler text provides a potential final model that accounts for score differential, time remaining, type of foul, and other potentially relevant covariates. Among their conclusions, the authors write “In general, we see a highly significant negative effect of foul differential—a strong tendency for referees to even out foul calls when one team starts amassing more fouls than the other. Important covariates to control for (because of their effects on the odds of a home foul) include score differential, whether the home team held the lead, time left in the first half, and the type of foul called.” 8.4 Parametric Bootstrapping 8.4.1 When and Why to Bootstrap The maximum likelihood estimates, confidence intervals, and hypothesis tests that we’ve obtained throughout the class have been based on statistical theory telling us things like: In LLSR and linear mixed effects models, regression coefficients follow \\(t\\)-distributions. In generalized linear regresson models, when the sample size is large, regression coefficients are approximately normally distributed. Likelihood ratio based tests (like drop-in-deviance tests) follow \\(\\chi^2\\) distributions (or F-distributions for models based on quaasilikelihood). All of these are based on model assumptions, as well as “large-sample” theory which will never be exactly true, but are often reasonable approximations. If we have doubts about model assumptions, like normality, or if our sample size is not that big, we might instead use a simulation-based method to calculate p-values and confidence intervals. A popular simulation-based approach is the parametric bootstrap. This is different than the bootstrapping procedude we learned in Stat 255, which is actually called the non-parametric bootstrap. 8.4.2 Parametric Bootstrap Procedure Fit the model to the actual data to estimate all parameters (\\(\\beta\\)’s, \\(\\sigma\\)’s, etc.) Simulate many datasets from model using estimated parameter values. For each simulated dataset, estimate parameters using simulated data. Calculate relevant statistics (t-statistics, F-statistics, Likelihood ratio’s, etc.) Form confidence intervals using distribution of simulated values. 8.4.3 A Simple Example We’ll start with a simple example, using a LLSR model. Recall the Kentucky Derby Example in Chapter 1 of the notes. We used a LSSR model to model a horse’s winning speed, with year (since) 1896 as the explanatory variable. derby.df &lt;- read.csv(&quot;https://raw.githubusercontent.com/proback/BeyondMLR/master/data/derbyplus.csv&quot;) derby.df &lt;- derby.df %&gt;% mutate( fast = ifelse(condition==&quot;fast&quot;,1,0), good = ifelse(condition==&quot;good&quot;,1,0), yearnew = year - 1896, fastfactor = ifelse(fast == 0, &quot;not fast&quot;, &quot;fast&quot;)) Fit the model to the actual data to estimate all parameters (\\(\\beta\\)’s, \\(\\sigma\\)’s, etc.) M &lt;- lm(speed ~ yearnew, data = derby.df) summary(M) Call: lm(formula = speed ~ yearnew, data = derby.df) Residuals: Min 1Q Median 3Q Max -3.08190 -0.50026 0.07387 0.67367 1.68720 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 51.588393 0.162549 317.37 &lt;2e-16 *** yearnew 0.026126 0.002322 11.25 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.9032 on 120 degrees of freedom Multiple R-squared: 0.5134, Adjusted R-squared: 0.5093 F-statistic: 126.6 on 1 and 120 DF, p-value: &lt; 2.2e-16 Simulate many datasets from model using estimated parameter values, and For each simulated dataset, estimate parameters using simulated data. # record estimates from the model b0 &lt;- M$coefficients[1] b1 &lt;- M$coefficients[2] sigma &lt;- summary(M)$sigma nreps &lt;- 10000 bootstrap_b0 &lt;- c(rep(NA, nreps)) bootstrap_b1 &lt;- c(rep(NA, nreps)) bootstrap_sigma &lt;- c(rep(NA, nreps)) B_Data &lt;- derby.df # simulate data and fit model for (i in 1:nreps){ # simulate new data B_Data &lt;- B_Data %&gt;% mutate(SimSpeed = b0 + b1*yearnew + rnorm(n= nrow(derby.df), mean=0, sd=sigma)) Mb &lt;- lm(data=B_Data, SimSpeed~yearnew) #fit model to simulated data bootstrap_b0[i] &lt;- Mb$coefficients[1] #record b0 from model on simulated data bootstrap_b1[i] &lt;- Mb$coefficients[2] #record b1 from model on simulated data bootstrap_sigma[i] &lt;- summary(Mb)$sigma #record sigma from model on simulated data } Bootstrap_Results &lt;- data.frame(bootstrap_b0, bootstrap_b1, bootstrap_sigma) Calculate relevant statistics (t-statistics, F-statistics, Likelihood ratio’s, etc.) Form confidence intervals using distribution of simulated values. 8.4.4 Parametric Bootstrap Confidence Intervals p1 &lt;- ggplot(data=Bootstrap_Results, aes(x=bootstrap_b0)) + geom_histogram() + geom_vline(xintercept=quantile(bootstrap_b0, c(.025, .975)), color=&quot;red&quot;) p1 quantile(bootstrap_b0, c(.025, .975)) ## 2.5% 97.5% ## 51.26868 51.91032 p2 &lt;- ggplot(data=Bootstrap_Results, aes(x=bootstrap_b1)) + geom_histogram() + geom_vline(xintercept=quantile(bootstrap_b1, c(.025, .975)), color=&quot;red&quot;) p2 quantile(bootstrap_b1, c(.025, .975)) ## 2.5% 97.5% ## 0.02163246 0.03069958 p3 &lt;- ggplot(data=Bootstrap_Results, aes(x=bootstrap_sigma)) + geom_histogram() + geom_vline(xintercept=quantile(bootstrap_sigma, c(.025, .975)), color=&quot;red&quot;) p3 quantile(bootstrap_sigma, c(.025, .975)) ## 2.5% 97.5% ## 0.7903002 1.0182309 Theory-Based intervals (based on t-distribution) confint(M) ## 2.5 % 97.5 % ## (Intercept) 51.26655655 51.91022874 ## yearnew 0.02152859 0.03072344 Thought Question: How is this approach to bootstrapping different than the non-parametric bootstrap we saw in 3.5.8 in the Stat 255 notes? What assumption does the parametric bootstrap make that the non-parameteric bootstrap doesn’t? 8.4.5 Model Comparison Tests with Parametric Bootstrap The distributions of ANOVA F-statistics and other likelihood-ratio-based test statistics for model comparison are vulnerable to deviations from model assumptions. When the assumptions are not valid, these stistics may not follow the distributions they are supposed to (F, \\(\\chi^2\\)), etc. We can use parametric bootstrapping to approximate the null distribution of these statistics in such situations. Process: Fit full and reduced models and calculate relevant statistic (F-statistic, LRT statistic, etc.) Simulate many datasets from the reduced model using estimated parameter values. For each simulated dataset, fit the reduced model and full model. Calculate statistic for model comparison (F-statistics, Likelihood ratio’s, etc.) on the models fit to the simulated data. Look at where the statistic from the actual data (calculated in (1)) lies, relative to those calculated from the simulated data in (4). (Thought question: Under what assumption were these data simulated?). The simulation-based p-value is the proportion of simulated statistics as extreme or more extreme as the one we observed. 8.4.6 Model Comparison for Kentucky Derby Data M_Red &lt;- lm(speed ~ yearnew, data = derby.df) M_Full &lt;- lm(speed ~ yearnew + fast + yearnew:fast, data=derby.df) anova(M_Red, M_Full) ## Analysis of Variance Table ## ## Model 1: speed ~ yearnew ## Model 2: speed ~ yearnew + fast + yearnew:fast ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 120 97.899 ## 2 118 58.991 2 38.908 38.914 1.048e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The observed F-statistic is 38.914. The associated p-value was calculated from an F-distribution with 2 and 118 df. If we have concerns about model assumptions, especially normality, the F-statistic might not really follow this F-distribution. 8.4.7 Code for Boostrap Model Comparison We’ll simulate the distribution of the F-statistic, using the parametric bootstrap. set.seed(02272022) # record estimates from reduced model b0 &lt;- M_Red$coefficients[1] b1 &lt;- M_Red$coefficients[2] sigma &lt;- summary(M_Red)$sigma nreps &lt;- 10000 bootstrap_F &lt;- c(rep(NA, nreps)) B_Data &lt;- derby.df # simulate data and fit model for (i in 1:nreps){ # simulate new data from reduced model B_Data &lt;- B_Data %&gt;% mutate(SimSpeed = b0 + b1*yearnew + rnorm(n= nrow(derby.df), mean=0, sd=sigma)) Mb_Red &lt;- lm(data=B_Data, SimSpeed~yearnew) #fit reduced model to simulated data Mb_Full &lt;- lm(data=B_Data, SimSpeed ~ yearnew + fast + yearnew:fast) #fit full model to simulated data bootstrap_F[i] &lt;- anova(Mb_Full, Mb_Red)$F[2] } Bootstrap_Results &lt;- data.frame(bootstrap_F) 8.4.8 Simulation-Based F-Test p1 &lt;- ggplot(data=Bootstrap_Results, aes(x=bootstrap_F)) + geom_histogram() + geom_vline(xintercept = 38.914, color=&quot;red&quot;, linetype=&quot;dotted&quot;, size=2) p1 mean(bootstrap_F&gt;38.914) ## [1] 0 None of our simulations produced a F-statistic even close to the one we observed in our actual data. There is virtually no chance we would have obtained an F-statistic as large as we saw in the data by chance, if the reduced model was really appropriate. We have strong evidence that the full model is a better fit. This is consistent with the theory-based F-test. 8.4.9 Model Comparison in Multilevel GLM M1 &lt;- glmer(foul.home ~ foul.diff + (1|game), family = binomial(link=&quot;logit&quot;), data = refdata) M2 &lt;- glmer(foul.home ~ foul.diff + (foul.diff|game), family = binomial(link=&quot;logit&quot;), data = refdata) anova(M1, M2) ## Data: refdata ## Models: ## M1: foul.home ~ foul.diff + (1 | game) ## M2: foul.home ~ foul.diff + (foul.diff | game) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## M1 3 6792.5 6812.1 -3393.3 6786.5 ## M2 5 6791.1 6823.6 -3390.5 6781.1 5.4682 2 0.06495 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The \\(\\chi^2\\) statistic of 5.4682 and fairly small p-value provide some evidence in favor of the larger model. Research has shown that when estimates of variance and covariance of random effects are impacted by boundary constraints, “theory-based” tests like the \\(\\chi^2\\) test used here are too conservative and produce higher p-values than they should. 8.4.10 Multilevel GLM Bootstrap Code Fitting the model manually gets complicated. The drop and simulate functions in the lme4 package do this automatically. We’ll simulate data from the reduced model, fit both models, and calculate the \\(\\chi^2\\) statistic, and repeat this 1,000 times. This establishes a bootstrap distribution for where we would expect this statistic to lie if the reduced model is actually “correct”. # This takes a LONG time to run! set.seed(02272022) nreps &lt;- 1000 ChiSq &lt;- rep(NA, nreps) for(i in 1:nreps){ SimData &lt;- drop(simulate(M1)) # this command simulates data directly from a model M1B &lt;-refit(M1, newresp=SimData) # refits M1 to simulated data M2B &lt;-refit(M2, newresp=SimData) # refits M2 to simulated data ChiSq[i] &lt;- anova(M1B,M2B)$Chisq[2] } ChiSq&lt;- write.csv(ChiSq, file=&quot;ChiSq.csv&quot;) 8.4.11 Simulation-Based \\(\\chi^2\\) Test p &lt;- ggplot(data=data.frame(ChiSq), aes(x=ChiSq)) + geom_histogram() + geom_vline(xintercept = 5.4682, color=&quot;red&quot;, linetype=&quot;dotted&quot;, size=2) p mean(ChiSq&gt;5.4682) ## [1] 0.037 The simulation-based p-value is 0.037. This is slightly smaller than the one based on the Chi-sqare distribution. Research has shown that when boundary constraints are an issue in estimating variance and correlation of random effects, “thory-based” tests are too conservative, and often yield p-values that are higher than they should be. Our results are consistent with this observation. "],["epilogue.html", "Chapter 9 Epilogue 9.1 Further Directions", " Chapter 9 Epilogue 9.1 Further Directions library(tidyverse) library(gridExtra) 9.1.1 More on GLM’s A generalized linear model consists of the following two pieces. A distribution for the response variable, given value(s) of explanatory variables. A link function expressing parameters associated with that distribution as a linear function of the explanatory variables. We’ve seen GLM’s using normal, Poisson, and binomial distributions. There are many other distribtions we could use to model the response variable, given value(s) of explanatory variables. Three such continuous distributions, and one discrete one are shown below. For each distribution, we would need to find an appropriate link function to connect parameters to a linear function of the explanatory variables. A possible (often advantageous) link function can be derived using calculus. See [Chapter 5 of the Roback and Legler text] (https://bookdown.org/roback/bookdown-BeyondMLR/ch-glms.html#generalized-linear-modeling) for details. In fact, the link functions we’ve seen are canonical links, but these are not the only possible link functions. 9.1.2 Models Beyond GLM’s We’ve also seen models that account for correlation between observations. There are other kinds of models that account for correlation arising from specific types of experimental designs. There is also considerable theory supporting the approaches we’ve used in this class. Here are some topics that build off of those we’ve discussed and relevant references for future reading. The field of spatial statistics is concerned with modeling correlation arising from observations being location in spatial proximity to each other. A good reference is Spatial Statistics and Modeling by Gaeton and Guyon. Time series analysis pertains to studying correlation between observations taken on the same units over time. The AR-1 model that we looked at briefly is an example of a basic time series model. One reference on time series is Time Series Analysis and Its Applications by Shumway and Stoffer Survival analysis is the branch of statistics associated with modeling the amount of time until an event occurs. For example, survival after being diagnosed with a disease. See Survival Analysis by Kleinbaum and Klein for more information. Designing experiments carefully allows a researcher to collect data in a way that leads to more precise estimation. Design and Analysis of Experiments by Montgomery provides a good introduction, and [Design of Analysis] (https://www.amazon.com/Design-Experiments-Introduction-Chapman-Statistical/dp/1584889233) by Morris offers a more advanced look. Linear algebra lies at the heart of statistical modeling. Each model is associated with an underlying “design” matrix. Estimates of model parameters and their distributions are derived using theory about these matrices. See Applied Linear Regression Models by Kutner et al. for an introduction to linear model theory, and [Linear Model Theory])(https://link.springer.com/book/10.1007/978-3-030-52063-2) by Zimmerman for a more advanced look. 9.1.3 Statistics Courses at Lawrence Most of you have already taken CMSC/STAT 205, and STAT 255. CMSC/STAT 208, Machine Learning, presents a very different focus than this course, focused on making accurate predictions, using modern, often computer-intensive approaches, rather than the kinds of statistical models we’ve seen in this class. MATH 340, Probability, studies the theory of random variables and probability distributions often used in statistics, such as binomial, normal, Poisson, etc. (Prerequisites: MATH 200 and 230) STAT 445, Mathematical Statistics, offers mathematical theory supporting our approaches point estimation and testing, such maximum likelihood, ANOVA and likelihood ratio tests, etc. (Prerequisite: MATH 340) STAT 450, Bayesian Statistics, examines a popular alternative to the classical “frequentist” approach to statistics by starting with a “prior belief” and updating it based on data we observe. (Prerequisite: MATH 340) Other departments, (Biology, Economics, Government, Psychology, among others) offer courses associated with analyzing data that arise in those fields. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
