[["index.html", "Stat 455: Advanced Statistical Modeling Notes Preface", " Stat 455: Advanced Statistical Modeling Notes 2022-01-14 Preface These notes are written to accompany the text Beyond Multiple Linear Regression by Roback and Legler. Much of the text is either directly from the book, or lightly modified/summarized. Most of the code originates from the book's Github repository. These notes will guide our lectures and class discussion, but they are not sufficient as a stand-alone reference. It is important to complete the reading assignments from the full text by Roback and Legler in addition to studying these notes. "],["review-of-multiple-linear-regression.html", "Chapter 1 Review of Multiple Linear Regression 1.1 Exploratory Data Analysis 1.2 Simple Linear Regression Model 1.3 Multiple Linear Regression with Two Predictors 1.4 Building a Multiple Linear Regression Model", " Chapter 1 Review of Multiple Linear Regression This chapter provides an outline of Sections 1.4-1.7 of Beyond Multiple Linear Regression by Roback and Legler. Much of the text is either directly from the book, or lightly modified/summarized. Most of the code originates from the book's Github repository. knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, fig.height = 3, fig.width = 6) # Packages required for Chapter 1 library(knitr) library(gridExtra) library(GGally) library(kableExtra) library(jtools) library(rsample) library(broom) library(tidyverse) 1.1 Exploratory Data Analysis 1.1.1 Kentucky Derby Data We use data from the Kentucky Derby, a 1.25 mile race run annually at Churchill Downs race track in Louisville, Kentucky. Our data set derbyplus.csv contains data from 1896-2017, and includes the following variables: year of the race, winning horse (winner), condition of the track (fast, good, slow) , average speed (in feet per second) of the winner, number of starters (horses who raced) We would like to use least squares linear regression techniques to model the speed of the winning horse as a function of track condition, field size, and trends over time. derby.df &lt;- read.csv(&quot;https://raw.githubusercontent.com/proback/BeyondMLR/master/data/derbyplus.csv&quot;) head(derby.df) ## year winner condition speed starters ## 1 1896 Ben Brush good 51.66 8 ## 2 1897 Typhoon II slow 49.81 6 ## 3 1898 Plaudit good 51.16 4 ## 4 1899 Manuel fast 50.00 5 ## 5 1900 Lieut. Gibson fast 52.28 7 ## 6 1901 His Eminence fast 51.66 5 1.1.2 Some Data Wrangling We modify the data to create: * indicator (0-1) variables for whether the track was in fast or good condition * a factor variable (fastfactor) telling whether or not the track was fast * a variable giving years since 1896 (yearnew) derby.df &lt;- derby.df %&gt;% mutate( fast = ifelse(condition==&quot;fast&quot;,1,0), good = ifelse(condition==&quot;good&quot;,1,0), yearnew = year - 1896, fastfactor = ifelse(fast == 0, &quot;not fast&quot;, &quot;fast&quot;)) table1 &lt;- derby.df %&gt;% filter(row_number() &lt; 6 | row_number() &gt; 117) kable(table1, booktabs=T,caption=&quot;The first five and the last five observations from the Kentucky Derby case study.&quot;) %&gt;% kable_styling(latex_options = &quot;scale_down&quot;) Table 1.1: The first five and the last five observations from the Kentucky Derby case study. year winner condition speed starters fast good yearnew fastfactor 1896 Ben Brush good 51.66 8 0 1 0 not fast 1897 Typhoon II slow 49.81 6 0 0 1 not fast 1898 Plaudit good 51.16 4 0 1 2 not fast 1899 Manuel fast 50.00 5 1 0 3 fast 1900 Lieut. Gibson fast 52.28 7 1 0 4 fast 2013 Orb slow 53.71 19 0 0 117 not fast 2014 California Chrome fast 53.37 19 1 0 118 fast 2015 American Pharoah fast 53.65 18 1 0 119 fast 2016 Nyquist fast 54.41 20 1 0 120 fast 2017 Always Dreaming fast 53.40 20 1 0 121 fast 1.1.3 Univariate Graphical Summaries Distributions of winning speeds and number of starters # EDA graphs speed_hist &lt;- ggplot(data = derby.df, aes(x = speed)) + geom_histogram(binwidth = 0.5, fill = &quot;white&quot;, color = &quot;black&quot;) + xlab(&quot;Winning speed (ft/s)&quot;) + ylab(&quot;Frequency&quot;) + labs(title=&quot;(a)&quot;) starters_hist &lt;- ggplot(data = derby.df, aes(x = starters)) + geom_histogram(binwidth = 3, fill = &quot;white&quot;, color = &quot;black&quot;) + xlab(&quot;Number of starters&quot;) + ylab(&quot;Frequency&quot;) + labs(title=&quot;(b)&quot;) grid.arrange(speed_hist, starters_hist, ncol = 2) Figure 1.1: Histograms of key continuous variables. Plot (a) shows winning speeds, while plot (b) shows the number of starters. 1.1.4 Bivariate Graphical Summaries The ggpairs function creates a scatterplot matrix displaying relationships between all pairs of variables. gg &lt;- ggpairs(data = derby.df, columns = c(&quot;condition&quot;, &quot;year&quot;, &quot;starters&quot;, &quot;speed&quot;)) gg Figure 1.2: Relationships between pairs of variables in the Kentucky Derby data set. We see evidence of higher speeds on fast tracks and also a tendency for recent years to have more fast conditions. We examine how winning speeds have changed over time, when the track is fast and when it is not fast. # Coded scatterplot ggplot(derby.df, aes(x = year, y = speed, colour = fastfactor)) + geom_point(aes(shape = fastfactor)) + geom_smooth(aes(linetype = fastfactor), method = lm, se = FALSE) Figure 1.3: Linear trends in winning speeds over time, presented separately for fast conditions vs. good or slow conditions. It appears that winning speeds have increased more rapidly for tracks that are not fast. This suggests an interaction between year and track condition, since the relationship between speed and year appears to differ depending on whether or not the track was fast. 1.2 Simple Linear Regression Model 1.2.1 Model for Winning Time and Year We begin with a simple linear regression model for winning speed (\\(Y\\)), using year since 1896 as the explanatory variable. This model has the form: \\[\\begin{equation} Y_{i}=\\beta_{0}+\\beta_{1}\\textrm{Yearnew}_{i}+\\epsilon_{i} \\quad \\textrm{where} \\quad \\epsilon_{i}\\sim \\textrm{N}(0,\\sigma^2). \\end{equation}\\] We obtain estimates of \\(\\beta_0\\) and \\(\\beta_1\\), denoted (\\(\\hat{\\beta_0}\\) and \\(\\hat{\\beta_1}\\)) by minimizing the sum of squared residuals \\(SSR=\\displaystyle\\sum_{i=1}^{n}\\left(Y_i- (\\beta_{0}+\\beta_{1}\\textrm{Yearnew}_{i})\\right)^2.\\) 1.2.2 First Model R Output We fit the model in R. model2 &lt;- lm(speed ~ yearnew, data = derby.df) coef(summary(model2)) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 51.58839264 0.162549197 317.37095 2.474501e-177 ## yearnew 0.02612601 0.002322013 11.25145 1.716806e-20 cat(&quot; R squared = &quot;, summary(model2)$r.squared, &quot;\\n&quot;, &quot;Residual standard error = &quot;, summary(model2)$sigma) ## R squared = 0.5133724 ## Residual standard error = 0.9032317 Interpretations: The expected winning speed in 1896 is 51.59 ft/s. Winning speed is expected to increase by 0.026 ft./s on average for each year since 1896. The low p-value provides evidence that average winning speed has increased over time. 51% of the total variability in winning speed is explained by the simple linear regression model with year since 1896 as the explanatory variable. We estimate that the error standard deviation \\(\\sigma\\) is 0.90. 1.2.3 Checking Model Assumptions # Residual diagnostics for Model 2 par(mar=c(4,4,4,4)) par(mfrow=c(2,2)) plot(model2) Figure 1.4: Residual plots for Model 2. par(mfrow=c(1,1)) The residual plots help tell us what trends/relationships our model is missing, or leaving unexplained. The upper left plot, Residuals vs. Fitted, can be used to check the Linearity assumption. Residuals should be patternless around Y = 0; if not, there is a pattern in the data that is currently unaccounted for. The upper right plot, Normal Q-Q, can be used to check the Normality assumption. Deviations from a straight line indicate that the distribution of residuals does not conform to a theoretical normal curve. The lower left plot, Scale-Location, can be used to check the Equal Variance assumption. Positive or negative trends across the fitted values indicate variability that is not constant. The lower right plot, Residuals vs. Leverage, can be used to check for influential points. Points with high leverage (having unusual values of the predictors) and/or high absolute residuals can have an undue influence on estimates of model parameters. There is typically no residual plot, to evaluate the Independence assumption. Evidence for lack of independence comes from knowing about the study design and methods of data collection. In this case, with a new field of horses each year, the assumption of independence is pretty reasonable. In this case, the Residuals vs. Fitted plot indicates that a quadratic fit might be better than the linear fit of Model 2; other assumptions look reasonable. 1.2.4 Quadratic Term for Year Let's add a quadratic term to the model \\[\\begin{equation*} Y_{i}=\\beta_{0}+\\beta_{1}\\textrm{Yearnew}_{i}+\\beta_{2}\\textrm{Yearnew}^2_{i}+\\epsilon_{i}\\quad \\textrm{where}\\quad \\epsilon_{i}\\sim \\textrm{N}(0,\\sigma^2). \\end{equation*}\\] 1.2.5 Quadratic Model in R derby.df &lt;- mutate(derby.df, yearnew2 = yearnew^2) model2q &lt;- lm(speed ~ yearnew + yearnew2, data = derby.df) coef(summary(model2q)) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 50.5874565658 2.081705e-01 243.009695 2.615174e-162 ## yearnew 0.0761728163 7.950413e-03 9.580989 1.838874e-16 ## yearnew2 -0.0004136099 6.358703e-05 -6.504628 1.920684e-09 cat(&quot; R squared = &quot;, summary(model2q)$r.squared, &quot;\\n&quot;, &quot;Residual standard error = &quot;, summary(model2q)$sigma) ## R squared = 0.6410103 ## Residual standard error = 0.7790385 # Fitted models for Model 2 and Model 2Q ggplot(derby.df, aes(x = year, y = speed)) + geom_point() + stat_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, linetype = 1) + stat_smooth(method = &quot;lm&quot;, formula = y ~ x + I(x^2), se = FALSE, linetype = 2) Figure 1.5: Linear (solid) vs. quadratic (dashed) fit. This model suggests that the rate of increase in winning speeds is slowing down over time. The low p-value on the quadratic term provides evidence that there is indeed a quadratic relationship between speed and year (as opposed to a linear one). Furthermore, the proportion of variation in winning speeds explained by the model has increased from 51.3% to 64.1%. 1.2.6 Quadratic Model Residual Plots # Residual diagnostics for Model 2 par(mar=c(4,4,4,4)) par(mfrow=c(2,2)) plot(model2q) Figure 1.6: Residual plots for Model 2Q. par(mfrow=c(1,1)) The quadratic trend in the residual vs fitted plot has disappeared, as the quadratic relationship is now explained in our model. 1.3 Multiple Linear Regression with Two Predictors 1.3.1 Model with Year and Fast Track We add an indicator variable for whether or not the track is fast in our model. Note that the text writes an indicator using the name of the 0-1 categorical variable, as opposed to the \\(\\text{I}_{\\text{Fast}}\\) notation I used in STAT 255. \\[ \\begin{equation} Y_{i}=\\beta_{0}+\\beta_{1}\\textrm{Yearnew}_{i}+\\beta_{2}\\textrm{Fast}_{i}+\\epsilon_{i}\\quad \\textrm{where}\\quad \\epsilon_{i}\\sim \\textrm{N}(0,\\sigma^2). \\end{equation} \\] 1.3.2 Multiple Regression Model in R model4 &lt;- lm(speed ~ yearnew + fast, data = derby.df) coef(summary(model4)) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 50.91782155 0.154601703 329.348388 5.360308e-178 ## yearnew 0.02258276 0.001918849 11.768907 1.116763e-21 ## fast 1.22684588 0.150721259 8.139833 4.393084e-13 cat(&quot; R squared = &quot;, summary(model4)$r.squared, &quot;\\n&quot;, &quot;Residual standard error = &quot;, summary(model4)$sigma) ## R squared = 0.6874141 ## Residual standard error = 0.7269468 Interpretations: winning speeds are, on average, 1.23 ft/s faster under fast conditions after accounting for time trends (i.e. assuming year is held constant). The low p-value provides evidence that winning speeds increase over time, after accounting for track condition. winning speeds are expected to increase by 0.023 ft/s per year, after accounting for track condition. The low p-value provides evidence that winning speeds are faster when the track is in fast condition, after accounting for year. This yearly effect is also smaller than the 0.026 ft/s per year we estimated the previous model, that did not account for track condition. The single-variable model appears to have slightly overestimated the average increase in speed. This is probably because track conditions have also improved over time (due to improvements in track maintenence). The single variable model cannot distinguish between improvements in track conditions and improvements in speed of the horses. The multiple regression model can estimate these effects separately. Based on the \\(R^2\\) value, Model 4 explains 68.7% of the year-to-year variability in winning speeds, a noticeable increase over using either explanatory variable alone. 1.3.3 Confidence Intervals from MLR Model Confidence Intervals for \\(\\beta_0, \\beta_1, \\beta_2\\). Under LINE assumptions, a confidence interval for \\(\\beta_j\\) is given by \\(\\hat{\\beta_j} \\pm t_{(n-p), (1-\\alpha/2)}^* \\text{SE}(\\beta_j)\\), where \\(t_{(n-p), (1-\\alpha/2)}^*\\) represents the \\((1-\\alpha/2)\\) quantile of a t-distribution with \\(n-p\\) degrees of freedom, \\(\\alpha\\) represents the level of significance (e.g. 0.05 for a 95% CI), and \\(p\\) represents the number of parameters \\(\\beta_0, \\beta_1, \\ldots...\\) confint(model4) ## 2.5 % 97.5 % ## (Intercept) 50.61169473 51.22394836 ## yearnew 0.01878324 0.02638227 ## fast 0.92840273 1.52528902 Interpretations: We can be 95% confident that average winning speeds increase between 0.019 and 0.026 ft/s each year, after accounting for track condition. We can be 95% confident that average winning speeds under fast conditions are between 0.93 and 1.53 ft/s higher than under non-fast conditions, after accounting for the effect of year. To make a prediction for a new case, such as the winning speed in 2017, we use a prediction interval: new.data &lt;- data.frame(yearnew = 2017 - 1896, fast = 1) predict(model4, new = new.data, interval = &quot;prediction&quot;) fit lwr upr 1 54.87718 53.4143 56.34006 Based on our model, we can be 95% confident that the winning speed in 2017 under fast conditions will be between 53.4 and 56.3 ft/s. Note that Always Dreaming's actual winning speed (53.40) barely fit within this interval---the 2017 winning speed was a borderline outlier on the slow side. If we wanted to estimate the average value of Y among all cases with the given explanatory variable values, we would use interval=&quot;confidence&quot;. This doesn't really make sense in this context, since there is only one winning speed each year. 1.3.4 Slopes for Fast, non-Fast Tracks In model4, we assume that the expected rate of change in winning speed over time is the same, regardless of whether the track is fast or not. In either case, it is given by \\(\\beta_1\\). Thus, Model 4 produces a picture that looks like this: equation1 &lt;- function(x){coef(model4)[2]*x+coef(model4)[1]} equation2 &lt;- function(x){coef(model4)[2]*x+coef(model4)[1]+coef(model4)[3]} ggplot(data=derby.df, aes(x=yearnew, y=speed, color=fastfactor)) + geom_point()+ stat_function(fun=equation1,geom=&quot;line&quot;,color=scales::hue_pal()(3)[3]) + stat_function(fun=equation2,geom=&quot;line&quot;,color=scales::hue_pal()(3)[1]) Recall, however, that the data suggested that speeds have increased more rapidly for tracks that are not fast. # Coded scatterplot ggplot(derby.df, aes(x = year, y = speed, colour = fastfactor)) + geom_point(aes(shape = fastfactor)) + geom_smooth(aes(linetype = fastfactor), method = lm, se = FALSE) Figure 1.7: Linear trends in winning speeds over time, presented separately for fast conditions vs. good or slow conditions. 1.3.5 MLR Model with Interaction We want to build a model allows winning speeds to increase at different rates for fast tracks than for those that are not fast. (i.e. a model that includes an interaction between fast and yearnew) Thus, consider Model 5: \\[ \\begin{equation*} \\begin{split} Y_{i}&amp;= \\beta_{0}+\\beta_{1}\\textrm{Yearnew}_{i}+\\beta_{2}\\textrm{Fast}_{i} \\\\ &amp;{}+\\beta_{3}\\textrm{Yearnew}_{i}\\times\\textrm{Fast}_{i}+\\epsilon_{i}\\quad \\textrm{where}\\quad \\epsilon_{i}\\sim \\textrm{N}(0,\\sigma^2) \\end{split} \\end{equation*} \\] ### Interaction Model Estimates LLSR provides the following parameter estimates: We can do this using either of the following commands model5 &lt;- lm(speed ~ yearnew + fast + yearnew:fast, data=derby.df) model5 &lt;- lm(speed ~ yearnew*fast, data=derby.df) coef(summary(model5)) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 50.52862926 0.205072338 246.394174 6.988530e-162 ## yearnew 0.03075099 0.003470967 8.859489 9.838736e-15 ## fast 1.83352259 0.262174513 6.993520 1.729697e-10 ## yearnew:fast -0.01149034 0.004116733 -2.791129 6.127912e-03 cat(&quot; R squared = &quot;, summary(model5)$r.squared, &quot;\\n&quot;, &quot;Residual standard error = &quot;, summary(model5)$sigma) ## R squared = 0.7067731 ## Residual standard error = 0.7070536 1.3.6 Model Equations for Fast, Non-Fast Tracks According to our model, estimated winning speeds can be found by: \\[ \\begin{equation} \\hat{Y}_{i}=50.53+0.031\\textrm{Yearnew}_{i}+1.83\\textrm{Fast}_{i}-0.011\\textrm{Yearnew}_{i}\\times\\textrm{Fast}_{i}. \\end{equation} \\] \\[ \\begin{align*} \\textrm{Fast}=0: &amp; \\\\ \\hat{Y}_{i} &amp;= 50.53+0.031\\textrm{Yearnew}_{i} \\\\ \\textrm{Fast}=1: &amp; \\\\ \\hat{Y}_{i} &amp;= (50.53+1.83)+(0.031-0.011)\\textrm{Yearnew}_{i} \\end{align*} \\] Interpretations \\(\\hat{\\beta}_{0} = 50.53\\). The expected winning speed in 1896 under non-fast conditions was 50.53 ft/s. \\(\\hat{\\beta}_{1} = 0.031\\). The expected yearly increase in winning speeds under non-fast conditions is 0.031 ft/s. \\(\\hat{\\beta}_{2} = 1.83\\). The winning speed in 1896 was expected to be 1.83 ft/s faster under fast conditions compared to non-fast conditions. \\(\\hat{\\beta}_{3} = -0.011\\). The expected yearly increase in winning speeds under fast conditions is 0.020 ft/s, compared to 0.031 ft/s under non-fast conditions, a difference of 0.011 ft/s. 1.4 Building a Multiple Linear Regression Model 1.4.1 Model Building Considerations We now add additional variables, with the goal of building a final model that provides insight into relationships between winning speed and other variables. There is no single correct model, but a good model will have the following characteristics: explanatory variables allow one to address primary research questions explanatory variables control for important covariates potential interactions have been investigated variables are centered where interpretations can be enhanced (e.g. subtract 1896 from year) unnecessary terms have been removed LINE assumptions and the presence of influential points have both been checked using residual plots the model tells a &quot;persuasive story parsimoniously&quot; Most good models should lead to similar conclusions. 1.4.2 Model Diagnostics Several tests and measures of model performance can be used when comparing different models for model building: \\(R^2\\). Measures the variability in the response variable explained by the model. One problem is that \\(R^2\\) always increases with extra predictors, even if the predictors add very little information. adjusted \\(R^2\\). Adds a penalty for model complexity to \\(R^2\\) so that any increase in performance must outweigh the cost of additional complexity. We should ideally favor any model with higher adjusted \\(R^2\\), regardless of size, but the penalty for model complexity (additional terms) is fairly ad-hoc. AIC (Akaike Information Criterion). Again attempts to balance model performance with model complexity, with smaller AIC levels being preferable, regardless of model size. The BIC (Bayesian Information Criterion) is similar to the AIC, but with a greater penalty for additional model terms. extra sum of squares F test. This is a generalization of the t-test for individual model coefficients which can be used to perform significance tests on nested models, where one model is a reduced version of the other. 1.4.3 Three Possible Models We'll consider three possible final models: Model A: \\[ \\begin{equation} \\begin{split} Y_{i}&amp;=\\beta_{0}+\\beta_{1}\\textrm{Yearnew}_{i}+\\beta_{2}\\textrm{Yearnew}^2_{i}+\\epsilon_{i}\\quad \\textrm{where}\\quad \\epsilon_{i}\\sim \\textrm{N}(0,\\sigma^2) \\end{split} \\end{equation} \\] Model B: \\[ \\begin{equation} \\begin{split} Y_{i}&amp;=\\beta_{0}+\\beta_{1}\\textrm{Yearnew}_{i}+\\beta_{2}\\textrm{Yearnew}^2_{i}+\\beta_{3}\\textrm{Fast}_{i}\\\\ &amp;{}+\\beta_{4}\\textrm{Good}_{i}+\\beta_{5}\\textrm{Starters}_{i}+\\epsilon_{i}\\quad \\textrm{where}\\quad \\epsilon_{i}\\sim \\textrm{N}(0,\\sigma^2) \\end{split} \\end{equation} \\] Note that this is equivalent to including the original track condition variable in a model. In this case, slow track is treated as the baseline variable, since we left the indicator for slow out of the model. Model C: \\[ \\begin{equation} \\begin{split} Y_{i}&amp;=\\beta_{0}+\\beta_{1}\\textrm{Yearnew}_{i}+\\beta_{2}\\textrm{Yearnew}^2_{i}+\\beta_{3}\\textrm{Fast}_{i}\\\\ &amp;{}+\\beta_{4}\\textrm{Good}_{i}+\\beta_{5}\\textrm{Starters}_{i} \\\\ &amp; + \\beta_6\\textrm{Yearnew}_{i}\\textrm{Fast}_{i}+ \\beta_7\\textrm{Yearnew}_{i}\\textrm{Good}_{i} \\\\ &amp; + \\beta_8\\textrm{Yearnew}^2_{i}\\textrm{Fast}_{i}+ \\beta_9\\textrm{Yearnew}^2_{i}\\textrm{Good}_{i} \\\\ &amp; + \\epsilon_{i}\\quad \\textrm{where}\\quad \\epsilon_{i}\\sim \\textrm{N}(0,\\sigma^2) \\end{split} \\end{equation} \\] 1.4.4 MLR Models Fit in R We fit each model in R. model0A &lt;- lm(speed ~ yearnew + yearnew2 , data = derby.df) model0B &lt;- lm(speed ~ yearnew + yearnew2 + fast + good + starters, data = derby.df) model0C &lt;- lm(speed ~ yearnew + yearnew2 + fast + good + starters + yearnew:fast + yearnew:good + yearnew2:fast + yearnew2:good, data = derby.df) 1.4.5 Model 0A Output coef(summary(model0A)) %&gt;% round(6) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 50.587457 0.208171 243.009695 0 ## yearnew 0.076173 0.007950 9.580989 0 ## yearnew2 -0.000414 0.000064 -6.504628 0 cat(&quot; R squared = &quot;, summary(model0A)$r.squared, &quot;\\n&quot;, &quot; Adjusted R squared = &quot;, summary(model0A)$adj.r.squared, &quot;\\n&quot;, &quot;Residual standard error = &quot;, summary(model0A)$sigma, &quot;\\n&quot;, &quot;AIC = &quot;, AIC(model0A)) ## R squared = 0.6410103 ## Adjusted R squared = 0.6349769 ## Residual standard error = 0.7790385 ## AIC = 290.258 1.4.6 Model 0B Output coef(summary(model0B))%&gt;% round(6) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 50.020315 0.194646 256.980337 0.000000 ## yearnew 0.070034 0.006130 11.423908 0.000000 ## yearnew2 -0.000370 0.000046 -8.041141 0.000000 ## fast 1.392666 0.130520 10.670102 0.000000 ## good 0.915698 0.207677 4.409248 0.000023 ## starters -0.025284 0.013602 -1.858827 0.065586 cat(&quot; R squared = &quot;, summary(model0B)$r.squared, &quot;\\n&quot;, &quot; Adjusted R squared = &quot;, summary(model0B)$adj.r.squared, &quot;\\n&quot;, &quot;Residual standard error = &quot;, summary(model0B)$sigma,&quot;\\n&quot;, &quot;AIC = &quot;, AIC(model0B)) ## R squared = 0.8266716 ## Adjusted R squared = 0.8192006 ## Residual standard error = 0.5482735 ## AIC = 207.4291 1.4.7 Model 0C Output coef(summary(model0C))%&gt;% round(6) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 49.703525 0.296614 167.569982 0.000000 ## yearnew 0.068568 0.013167 5.207395 0.000001 ## yearnew2 -0.000290 0.000102 -2.835528 0.005430 ## fast 1.697589 0.337378 5.031710 0.000002 ## good 1.704844 0.468469 3.639181 0.000415 ## starters -0.018592 0.013107 -1.418444 0.158838 ## yearnew:fast 0.004223 0.014398 0.293292 0.769841 ## yearnew:good -0.031672 0.021548 -1.469858 0.144404 ## yearnew2:fast -0.000128 0.000114 -1.124264 0.263305 ## yearnew2:good 0.000249 0.000213 1.168083 0.245254 cat(&quot; R squared = &quot;, summary(model0C)$r.squared, &quot;\\n&quot;, &quot; Adjusted R squared = &quot;, summary(model0C)$adj.r.squared, &quot;\\n&quot;, &quot;Residual standard error = &quot;, summary(model0C)$sigma, &quot;\\n&quot;, &quot;AIC = &quot;, AIC(model0C)) ## R squared = 0.8498007 ## Adjusted R squared = 0.8377311 ## Residual standard error = 0.5194172 ## AIC = 197.9556 1.4.8 Goodness of Fit Tests When two models are nested (that is, all the terms in the smaller model also appear in the larger model) we can compare them using a goodness of fit test. Reduced Model: \\(\\hat{y}_i = b_0 + b_1x_{i1} + b_2{x_i2} + \\ldots + b_qx_{iq}\\) Full Model: \\(\\hat{y}_i = b_0 + b_1x_{i1} + b_2{x_i2} + \\ldots + b_qx_{iq} + b_{q+1}x_{i{q+1}} \\ldots + b_px_{ip}\\) p = # parameters in Full Model q = # parameters in Reduced Model n = number of observations The hypothesis are: Null Hypothesis: Smaller model adequately eplains variability in the response variable. Alternative Hypothesis: Larger model better explains variability in the response variable than the smaller one. 1.4.9 ANOVA F-Statistic We calculate an F-statistic using the formula: \\[ F = \\frac{\\frac{\\text{SSR}_{\\text{Reduced}}-\\text{SSR}_{\\text{Full}}}{p-q}}{\\frac{\\text{SSR}_{\\text{Full}}}{n-(p+1)}} \\] When the null hypothesis is true, this statistic follows an F-distribution with \\(p-q\\) and \\(n-p\\) degrees of freedom. # Compare model0A and model0B anova(model0A, model0B, test = &quot;F&quot;) Analysis of Variance Table Model 1: speed ~ yearnew + yearnew2 Model 2: speed ~ yearnew + yearnew2 + fast + good + starters Res.Df RSS Df Sum of Sq F Pr(&gt;F) 1 119 72.221 2 116 34.870 3 37.351 41.418 &lt; 0.00000000000000022 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 There is very strong evidence that track condition and number of starters help explain variability in winning speed. # Compare model0A and model0B anova(model0B, model0C, test = &quot;F&quot;) Analysis of Variance Table Model 1: speed ~ yearnew + yearnew2 + fast + good + starters Model 2: speed ~ yearnew + yearnew2 + fast + good + starters + yearnew:fast + yearnew:good + yearnew2:fast + yearnew2:good Res.Df RSS Df Sum of Sq F Pr(&gt;F) 1 116 34.870 2 112 30.217 4 4.6531 4.3117 0.002784 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 There is evidence of interaction between year and track conditions. Observations: There is strong evidence that model B is better than model A. Accounting for condition of track and number of starters helps explain variability in winning speeds. Models B and C both seem like reasonable fits. Adjusted R^2, AIC, and the F-test all favor model C over model B. Model C is, however, much harder to interpret. The p-values on any single interaction term were large, even though the model testing for significance of interactions collectively was small. When in doubt, it's better to go with the simpler model, unless there is clear reason to choose the more complex one. It is important to consider intuition, domain area knowledge, and interpretability when choosing a model. Do not choose a model based on statistical tests alone! 1.4.10 Final Model Residual Plots We'll go with model B. We use residual plots to check model assumptions. # Residual diagnostics for Model B par(mar=c(4,4,4,4)) par(mfrow=c(2,2)) plot(model0B) Figure 1.8: Residual plots for Model 0B. par(mfrow=c(1,1)) There do not appear to be any major model violations. Model B Coefficients Table: coef(summary(model0B))%&gt;% round(6) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 50.020315 0.194646 256.980337 0.000000 ## yearnew 0.070034 0.006130 11.423908 0.000000 ## yearnew2 -0.000370 0.000046 -8.041141 0.000000 ## fast 1.392666 0.130520 10.670102 0.000000 ## good 0.915698 0.207677 4.409248 0.000023 ## starters -0.025284 0.013602 -1.858827 0.065586 cat(&quot; R squared = &quot;, summary(model0B)$r.squared, &quot;\\n&quot;, &quot; Adjusted R squared = &quot;, summary(model0B)$adj.r.squared, &quot;\\n&quot;, &quot;Residual standard error = &quot;, summary(model0B)$sigma,&quot;\\n&quot;, &quot;AIC = &quot;, AIC(model0B)) ## R squared = 0.8266716 ## Adjusted R squared = 0.8192006 ## Residual standard error = 0.5482735 ## AIC = 207.4291 1.4.11 Overall Conclusions Conclusions: * The rate of increase in winning speeds is slowing over time (negative quadratic term) * The better the condition of the track, the faster the horses tend to run * larger field, with more starters, is associated with slower winning times Notice this last conclusion appears contradictory to our exploratory data analysis, which showed a positive relationship between starters and speed. gg &lt;- ggpairs(data = derby.df, columns = c(&quot;condition&quot;, &quot;year&quot;, &quot;starters&quot;, &quot;speed&quot;)) gg Figure 1.9: Relationships between pairs of variables in the Kentucky Derby data set. This happens because over time, the number of starters in the race has increased, as have winning speeds. So, it appears that having more starters is associated with faster winning speeds, but year is acting as a confounding variable. The multiple regression model is able to separate the effect of year from that of number of starters. The model tells us that assuming year is held constant, having more starters is actually associated with a slower winning speed. A situation like this, where adding a variable (such as year) to a model results in an apparent trend disappearing or reversing itself, is called Simpson's Paradox. "],["introduction-to-correlated-data.html", "Chapter 2 Introduction to Correlated Data 2.1 Introduction to Correlated Data 2.2 Linear Mixed Effects Models 2.3 A Second Mice Experiment 2.4 A Multilevel Experiment", " Chapter 2 Introduction to Correlated Data library(tidyverse) library(lme4) library(lmerTest) library(knitr) 2.1 Introduction to Correlated Data 2.1.1 Weight Gain in Mice: Experiment Design #1 Consider an experiment designed to assess the impact of three different diets on weight gain in mice. We observe six different litters of mice, with six mice in each litter. Within each litter, two mice are randomly assigned to each of the three diets. Researchers recorded the mean weight gain in each mouse over a four-week period. Experimental Design 1: Figure 2.1: Mouse Experiment Version 1 2.1.2 Mice Experiment 1 Data The first 10 rows of the dataset look like this: head(mice,10) ## litter diet weight_gain ## 1 1 A -0.03526041 ## 2 1 B -0.06841666 ## 3 1 C -0.06351305 ## 4 1 A -0.05171452 ## 5 1 B -0.06917391 ## 6 1 C -0.05951775 ## 7 2 A 0.07584083 ## 8 2 B 0.04913527 ## 9 2 C 0.07958384 ## 10 2 A 0.07278071 2.1.3 A Naive Graphical Analysis Let's temporarily ignore the fact that some mice came from the same litter, and treat all observations as independent. The plot below shows the weight gain (or loss) for each of the mice, by diet. The red dots and connecting lines show the mean weight gain for each diet. The ensuing table shows the mean and standard deviation in weight gain for each of the three diets. ggplot(data=mice, aes(x=factor(diet), y=weight_gain)) + geom_point() + stat_summary(fun=&quot;mean&quot;, geom=&quot;line&quot;, aes(group=factor(1))) + stat_summary(fun=&quot;mean&quot;, geom=&quot;point&quot;, color=&quot;red&quot;, size=2) Question: Based on this graph, do you think there is evidence of diets have an effect on weight gain in mice? Why or why not? 2.1.4 A More Informed Graphical Analysis So far, we've ignored the fact that some of the mice came from the same litter. Now, let's take litter into account. The figure below colors the mice by litter. The lines represent the average weight gain (or loss) in each litter. ggplot(data=mice, aes(x=factor(diet), y=weight_gain, color=factor(litter))) + geom_point() + stat_summary(fun=&quot;mean&quot;, geom=&quot;line&quot;, aes(group=factor(litter))) It may be helpful to examine each litter individually. ggplot(data=mice, aes(x=factor(diet), y=weight_gain, color=factor(litter))) + geom_point() + facet_grid(.~litter, scales = &quot;free&quot;) + stat_summary(fun=&quot;mean&quot;, geom=&quot;line&quot;, aes(group=factor(litter))) Question: Based on the information about litters, do your thoughts about whether diets have an effect on weight gain in mice change? Does there appear to be stronger evidence of differences between groups? Weaker? Same? 2.1.5 Table of Mean Weight By Diet mouse_groups &lt;- mice %&gt;% group_by(diet)%&gt;% summarize(Mean_Weight=mean(weight_gain), SD_Weight = sd(weight_gain), N=n()) mouse_groups ## # A tibble: 3 x 4 ## diet Mean_Weight SD_Weight N ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 A 0.0580 0.0567 12 ## 2 B 0.0340 0.0583 12 ## 3 C 0.0471 0.0612 12 2.1.6 Table of Mean Weight By Diet and Litter mouse_groups &lt;- mice %&gt;% group_by(diet, litter)%&gt;% summarize(Mean_Weight=mean(weight_gain), SD_Weight = sd(weight_gain), N=n()) mouse_groups ## # A tibble: 18 x 5 ## # Groups: diet [3] ## diet litter Mean_Weight SD_Weight N ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 A 1 -0.0435 0.0116 2 ## 2 A 2 0.0743 0.00216 2 ## 3 A 3 0.0192 0.00282 2 ## 4 A 4 0.104 0.00487 2 ## 5 A 5 0.110 0.00145 2 ## 6 A 6 0.0833 0.00721 2 ## 7 B 1 -0.0688 0.000535 2 ## 8 B 2 0.0554 0.00881 2 ## 9 B 3 -0.0108 0.00781 2 ## 10 B 4 0.0731 0.00482 2 ## 11 B 5 0.0873 0.00890 2 ## 12 B 6 0.0682 0.00430 2 ## 13 C 1 -0.0615 0.00283 2 ## 14 C 2 0.0746 0.00711 2 ## 15 C 3 0.000839 0.00489 2 ## 16 C 4 0.0918 0.00638 2 ## 17 C 5 0.0979 0.0214 2 ## 18 C 6 0.0792 0.00310 2 Since each mouse in a litter received a different treatment, we can use the standard deviations between mice in the same litter to assess the amount of unexplained variability after accounting for litter and diet. Notice standard deviations are much smaller when we account for litter. Most of the unexplained variability in the first table is explained when we account for litter. When we fail to account for litter, variability thqt can be explained by differences between litters becomes conflated with unexplained variability. This causes us to overestimate unexplained variability and makes differences between groups look less meaningful than they really are. 2.1.7 Assessing Evidence of Differences Conceptually, we can assess whether there is evidence of differences between the diets by considering differences in mean weights, relative to the amount of unexplained variability between mice in the same litter and on the same diet. Recall that when testing for a difference between two groups, a t-statistic is calculated using the formula \\[ t= \\frac{\\bar{x}_1-\\bar{x}_2}{\\textrm{SE}(\\bar{x}_1-\\bar{x}_2)}=\\frac{\\bar{x}_1-\\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1}+\\frac{s_2^2}{n_2}}} \\] The numerator measures the size of the differences between the groups, and the denominator measures the amount of unexplained variability between individuals in the same group. 2.1.8 An Improper Statistical Analysis We've seen graphically, and in table form, how accounting for litter impacts our ability to discern differences between diets. Now, let's look at how this happens in a statistical model. If we ignore the fact that some mice are from the same litter, and wrongly treat them as independent, we might use an ordinary linear least squares regression model. M_LLSR &lt;- lm(data=mice, weight_gain~factor(diet)) summary(M_LLSR)$coefficients ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.05798494 0.01696450 3.4180166 0.001693572 ## factor(diet)B -0.02394185 0.02399142 -0.9979334 0.325573272 ## factor(diet)C -0.01085590 0.02399142 -0.4524907 0.653876252 The p-values on line 2 is large, indicating that there is not evidence of differences in weight gain between mice on diet 2, and the baseline diet (diet 1). The same is true for a comparison of diets 3 and 1, as seen on the third line. 2.1.9 A More Appropriate Statistical Analysis The following command fits a linear mixed effects model (or multilevel model) that accounts for correlation between mice in the same litter. M_LME &lt;- lmer(data=mice, weight_gain~factor(diet) + (1 | factor(litter))) summary(M_LME)$coeff ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 0.05798494 0.025057548 5.046907 2.314071 0.068074358859032 ## factor(diet)B -0.02394185 0.002962717 28.000000 -8.081043 0.000000008464652 ## factor(diet)C -0.01085590 0.002962717 28.000000 -3.664169 0.001025965687040 Estimates are unchanged, but standard errors decrease by a factor of almost 10. t-statistics are now high, and p-values low, indicating differences between the diets Just as we saw graphically, and in tables, accounting for differences between litters allows us to accurately quantify unexplained variability, and assess whether there is evidence of differences in weight gain between the diets. 2.2 Linear Mixed Effects Models 2.2.1 LLSR Model for Mice Experiment Let \\(Y_{ij}\\) denote the weight gain of mouse \\(j\\) in litter \\(i\\). \\(j=1,2,\\ldots, 6\\), \\(j=1,2,\\ldots, 6\\). In an ordinary linear least squares regression model, we assume that: each diet has an expected (or average) weight gain individual mice vary from their expected weights randomly, according to normal distributions with constant variance \\(\\sigma^2\\) no two mice are any more or less alike than any others, except for diet (which is not true in this context) A model would have the form: \\[ Y_{ij} = \\beta_{0}+\\beta_{1}\\textrm{DietB}_{ij} +\\beta_{2}\\textrm{DietC}_{ij} + \\epsilon_{ij}, \\] where \\(\\epsilon_{ij} \\sim\\mathcal{N}(0, \\sigma^2)\\). Examples: Diet Expected Weight Random Deviation Litter 1, Mouse 1 A \\(\\beta_0\\) \\(\\epsilon_{11}\\) Litter 1, Mouse 3 B \\(\\beta_0 + \\beta_1\\) \\(\\epsilon_{13}\\) Litter 1, Mouse 5 C \\(\\beta_0 + \\beta_2\\) \\(\\epsilon_{15}\\) Litter 2, Mouse 1 A \\(\\beta_0\\) \\(\\epsilon_{21}\\) Litter 2, Mouse 3 B \\(\\beta_0 + \\beta_1\\) \\(\\epsilon_{23}\\) Litter 2, Mouse 5 C \\(\\beta_0 + \\beta_2\\) \\(\\epsilon_{25}\\) 2.2.2 Model Accounting For Correlation Let \\(Y_{ij}\\) denote the weight gain of mouse \\(j\\) in litter \\(i\\). \\(j=1,2,\\ldots, 6\\), \\(j=1,2,\\ldots, 6\\). We assume that: expected (or average) weight gain differs between diets individual litters vary from their expected weight randomly, according to normal distributions with constant variance \\(\\sigma^2_l\\) within each litter, individual mice vary from their expected weights randomly, according to normal distributions with constant variance \\(\\sigma^2\\) A model would have the form: \\[ Y_{ij} = \\beta_{0}+\\beta_{1}\\textrm{DietB}_{ij} +\\beta_{2}\\textrm{DietC}_{ij} + l_{i} + \\epsilon_{ij}, \\] where \\(l_i\\sim\\mathcal{N}(0, \\sigma^2_l)\\), and \\(\\epsilon_{ij} \\sim\\mathcal{N}(0, \\sigma^2)\\). Diet Expected Weight Random Deviation Litter 1, Mouse 1 A \\(\\beta_0\\) \\(l_1 + \\epsilon_{11}\\) Litter 1, Mouse 3 B \\(\\beta_0 + \\beta_1\\) \\(l_1 + \\epsilon_{13}\\) Litter 1, Mouse 5 C \\(\\beta_0 + \\beta_2\\) \\(l_1 + \\epsilon_{15}\\) Litter 2, Mouse 1 A \\(\\beta_0\\) \\(l_2 + \\epsilon_{21}\\) Litter 2, Mouse 3 B \\(\\beta_0 + \\beta_1\\) \\(l_2 + \\epsilon_{23}\\) Litter 2, Mouse 5 C \\(\\beta_0 + \\beta_2\\) \\(l_2 + \\epsilon_{25}\\) 2.2.3 Questions of Interest The model \\[ Y_{ij} = \\beta_{0}+\\beta_{1}\\textrm{DietB}_{ij} +\\beta_{2}\\textrm{DietC}_{ij} + l_{i} + \\epsilon_{ij}, \\] where \\(l_i\\sim\\mathcal{N}(0, \\sigma^2_l)\\), and \\(\\epsilon_{ij} \\sim\\mathcal{N}(0, \\sigma^2)\\) has 5 parameters: \\(\\beta_0\\) - average weight gain for mice on diet A. \\(\\beta_1\\) - difference in average weight gain for mice on diet B, compared to to diet A \\(\\beta_2\\) - difference in average weight gain for mice on diet C, compared to to diet A \\(\\sigma_l\\) - standard deviation in the distribution of differences between litters (i.e. variability explained by litter) \\(\\sigma\\) - standard deviation in the distribution of differences between individual mice in the same litter (i.e. unexplained variability) Thus, for a mouse in litter 1, the expected weight gain follows a normal distribution with mean \\(\\beta_0\\) and variance \\(\\sigma^2_l + \\sigma^2\\). For a mouse in litter 2, the expected weight gain follows a normal distribution with mean \\(\\beta_0 + \\beta_2\\) and variance \\(\\sigma^2_l + \\sigma^2\\) This is based on the fact that the sum of two independent normal random variables is normal, with mean equal to the sum of the means and variance equal to the sum of the variances. 2.2.4 Fixed and Random Effects In this case, we want to test for whether there are differences in weight gain between the diets. There is no reason to test for differences in weight gain between the litters. Differences between these specific litters of mice are not important to us. We're not interested in drawing conclusions about these specific mice. They're just a sample of participants, being used to investigate the diets. It's likely that we'll never acually see these specific litters of mice beyond this study. We still need to account for litter, though, because it helps explain, or account for, variability that would otherwise go unexplained. Variables for which we want to investigate differences or relationships are called fixed effects. We should build these into the &quot;expectation structure&quot; of the model, using \\(\\beta_j\\)'s. Variables that we are not interested in testing for differences or relationships between, but that we still want to include in our model in order to account for correlation and explain variability are called random effects. We should add these to the model as normally distributed error terms. Accounting for random effects allows us to accurately calculate standard errors associated with fixed effects. A model that involves both fixed and random effects is called a linear mixed effects model. 2.2.5 Fitting the Model in R To fit a linear mixed effects model in R, we use the lmer() command that is part of the lme4 package. It is also helpful to load the lmerTest package, in order to obtain p-values in the output. To add a random effect for a variable add (1 | variable_name) in the model. M_LME &lt;- lmer(data=mice, weight_gain~factor(diet) + (1 | factor(litter))) summary(M_LME) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: weight_gain ~ factor(diet) + (1 | factor(litter)) ## Data: mice ## ## REML criterion at convergence: -193.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.2468 -0.7088 0.0247 0.6028 1.9280 ## ## Random effects: ## Groups Name Variance Std.Dev. ## factor(litter) (Intercept) 0.00374095 0.061163 ## Residual 0.00005267 0.007257 ## Number of obs: 36, groups: factor(litter), 6 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 0.057985 0.025058 5.046907 2.314 0.06807 . ## factor(diet)B -0.023942 0.002963 28.000000 -8.081 0.00000000846 *** ## factor(diet)C -0.010856 0.002963 28.000000 -3.664 0.00103 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) fct()B ## factor(dt)B -0.059 ## factor(dt)C -0.059 0.500 Estimates and Interpretations \\(\\beta_0 = 0.058\\): We estimate that average weight gain for Diet A is 0.058 g. \\(\\beta_1 = -0.024\\): We estimate that mice on diet B gain 0.024 g. less than mice on diet A, on average. \\(\\beta_2 = -0.011\\): We estimate that mice on diet C gain 0.011 g. less than mice on diet A, on average. The &quot;Random effects&quot; table gives estimates of \\(\\sigma^2_l\\) (litters) and \\(\\sigma^2\\) (Residual). \\(\\sigma_l = 0.061\\): We estimate that the standard deviation in differences in weights between litters, after accounting for diet, is 0.061 g. \\(\\sigma = 0.007\\): We estimate that the standard deviation in differences in weights between mice within a litter, after accounting for diet, is 0.007 g. There is evidence of differences between the diets. There is more variability in weight between different litters than between mice in the same litter, after accounting for diet. 2.2.6 Why Not Fixed Effect for Litter? Why would a model like the following, which uses litter as an expanatory variable in Example 1, not be very useful? M_fixed_litter &lt;- lm(data=mice, weight_gain~ factor(diet) + factor(litter)) summary(M_fixed_litter) ## ## Call: ## lm(formula = weight_gain ~ factor(diet) + factor(litter), data = mice) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.0164273 -0.0051744 0.0001942 0.0044281 0.0138701 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.046333 0.003421 -13.544 0.0000000000000815 *** ## factor(diet)B -0.023942 0.002963 -8.081 0.0000000084646521 *** ## factor(diet)C -0.010856 0.002963 -3.664 0.00103 ** ## factor(litter)2 0.126011 0.004190 30.075 &lt; 0.0000000000000002 *** ## factor(litter)3 0.061021 0.004190 14.564 0.0000000000000136 *** ## factor(litter)4 0.147712 0.004190 35.254 &lt; 0.0000000000000002 *** ## factor(litter)5 0.156366 0.004190 37.320 &lt; 0.0000000000000002 *** ## factor(litter)6 0.134801 0.004190 32.173 &lt; 0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.007257 on 28 degrees of freedom ## Multiple R-squared: 0.9874, Adjusted R-squared: 0.9843 ## F-statistic: 314.5 on 7 and 28 DF, p-value: &lt; 0.00000000000000022 We're now estimating 8 \\(\\beta&#39;s\\) instead of 3. Each time we estimate an additional parameter, we lose a degree of freedom, making estimates and predictions less precise. We don't care about differences between the litters, so \\(\\beta_3, \\beta_4, \\ldots, \\beta_7\\) are not useful. Imagine if we had many more litters. Things would get really messy, and unnecessarily so. If, for some reason, we really wanted to test for differences in weight gain between these specific litters of mice, then we would treat them as fixed effects, but it's hard to see why we would want to do that. 2.3 A Second Mice Experiment 2.3.1 Weight Gain in Mice: Experiment 2 Now consider a different structure of the mouse experiment. In this version of the experiment, the three diets were randomly assigned to six pregnant mice, so that two mice were assigned to each diet. Each of the six mice (dams), gave birth to six pups, creating six litters of six, as seen before. Researchers the observed the mean weight gain of the pups over a four week period. Now, each pup in a litter has necessarily been assigned to the same diet, since diets were assigned to the dams, before the pups were born. Experimental Design 2: Figure 2.2: Mouse Experiment Version 2 2.3.2 Mice Experiment 2 Data The first 15 rows of the dataset look like this: head(mice2,15) ## litter diet weight_gain ## 1 1 A -0.0352604099 ## 2 1 A -0.0474166604 ## 3 1 A -0.0545130532 ## 4 1 A -0.0517145212 ## 5 1 A -0.0481739132 ## 6 1 A -0.0505177486 ## 7 2 A 0.0758408263 ## 8 2 A 0.0701352749 ## 9 2 A 0.0885838352 ## 10 2 A 0.0727807107 ## 11 2 A 0.0826007925 ## 12 2 A 0.0785294998 ## 13 3 B 0.0002306143 ## 14 3 B -0.0163362762 ## 15 3 B -0.0146213462 2.3.3 A Naive Graphical Analysis for Experiment 2 Again, we'll temporarily ignore the fact that mice come from the same litter and treat all observations as independent. ggplot(data=mice2, aes(x=factor(diet), y=weight_gain)) + geom_point() + stat_summary(fun=&quot;mean&quot;, geom=&quot;line&quot;, aes(group=factor(1)))+ stat_summary(fun=&quot;mean&quot;, geom=&quot;point&quot;, color=&quot;red&quot;, size=2) 2.3.4 A More Informed Graphical Analysis for Experiment 2 Now, we'll account for the fact that mice in the same litter got the same diets. The plot below adds color to show litter. ggplot(data=mice2, aes(x=factor(diet), y=weight_gain, color=factor(litter))) + geom_point() Since diets were assigned to litters, not individual mice, it is the litters we should be comparing. When comparing diets, our observational units are litters, not individual mice. Since there are only 6 litters, our sample size is 6, rather than 36. Thus, the best graphical analysis would come from the following plot, which displays average weight for each litter: Litters &lt;- mice2 %&gt;% group_by(diet, litter)%&gt;% summarize(mean_weight_gain=mean(weight_gain), N=n()) head(Litters) ## # A tibble: 6 x 4 ## # Groups: diet [3] ## diet litter mean_weight_gain N ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 A 1 -0.0479 6 ## 2 A 2 0.0781 6 ## 3 B 3 -0.00791 6 ## 4 B 4 0.0788 6 ## 5 C 5 0.0994 6 ## 6 C 6 0.0779 6 ggplot(data=Litters, aes(x=factor(diet), y=mean_weight_gain, color=factor(litter))) + geom_point() 2.3.5 Table of Mean Weight By Diet for Experiment 2 mouse_groups &lt;- mice2 %&gt;% group_by(diet)%&gt;% summarize(Mean_Weight=mean(weight_gain), SD_Weight = sd(weight_gain), N=n()) mouse_groups ## # A tibble: 3 x 4 ## diet Mean_Weight SD_Weight N ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 A 0.0151 0.0661 12 ## 2 B 0.0354 0.0457 12 ## 3 C 0.0887 0.0137 12 This standard deviations in this table pertain to variability between the 12 mice that got each diet (6 from one litter and 6 from another). These are not useful here, since diets were assigned to litters, not individual mice. 2.3.6 Table Comparing Litters Means by Diet for Experiment 2 We now look at means and standard deviations between litter means, using the average rate in each litter as the response variable. litter_groups &lt;- Litters %&gt;% group_by(diet)%&gt;% summarize(Mean_Weight=mean(mean_weight_gain), SD_Weight = sd(mean_weight_gain), N=n()) litter_groups ## # A tibble: 3 x 4 ## diet Mean_Weight SD_Weight N ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 A 0.0151 0.0891 2 ## 2 B 0.0354 0.0613 2 ## 3 C 0.0887 0.0152 2 2.3.7 An Inappropriate Model for the Second Design An ordinarly linear least squares regression model fails to account for the fact that treatments were assigned to litters, not mice. It is based on the assumption that we have 36 independent mice (which is incorret). Such a model would have the form \\[ Y_{ij} = \\beta_{0}+\\beta_{1}\\textrm{DietB}_{ij} +\\beta_{2}\\textrm{DietC}_{ij} + \\epsilon_{ij}, \\] Output for such a model is shown below. M2_LLSR &lt;- lm(data=mice2, weight_gain~factor(diet)) summary(M2_LLSR) ## ## Call: ## lm(formula = weight_gain ~ factor(diet), data = mice2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.069586 -0.041328 -0.005675 0.041915 0.073511 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.01507 0.01359 1.109 0.275297 ## factor(diet)B 0.02036 0.01922 1.060 0.297007 ## factor(diet)C 0.07358 0.01922 3.829 0.000545 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.04707 on 33 degrees of freedom ## Multiple R-squared: 0.3215, Adjusted R-squared: 0.2804 ## F-statistic: 7.819 on 2 and 33 DF, p-value: 0.001662 2.3.8 A More Appropriate Model for Experiment 2 A linear mixed effects model with a random term for litter accounts for the fact that treatments were applied to litters, not individual mice. This model has the form: \\[ Y_{ij} = \\beta_{0}+\\beta_{1}\\textrm{DietB}_{ij} +\\beta_{2}\\textrm{DietC}_{ij} + l_{i} + \\epsilon_{ij}, \\] where \\(l_i\\sim\\mathcal{N}(0, \\sigma^2_l)\\), and \\(\\epsilon_{ij} \\sim\\mathcal{N}(0, \\sigma^2)\\) Output for a model that accounts for correlation between mice in the same litter is shown. M2_LME &lt;- lmer(data=mice2, weight_gain~factor(diet) + (1 | factor(litter))) summary(M2_LME) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: weight_gain ~ factor(diet) + (1 | factor(litter)) ## Data: mice2 ## ## REML criterion at convergence: -206.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.33470 -0.59248 0.03505 0.59073 1.91089 ## ## Random effects: ## Groups Name Variance Std.Dev. ## factor(litter) (Intercept) 0.00396804 0.062992 ## Residual 0.00005093 0.007136 ## Number of obs: 36, groups: factor(litter), 6 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 0.01507 0.04459 3.00000 0.338 0.758 ## factor(diet)B 0.02036 0.06306 3.00000 0.323 0.768 ## factor(diet)C 0.07358 0.06306 3.00000 1.167 0.328 ## ## Correlation of Fixed Effects: ## (Intr) fct()B ## factor(dt)B -0.707 ## factor(dt)C -0.707 0.500 Estimates are the same Standard errors are larger, due mostly to the fact that our sample size is 6, instead of 36 after accounting for diet, standard deviation in weights between litters is estimated to be 0.0629 g. (estimate of \\(\\sigma_l\\)) after accounting for diet, standard deviation in weights between mice in the same litter is estimated to be 0.0071 g. (estimate of \\(\\sigma\\)) 2.3.9 Model for Litter Means Alternatively, we could fit a model, using the 6 litters as our observations, with the mean weight in each litter as the response variable. If we now let \\(Y_i\\) represent the mean weight in litter i, our model has the form: \\[ Y_{i} = \\beta_{0}+\\beta_{1}\\textrm{DietB}_{i} +\\beta_{2}\\textrm{DietC}_{i} + \\epsilon_{i}, \\] where \\(\\epsilon_{i} \\sim\\mathcal{N}(0, \\sigma^2)\\) Since it is reasonable to assume that litters are independent, we could use an ordinary LLSR model in this context. M2_Means &lt;- lm(data=Litters, mean_weight_gain~factor(diet)) summary(M2_Means) ## ## Call: ## lm(formula = mean_weight_gain ~ factor(diet), data = Litters) ## ## Residuals: ## 1 2 3 4 5 6 ## -0.06301 0.06301 -0.04335 0.04335 0.01078 -0.01078 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.01507 0.04459 0.338 0.758 ## factor(diet)B 0.02036 0.06306 0.323 0.768 ## factor(diet)C 0.07358 0.06306 1.167 0.328 ## ## Residual standard error: 0.06306 on 3 degrees of freedom ## Multiple R-squared: 0.3261, Adjusted R-squared: -0.1231 ## F-statistic: 0.7259 on 2 and 3 DF, p-value: 0.5532 Estimates, standard errors, and p-values are identical to the ones seen in the mixed-effects model. 2.3.10 Fixed Effect for Litter in Experiment 2 If we try to treat litter as a fixed effect in Experiment 2, we would not even be able to estimate all of the parameters. M2_fixed_litter &lt;- lm(data=mice2, weight_gain~ factor(diet) + factor(litter)) summary(M2_fixed_litter) ## ## Call: ## lm(formula = weight_gain ~ factor(diet) + factor(litter), data = mice2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.0166840 -0.0041608 0.0003311 0.0042513 0.0136135 ## ## Coefficients: (2 not defined because of singularities) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.047933 0.002913 -16.453 &lt; 0.0000000000000002 *** ## factor(diet)B 0.126712 0.004120 30.755 &lt; 0.0000000000000002 *** ## factor(diet)C 0.125801 0.004120 30.533 &lt; 0.0000000000000002 *** ## factor(litter)2 0.126011 0.004120 30.585 &lt; 0.0000000000000002 *** ## factor(litter)3 -0.086691 0.004120 -21.041 &lt; 0.0000000000000002 *** ## factor(litter)4 NA NA NA NA ## factor(litter)5 0.021565 0.004120 5.234 0.000012 *** ## factor(litter)6 NA NA NA NA ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.007136 on 30 degrees of freedom ## Multiple R-squared: 0.9858, Adjusted R-squared: 0.9835 ## F-statistic: 417.2 on 5 and 30 DF, p-value: &lt; 0.00000000000000022 2.4 A Multilevel Experiment 2.4.1 Experiment 2 Illustration In example 2, we saw that treatments (diets) were assigned to litters (dams), but measurements were taken on the individual mice (pups). 2.4.2 Experiment with Variables Assigned at Different Levels Now imagine qn experimemt with the following setup diets are still assigned to dams, prior to the birth of the pups, so all mice in the same litter get the same diet within each litter three mice are given nutritional supplements after their birth and the other three are not We want to study the effect of diet and supplement on weight gain. One treatment (diet) is assigned to litters, while the other (supplement) is assigned to individual mice. For the purpose of comparing diets, our observational units are 6 independent litters. For the purpose of comparing supplements, our observational units are 36 individual mice (who are not independent) An experiment where treatments are assigned at different levels is called a multilevel experiment level 1 observational units are mice, and level 1 treatment is supplement level 2 observational units are litters, and level 2 treatment is diet 2.4.3 Experiment 3 Data head(mice3,15) ## litter diet supplement weight_gain ## 1 1 A 1 -0.033260410 ## 2 1 A 0 -0.047416660 ## 3 1 A 1 -0.052513053 ## 4 1 A 0 -0.051714521 ## 5 1 A 1 -0.046173913 ## 6 1 A 0 -0.050517749 ## 7 2 A 1 0.077840826 ## 8 2 A 0 0.070135275 ## 9 2 A 1 0.090583835 ## 10 2 A 0 0.072780711 ## 11 2 A 1 0.084600792 ## 12 2 A 0 0.078529500 ## 13 3 B 1 0.002230614 ## 14 3 B 0 -0.016336276 ## 15 3 B 1 -0.012621346 2.4.4 Graphical Analysis for Experiment 3 We use color to represent litter, and shape to represent supplement. We'll use the argument position=position_jitterdodge() to stagger litters and supplement levels, which avoids overlap and makes the graph easier to read. ggplot(data=mice3, aes(x=factor(diet), y=weight_gain, color=factor(litter), shape=factor(supplement))) + geom_point(position=position_jitterdodge()) 2.4.5 An Inappropriate Model for the 3rd Design An ordinarly linear least squares regression model fails to account for the fact that treatments were assigned to litters, not mice. It is based on the assumption that we have 36 independent mice (which is incorret). The model has the form \\[ Y_{ij} = \\beta_{0} + \\alpha\\textrm{Supplement}_i + \\beta_{1}\\textrm{DietB}_{ij} +\\beta_{2}\\textrm{DietC}_{ij} + \\epsilon_{ij}, \\] where \\(\\epsilon_{ij} \\sim\\mathcal{N}(0, \\sigma^2)\\) Output for such a model is shown below. M3_LLSR &lt;- lm(data=mice3, weight_gain~supplement + factor(diet)) summary(M3_LLSR) ## ## Call: ## lm(formula = weight_gain ~ supplement + factor(diet), data = mice3) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.072685 -0.040982 -0.005618 0.040366 0.070412 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.011974 0.015895 0.753 0.456766 ## supplement 0.008198 0.015895 0.516 0.609538 ## factor(diet)B 0.020361 0.019467 1.046 0.303431 ## factor(diet)C 0.073578 0.019467 3.780 0.000648 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.04768 on 32 degrees of freedom ## Multiple R-squared: 0.3263, Adjusted R-squared: 0.2632 ## F-statistic: 5.167 on 3 and 32 DF, p-value: 0.005021 2.4.6 A More Appropriate Model for Experiment 3 We instead fit a linear mixed effects model. Since we want to study the effects of diet and supplement, we treat supplement and diet as fixed effects. Since we want to account for correlation due to mice being in the same litter, we treat litter as a random effect. Our model has the form \\[ Y_{ij} = \\beta_{0} + \\alpha\\textrm{Supplement}_i + \\beta_{1}\\textrm{DietB}_{ij} +\\beta_{2}\\textrm{DietC}_{ij} + l_{i} + \\epsilon_{ij}, \\] where \\(l_i\\sim\\mathcal{N}(0, \\sigma^2_l)\\), and \\(\\epsilon_{ij} \\sim\\mathcal{N}(0, \\sigma^2)\\) Output for a model that accounts for correlation between mice in the same litter is shown. M3_LME &lt;- lmer(data=mice3, weight_gain ~ supplement + factor(diet) + (1 | factor(litter))) summary(M3_LME) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: weight_gain ~ supplement + factor(diet) + (1 | factor(litter)) ## Data: mice3 ## ## REML criterion at convergence: -203.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.12499 -0.76119 0.06055 0.60135 1.64980 ## ## Random effects: ## Groups Name Variance Std.Dev. ## factor(litter) (Intercept) 0.00396973 0.063006 ## Residual 0.00004076 0.006384 ## Number of obs: 36, groups: factor(litter), 6 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 0.011974 0.044603 3.003417 0.268 0.805735 ## supplement 0.008198 0.002128 29.000000 3.853 0.000596 *** ## factor(diet)B 0.020361 0.063060 3.000000 0.323 0.767980 ## factor(diet)C 0.073578 0.063060 3.000000 1.167 0.327609 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) spplmn fct()B ## supplement -0.024 ## factor(dt)B -0.707 0.000 ## factor(dt)C -0.707 0.000 0.500 Interpretations Interpretations for fixed effects are the same as in LLSR. We expect mice on the supplement to gain 0.008 g. more than mice not on the supplement, assuming they get the same diet. We expect mice in diet B to gain 0.02 g. more than mice on diet A, assuming supplement is held constant. We expect mice in diet C to gain 0.07 g. more than mice on diet A, assuming supplement is held constant After accounting for differences in diet and supplement, the standard deviation in weights between litters is estimated to be 0.063 g. (an estimate of \\(\\sigma_l\\)). After accounting for differences in diet and supplement, the standard deviation in weights between mice in the same litter is estimated to be 0.00638 g. (an estimate of \\(\\sigma\\)). 2.4.7 Comparison of LLSR and LME Models Compared to the incorrect LLSR model, when we use the linear mixed effects model: estimates for fixed effects supplement and diet do not change standard error for supplement is smaller - we get a more precise comparison for supplements because the model has accounted for variability due to differences in litters standard error for diet is larger - since diets were assigned to litters, our sample size is 6, not 36, so standard errors are higher The mixed effects model suggests evidence of differences due to supplement, but not evidence of differences due to diet. This is the opposite of the incorrect LLSR model. "],["multilevel-models.html", "Chapter 3 Multilevel Models 3.1 Music Performance Anxiety Study: Data and Exploratory Analysis 3.2 Modeling the Musician Data 3.3 Random Slopes Model 3.4 Unconditional Means Model 3.5 Building A Multilevel Model", " Chapter 3 Multilevel Models These notes provide a summary of Chapter 8 in Beyond Multiple Linear Regression by Roback and Legler. Much of the code that appears here comes from the textbook's Github repository. # Packages required for Chapter 8 library(MASS) library(gridExtra) library(mnormt) library(lme4) library(lmerTest) library(knitr) library(kableExtra) library(tidyverse) 3.1 Music Performance Anxiety Study: Data and Exploratory Analysis 3.1.1 Description of the Study A study by Miller (2010) examined the emotional state of musicians before performances and factors that might affect their emotional state. data on 497 different performances by 37 different performers performers completed Positive Affect Negative Affect Schedule (PANAS) before each performance, measuring characteristics of anxiety and happiness before performing we are interested in whether there are relationships between performance anxiety and characteristics such as performance type (solo, large ensemble, or small ensemble); audience (instructor, public, students, or juried); if the piece was played from memory; age; gender; instrument (voice, orchestral, or keyboard); and, years studying the instrument also have information on personalities of musicians, obtained through through the Multidimensional Personality Questionnaire (MPQ), which provided scores for absorption positive emotionality (PEM---a composite of well-being, social potency, achievement, and social closeness); negative emotionality (NEM---a composite of stress reaction, alienation, and aggression); and, constraint (a composite of control, harm avoidance, and traditionalism). 3.1.2 Variables We focus on the following variables: id = unique musician identification number diary = cumulative total of diaries filled out by musician perf_type = type of performance (Solo, Large Ensemble, or Small Ensemble) audience = who attended (Instructor, Public, Students, or Juried) memory = performed from Memory, using Score, or Unspecified na = negative affect score from PANAS gender = musician gender instrument = Voice, Orchestral, or Piano mpqab = absorption subscale from MPQ mpqpem = positive emotionality (PEM) composite scale from MPQ mpqnem = negative emotionality (NEM) composite scale from MPQ 3.1.3 The Data #Getting started music = read.csv(&quot;https://raw.githubusercontent.com/proback/BeyondMLR/master/data/musicdata.csv&quot;) head(music,10) # examine first 10 rows ## X id diary previous perform_type memory audience pa na age ## 1 1 1 1 0 Solo Unspecified Instructor 40 11 18 ## 2 2 1 2 1 Large Ensemble Memory Public Performance 33 19 18 ## 3 3 1 3 2 Large Ensemble Memory Public Performance 49 14 18 ## 4 4 1 4 3 Solo Memory Public Performance 41 19 18 ## 5 5 1 5 4 Solo Memory Student(s) 31 10 18 ## 6 6 1 6 5 Solo Memory Student(s) 33 13 18 ## 7 7 1 7 6 Solo Memory Instructor 34 11 18 ## 8 8 1 8 7 Solo Memory Juried Recital 43 13 18 ## 9 9 1 9 8 Solo Score Instructor 34 10 18 ## 10 10 1 10 9 Solo Score Student(s) 45 10 18 ## gender instrument years_study mpqab mpqsr mpqpem mpqnem mpqcon ## 1 Female voice 3 16 7 52 16 30 ## 2 Female voice 3 16 7 52 16 30 ## 3 Female voice 3 16 7 52 16 30 ## 4 Female voice 3 16 7 52 16 30 ## 5 Female voice 3 16 7 52 16 30 ## 6 Female voice 3 16 7 52 16 30 ## 7 Female voice 3 16 7 52 16 30 ## 8 Female voice 3 16 7 52 16 30 ## 9 Female voice 3 16 7 52 16 30 ## 10 Female voice 3 16 7 52 16 30 dim(music) # should be 497 x 18 ## [1] 497 18 Full Dataset 3.1.4 Some Data Wrangling We'll select variables we're interested in working with. select &lt;- dplyr:: select keydata &lt;- music %&gt;% dplyr::select(id, diary, perform_type, memory, audience, na, gender, instrument, mpqab, mpqpem, mpqnem) head(keydata) ## id diary perform_type memory audience na gender instrument ## 1 1 1 Solo Unspecified Instructor 11 Female voice ## 2 1 2 Large Ensemble Memory Public Performance 19 Female voice ## 3 1 3 Large Ensemble Memory Public Performance 14 Female voice ## 4 1 4 Solo Memory Public Performance 19 Female voice ## 5 1 5 Solo Memory Student(s) 10 Female voice ## 6 1 6 Solo Memory Student(s) 13 Female voice ## mpqab mpqpem mpqnem ## 1 16 52 16 ## 2 16 52 16 ## 3 16 52 16 ## 4 16 52 16 ## 5 16 52 16 ## 6 16 52 16 3.1.5 Multilevel Structure Note that we have multiple observations on the same musicians Since observations on the same musician will be correlated, we need to use a multilevel model with a random effect for musician. Level One Variables: are those measured at the most frequently occurring observational unit (the 497 performances) - negative affect (our response variable) - performance characteristics (type, audience, if music was performed from memory) - number of previous performances with a diary entry Level Two Variables: are those measured on larger observational units (the musicians) - demographics (age and gender of musician) - instrument used and number of previous years spent studying that instrument - baseline personality assessment (MPQ measures of positive emotionality, negative emotionality, constraint, stress reaction, and absorption) 3.1.6 Questions of Interest Do musicians playing orchestral instruments experience different levels or performance anxiety than those playing keyboard instruments or vocalists? Does playing in a large ensemble (as opposed to a small group or solo performance) have an impact on performance anxiety? Does the type of audience impact performance anxiety? Does performance anxiety decrease with experience? Are measures of the musician's attitude/personality, such as positive emotions, negative emotions, and absorption associated with performance anxiety? For a single musician, is the amount of performance anxiety consistent across performances, or does it vary from one performance to the next? 3.1.7 Number of Performances by Musician When creating graphical summaries of level one covariates (variables) it is helpful to plot both 1) the 497 observations individually, and 2) averages for each of the 37 individuals, averaging across performances. Number of performances by each musician: # number of diary entries for each subject music %&gt;% count(id) ## id n ## 1 1 13 ## 2 2 14 ## 3 3 15 ## 4 5 12 ## 5 6 15 ## 6 7 15 ## 7 8 14 ## 8 9 15 ## 9 10 15 ## 10 12 13 ## 11 13 15 ## 12 15 15 ## 13 16 6 ## 14 17 15 ## 15 18 15 ## 16 19 15 ## 17 20 2 ## 18 21 15 ## 19 22 15 ## 20 24 15 ## 21 25 15 ## 22 27 15 ## 23 28 15 ## 24 29 15 ## 25 30 14 ## 26 32 15 ## 27 33 6 ## 28 34 15 ## 29 35 15 ## 30 36 15 ## 31 37 15 ## 32 38 15 ## 33 39 15 ## 34 40 15 ## 35 41 11 ## 36 42 13 ## 37 43 4 3.1.8 Number of Performances of Each Type We summarize level one covariates, ignoring the fact that there are multiple observations on the same musicians. # Exploratory data analysis # Summarize Level 1 covariates (and responses) by # ignoring within subject correlation and pretending # all observations are independent music %&gt;% count(perform_type) ## perform_type n ## 1 Large Ensemble 136 ## 2 Small Ensemble 82 ## 3 Solo 279 music %&gt;% count(audience) ## audience n ## 1 Instructor 149 ## 2 Juried Recital 44 ## 3 Public Performance 204 ## 4 Student(s) 100 3.1.9 Distribution of Negative Affect for All Performances We display the distribution of the response variable (negative affect) across all 497 performances. # create ggplot theme for plots # theme with grid, grey background theme.1 &lt;- theme(axis.title.x = element_text(size = 14), axis.title.y = element_text(size = 14), plot.title=element_text(hjust=.9,face=&quot;italic&quot;,size=12)) ## Histogram of negative affect frequencies na.all &lt;- ggplot(data=music,aes(x=na)) + geom_histogram(binwidth = 2, fill = &quot;white&quot;,color = &quot;black&quot;) + theme.1 + xlim(10,35) + xlab(&quot;Negative Affect&quot;) + ylab(&quot;Frequency&quot;) + labs(title=&quot;(a)&quot;) na.all 3.1.10 Distribution of Average Negative Affect for each Musician We also create a level two dataset, containing the average negative affect across all of the musician's performances. # Create Level2 data set by picking off one observation # per subject, which would be easier if every subject # had a diary entry labeled &#39;1&#39; - should be 37 rows # and 6 columns (one per L2 variable) music.lev2 &lt;- keydata %&gt;% group_by(id) %&gt;% filter(row_number() == 1) %&gt;% select(id, gender:mpqnem) # Add average across all performances for each subject # for EDA plots meanbysubj &lt;- music %&gt;% group_by(id) %&gt;% summarise(meanbysubj = mean(na, na.rm = TRUE)) music.lev2 &lt;- music.lev2 %&gt;% left_join(meanbysubj, by = &quot;id&quot;) head(music.lev2) ## # A tibble: 6 x 7 ## # Groups: id [6] ## id gender instrument mpqab mpqpem mpqnem meanbysubj ## &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 Female voice 16 52 16 12.3 ## 2 2 Female voice 25 28 21 13.8 ## 3 3 Female voice 12 23 21 13.6 ## 4 5 Female orchestral instrument 28 54 40 18 ## 5 6 Female voice 27 58 26 12.7 ## 6 7 Female orchestral instrument 11 41 44 17.5 We display the mean negative affect scores for each of the 37 musicians. na.mean &lt;- ggplot(data=music.lev2,aes(x=meanbysubj)) + geom_histogram(binwidth = 2, fill = &quot;white&quot;, color = &quot;black&quot;) + theme.1 + xlim(10,35) + xlab(&quot;Mean Negative Affect&quot;) + ylab(&quot;Frequency&quot;) + labs(title=&quot;(b)&quot;) na.mean 3.1.11 Distribution of Level Two Covariates We examine the distribution of level 2 covariate instrument type (obtained from first performance by each musician, since these will be the same for all performances). music.lev2 %&gt;% ungroup(id) %&gt;% count(instrument) ## # A tibble: 3 x 2 ## instrument n ## &lt;fct&gt; &lt;int&gt; ## 1 keyboard (piano or organ) 5 ## 2 orchestral instrument 17 ## 3 voice 15 3.1.12 Distributions of NEM, PEM, Absorption nem1 &lt;- ggplot(data=music.lev2,aes(x=mpqnem)) + geom_histogram(binwidth = 5, fill = &quot;white&quot;, color = &quot;black&quot;) + theme.1 + xlab(&quot;NEM&quot;) + ylab(&quot;Frequency&quot;) + labs(title=&quot;(a)&quot;) pem1 &lt;- ggplot(data=music.lev2,aes(x=mpqpem)) + geom_histogram(binwidth = 5, fill = &quot;white&quot;, color = &quot;black&quot;) + theme.1 + xlab(&quot;PEM&quot;) + ylab(&quot;&quot;) + labs(title=&quot;(b)&quot;) abs &lt;- ggplot(data=music.lev2,aes(x=mpqab)) + geom_histogram(binwidth = 5, fill = &quot;white&quot;, color = &quot;black &quot;) + theme.1 + xlab(&quot;Absorption&quot;) + ylab(&quot;&quot;) + labs(title=&quot;(c)&quot;) grid.arrange(nem1,pem1,abs,ncol=3) 3.1.13 Negative Affect by Performance Type, Audience Type, and Previous Performances Boxplots of two categorical Level One covariates (performance type (a) and audience type (b)) vs. model response, and scatterplot of one continuous Level One covariate (number of previous diary entries (c)) vs. model response (negative affect). Each plot contains one observation for each of the 497 performances. # Look at relationships among Level 1 covariates and # primary response (again ignoring correlation). # Boxplots for categorical covariates and # scatterplots and lattice plot for continuous covariates. # boxplot of negative affect by performance type box.perform &lt;- ggplot(data=music,aes(factor(perform_type),na)) + geom_boxplot() + theme.1 + coord_flip() + ylab(&quot;Negative affect&quot;) + xlab(&quot;&quot;) + labs(title=&quot;(a) Negative Affect by Instrument Type&quot;) # boxplot of negative affect by audience box.audience &lt;- ggplot(data=music,aes(factor(audience),na)) + geom_boxplot() + theme.1 + coord_flip() + ylab(&quot;Negative affect&quot;) + xlab(&quot;&quot;) + labs(title=&quot;(b) Negative Affect by Performance Type&quot;) # scatterplot of negative affect versus number of # previous performances scatter.previous &lt;- ggplot(data=music, aes(x=previous,y=na)) + geom_point() + theme.1 + geom_smooth(method=&quot;lm&quot;,color=&quot;black&quot;) + ylab(&quot;Negative affect&quot;) + xlab(&quot;Previous Performances&quot;) + labs(title=&quot;(c) Negative Affect by Number of Previous Performances&quot;) # all three together grid.arrange(box.perform,box.audience,scatter.previous,ncol=2) 3.1.14 Lattice Plot for Negative Affect by Performance Type We plot negative affect by type of performance for each musician individually. (Lattice plot) # Lattice plot for NA vs. Performance Type ggplot(music,aes(x=factor(perform_type),y=na)) + theme.1 + geom_dotplot(binaxis=&quot;y&quot;,stackdir=&quot;center&quot;,binwidth=25/30) + facet_wrap(~id,ncol=5) + theme(strip.text.x=element_blank()) + coord_flip() + labs(x=&quot;Performance Type&quot;,y=&quot;Negative Affect&quot;) 3.1.15 Lattice Plot for Negative Affect by Audience Type We plot negative affect by type of audience for each musician individually. # Lattice plot for NA vs. Audience ggplot(music,aes(x=factor(audience),y=na)) + theme.1 + geom_dotplot(binaxis=&quot;y&quot;,stackdir=&quot;center&quot;,binwidth=25/30) + facet_wrap(~id,ncol=5) + theme(strip.text.x=element_blank()) + coord_flip() + labs(x=&quot;Audience&quot;,y=&quot;Negative Affect&quot;) 3.1.16 Lattice Plot for Previous Performances vs Negative Affect We plot of previous performances vs. negative affect, with separate scatterplots with fitted lines by musician # Lattice plot for NA vs. Previous Performances ggplot(music,aes(x=previous,y=na)) + theme.1 + geom_point() + geom_smooth(method=&quot;lm&quot;,color=&quot;black&quot;) + facet_wrap(~id,ncol=5) + theme(strip.text.x=element_blank()) + ylim(10,35) + labs(x=&quot;Previous Performances&quot;,y=&quot;Negative Affect&quot;) 3.1.17 Negative Affect by Instrument Type Boxplots of the categorical Level Two covariate (instrument) vs. model response (negative affect). Plot (a) is based on all 497 observations from all 37 subjects, while plot (b) uses only one observation per subject. # Look at relationships among Level 2 covariates and # negative affect (again ignoring correlation) instr.all &lt;- ggplot(data=music,aes(factor(instrument),na)) + geom_boxplot() + coord_flip() + theme.1 + ylab(&quot;Negative Affect&quot;) + xlab(&quot;&quot;) + labs(title=&quot;(a)&quot;) + ylim(10,35) instr.mean &lt;- ggplot(data=music.lev2, aes(factor(instrument),meanbysubj)) + geom_boxplot() + coord_flip() + theme.1 + ylab(&quot;Mean Negative Affect&quot;) + xlab(&quot;&quot;) + labs(title=&quot;(b)&quot;) + ylim(10,35) grid.arrange(instr.all, instr.mean, ncol = 1) 3.1.18 More Data Wrangling We create variables for whether or not musician played an orchestral instrument (as opposed to playing piano or being a vocalist), and for whether performance was part of a large ensemble (as opposed to a small ensemble or solo). 3.1.19 Lattice Plot for Large Ensemble Effect # Lattice plot for NA vs. Performance Type ggplot(music,aes(x=large,y=na)) + theme.1 + geom_point() + geom_smooth(method=&quot;lm&quot;,color=&quot;black&quot;) + facet_wrap(~id,ncol=5) + theme(strip.text.x=element_blank()) + ylim(10,35) + labs(x=&quot;Large Ensemble Performance&quot;,y=&quot;Negative Affect&quot;) 3.1.20 Boxplots for Orchestral Instrument Effect # Look at relationships among Level 2 covariates and # negative affect (again ignoring correlation) instr.all &lt;- ggplot(data=music,aes(factor(orch),na)) + geom_boxplot() + coord_flip() + theme.1 + ylab(&quot;Negative Affect&quot;) + xlab(&quot;Orchestral Instrument&quot;) + labs(title=&quot;(a)&quot;) + ylim(10,35) instr.mean &lt;- ggplot(data=music.lev2, aes(factor(orch),meanbysubj)) + geom_boxplot() + coord_flip() + theme.1 + ylab(&quot;Mean Negative Affect&quot;) + xlab(&quot;Orchestral Instrument&quot;) + labs(title=&quot;(b)&quot;) + ylim(10,35) grid.arrange(instr.all, instr.mean, ncol = 1) 3.1.21 Negative Affect by PEM, NEM, Absorption Scatterplots of continuous Level Two covariates (positive emotionality (PEM), negative emotionality (NEM), and absorption) vs. model response (negative affect). The top plots (a1, b1, c1) are based on all 497 observations from all 37 subjects, while the bottom plots (a2, b2, c2) use only one observation per subject. pem2.all &lt;- ggplot(data=music,aes(x=mpqpem,y=na)) + geom_point() + geom_smooth(method=&quot;lm&quot;,color=&quot;black&quot;) + theme.1 + ylab(&quot;Negative Affect&quot;) + xlab(&quot;PEM&quot;) + labs(title=&quot;(a1)&quot;) nem2.all &lt;- ggplot(data=music,aes(x=mpqnem,y=na)) + geom_point() + geom_smooth(method=&quot;lm&quot;,color=&quot;black&quot;) + theme.1 + ylab(&quot;&quot;) + xlab(&quot;NEM&quot;) + labs(title=&quot;(b1)&quot;) abs2.all &lt;- ggplot(data=music,aes(x=mpqab,y=na)) + geom_point() + geom_smooth(method=&quot;lm&quot;,color=&quot;black&quot;) + theme.1 + ylab(&quot;&quot;) + xlab(&quot;Absorption&quot;) + labs(title=&quot;(c1)&quot;) pem2.mean &lt;- ggplot(data = music.lev2, aes(x = mpqpem, y = meanbysubj)) + geom_point() + geom_smooth(method = &quot;lm&quot;, color = &quot;black&quot;) + theme.1 + ylab(&quot;Mean Negative Affect&quot;) + xlab(&quot;PEM&quot;) + labs(title = &quot;(a2)&quot;) nem2.mean &lt;- ggplot(data = music.lev2, aes(x = mpqnem, y = meanbysubj)) + geom_point() + geom_smooth(method = &quot;lm&quot;, color = &quot;black&quot;) + theme.1 + ylab(&quot;&quot;) + xlab(&quot;NEM&quot;) + labs(title = &quot;(b2)&quot;) abs2.mean &lt;- ggplot(data = music.lev2, aes(x = mpqab, y = meanbysubj)) + geom_point() + geom_smooth(method = &quot;lm&quot;, color = &quot;black&quot;) + theme.1 + ylab(&quot;&quot;) + xlab(&quot;Absorption&quot;) + labs(title=&quot;(c2)&quot;) mli.scatmat1 &lt;- grid.arrange(pem2.all, nem2.all, abs2.all, pem2.mean, nem2.mean, abs2.mean, ncol = 3) grid.arrange(pem2.all, nem2.all, abs2.all, pem2.mean, nem2.mean, abs2.mean, ncol = 3) 3.2 Modeling the Musician Data 3.2.1 Model Notation Let \\(Y_{ij}\\) be the negative affect (na) score of the \\(i^{th}\\) subject before performance \\(j\\). head(music) ## X id diary previous perform_type memory audience pa na age ## 1 1 1 1 0 Solo Unspecified Instructor 40 11 18 ## 2 2 1 2 1 Large Ensemble Memory Public Performance 33 19 18 ## 3 3 1 3 2 Large Ensemble Memory Public Performance 49 14 18 ## 4 4 1 4 3 Solo Memory Public Performance 41 19 18 ## 5 5 1 5 4 Solo Memory Student(s) 31 10 18 ## 6 6 1 6 5 Solo Memory Student(s) 33 13 18 ## gender instrument years_study mpqab mpqsr mpqpem mpqnem mpqcon orch large ## 1 Female voice 3 16 7 52 16 30 0 0 ## 2 Female voice 3 16 7 52 16 30 0 1 ## 3 Female voice 3 16 7 52 16 30 0 1 ## 4 Female voice 3 16 7 52 16 30 0 0 ## 5 Female voice 3 16 7 52 16 30 0 0 ## 6 Female voice 3 16 7 52 16 30 0 0 For example \\(Y_{15}=10\\). We'll investigate the relationship between negative affect and playing an orchestral instrument (level 2), and playing in a large ensemble (level 1), as well as a possible interaction between these explanatory variables. 3.2.2 LLSR Model (Clearly inappropriate) We treat the 497 observations as independent and run a linear least-squares regression model. The model is: \\[ \\begin{align*} Y_{ij} &amp; = \\alpha_{0}+\\alpha_{1}\\textrm{Orch}_{i}+\\beta_{0}\\textrm{LargeEns}_{ij}+\\beta_{1}\\textrm{Orch}_{i}\\textrm{LargeEns}_{ij} +\\epsilon_{ij}, \\end{align*} \\] where \\(\\epsilon_{ij} \\sim\\mathcal{N}(0,\\sigma^2)\\). 3.2.3 LLSR Model Output # Linear least square regression model with LINE conditions model0 &lt;- lm(na ~ orch + large + orch:large, data = music) summary(model0) Call: lm(formula = na ~ orch + large + orch:large, data = music) Residuals: Min 1Q Median 3Q Max -7.510 -3.721 -1.444 3.279 19.279 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 15.7212 0.3591 43.778 &lt; 0.0000000000000002 *** orch 1.7887 0.5516 3.243 0.00126 ** large -0.2767 0.7910 -0.350 0.72662 orch:large -1.7087 1.0621 -1.609 0.10831 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 5.179 on 493 degrees of freedom Multiple R-squared: 0.02782, Adjusted R-squared: 0.0219 F-statistic: 4.702 on 3 and 493 DF, p-value: 0.003012 Clear violation of independence assumption! Performances by same musician likely to have higher correlation than those by different musicians. Intuitively, this model is likely to: * overestimate uncertainty associated with the level one variable (large ensemble), since it will fail to account for variability that can be explained by differences between musicians * underestimate uncertainty associated with the level two variable (orchestral instrument), since it will act as if the sample size is 497 independent performances, instead of 37 independent musicians 3.2.4 Random vs. Fixed Effects Instead, we fit a linear mixed effect model to account for the multilevel structure in the data. We're interested in comparing axiety between instrument types (instrumental, non-instrumental) and types of performance (solos, small ensembles, and large ensembles), so instrument type and performance type are fixed effects. We're not interested in comparing the 37 musicians themselves, but we want to account for correlation due to having multiple performances by the same musicians. We can think of them as a sample from a larger population of all musicians. Including a random effect for musician in our model helps explain variability in performance anxiety, and allows us to draw more precise conclusions about performance type. Fixed effects tell us about the mean structure (expected response). Random effects tell us about the amount of variability associated with our estimates. 3.2.5 An Initial Linear Mixed Effect Model This model has the form: \\[ \\begin{align*} Y_{ij} &amp; = \\alpha_{0}+\\alpha_{1}\\textrm{Orch}_{i}+\\beta_{0}\\textrm{LargeEns}_{ij}+\\beta_{1}\\textrm{Orch}_{i}\\textrm{LargeEns}_{ij} + u_{i}+\\epsilon_{ij}, \\end{align*} \\] where \\(u_i \\sim\\mathcal{N}(0,\\sigma^2_u)\\), and \\(\\epsilon_{ij} \\sim\\mathcal{N}(0,\\sigma^2)\\). We assume \\(u_i\\) and \\(\\epsilon_{ij}\\) are independent. \\(u_i\\) is a random effect corresponding to musician id. 3.2.6 Initial Mixed Effects Model in R We fit the model using the lmer() function in the lme4 package. If the the lmerTest package is loaded, approximate p-values are returned. These are approximate, because the exact distribution of the t-statistics is unknown. Satterthwaite showed that these t-statistics approximately follow t-distributions, with non-integer degrees of freedom. model1 &lt;- lmer(data=music, na ~ orch + large + orch:large + (1 | id), REML=TRUE) summary(model1) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ orch + large + orch:large + (1 | id) Data: music REML criterion at convergence: 2987.4 Scaled residuals: Min 1Q Median 3Q Max -1.9216 -0.6688 -0.1564 0.5043 4.1699 Random effects: Groups Name Variance Std.Dev. id (Intercept) 5.131 2.265 Residual 21.882 4.678 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 15.9026 0.6187 41.4059 25.703 &lt;0.0000000000000002 *** orch 1.7100 0.9131 42.8467 1.873 0.0679 . large -0.8918 0.8415 473.6492 -1.060 0.2898 orch:large -1.4650 1.0880 488.6918 -1.347 0.1788 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) orch large orch -0.678 large -0.282 0.191 orch:large 0.218 -0.308 -0.773 3.2.7 Mixed Effects Model Interpretations For orch=0, the prediction equation is: \\[ \\hat{Y}_{ij} = \\alpha_{0}+\\beta_{0}\\textrm{LargeEns}_{ij} \\] we estimate that the average negative affect score for performers with non-orchestral instruments when playing a solo or with a small ensemble is \\(\\hat{\\alpha}_0 = 15.9\\). We estimate that for non-orchestral musicians, average negative affect is \\(\\hat{\\beta}_0 = -0.89\\) (i.e. 0.89 points lower) when performing in a large ensemble, compared with playing in a small ensemble or a solo. For orch=1, the prediction equation is: \\[ \\hat{Y}_{ij} = (\\alpha_{0}+\\alpha_{1})+(\\beta_{0} + \\beta_1)\\textrm{LargeEns}_{ij} \\] we estimate that the average negative affect score for performers with orchestral instruments when performing in solos or small ensembles is \\(\\hat{\\alpha}_0 + \\hat{\\alpha}_0 = 17.3\\). We estimate that for orchestral musicians, average negative affect is \\(\\hat{\\beta}_0 + \\hat{\\beta}_1 = -0.89 - 1.46 = -2.35\\) (i.e. 2.35 points lower) when performing in a large ensemble, compared with playing in a small ensemble or a solo. Negative affect score tends to be higher for orchestral musicians than non orchestral musicians when performing solos or in small ensembles, but that negative affect also decreases more for orchestral musicians than non-orchestral musicians, when playing in a large ensemble. The interaction term is not statistically significany, indicating it is plausible that the effect of playing in a large ensemble, compared to a solo or with a small ensemble is the same for orchestral and non-orchestral musicians. After accounting for performance type and instrument type, and their interaction, the standard deviation in negative affect scores between different musicians is estimated to be \\(\\hat{\\sigma}_u=2.265\\). After accounting for performance type, instrument type, and their interaction, the standard deviation in negative affect scores between different performances by the same musician is estimated to be \\(\\hat{\\sigma}_u=4.68\\). There is more variability in negative affect between different performances by the same musician than between performances by different musicians, after accounting for performance type, instrument type, and their interaction. Standard errors on level 1 variable orch goes up considerably, which is expected since the mixed effects model understands that the appropriate sampel size is the 37 musicians not the 497 performances. Standard errors on level 2 variable large and the interaction go up slightly as well. This is different than what we've seen before. Since there is more variability between individual performances, than between musicians (\\(\\sigma&gt;\\sigma_l\\)), accounting for variability explained by performers does not improve precision of estimates. 3.2.8 Mixed Effects Model Without Interaction We might drop the interaction term to make interpretation easier. This gives the model: \\[ \\begin{align*} Y_{ij} &amp; = \\alpha_{0}+\\alpha\\textrm{Orch}_{i}+\\beta\\textrm{LargeEns}_{ij} + u_{i}+\\epsilon_{ij}, \\end{align*} \\] where \\(u_i \\sim\\mathcal{N}(0,\\sigma^2)\\), and \\(\\epsilon_{ij} \\sim\\mathcal{N}(0,\\sigma^2)\\). We assume \\(u_i\\) and \\(\\epsilon_{ij}\\) are independent. model1b &lt;- lmer(data=music, na ~ orch + large + (1 | id), REML=TRUE) summary(model1b) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ orch + large + (1 | id) Data: music REML criterion at convergence: 2991.2 Scaled residuals: Min 1Q Median 3Q Max -1.9316 -0.6953 -0.1835 0.4684 4.1262 Random effects: Groups Name Variance Std.Dev. id (Intercept) 5.214 2.283 Residual 21.901 4.680 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 16.0853 0.6074 38.0476 26.482 &lt; 0.0000000000000002 *** orch 1.3317 0.8742 35.4893 1.523 0.136533 large -1.7707 0.5339 493.3004 -3.317 0.000978 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) orch orch -0.658 large -0.182 -0.077 3.2.9 Interpretations for Model without Interaction we estimate that the average negative affect score for performers with non-orchestral instruments when playing a solo or with a small ensemble is \\(\\hat{\\alpha}_0 = 16.09\\). We estimate that, average negative affect is \\(\\hat{\\alpha}_1 = 1.33\\) points higher for musicians playing an orchestral instrument, compared to those playing a keyboard or vocalists, assuming performance type is the same. We estimate that, average negative affect is \\(\\hat{\\beta}_0 = -1.77\\) points (i.e. 1.78 points lower) when performing in a large ensemble, compared with playing in a small ensemble or a solo, assuming instrumental type is the same. After accounting for performance type and instrument type there the standard deviation in negative affect scores between different musicians is estimated to be \\(\\hat{\\sigma}_u=2.28\\). After accounting for performance type, instrument type, there the standard deviation in negative affect scores between different performances by the same musician is estimated to be \\(\\hat{\\sigma}_u=4.68\\). There is more variability in negative affect between different performances by the same musician than between performances by different musicians, after accounting for performance type, instrument type. 3.2.10 Assumptions in First Mixed Effects Model This model assumes that: Expected negative affect differs between instrument types and performance types, and the effect of performing in a large ensemble is allowed to differ between instrumental and non-instrumental musicians. Negative affect scores for different musicians deviate from one another according to a normal distribution with mean 0 and standard deviation \\(\\sigma_u\\) (introducing correlation in error terms between performances by the same musician). For each musician, negative affect scores between performances deviate from each other according to a normal distribution with standard deviation \\(\\sigma\\). 3.3 Random Slopes Model 3.3.1 Differences in Large vs Small/Solo The random effect \\(u_i\\) in the previous model captures random deviations in negative affect score between individual musicians, after accounting for instrument type and performance type. The model assumes that the difference in negative affect, when performing in an ensemble compared to performing a solo or in a small ensemble is constant accross musicians. This difference can be estimated using fixed effects (e.g. \\(\\beta\\)). Alternatively, we might want to build a model that allows differences in negative affect between solos/small ensemble performances and large ensemble performances to vary randomly between performers. Recall the lattice plot: # Lattice plot for NA vs. Performance Type ggplot(music,aes(x=large,y=na)) + theme.1 + geom_point() + geom_smooth(method=&quot;lm&quot;,color=&quot;black&quot;) + facet_wrap(~id,ncol=5) + theme(strip.text.x=element_blank()) + ylim(10,35) + labs(x=&quot;Large Ensemble Performance&quot;,y=&quot;Negative Affect&quot;) 3.3.2 Random Slopes Model To do this, we add a random effect for the slope (or in this case difference) between performance types for each performer. Model: \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0}+\\alpha\\textrm{Orch}_{i}+\\beta\\textrm{LargeEns}_{ij}] \\textrm{} + [u_{i}+v_{i}\\textrm{LargeEns}_{ij}+\\epsilon_{ij}] \\end{align*} \\] The first set of brackets describes the fixed effects, or expectation structure, and the second set describes the random component, or variability associated with performances. \\(u_i\\) - (the random intercept) is a random effect pertaining to negative affect scores between musicians for solos/small ensembles (one \\(u\\) for each musician). \\(v_i\\) - (the random slope) is a random effect pertaining to changes in negative affect scores for large ensemble performances, compared to solo/small ensemble performances for individual musicians (one \\(v\\) for each musician). \\(\\epsilon_{ij}\\) - is a random error term pertaining to differences between individual performances by the same musician. (one \\(\\epsilon\\) per performance.) 3.3.3 Specifying Distribution of Random Effects We still assume all of the random effects, \\(u_i\\), \\(v_i\\), and \\(\\epsilon_{ij}\\) follow normal distributions. assume that the errors associated with each performance of a particular musician can be described as: \\(\\epsilon_{ij}\\sim N(0,\\sigma^2)\\). We allow for the possibility of correlation between intercept \\(u_i\\) and slope \\(v_i\\) for user i. This allows the for possibility that musicians with higher performance anxiety playing solos or in small ensembles might see a more (or less) decrease when playing in a large ensemble than those with less performance anxiety when playing solos or in small ensembles. To allow for this correlation, we assume that \\(u_i\\) and \\(v_i\\) follow a multivariate normal distribution Mathematically, we can express this as: \\[ \\begin{equation*} \\left[ \\begin{array}{c} u_{i} \\\\ v_{i} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{u}^{2} &amp; \\rho_{uv}\\sigma_{u}\\sigma_v \\\\ \\rho_{uv}\\sigma_{u}\\sigma_v &amp; \\sigma_{v}^{2} \\end{array} \\right] \\right) \\end{equation*} \\] where \\(\\sigma_{u}^{2}\\) is the variance of the \\(u_{i}\\) terms, \\(\\sigma_{v}^{2}\\) is the variance of the \\(v_{i}\\) terms, and \\[ \\begin{equation*} \\rho_{uv} = \\frac{\\sigma_{uv}}{\\sigma_{u}\\sigma_{v}} \\end{equation*} \\] represents the correlation between \\(u_i\\) and \\(v_i\\) \\((-1\\leq\\rho_{uv}\\leq1)\\). \\(\\sigma_{uv}\\) is the covariance between the \\(u_{i}\\) and the \\(v_{i}\\) terms (describing how those two terms vary together). We still assume \\(\\epsilon_{ij}\\) is independent of \\(u_i\\) and \\(v_i\\). 3.3.4 Random Slopes Model with Error Term Distributions Model: \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0}+\\alpha\\textrm{Orch}_{i}+\\beta\\textrm{LargeEns}_{ij}] \\textrm{} + [u_{i}+v_{i}\\textrm{LargeEns}_{ij}+\\epsilon_{ij}] \\end{align*} \\] \\(\\epsilon_{ij}\\sim N(0,\\sigma^2)\\), and \\[ \\begin{equation*} \\left[ \\begin{array}{c} u_{i} \\\\ v_{i} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{u}^{2} &amp; \\rho_{uv}\\sigma_{u}\\sigma_v \\\\ \\rho_{uv}\\sigma_{u}\\sigma_v &amp; \\sigma_{v}^{2} \\end{array} \\right] \\right) \\end{equation*} \\] 3.3.5 Random Slopes Model in R To fit the random slopes model in R, we write (large | id), instead of (1 | id). model2b &lt;- lmer(data=music, na ~ orch + large + (large | id), REML=TRUE) summary(model2b) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ orch + large + (large | id) Data: music REML criterion at convergence: 2990.7 Scaled residuals: Min 1Q Median 3Q Max -1.9563 -0.6808 -0.1900 0.4821 4.1544 Random effects: Groups Name Variance Std.Dev. Corr id (Intercept) 5.8311 2.4148 large 0.7198 0.8484 -0.59 Residual 21.7807 4.6670 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 16.1722 0.6210 36.3694 26.043 &lt; 0.0000000000000002 *** orch 1.1911 0.8710 35.6123 1.367 0.18005 large -1.7474 0.5485 28.6734 -3.186 0.00347 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) orch orch -0.642 large -0.253 -0.102 we estimate that the average negative affect score for performers with non-orchestral instruments when playing a solo or with a small ensemble is \\(\\hat{\\alpha}_0 = 16.17\\). We estimate that, average negative affect is \\(\\hat{\\alpha}_1 = 1.19\\) points higher for musicians playing an orchestral instrument, compared to those playing a keyboard or vocalists, assuming type of performance is the same. We estimate that, average negative affect is \\(\\hat{\\beta}_0 = -1.75\\) points (i.e. 1.75 points lower) when performing in a large ensemble, compared with playing in a small ensemble or a solo, assuming instrument type is the same. After accounting for performance type and instrument type the standard deviation in negative affect scores between different musicians for solos/small ensembles is estimated to be \\(\\hat{\\sigma}_u=2.41\\). After accounting for performance type and instrument type the standard deviation in changes in negative affect scores for large ensemble performances, compared to solo/small ensemble performances is estimated to be \\(\\hat{\\sigma}_u=0.85\\). After accounting for performance type, and instrument type, the standard deviation in negative affect scores between different performances by the same musician is estimated to be \\(\\hat{\\sigma}_u=4.67\\). The correlation between negative affect scores for solos/small ensembles and change in negative affect scores when playing in large ensembles is \\(\\rho_{uv}=-0.59\\), indicating a negative correlation. Musicians with larger negative effect scores for solo/small ensemble performances see tend to have greater decreases in performance anxiety for large ensemble performances. 3.3.6 More on Interpreting Parameters Both \\(\\beta=-1.74\\) and \\(\\rho_{uv}=-0.59\\) seem to suggest negative relationships involving performance anxiety associated with playing in a large ensemble. Let's think carefully about what each of these tells us, and how they're different. \\(\\beta=-1.74\\) tells us that on average, a musicians's negative affect score for performance anxiety is expected to decrease by 1.74 points when playing in a large ensemble, compared to a solo or small ensemble performance. \\(rho_uv = -0.59\\) tells us that musicians who have higher performance anxiety than expected when playing a solo or small ensemble tend to see a bigger decrease in anxiety when playing in a large ensemble than those who have less anxiety playing in a solo or small ensemble. Illustration: Each line represents one of the 37 musicians. The thick black line represents average change. \\(\\beta=1.74\\) is indicated by negative slope on thick black line \\(\\rho_{uv}=-0.59\\) is indicated by lines with bigger negative affects on left having steeper negative slopes. Thought Question: Why would it not make sense to add a random slope for instrument type? 3.3.7 Model Comparisons We can compare the models using AIC and BIC. AIC(model2b, model1b) ## df AIC ## model2b 7 3004.667 ## model1b 5 3001.200 BIC(model2b, model1b) ## df BIC ## model2b 7 3034.127 ## model1b 5 3022.243 parameter estimates for the remaining 6 fixed effects and variance components closely mirror the corresponding parameter estimates from the first model. Removing the error term on the slope has improved (reduced) both the AIC and BIC measures of overall model performance. Instead of assuming that the large ensemble effects, after accounting for instrument played, vary by individual, we'll assume that large ensemble effect is fixed across subjects. It is often beneficial to use an error term on the intercept equation to account for differences between subjects, but with no random slope terms unless there is an a priori reason to allow effects to vary by subject or if the model performs better after building in those additional error terms. 3.3.8 Random Slopes Model with Interaction Model: \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0}+\\alpha_1\\textrm{Orch}_{i}+\\beta_0\\textrm{LargeEns}_{ij} + \\beta_1\\textrm{Orch}_{i}\\textrm{LargeEns}_{ij}] \\\\ \\textrm{} &amp;+ [u_{i}+v_{i}\\textrm{LargeEns}_{ij}+\\epsilon_{ij}] \\end{align*} \\] \\(\\epsilon_{ij}\\sim N(0,\\sigma^2)\\), and \\[ \\begin{equation*} \\left[ \\begin{array}{c} u_{i} \\\\ v_{i} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cc} \\sigma_{u}^{2} &amp; \\rho_{uv}\\sigma_{u}\\sigma_v \\\\ \\rho_{uv}\\sigma_{u}\\sigma_v &amp; \\sigma_{v}^{2} \\end{array} \\right] \\right) \\end{equation*} \\] 3.3.9 Random Slopes Model with Interaction in R model2 &lt;- lmer(data=music, na ~ orch + large + orch:large + (large | id), REML=TRUE) summary(model2) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ orch + large + orch:large + (large | id) Data: music REML criterion at convergence: 2987 Scaled residuals: Min 1Q Median 3Q Max -1.9404 -0.6625 -0.1771 0.4796 4.1860 Random effects: Groups Name Variance Std.Dev. Corr id (Intercept) 5.655 2.3781 large 0.452 0.6723 -0.63 Residual 21.807 4.6698 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 15.9297 0.6415 32.2972 24.833 &lt;0.0000000000000002 *** orch 1.6926 0.9452 33.6207 1.791 0.0824 . large -0.9106 0.8452 41.5021 -1.077 0.2876 orch:large -1.4239 1.0992 31.6101 -1.295 0.2046 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) orch large orch -0.679 large -0.368 0.250 orch:large 0.283 -0.402 -0.769 3.3.10 Formulation of Random Slopes Model with Interaction Two level model for performance anxiety, using large ensemble and playing an orchestral instrument as explanatory variables. Level One: \\[ \\begin{equation*} Y_{ij} = a_{i}+b_{i}\\textrm{LargeEns}_{ij}+\\epsilon_{ij} \\end{equation*} \\] Level Two: \\[ \\begin{align*} a_{i} &amp; = \\alpha_{0}+\\alpha_{1}\\textrm{Orch}_{i}+u_{i} \\\\ b_{i} &amp; = \\beta_{0}+\\beta_{1}\\textrm{Orch}_{i}+v_{i}, \\end{align*} \\] Parameters to Estimate: 4 fixed effects: \\(\\alpha_{0}\\), \\(\\alpha_{1}\\), \\(\\beta_{0}\\) and \\(\\beta_{1}\\). Fixed effects are the fixed but unknown population effects associated with certain covariates. The intercepts and slopes for each subject from Level One, \\(a_{i}\\) and \\(b_{i}\\), don't need to be formally estimated. They serve to conceptually connect Level One with Level Two. Substituting the two Level Two equations into the Level One equation gives: \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0}+\\alpha_{1}\\textrm{Orch}_{i}+\\beta_{0}\\textrm{LargeEns}_{ij}+\\beta_{1}\\textrm{Orch}_{i}\\textrm{LargeEns}_{ij}] \\\\ &amp; \\textrm{} + [u_{i}+v_{i}\\textrm{LargeEns}_{ij}+\\epsilon_{ij}] \\end{align*} \\] Thus, we can think of a multilevel model as a model where the slope and intercept at level one are themselves linear functions of a variable at level 2. 3.4 Unconditional Means Model 3.4.1 Unconditional Means Model Formulation When building models, it is often helpful to start with a model that does not include any explatory variables. This model allows us to compare variability within subject to variability between subjects. This model is called an unconditional means model (or random intercepts model). Model: \\[ \\begin{equation*} Y_{ij}=\\alpha_{0}+u_{i}+\\epsilon_{ij} \\end{equation*} \\] where \\(u_i\\sim N(0, \\sigma^2_u)\\) and \\(\\epsilon_{ij}\\sim N(0, \\sigma^2)\\). the true mean response of all observations for subject \\(i\\) is \\(\\alpha_0 + u_i\\) \\(\\alpha_{0}\\) is the grand mean -- the true mean of all observations across the entire population. \\(\\sigma^2\\) is the within-person variability \\(\\sigma_{u}^{2}\\) is the between-person variability. 3.4.2 Unconditional Means Model in R #Model A (Unconditional means model) model.a &lt;- lmer(na ~ 1 + (1 | id), REML = TRUE, data = music) summary(model.a) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ 1 + (1 | id) Data: music REML criterion at convergence: 3005.8 Scaled residuals: Min 1Q Median 3Q Max -1.9041 -0.6894 -0.2076 0.5284 4.1286 Random effects: Groups Name Variance Std.Dev. id (Intercept) 4.95 2.225 Residual 22.46 4.739 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 16.2370 0.4279 36.6717 37.94 &lt;0.0000000000000002 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 3.4.3 Unconditional Means Model Interpretations \\(\\hat{\\alpha}_{0}=16.2=\\) the estimated mean performance anxiety score across all performances and all subjects. \\(\\hat{\\sigma}=4.739=\\) the estimated standard deviation in within-person deviations. \\(\\hat{\\sigma}_{u}=2.225=\\) the estimated standard deviation in between-person deviations. The relative levels of between- and within-person variabilities can be compared through the intraclass correlation coefficient. \\[ \\begin{equation*} \\hat{\\rho}=\\frac{\\textrm{Between-person variability}}{\\textrm{Total variability}} = \\frac{\\hat{\\sigma}_{u}^{2}}{\\hat{\\sigma}_{u}^{2}+\\hat{\\sigma}^2} = \\frac{5.0}{5.0+22.5} = .182. \\end{equation*} \\] Thus, 18.2% of the total variability in performance anxiety scores are attributable to differences among musicians In this particular model, we can also say that the average correlation for any pair of responses from the same individual is a moderately low .182. 3.5 Building A Multilevel Model We now return to the multi-level model from section 8.5 that included orch and Large as explanatory variables, as well as random effects for the intercept and effect of playing in a large ensemble for each musician. We add negative emotionality (MPQnem) as a Level Two predictor. \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0}+\\alpha_{1}\\textrm{Orch}_{i}+\\alpha_{2}\\textrm{MPQnem}_{i}+\\beta_{0}\\textrm{LargeEns}_{ij} \\\\ &amp; \\textrm{} + \\beta_{1}\\textrm{Orch}_{i}\\textrm{LargeEns}_{ij}+\\beta_{2}\\textrm{MPQnem}_{i}\\textrm{LargeEns}_{ij}] \\\\ &amp; \\textrm{} + [u_{i}+v_{i}\\textrm{LargeEns}_{ij}+\\epsilon_{ij}] \\end{align*} \\] where error terms are defined as before. #Add negative emotionality as second L2 covariate model3 &lt;- lmer(na ~ orch + mpqnem + large + (1 | id), data = music, REML=TRUE) summary(model3) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ orch + mpqnem + large + (1 | id) Data: music REML criterion at convergence: 2981.4 Scaled residuals: Min 1Q Median 3Q Max -2.0473 -0.6655 -0.1542 0.4747 4.0114 Random effects: Groups Name Variance Std.Dev. id (Intercept) 2.991 1.730 Residual 21.884 4.678 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 11.79704 1.12576 33.69922 10.479 0.00000000000386 *** orch 0.77284 0.73202 34.29199 1.056 0.298462 mpqnem 0.14375 0.03406 33.93766 4.221 0.000172 *** large -1.83298 0.52531 480.85113 -3.489 0.000529 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) orch mpqnem orch -0.121 mpqnem -0.894 -0.183 large -0.031 -0.079 -0.073 3.5.1 Centering Covariates It makes no sense to draw conclusions about performance anxiety levels for subjects with MPQNEM scores of 0 at baseline (as in \\(\\hat{\\beta}_{0}\\)), since the minimum NEM composite score among subjects in this study was 11. We subtract the mean, so that a value of 0 now correspons to the average MPQnem. music &lt;- music %&gt;% mutate(cmpqnem = mpqnem - mean(mpqnem)) # Model E (Center baseline NEM in Model D) model3c &lt;- lmer(na ~ orch + cmpqnem + large + (1 | id), data = music, REML=TRUE) summary(model3c) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ orch + cmpqnem + large + (1 | id) Data: music REML criterion at convergence: 2981.4 Scaled residuals: Min 1Q Median 3Q Max -2.0473 -0.6655 -0.1542 0.4747 4.0114 Random effects: Groups Name Variance Std.Dev. id (Intercept) 2.991 1.730 Residual 21.884 4.678 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 16.34397 0.50861 37.71295 32.135 &lt; 0.0000000000000002 *** orch 0.77284 0.73202 34.29199 1.056 0.298462 cmpqnem 0.14375 0.03406 33.93766 4.221 0.000172 *** large -1.83298 0.52531 480.85113 -3.489 0.000529 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) orch cmpqnm orch -0.655 cmpqnem 0.139 -0.183 large -0.223 -0.079 -0.073 Notice that only the intercept changes, since this is the only interpretation that depends on setting the mpqnem value equal to 0. Interpretation of Intercept: \\(\\hat{\\alpha}_{0} = 16.34\\). The estimated mean performance anxiety for solos and small ensembles (large=0) is 16.34 for keyboard players and vocalists (orch=0) with an average level of negative emotionality at baseline (mpqnem=31.63). 3.5.2 A Possible Final Model We'll add information about the following level 1 variables, pertaining to individual performances: * number of previous performances, * whether the audience is made up of students, * whether the performance is juried, * whether it is public, * whether it is a solo We'll also consider the following level 2 variables, pertaining to musicians: * mpqpem (positive emotion) * mpqab (absorption) * orch (orchestral instument) * mpqnem (negative emotion) We consider three potential final models: Model A: A two-level model with random slopes and an interaction between solo and mpqnem. \\[ \\begin{equation*} Y_{ij} = a_{i}+b_{i}\\textrm{previous}_{ij}+c_{i}\\textrm{students}_{ij}+ d_{i}\\textrm{juried}_{ij}+e_{i}\\textrm{public}_{ij}+f_{i}\\textrm{solo}_{ij}+\\epsilon_{ij} \\end{equation*} \\] - Level Two: \\[ \\begin{align*} a_{i} &amp; = \\alpha_{0}+\\alpha_{1}\\textrm{mpqpem}_{i}+\\alpha_{2}\\textrm{mpqab}_{i} + \\alpha_{3}\\textrm{orch}_{i}+\\alpha_{4}\\textrm{mpqnem}_{i}+u_{i} \\\\ b_{i} &amp; = \\beta_{0}+v_{i}, \\\\ c_{i} &amp; = \\gamma_{0}+w_{i}, \\\\ d_{i} &amp; = \\delta_{0}+x_{i}, \\\\ e_{i} &amp; = \\varepsilon_{0}+y_{i}, \\\\ f_{i} &amp; = \\zeta_{0}+\\zeta_{1}\\textrm{mpqnem}_{i}+z_{i}, \\end{align*} \\] After substitution, this can be written in the form \\[ \\begin{align*} Y_{ij} &amp; = \\alpha_{0}+\\alpha_{1}\\textrm{mpqpem}_{i} + \\alpha_{2}\\textrm{mpqab}_{i} + \\alpha_{3}\\textrm{orch}_{i}+\\alpha_{4}\\textrm{mpqnem}_{i} + u_{i} \\\\ &amp; +\\beta_{0}\\textrm{previous}_{ij} + v_{i}\\textrm{previous}_{ij} + \\gamma_{0}\\textrm{students}+w_{i}\\textrm{students}_{ij} + \\delta_{0}\\textrm{juried}_{ij}+x_{i}\\textrm{juried}_{ij} \\\\ &amp; + \\varepsilon_{0}\\textrm{public}+y_{i}\\textrm{public}_{ij}+ \\zeta_{0}\\textrm{solo}_{ij}+\\zeta_{1}\\textrm{mpqnem}_{i}\\textrm{solo}_{ij} \\\\ &amp; + z_{i}\\textrm{solo}_{ij}+\\epsilon_{ij} \\end{align*} \\] Grouping fixed and random effects, we get \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0}+\\alpha_{1}\\textrm{mpqpem}_{i} + \\alpha_{2}\\textrm{mpqab}_{i} + \\alpha_{3}\\textrm{orch}_{i}+\\alpha_{4}\\textrm{mpqnem}_{i} \\\\ &amp; +\\beta_{0}\\textrm{previous}_{ij} + \\gamma_{0}\\textrm{students} + \\delta_{0}\\textrm{juried}_{ij} + \\varepsilon_{0}\\textrm{public} + \\zeta_{0}\\textrm{solo}_{ij} +\\zeta_{1}\\textrm{mpqnem}_{i}\\textrm{solo}_{ij}] \\\\ &amp; + [u_{i} + v_{i}\\textrm{previous}_{ij} +w_{i}\\textrm{students}_{ij} +x_{i}\\textrm{juried}_{ij} +y_{i}\\textrm{public}_{ij} \\\\ &amp; + z_{i}\\textrm{solo}_{ij}+\\epsilon_{ij} ] \\end{align*} \\] This model accounts for random differences in performance anxiety between musicians, and also allows for the way anxiety changes with respect to changes in level one variables (previous, students, juried, public, solo, mpqnem) to vary randomly between performers. In addition, we assume the following variance-covariance structure at Level Two: \\[ \\left[ \\begin{array}{c} u_{i} \\\\ v_{i} \\\\ w_{i} \\\\ x_{i} \\\\ y_{i} \\\\ z_{i} \\end{array} \\right] \\sim N \\left( \\left[ \\begin{array}{c} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{cccccc} \\sigma_{u}^{2} &amp; &amp; &amp; &amp; &amp; \\\\ \\sigma_{uv} &amp; \\sigma_{v}^{2} &amp; &amp; &amp; &amp; \\\\ \\sigma_{uw} &amp; \\sigma_{vw} &amp; \\sigma_{w}^{2} &amp; &amp; &amp; \\\\ \\sigma_{ux} &amp; \\sigma_{vx} &amp; \\sigma_{wx} &amp; \\sigma_{x}^{2} &amp; &amp; \\\\ \\sigma_{uy} &amp; \\sigma_{vy} &amp; \\sigma_{wy} &amp; \\sigma_{xy} &amp; \\sigma_{y}^{2} &amp; \\\\ \\sigma_{uz} &amp; \\sigma_{vz} &amp; \\sigma_{wz} &amp; \\sigma_{xz} &amp; \\sigma_{yz} &amp; \\sigma_{z}^{2} \\end{array} \\right] \\right). \\] Being able to write out these mammoth variance-covariance matrices is less important than recognizing the number of variance components that must be estimated by our intended model. 3.5.3 More Data Wrangling # Add new indicators to music data set music &lt;- music %&gt;% mutate(students = ifelse(audience==&quot;Student(s)&quot;,1,0), juried = ifelse(audience==&quot;Juried Recital&quot;,1,0), public = ifelse(audience==&quot;Public Performance&quot;,1,0), solo = ifelse(perform_type==&quot;Solo&quot;,1,0), memory1 = ifelse(memory==&quot;Memory&quot;,1,0), female = ifelse(gender==&quot;Female&quot;,1,0), vocal = ifelse(instrument==&quot;voice&quot;,1,0) ) 3.5.4 Fitting Model A modelA &lt;- lmer(na ~ previous + students + juried + public + solo + mpqpem + mpqab + orch + mpqnem + mpqnem:solo + (previous + students + juried + public + solo | id), data = music, REML=TRUE) summary(modelA) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ previous + students + juried + public + solo + mpqpem + mpqab + orch + mpqnem + mpqnem:solo + (previous + students + juried + public + solo | id) Data: music REML criterion at convergence: 2882.3 Scaled residuals: Min 1Q Median 3Q Max -2.1919 -0.6058 -0.1118 0.5345 3.9995 Random effects: Groups Name Variance Std.Dev. Corr id (Intercept) 14.4566 3.8022 previous 0.0707 0.2659 -0.65 students 8.2131 2.8659 -0.63 0.00 juried 18.3331 4.2817 -0.64 -0.12 0.83 public 12.7857 3.5757 -0.83 0.33 0.66 0.57 solo 0.7663 0.8754 -0.67 0.47 0.49 0.20 0.90 Residual 15.2843 3.9095 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 8.37271 1.91346 63.87462 4.376 0.0000457 *** previous -0.14303 0.06247 37.27430 -2.290 0.027794 * students 3.61094 0.76792 32.20414 4.702 0.0000465 *** juried 4.07294 1.03152 36.39148 3.948 0.000346 *** public 3.06498 0.89233 36.54339 3.435 0.001492 ** solo 0.51323 1.39646 262.84884 0.368 0.713527 mpqpem -0.08315 0.02407 38.74755 -3.454 0.001352 ** mpqab 0.20382 0.04740 35.95499 4.300 0.000125 *** orch 1.53123 0.58387 42.87273 2.623 0.012034 * mpqnem 0.11453 0.03590 43.18022 3.190 0.002650 ** solo:mpqnem 0.08308 0.04158 171.42767 1.998 0.047323 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) previs stdnts juried public solo mpqpem mpqab orch previous -0.230 students -0.261 -0.027 juried -0.252 -0.084 0.543 public -0.350 0.156 0.583 0.434 solo -0.449 -0.014 0.084 -0.003 0.220 mpqpem -0.392 0.010 0.002 0.026 -0.003 -0.068 mpqab -0.397 -0.017 -0.010 -0.034 -0.061 -0.030 -0.259 orch 0.088 -0.036 0.000 0.026 0.035 0.111 -0.244 -0.065 mpqnem -0.556 -0.024 -0.017 0.053 -0.038 0.635 -0.061 0.065 -0.131 solo:mpqnem 0.345 0.052 0.034 0.033 0.045 -0.906 0.067 0.019 -0.056 mpqnem previous students juried public solo mpqpem mpqab orch mpqnem solo:mpqnem -0.698 optimizer (nloptwrap) convergence code: 0 (OK) Model failed to converge with max|grad| = 0.0157114 (tol = 0.002, component 1) 3.5.5 A Model Without Random Slopes We consider eliminating the random slope terms, resulting in a model of the form: \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0}+\\alpha_{1}\\textrm{mpqpem}_{i} + \\alpha_{2}\\textrm{mpqab}_{i} + \\alpha_{3}\\textrm{orch}_{i}+\\alpha_{4}\\textrm{mpqnem}_{i} \\\\ &amp; +\\beta_{0}\\textrm{previous}_{ij} + \\gamma_{0}\\textrm{students} + \\delta_{0}\\textrm{juried}_{ij} + \\varepsilon_{0}\\textrm{public} + \\zeta_{0}\\textrm{solo}_{ij} +\\zeta_{1}\\textrm{mpqnem}_{i}\\textrm{solo}_{ij}] \\\\ &amp; + [u_{i} +\\epsilon_{ij} ] \\end{align*} \\] This model accounts for random differences in performance anxiety between musicians, but assumes that the way anxiety changes with respect to changes in level one variables (previous, students, juried, public, solo, mpqnem) is the same for all performers. 3.5.6 Fitting Model B in R modelB &lt;- lmer(na ~ previous + students + juried + public + solo + mpqpem + mpqab + orch + mpqnem + mpqnem:solo + (1 | id), data = music, REML=TRUE) summary(modelB) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ previous + students + juried + public + solo + mpqpem + mpqab + orch + mpqnem + mpqnem:solo + (1 | id) Data: music REML criterion at convergence: 2920.3 Scaled residuals: Min 1Q Median 3Q Max -1.9919 -0.7026 -0.1252 0.5162 3.9367 Random effects: Groups Name Variance Std.Dev. id (Intercept) 1.848 1.36 Residual 19.272 4.39 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 7.70582 1.99554 51.87716 3.862 0.000314 *** previous -0.12817 0.04677 473.53232 -2.740 0.006368 ** students 3.75767 0.61372 485.24491 6.123 0.0000000019 *** juried 4.28176 0.78158 483.19106 5.478 0.0000000692 *** public 3.09805 0.66208 481.42142 4.679 0.0000037469 *** solo -0.26784 1.41139 469.85154 -0.190 0.849569 mpqpem -0.05917 0.02795 30.52940 -2.117 0.042531 * mpqab 0.19185 0.05610 33.15989 3.420 0.001678 ** orch 1.23579 0.65797 34.10231 1.878 0.068929 . mpqnem 0.10568 0.03743 69.85950 2.823 0.006188 ** solo:mpqnem 0.10640 0.04144 416.29568 2.567 0.010596 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) previs stdnts juried public solo mpqpem mpqab orch previous -0.120 students -0.157 -0.042 juried -0.103 -0.065 0.309 public -0.225 -0.015 0.526 0.315 solo -0.424 -0.060 0.073 0.010 0.220 mpqpem -0.398 0.000 -0.007 -0.004 -0.016 -0.023 mpqab -0.389 -0.001 -0.029 -0.036 -0.086 -0.040 -0.368 orch 0.089 -0.022 0.017 0.036 0.089 0.104 -0.259 -0.059 mpqnem -0.627 -0.042 -0.003 0.045 -0.006 0.591 -0.008 0.088 -0.124 solo:mpqnem 0.344 0.063 0.039 0.012 0.045 -0.912 0.017 0.019 -0.032 mpqnem previous students juried public solo mpqpem mpqab orch mpqnem solo:mpqnem -0.632 AIC(modelA, modelB) ## df AIC ## modelA 33 2948.349 ## modelB 13 2946.328 BIC(modelA, modelB) ## df BIC ## modelA 33 3087.232 ## modelB 13 3001.040 Both AIC and BIC favor Model B. 3.5.7 One More Possible Model Finally, we consider a simpler model that accounts for only positive and negative emotions at level two. \\[ \\begin{align*} Y_{ij} &amp; = [\\alpha_{0}+\\alpha_{1}\\textrm{mpqpem}_{i} + \\alpha_{2}\\textrm{mpqnem}_{i} \\\\ &amp; +\\beta_{0}\\textrm{previous}_{ij} + \\gamma_{0}\\textrm{students} + \\delta_{0}\\textrm{juried}_{ij} + \\varepsilon_{0}\\textrm{public} + \\zeta_{0}\\textrm{solo}_{ij} +\\zeta_{1}\\textrm{mpqnem}_{i}\\textrm{solo}_{ij}] \\\\ &amp; + [u_{i} +\\epsilon_{ij} ] \\end{align*} \\] modelC &lt;- lmer(na ~ previous + students + juried + public + solo + mpqpem + mpqnem + mpqnem:solo + (1 | id), data = music, REML=TRUE) summary(modelC) Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ lmerModLmerTest] Formula: na ~ previous + students + juried + public + solo + mpqpem + mpqnem + mpqnem:solo + (1 | id) Data: music REML criterion at convergence: 2931.1 Scaled residuals: Min 1Q Median 3Q Max -2.0015 -0.7103 -0.1269 0.5231 4.0510 Random effects: Groups Name Variance Std.Dev. id (Intercept) 3.236 1.799 Residual 19.279 4.391 Number of obs: 497, groups: id, 37 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 9.927921 2.093605 55.074190 4.742 0.000015371131 *** previous -0.127735 0.046943 471.743502 -2.721 0.00675 ** students 3.855901 0.618592 482.592236 6.233 0.000000000997 *** juried 4.320965 0.786379 480.880270 5.495 0.000000063545 *** public 3.211002 0.667621 487.490870 4.810 0.000002018574 *** solo -0.222631 1.429140 484.511985 -0.156 0.87627 mpqpem -0.006105 0.029535 34.036100 -0.207 0.83748 mpqnem 0.104837 0.041660 68.959080 2.517 0.01418 * solo:mpqnem 0.103699 0.042476 466.126986 2.441 0.01500 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) previs stdnts juried public solo mpqpem mpqnem previous -0.111 students -0.162 -0.041 juried -0.118 -0.069 0.308 public -0.256 -0.011 0.524 0.312 solo -0.434 -0.061 0.068 0.012 0.207 mpqpem -0.675 -0.006 -0.011 -0.007 -0.022 -0.010 mpqnem -0.634 -0.044 0.000 0.053 0.007 0.562 -0.006 solo:mpqnem 0.343 0.067 0.040 0.005 0.052 -0.915 0.016 -0.587 3.5.8 AIC and BIC Comparisons for Models B and C AIC(modelB, modelC) ## df AIC ## modelB 13 2946.328 ## modelC 11 2953.082 BIC(modelB, modelC) ## df BIC ## modelB 13 3001.040 ## modelC 11 2999.377 AIC favors model B, while BIC favors model C. 3.5.9 Likelihood Ratio Test Since all of the fixed effects in Model C also appear in Model B, (Model C is a nested version of Model B), we can use a likelihood ratio test (drop in deviance test), which is similar to the ANOVA F-Test, to compare the models. When using mixed effects models, the test statistic for this goodness of fit test follows a \\(\\chi^2\\) distribution, rather than an F-distribution, so we use test = &quot;Chisq&quot;. # anova() automatically uses ML for LRT tests drop_in_dev &lt;- anova(modelB, modelC, test = &quot;Chisq&quot;) drop_in_dev Data: music Models: modelC: na ~ previous + students + juried + public + solo + mpqpem + modelC: mpqnem + mpqnem:solo + (1 | id) modelB: na ~ previous + students + juried + public + solo + mpqpem + modelB: mpqab + orch + mpqnem + mpqnem:solo + (1 | id) npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) modelC 11 2936.7 2983.0 -1457.4 2914.7 modelB 13 2925.6 2980.3 -1449.8 2899.6 15.182 2 0.0005049 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The small p-value provides evidence against the null hypothesis that model C is sufficient, suggesting that accounting for absorption and whether the musician plays an orchestral instrument does indeed help explain variability in performance anxiety. We'll go with Model B as our final model. 3.5.10 Final Conclusions summary(modelB) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: na ~ previous + students + juried + public + solo + mpqpem + ## mpqab + orch + mpqnem + mpqnem:solo + (1 | id) ## Data: music ## ## REML criterion at convergence: 2920.3 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.9919 -0.7026 -0.1252 0.5162 3.9367 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 1.848 1.36 ## Residual 19.272 4.39 ## Number of obs: 497, groups: id, 37 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 7.70582 1.99554 51.87716 3.862 0.000314 *** ## previous -0.12817 0.04677 473.53232 -2.740 0.006368 ** ## students 3.75767 0.61372 485.24491 6.123 0.0000000019 *** ## juried 4.28176 0.78158 483.19106 5.478 0.0000000692 *** ## public 3.09805 0.66208 481.42142 4.679 0.0000037469 *** ## solo -0.26784 1.41139 469.85154 -0.190 0.849569 ## mpqpem -0.05917 0.02795 30.52940 -2.117 0.042531 * ## mpqab 0.19185 0.05610 33.15989 3.420 0.001678 ** ## orch 1.23579 0.65797 34.10231 1.878 0.068929 . ## mpqnem 0.10568 0.03743 69.85950 2.823 0.006188 ** ## solo:mpqnem 0.10640 0.04144 416.29568 2.567 0.010596 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) previs stdnts juried public solo mpqpem mpqab orch ## previous -0.120 ## students -0.157 -0.042 ## juried -0.103 -0.065 0.309 ## public -0.225 -0.015 0.526 0.315 ## solo -0.424 -0.060 0.073 0.010 0.220 ## mpqpem -0.398 0.000 -0.007 -0.004 -0.016 -0.023 ## mpqab -0.389 -0.001 -0.029 -0.036 -0.086 -0.040 -0.368 ## orch 0.089 -0.022 0.017 0.036 0.089 0.104 -0.259 -0.059 ## mpqnem -0.627 -0.042 -0.003 0.045 -0.006 0.591 -0.008 0.088 -0.124 ## solo:mpqnem 0.344 0.063 0.039 0.012 0.045 -0.912 0.017 0.019 -0.032 ## mpqnem ## previous ## students ## juried ## public ## solo ## mpqpem ## mpqab ## orch ## mpqnem ## solo:mpqnem -0.632 Key Findings: After controlling for other factors we have evidence that: performance anxiety is higher when a musician is performing in front of students, a jury, or the general public rather than their instructor performance anxiety is is lower for each additional diary the musician previously filled out musicians with lower levels of positive emotionality and higher levels of absorption tend to experience greater performance anxiety those who play orchestral instruments experience more performance anxiety than those who play keyboards or sing. musicians with higher levels of negative emotionality experience higher levels of performance anxiety, and that this association is even more pronounced when musicians are performing solos rather than as part of an ensemble group. Interpretations of key fixed effects: A one-point increase in baseline level of negative emotionality is associated with an estimated 0.11 mean increase in performance anxiety for musicians performing in an ensemble group (solo=0), after controlling for previous diary entries, audience, positive emotionality, absorption, and instrument. When musicians play solos, a one-point increase in baseline level of negative emotionality is associated with an estimated \\(0.10568+0.10640=0.21208\\) mean increase in performance anxiety, approximately twice as high st musicians playing in ensemble groups (0.10568), controlling for the effects of previous diary entries, audience, positive emotionality, absorption, and instrument. Interpretations of random effects: After accounting for the effects of previous diary entries, audience, positive emotionality, absorption, and instrument, there is more variability in performance anxiety between performances by the same musician (\\(\\sigma=4.39\\)), than in variability between performance anxiety of different musicians (\\(\\sigma=1.36\\)) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
