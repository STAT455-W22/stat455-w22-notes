select(-c("name")) %>%
arrange(schoolid, year08) %>%
mutate(year08 = as.numeric(year08))
head(chart.long)
#Getting started-3
# Add average across all years for each school for EDA plots
chart.means <- chart.long %>%
group_by(schoolid) %>%
summarise(mean3yr = mean(MathAvgScore, na.rm=T))
chart.wide <- chart.wide %>%
mutate(urban0 = ifelse(urban==1, "urban", "rural"),
charter0 = ifelse(charter==1, "charter",
"public non-charter")) %>%
left_join(chart.means, by="schoolid")
###histogram of mean math scores (1 obs per school)
ggplot(data=chart.wide,aes(x=mean3yr)) +
geom_histogram(binwidth=5,color="black",fill="white") +
xlab("Mean Math Scores by School") + ylab("Frequency")
charter.school <- ggplot(data = chart.wide,
aes(x = factor(charter0), y = mean3yr)) +
geom_boxplot() + coord_flip()  + ylab("Mean Math Scores by School") +
xlab("") + labs(title="(a)")
urban.school <- ggplot(data = chart.wide,
aes(x = factor(urban0), y = mean3yr)) +
geom_boxplot() + coord_flip() + ylab("Mean Math Scores by School") +
xlab("") + labs(title="(b)")
grid.arrange(charter.school,urban.school,ncol=1,nrow=2)
PctFree.school <- ggplot(data = chart.wide,
aes(x = schPctfree, y = mean3yr)) +
geom_point()  +
geom_smooth(se=FALSE,method="lm",color="red") +
xlab("Percent Free/Reduced Lunch") +
ylab("Mean Math Scores\nby School") + labs(title="(a)")
PctSped.school <- ggplot(data = chart.wide,
aes(x = schPctsped, y = mean3yr)) +
geom_point() +
geom_smooth(se=FALSE,method="lm",color="red") +
xlab("Percent Special Ed") +
ylab("Mean Math Scores\nby School") + labs(title="(b)")
grid.arrange(PctFree.school, PctSped.school, ncol = 2)
chart.wide %>% group_by(charter) %>% summarise(Percent_Free_Red_Lunch = mean(schPctfree),
Percent_Special_Ed = mean(schPctsped),
Mean_Math_Score = mean(mean3yr),
N=n())
smallchart.long <- filter(chart.long, row_number() <= 72)
#Lattice plots
#  First change names of Central and Chaska
smallchart.long$schoolName[7:9]="CENTRAL108"
smallchart.long$schoolName[37:39]="CHASKAEAST"
smallchart.long$schoolName[40:42]="CHASKAWEST"
smallchart.long$schoolName[64:66]="CENTRAL13"
ggplot(smallchart.long, aes(x = year08, y = MathAvgScore)) +
geom_point() + geom_line() +
facet_wrap(~schoolName,ncol=6) +
scale_x_continuous(limits=c(0,2), breaks=c(0,1,2)) +
scale_y_continuous(limits=c(640,665)) + theme(strip.text.x=element_blank()) +
labs(x="Years since 2008",y="Math Scores")
set.seed(27)  #pulls same random sample every time
wide.charter <- chart.wide %>% filter(charter==1)  #dataframe with just charter schools
# select a sample of public schools with size equal to number of charter schools
samp = sample(1:length(chart.wide$charter==0), size=dim(wide.charter)[1])
wide.public <- chart.wide %>%
filter(charter == 0) %>%
sample_n( dim(wide.charter)[1] )
sampdata <- bind_rows(wide.charter, wide.public) %>%
select(-X1) %>%
mutate(vars = row_number())   # Just use numbers 1-146 as school ids
set.seed(27)  #pulls same random sample every time
wide.charter <- chart.wide %>% filter(charter==1)  #dataframe with just charter schools
# select a sample of public schools with size equal to number of charter schools
samp = sample(1:length(chart.wide$charter==0), size=dim(wide.charter)[1])
wide.public <- chart.wide %>%
filter(charter == 0) %>%
sample_n( dim(wide.charter)[1] )
sampdata <- bind_rows(wide.charter, wide.public) %>%
mutate(vars = row_number())   # Just use numbers 1-146 as school ids
#convert to long form
sampdata.l <- sampdata %>%
pivot_longer(names_to = "key", values_to = "MathAvgScore", cols=MathAvgScore.0:MathAvgScore.2) %>%
separate(key, into = c("name", "year08"), sep = "\\.") %>%
select(-name) %>%
arrange(charter, vars, year08) %>%
mutate(year08 = as.numeric(year08))
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, fig.width = 6, fig.height = 3)
# Packages required for Chapter 9
library(MASS)
library(gridExtra)
library(mnormt)
library(lme4)
library(lmerTest)
library(knitr)
library(kableExtra)
library(tidyverse)
library(Hmisc)
library(nlme)
#Getting started
chart.wide = read_csv("https://raw.githubusercontent.com/proback/BeyondMLR/master/data/chart_wide_condense.csv")
chart.wide <- chart.wide %>% select(-c(schPctnonw))
head(head(chart.wide))
summary(chart.wide)
sum(complete.cases(chart.wide))
#Getting started-2
# Create data frame in LONG form (one obs per school-year)
#   chart.long is 1854x10 with 121 NAs for MathAvgScore
select <- dplyr::select
chart.long <- chart.wide %>%
pivot_longer(cols=MathAvgScore.0:MathAvgScore.2,
names_to = "key",  # years since 2008
values_to = "MathAvgScore") %>%
separate(key, into = c("name", "year08"), sep = "\\.") %>%
select(-c("name")) %>%
arrange(schoolid, year08) %>%
mutate(year08 = as.numeric(year08))
head(chart.long)
#Getting started-3
# Add average across all years for each school for EDA plots
chart.means <- chart.long %>%
group_by(schoolid) %>%
summarise(mean3yr = mean(MathAvgScore, na.rm=T))
chart.wide <- chart.wide %>%
mutate(urban0 = ifelse(urban==1, "urban", "rural"),
charter0 = ifelse(charter==1, "charter",
"public non-charter")) %>%
left_join(chart.means, by="schoolid")
###histogram of mean math scores (1 obs per school)
ggplot(data=chart.wide,aes(x=mean3yr)) +
geom_histogram(binwidth=5,color="black",fill="white") +
xlab("Mean Math Scores by School") + ylab("Frequency")
charter.school <- ggplot(data = chart.wide,
aes(x = factor(charter0), y = mean3yr)) +
geom_boxplot() + coord_flip()  + ylab("Mean Math Scores by School") +
xlab("") + labs(title="(a)")
urban.school <- ggplot(data = chart.wide,
aes(x = factor(urban0), y = mean3yr)) +
geom_boxplot() + coord_flip() + ylab("Mean Math Scores by School") +
xlab("") + labs(title="(b)")
grid.arrange(charter.school,urban.school,ncol=1,nrow=2)
PctFree.school <- ggplot(data = chart.wide,
aes(x = schPctfree, y = mean3yr)) +
geom_point()  +
geom_smooth(se=FALSE,method="lm",color="red") +
xlab("Percent Free/Reduced Lunch") +
ylab("Mean Math Scores\nby School") + labs(title="(a)")
PctSped.school <- ggplot(data = chart.wide,
aes(x = schPctsped, y = mean3yr)) +
geom_point() +
geom_smooth(se=FALSE,method="lm",color="red") +
xlab("Percent Special Ed") +
ylab("Mean Math Scores\nby School") + labs(title="(b)")
grid.arrange(PctFree.school, PctSped.school, ncol = 2)
chart.wide %>% group_by(charter) %>% summarise(Percent_Free_Red_Lunch = mean(schPctfree),
Percent_Special_Ed = mean(schPctsped),
Mean_Math_Score = mean(mean3yr),
N=n())
smallchart.long <- filter(chart.long, row_number() <= 72)
#Lattice plots
#  First change names of Central and Chaska
smallchart.long$schoolName[7:9]="CENTRAL108"
smallchart.long$schoolName[37:39]="CHASKAEAST"
smallchart.long$schoolName[40:42]="CHASKAWEST"
smallchart.long$schoolName[64:66]="CENTRAL13"
ggplot(smallchart.long, aes(x = year08, y = MathAvgScore)) +
geom_point() + geom_line() +
facet_wrap(~schoolName,ncol=6) +
scale_x_continuous(limits=c(0,2), breaks=c(0,1,2)) +
scale_y_continuous(limits=c(640,665)) + theme(strip.text.x=element_blank()) +
labs(x="Years since 2008",y="Math Scores")
set.seed(27)  #pulls same random sample every time
wide.charter <- chart.wide %>% filter(charter==1)  #dataframe with just charter schools
# select a sample of public schools with size equal to number of charter schools
samp = sample(1:length(chart.wide$charter==0), size=dim(wide.charter)[1])
wide.public <- chart.wide %>%
filter(charter == 0) %>%
sample_n( dim(wide.charter)[1] )
sampdata <- bind_rows(wide.charter, wide.public) %>%
mutate(vars = row_number())   # Just use numbers 1-146 as school ids
#convert to long form
sampdata.l <- sampdata %>%
pivot_longer(names_to = "key", values_to = "MathAvgScore", cols=MathAvgScore.0:MathAvgScore.2) %>%
separate(key, into = c("name", "year08"), sep = "\\.") %>%
select(-name) %>%
arrange(charter, vars, year08) %>%
mutate(year08 = as.numeric(year08))
##Spaghetti Plots
#get rid of NA data
newsampdata.l <- sampdata.l %>% na.omit()
ggplot(newsampdata.l, aes(x = year08, y = MathAvgScore)) +
geom_line(aes(group=schoolid),color="grey") +
facet_grid(.~charter0) +
geom_smooth(aes(group=1),color="black",size=1) +
labs(x="Years since 2008",y="Math Scores")
# divide into quartiles
newsampdata.l <- newsampdata.l %>%
mutate(splitup = paste("Quartile",
as.numeric(cut2(schPctfree, g=4))))
ggplot(newsampdata.l,aes(x=year08,y=MathAvgScore)) +
geom_line(aes(group=schoolid),color="grey") +
geom_smooth(method="loess",color="black",se=FALSE,size=.75) +
facet_grid(~splitup) +
labs(x="Years since 2008",y="Math Scores") +
scale_x_continuous(limits=c(0,2), breaks=c(0,1,2))
#Model A (Unconditional means model)
model.a <- lmer(MathAvgScore~ 1 + (1|schoolid),
REML=T, data=chart.long)
summary(model.a)
#Model B (Unconditional growth)
model.b <- lmer(MathAvgScore~ year08 + (year08|schoolid),
REML=T, data=chart.long)
summary(model.b)
#center year and calculate year^2
chart.long <- chart.long %>%
mutate(yearc = year08 - 1,
yearc2 = yearc ^ 2)
# Modeling quadratic time trend
model.b1 <- lmer(MathAvgScore~ yearc + yearc2 + (1|schoolid),
REML=T, data=chart.long)
summary(model.b1)
ggplot(data=chart.long, aes(x=yearc, y=MathAvgScore)) + geom_point() + stat_smooth(method="lm", se=TRUE, fill=NA, formula=y ~ poly(x, 2, raw=TRUE),colour="red")
# Modeling quadratic time trend
model.b2 <- lmer(MathAvgScore~ yearc + yearc2 + ((yearc2 + yearc) |schoolid),
REML=T, data=chart.long)
summary(model.b2)
# Modeling quadratic time trend
model.b3 <- lmer(MathAvgScore~ yearc + yearc2 + ((yearc) |schoolid),
REML=T, data=chart.long)
summary(model.b3)
# Intercept only
BIC(model.b1)
# Intercept and linear term
BIC(model.b3)
# Modeling piecewise linear time trend with 3 time points
#   (won't work in general)
chart.long <- chart.long %>%
mutate(year0809 = ifelse(year08==1, 1, 0),
year0810 = ifelse(year08==2, 1, 0))
head(chart.long)
model.b4 <- lmer(MathAvgScore~ year0809 + year0810 +
(1|schoolid), REML=T, data=chart.long)
summary(model.b4)
ggplot(data=chart.long, aes(x=yearc, y=MathAvgScore)) + geom_point() + stat_smooth(method="lm", se=TRUE, fill=NA, formula=y ~ poly(x, 2, raw=TRUE),colour="red") +
geom_segment(aes(x = -1 , y = fixef(model.b4)[1], xend = 0, yend = fixef(model.b4)[1] + fixef(model.b4)[2]), colour = "blue")+
geom_segment(aes(x = 0 , y = fixef(model.b4)[1], xend = 1, yend = fixef(model.b4)[1] + fixef(model.b4)[3]), colour = "blue")
AIC(model.b1)   # quadratic
AIC(model.b4)   # piecewise
BIC(model.b1)   #quadratic
BIC(model.b4)   #piecewise
#Model C (uncontrolled effects of school type on
#   intercept and slope)
model.c <- lmer(MathAvgScore~ charter + year08 +
charter:year08 + (year08|schoolid),
REML=T, data=chart.long)
summary(model.c)
#    Model B
fixef.b <- fixef(model.b)
fit.b <- fixef.b[[1]] + c(0,1,2)*fixef.b[[2]]
fit.frame1 <- data.frame(fit.b=fit.b,num=c(0,1,2))
fit.plot1 <- ggplot(fit.frame1,aes(x=num,y=fit.b)) +
geom_point(shape=1,fill="black",size=3) +
geom_line() +
scale_y_continuous(limits=c(640,660)) +
labs(x="Years since 2008",y="Predicted Math Score",
title="Model B \n Unconditional growth")
#    Model C.
fixef.c <- fixef(model.c)
fit.c0 <- fixef.c[[1]] + c(0,1,2)*fixef.c[[3]]
fit.c1 <- fixef.c[[1]] + fixef.c[[2]] +
c(0,1,2)*fixef.c[[3]] +
c(0,1,2)*fixef.c[[4]]
fit.frame2 <- data.frame(fit=c(fit.c0,fit.c1),
num=c(0,1,2,0,1,2),
type0=c(rep("Public Non-charter",3),rep("Charter",3)))
fit.plot2 <- ggplot(fit.frame2,aes(x=num,y=fit)) +
geom_point(aes(shape=type0)) +
theme(legend.position=c(.2,.9)) +
theme(legend.title=element_blank()) +
geom_line(aes(linetype=type0)) +
scale_y_continuous(limits=c(640,660)) +
labs(x="Years since 2008",y="Predicted Math Score",
title="Model C \n Uncontrolled charter effect")
grid.arrange(fit.plot1, fit.plot2, ncol=2)
# keep only schools with observed scores for all 3 years
chart.long1 <- chart.long %>% filter(schoolid %in% chart.wide[complete.cases(chart.wide),]$schoolid)
AR1.sim = gls(MathAvgScore ~ charter + year08 + charter:year08, data = chart.long1,
correlation = corAR1(form = ~ year08 | schoolid))
summary(AR1.sim)
# keep only schools with observed scores for all 3 years
chart.long1 <- chart.long %>% filter(schoolid %in% chart.wide[complete.cases(chart.wide),]$schoolid)
AR1.sim = gls(MathAvgScore ~ charter + year08 + charter:year08, data = chart.long1,
correlation = corAR1(form = ~ 1 | schoolid))
summary(AR1.sim)
# keep only schools with observed scores for all 3 years
chart.long1 <- chart.long %>% filter(schoolid %in% chart.wide[complete.cases(chart.wide),]$schoolid)
AR1.sim = gls(MathAvgScore ~ charter + year08 + charter:year08, data = chart.long1,
correlation = corAR1(form = ~ 1 | year08))
summary(AR1.sim)
# keep only schools with observed scores for all 3 years
chart.long1 <- chart.long %>% filter(schoolid %in% chart.wide[complete.cases(chart.wide),]$schoolid)
AR1.sim = gls(MathAvgScore ~ charter + year08 + charter:year08, data = chart.long1,
correlation = corAR1(form = ~ 1 | schoolid))
summary(AR1.sim)
# keep only schools with observed scores for all 3 years
chart.long1 <- chart.long %>% filter(schoolid %in% chart.wide[complete.cases(chart.wide),]$schoolid)
AR1.sim = gls(MathAvgScore ~ charter + year08 + charter:year08, data = chart.long1,
correlation = corAR1(form = ~ 1 | year08))
summary(AR1.sim)
# keep only schools with observed scores for all 3 years
chart.long1 <- chart.long %>% filter(schoolid %in% chart.wide[complete.cases(chart.wide),]$schoolid)
AR1.sim = gls(MathAvgScore ~ charter + year08 + charter:year08, data = chart.long1,
correlation = corAR1(form = ~ year08 | schoolid))
summary(AR1.sim)
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, fig.height = 3, fig.width = 6)
# Packages required for Chapter 1
library(knitr)
library(gridExtra)
library(GGally)
library(kableExtra)
library(jtools)
library(rsample)
library(broom)
library(tidyverse)
derby.df <- read.csv("https://raw.githubusercontent.com/proback/BeyondMLR/master/data/derbyplus.csv")
head(derby.df)
derby.df <- derby.df %>%
mutate( fast = ifelse(condition=="fast",1,0),
good = ifelse(condition=="good",1,0),
yearnew = year - 1896,
fastfactor = ifelse(fast == 0, "not fast", "fast"))
table1 <- derby.df %>%
filter(row_number() < 6 | row_number() > 117)
kable(table1, booktabs=T,caption="The first five and the last five observations from the Kentucky Derby case study.") %>%
kable_styling(latex_options = "scale_down")
# EDA graphs
speed_hist <- ggplot(data = derby.df, aes(x = speed)) +
geom_histogram(binwidth = 0.5, fill = "white",
color = "black") +
xlab("Winning speed (ft/s)") + ylab("Frequency") + labs(title="(a)")
starters_hist <- ggplot(data = derby.df, aes(x = starters)) +
geom_histogram(binwidth = 3, fill = "white",
color = "black") +
xlab("Number of starters") + ylab("Frequency") + labs(title="(b)")
grid.arrange(speed_hist, starters_hist, ncol = 2)
gg <- ggpairs(data = derby.df,
columns = c("condition", "year", "starters", "speed"))
gg
# Coded scatterplot
ggplot(derby.df, aes(x = year, y = speed, colour = fastfactor)) +
geom_point(aes(shape = fastfactor)) +
geom_smooth(aes(linetype = fastfactor), method = lm, se = FALSE)
model2 <- lm(speed ~ yearnew, data = derby.df)
coef(summary(model2))
cat(" R squared = ", summary(model2)$r.squared, "\n",
"Residual standard error = ", summary(model2)$sigma)
# Residual diagnostics for Model 2
par(mar=c(4,4,4,4))
par(mfrow=c(2,2))
plot(model2)
par(mfrow=c(1,1))
derby.df <- mutate(derby.df, yearnew2 = yearnew^2)
model2q <- lm(speed ~ yearnew + yearnew2, data = derby.df)
coef(summary(model2q))
cat(" R squared = ", summary(model2q)$r.squared, "\n",
"Residual standard error = ", summary(model2q)$sigma)
# Fitted models for Model 2 and Model 2Q
ggplot(derby.df, aes(x = year, y = speed)) +
geom_point() +
stat_smooth(method = "lm", formula = y ~ x,
se = FALSE, linetype = 1) +
stat_smooth(method = "lm", formula = y ~ x + I(x^2),
se = FALSE, linetype = 2)
# Residual diagnostics for Model 2
par(mar=c(4,4,4,4))
par(mfrow=c(2,2))
plot(model2q)
par(mfrow=c(1,1))
model4 <- lm(speed ~ yearnew + fast, data = derby.df)
coef(summary(model4))
cat(" R squared = ", summary(model4)$r.squared, "\n",
"Residual standard error = ", summary(model4)$sigma)
confint(model4)
new.data <- data.frame(yearnew = 2017 - 1896, fast = 1)
predict(model4, new = new.data, interval = "prediction")
equation1 <- function(x){coef(model4)[2]*x+coef(model4)[1]}
equation2  <- function(x){coef(model4)[2]*x+coef(model4)[1]+coef(model4)[3]}
ggplot(data=derby.df, aes(x=yearnew, y=speed, color=fastfactor)) + geom_point()+
stat_function(fun=equation1,geom="line",color=scales::hue_pal()(3)[3]) +
stat_function(fun=equation2,geom="line",color=scales::hue_pal()(3)[1])
# Coded scatterplot
ggplot(derby.df, aes(x = year, y = speed, colour = fastfactor)) +
geom_point(aes(shape = fastfactor)) +
geom_smooth(aes(linetype = fastfactor), method = lm, se = FALSE)
model5 <- lm(speed ~ yearnew + fast + yearnew:fast, data=derby.df)
model5 <- lm(speed ~  yearnew*fast, data=derby.df)
coef(summary(model5))
cat(" R squared = ", summary(model5)$r.squared, "\n",
"Residual standard error = ", summary(model5)$sigma)
model0A <- lm(speed ~ yearnew + yearnew2 , data = derby.df)
model0B <- lm(speed ~ yearnew + yearnew2 + fast + good + starters, data = derby.df)
model0C <- lm(speed ~ yearnew + yearnew2 + fast + good + starters +
yearnew:fast + yearnew:good + yearnew2:fast +
yearnew2:good, data = derby.df)
options(scipen = 999)
coef(summary(model0A)) %>% round(6)
cat(" R squared = ", summary(model0A)$r.squared, "\n",
" Adjusted R squared = ", summary(model0A)$adj.r.squared, "\n",
"Residual standard error = ", summary(model0A)$sigma, "\n",
"AIC = ", AIC(model0A))
coef(summary(model0B))%>% round(6)
cat(" R squared = ", summary(model0B)$r.squared, "\n",
" Adjusted R squared = ", summary(model0B)$adj.r.squared, "\n",
"Residual standard error = ", summary(model0B)$sigma,"\n",
"AIC = ", AIC(model0B))
coef(summary(model0C))%>% round(6)
cat(" R squared = ", summary(model0C)$r.squared, "\n",
" Adjusted R squared = ", summary(model0C)$adj.r.squared, "\n",
"Residual standard error = ", summary(model0C)$sigma, "\n",
"AIC = ", AIC(model0C))
# Compare model0A and model0B
anova(model0A, model0B, test = "F")
# Compare model0A and model0B
anova(model0B, model0C, test = "F")
# Residual diagnostics for Model B
par(mar=c(4,4,4,4))
par(mfrow=c(2,2))
plot(model0B)
par(mfrow=c(1,1))
coef(summary(model0B))%>% round(6)
cat(" R squared = ", summary(model0B)$r.squared, "\n",
" Adjusted R squared = ", summary(model0B)$adj.r.squared, "\n",
"Residual standard error = ", summary(model0B)$sigma,"\n",
"AIC = ", AIC(model0B))
gg <- ggpairs(data = derby.df,
columns = c("condition", "year", "starters", "speed"))
gg
summary(model4)
View(derby.df)
y <- derby.df$speed
X <- cbind(1, derby.df$yearnew, derby.df$fast)
head(y)
head(X)
solve(t(X) %*% X) %*% t(X) %*% y
summary(model4)
dim(derby.df)
t=8.14
gf_dist("t", df=119, geom = "area", fill = ~ (abs(x)< abs(ts)), show.legend=FALSE) + geom_vline(xintercept=c(t, -t), color="red")  + xlab("t")
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, fig.height = 3, fig.width = 6)
# Packages required for Chapter 1
library(knitr)
library(gridExtra)
library(GGally)
library(kableExtra)
library(jtools)
library(rsample)
library(broom)
library(tidyverse)
library(ggformula)
t=8.14
gf_dist("t", df=119, geom = "area", fill = ~ (abs(x)< abs(ts)), show.legend=FALSE) + geom_vline(xintercept=c(t, -t), color="red")  + xlab("t")
t=8.14
gf_dist("t", df=119, geom = "area", fill = ~ (abs(x)< abs(t)), show.legend=FALSE) + geom_vline(xintercept=c(t, -t), color="red")  + xlab("t")
t <- 8.14
gf_dist("t", df=119, geom = "area", fill = ~ (abs(x)< abs(t)), show.legend=FALSE) #+ geom_vline(xintercept=c(t, -t), color="red")  + xlab("t")
ts=3.027
gf_dist("t", df=51, geom = "area", fill = ~ (abs(x)< abs(ts)), show.legend=FALSE) + geom_vline(xintercept=c(ts, -ts), color="red")  + xlab("t")
ts <- 8.14
gf_dist("t", df=51, geom = "area", fill = ~ (abs(x)< abs(ts)), show.legend=FALSE) + geom_vline(xintercept=c(ts, -ts), color="red")  + xlab("t")
ts <- 8.14
gf_dist("t", df=51, geom = "area", fill = ~ (abs(x)< abs(t)), show.legend=FALSE) + geom_vline(xintercept=c(t, -t), color="red")  + xlab("t")
tstat <- 8.14
gf_dist("t", df=51, geom = "area", fill = ~ (abs(x)< abs(tstat)), show.legend=FALSE) + geom_vline(xintercept=c(tstat, -tstat), color="red")  + xlab("t")
tstat <- 8.14
gf_dist("t", df=51, geom = "area", fill = ~ (abs(x)< abs(tstat)), show.legend=FALSE) + geom_vline(xintercept=c(tstat, -tstat), color="blue")  + xlab("t")
tstat <- 8.14
gf_dist("t", df=51, geom = "area", fill = ~ (abs(x)< abs(tstat)), show.legend=FALSE) + geom_vline(xintercept=c(tstat, -tstat), color="red")  + xlab("t")
tstat <- 8.14
gf_dist("t", df=51, geom = "area", fill = (abs(x)< abs(tstat)), show.legend=FALSE) + geom_vline(xintercept=c(tstat, -tstat), color="red")  + xlab("t")
tstat <- 8.14
gf_dist("t", df=51, geom = "area", fill = ~!(abs(x)< abs(tstat)), show.legend=FALSE) + geom_vline(xintercept=c(tstat, -tstat), color="red")  + xlab("t")
2*pt(abs(ts), df=51, tail=upper)
?pt
2*pt(abs(ts), df=51, lower.tail=FALSE)
2*pt(ts, df=51, lower.tail=FALSE)
2*pt(8.14, df=119, lower.tail=FALSE)
tstat <- 8.14
gf_dist("t", df=119, geom = "area", fill = ~(abs(x)< abs(tstat)), show.legend=FALSE) + geom_vline(xintercept=c(tstat, -tstat), color="red")  + xlab("t")
tstat <- -1.42
gf_dist("t", df=10, geom = "area", fill = ~(abs(x)< abs(tstat)), show.legend=FALSE) + geom_vline(xintercept=c(tstat, -tstat), color="red")  + xlab("t")
tstat <- -1.42
gf_dist("t", df=112, geom = "area", fill = ~(abs(x)< abs(tstat)), show.legend=FALSE) + geom_vline(xintercept=c(tstat, -tstat), color="red")  + xlab("t")
2*pt(-1.42, df=112, lower.tail=TRUE)
sum((derby.df$speed - mean(derby.df$speed))^2)
sum((derby.df$speed - model4$fitted.values)^2)
(201.1791-62.88574)/201.1791
((201.1791-62.88574)/2)/(62.88574/119)
F=130.8477
gf_dist("f", df1=2, df2=119, geom = "area", fill = ~ (abs(x)< abs(ts)), show.legend=FALSE) + geom_vline(xintercept=c(ts), color="red")  + xlab("t")
Fstat=130.8477
gf_dist("f", df1=2, df2=119, geom = "area", fill = ~ (abs(x)< abs(Fstat)), show.legend=FALSE) + geom_vline(xintercept=c(Fstat), color="red")  + xlab("t")
1-pf(Fstat, df1=2, df2=119)
pf(Fstat, df1=2, df2=119, tail.upper=TRUE)
pf(Fstat, df1=2, df2=119, upper.tail=TRUE)
?pf
pf(Fstat, df1=2, df2=119, lower.tail=FALSE)
gf_dist("f", df1=5, df2=5, color = ~ "5,5 df", kind = "density")  %>%
gf_dist("f", df1=5, df2=20, color = ~ "5,20 df", kind = "density") %>%
gf_dist("f", df1=20, df2=5, color = ~ "20,5 df", kind = "density") %>%
gf_dist("f", df1=20, df2=20, color = ~ "20,20 df", kind = "density") + xlim(c(0,10)) + xlab("F")
# Compare model0A and model0B
anova(model0B, model0C, test = "F")
Fstat=4.3117
gf_dist("f", df1=4, df2=116, geom = "area", fill = ~ (abs(x)< abs(Fstat)), show.legend=FALSE) + geom_vline(xintercept=c(Fstat), color="red")  + xlab("t")
pf(Fstat, df1=4, df2=116, lower.tail=FALSE)
pf(Fstat, df1=4, df2=112, lower.tail=FALSE)
