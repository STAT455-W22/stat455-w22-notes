# Review of Multiple Linear Regression


**Chapter 1 Learning Outcomes**

1. Identify violations of linear least squares regression (LLSR) assumptions based on descriptions of data collection.      

2. Interpret parameter estimates in LLSR models, including models with transformations and/or interactions.     

3. Calculate expected responses and expected changes associated with explanatory variables in a LLSR model.      

4. Calculate standard errors, t-statistics, residual standard error, $R^2$, and F-statistics in a LLSR model's R output.          

5. Interpret standard errors, t-statistics, residual standard error, $R^2$, and F-statistics in a LLSR model's R output.          


6. Analyze data using linear least squares regression in R.           

This chapter provides an outline of Sections 1.4-1.7 of [Beyond Multiple Linear Regression](https://bookdown.org/roback/bookdown-BeyondMLR/) by Roback and Legler. Much of the text is either directly from the book, or lightly modified/summarized. Most of the code originates from the book's [Github repository](https://github.com/proback/BeyondMLR).  

```{r load_packages1, message = FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, fig.height = 3, fig.width = 6)
# Packages required for Chapter 1
library(knitr) 
library(gridExtra)
library(GGally)
library(kableExtra)
library(jtools)
library(rsample)
library(broom)
library(tidyverse)    
library(ggformula)
```


## Exploratory Data Analysis

### Kentucky Derby Data

We use data from the Kentucky Derby, a 1.25 mile race run annually at Churchill Downs race track in Louisville, Kentucky. 

Our data set `derbyplus.csv` contains data from 1896-2017, and includes the following variables: 

*  `year` of the race,    
*  winning horse (`winner`),   
*  `condition` of the track (fast, good, slow) ,    
*  average `speed` (in feet per second) of the winner,    
*   number of `starters` (horses who raced) 

We would like to use least squares linear regression techniques to model the speed of the winning horse as a function of track condition, field size, and trends over time.  

**Sample and Population**   

Statistics are often used to generalize conclusions from a sample to a larger population. In this scenario, it's not immediately clear what a larger population of interest might be. The Kentucky Derby is run only once each year, and we have results for all years between 1896 and 2017. We could imagine, however, that even if the same horses were to run the race multiple times, even under the same track conditions, their times might vary from one race to the next. Thus, we can think of the larger population as being all races that might have been run with the same horses, under similar conditions.    


```{r introtable1,echo=TRUE, warning=FALSE}
derby.df <- read.csv("https://raw.githubusercontent.com/proback/BeyondMLR/master/data/derbyplus.csv")
head(derby.df)
```

### Some Data Wrangling

We modify the data to create:      
* indicator (0-1) variables for whether the track was in fast or good condition    
* a factor variable (`fastfactor`) telling whether or not the track was fast     
* a variable giving years since 1896 (`yearnew`)

```{r,echo=TRUE, warning=FALSE}
derby.df <- derby.df %>%
  mutate( fast = ifelse(condition=="fast",1,0), 
          good = ifelse(condition=="good",1,0),
          yearnew = year - 1896,
          fastfactor = ifelse(fast == 0, "not fast", "fast"))
table1 <- derby.df %>%
  filter(row_number() < 6 | row_number() > 117)
kable(table1, booktabs=T,caption="The first five and the last five observations from the Kentucky Derby case study.") %>%
  kable_styling(latex_options = "scale_down")
```


### Univariate Graphical Summaries

Distributions of winning speeds and number of starters    

```{r twohist, fig.align = "center", out.width="90%", fig.cap = 'Histograms of key continuous variables.  Plot (a) shows winning speeds, while plot (b) shows the number of starters.', echo=TRUE, message=FALSE}
# EDA graphs
speed_hist <- ggplot(data = derby.df, aes(x = speed)) + 
  geom_histogram(binwidth = 0.5, fill = "white",
                 color = "black") + 
  xlab("Winning speed (ft/s)") + ylab("Frequency") + labs(title="(a)")
starters_hist <- ggplot(data = derby.df, aes(x = starters)) + 
  geom_histogram(binwidth = 3, fill = "white",
                 color = "black") + 
  xlab("Number of starters") + ylab("Frequency") + labs(title="(b)")
grid.arrange(speed_hist, starters_hist, ncol = 2)
```

### Bivariate Graphical Summaries

The `ggpairs` function creates a scatterplot matrix displaying relationships between all pairs of variables.  

```{r bivariate, fig.align = "center", out.width = "90%", fig.cap = 'Relationships between pairs of variables in the Kentucky Derby data set.', echo=TRUE, warning=FALSE, message = FALSE}
gg <- ggpairs(data = derby.df, 
              columns = c("condition", "year", "starters", "speed"))
gg
```

* We see evidence of higher speeds on fast tracks and also a tendency for recent years to have more fast conditions.  

We examine how winning speeds have changed over time, when the track is fast and when it is not fast.   

```{r codeds, fig.align = "center", out.width = "90%", fig.cap = 'Linear trends in winning speeds over time, presented separately for fast conditions vs. good or slow conditions.', echo=TRUE, warning=FALSE, message=FALSE}
# Coded scatterplot
ggplot(derby.df, aes(x = year, y = speed, colour = fastfactor)) +
  geom_point(aes(shape = fastfactor)) +
  geom_smooth(aes(linetype = fastfactor), method = lm, se = FALSE)
```

* It appears that winning speeds have increased more rapidly for tracks that are not fast. This suggests an interaction between year and track condition, since the relationship between speed and year appears to differ depending on whether or not the track was fast.    


## Simple Linear Regression Model 

### Model for Winning Time and Year

We begin with a simple linear regression model for winning speed ($Y$), using year since 1896 as the explanatory variable. This model has the form:  

\begin{equation}
 Y_{i}=\beta_{0}+\beta_{1}\textrm{Yearnew}_{i}+\epsilon_{i} \quad \textrm{where} \quad \epsilon_{i}\sim \textrm{N}(0,\sigma^2).
\end{equation}

We obtain estimates of $\beta_0$ and $\beta_1$, denoted ($\hat{\beta_0}$ and $\hat{\beta_1}$) by minimizing the sum of squared residuals $SSR=\displaystyle\sum_{i=1}^{n}\left(Y_i- (\beta_{0}+\beta_{1}\textrm{Yearnew}_{i})\right)^2.$ 

### First Model R Output

We fit the model in R. 

```{r model2, comment=NA}
model2 <- lm(speed ~ yearnew, data = derby.df)
summary(model2)
```


**Interpretations:**

* The expected winning speed in 1896 is 51.59 ft/s.    
* Winning speed is expected to increase by 0.026 ft./s on average for each year since 1896. The low p-value provides evidence that average winning speed has increased over time.      
* 51\% of the total variability in winning speed is explained by the simple linear regression model with year since 1896 as the explanatory variable.    
* We estimate that the error standard deviation $\sigma$ is 0.90. This represents the average deviation between the actual winning speed in a given year and the model's predicted winning speed. If there were multiple races run in the same year, this could be interpreted as the variability in winning speeds between different races run in the same year.    





### Calculations in SLR 

The `summary` command for a linear model in R displays a table with 4 columns. 


* **Estimate** gives the least-squares estimates $b_0, b_1, \ldots, b_p$     

* **Standard Error** gives estimates of the standard deviation in the sampling distribution for estimate. It tells us how the estimate is expected to vary between different samples of the given size. Standard error formulas are given in the table below.     

* **t value** is the estimate divided by its standard error.     

* **Pr(>|t|)** is a p-value for the hypothesis test associated with the null hypothesis $\beta_j = 0$, where $\beta_j$ is the regression coefficient pertaining to the given line. Note that $\beta_j$ is the unknown population parameter estimated by $b_j$.   

* The **Residual Standard Error** is $s =\sqrt{\frac{\text{SSR}}{n-(p+1)}} = \sqrt{\frac{\displaystyle\sum_{i=1}^n(y_i-\hat{y}_i)^2}{(n-(p+1))}}$. This is an estimate of $\sigma$, which represents the standard deviation in the distribution of the response variable for given value(s) or category(ies) of explanatory variable(s). It tells us how much variability is expected in the response variable between different individuals with the same values/categories of the explanatory variables.     

* The **degrees of freedom** are $n-(p+1)$.     

* The **Multiple R-Squared** value is the $R^2$ value seen in Chapter 2. $R^2 = \frac{\text{SST} -\text{SSR}}{\text{SST}} = \frac{\displaystyle\sum_{i=1}^n(y_i-\hat{y}_i)^2}{\displaystyle\sum_{i=1}^n(y_i-\bar{y}_i)^2}$

* We know that $R^2$ can never decrease when additional variables are added to a model. The **Adjusted-R^2** value is an alternate version of $R^2$ that is designed to penalize adding variables that do little to explain variation in the response.   

* The F-statistic on the bottom line of the R-output corresponds to an F-test of the given model against a reduced model that include no explanatory variables. The p-value on this line is associated with the test of the null hypothesis that there is no relationship between the response variable and any of the explanatory variables. Since SSR for this reduced model is equal to SST, the F-statistic calculation simplifies to:   

\[
F=\frac{\frac{SST - SSR}{p}}{\frac{SSR}{n-(p+1)}}
\]

The degrees of freedom associated with the F-statistic are given by $p$ and $(n-(p+1))$. 


**Standard Error Formulas**

|Scenario| Standard Error | 
|---------|-----|     
| Single Mean | $SE(b_0)=\frac{s}{\sqrt{n}}$ |   
| Difference in Means | $SE(b_j)=s\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}$ |   
| Single Proportion| $SE(\hat{p}) = \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$|
| Difference in Proportions| $SE(\hat{p}) = \sqrt{\left(\frac{\hat{p_1}(1-\hat{p}_1)}{n_1}+\frac{\hat{p_2}(1-\hat{p_2})}{n_2}\right)}$|
| Intercept in Simple Linear Regression | $SE(b_0)=s\sqrt{\frac{1}{n}+\frac{\bar{x}^2}{\sum(x_i-\bar{x})^2}}$ |    
| Slope in Simple Linear Regression | $SE(b_1)=\sqrt{\frac{s^2}{\sum(x_i-\bar{x})^2}}=\sqrt{\frac{1}{n-2}\frac{{\sum(\hat{y}_i-y_i)^2}}{\sum(x_i-\bar{x})^2}}$ | 

* $s=\sqrt{\frac{\displaystyle\sum_{i=1}^n(y_i-\hat{y}_i)^2}{(n-(p+1))}}$, (p is number of regression coefficients not including $b_0$) is sample standard deviation. Note that in the one-sample case, this simplifies to the standard deviation formula we've seen previously.        

* In the 2nd formula, the standard error estimate $s\sqrt{\frac{1}{n_1+n_2}}$ is called a "pooled" estimate since it combines information from all groups. When there is reason to believe standard deviation differs between groups, we often use an "unpooled" standard error estimate of $\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}$, where $s_1, s_2$ represent the standard deviation for groups 1 and 2. 


**Variability Sums of Squares**     

* the total variability in the response variable is the sum of the squared differences between the observed values and the overall average.   

\[\text{Total Variability in Response Var.}= \text{SST} =\displaystyle\sum_{i=1}^n(y_i-\bar{y})^2\]

* the variability remaining unexplained even after accounting for explanatory variable(s) in a model is given by the sum of squared residuals. We abbreviate this SSR, for sum of squared residuals.    

\[
\text{SSR} = \text{Variability Remaining}=\displaystyle\sum_{i=1}^n(y_i-\hat{y}_i)^2
\]

* the variability explained by the model, abbreviated SSM, is given by 

\[ \text{SSM} = \text{SST} - \text{SSR} \]


* The coefficient of determination (abbreviated $R^2$) is defined as    

\[R^2=\frac{\text{Variability Explained by Model}}{\text{Total Variability}}=\frac{\text{SSM}}{\text{SST}} =\frac{\displaystyle\sum_{i=1}^n(\hat{y}_i-\bar{y})^2}{\displaystyle\sum_{i=1}^n(y_i-\bar{y})^2}\]

Note that some texts use different abbreviations than the ones used here. When working with resources outside this class, be sure to carefully check the notation being used. 


The estimated regression equation is 

\[
\text{Speed} = 51.59 - 0.026 \times\text{YearNew}, \text{where } \epsilon_i\sim\mathcal{N}(0, \sigma)
\]

* SSR is:

```{r}
sum(model2$residuals^2)
```

* SST is:

```{r}
sum((derby.df$speed - mean(derby.df$speed))^2)
```


* The residual standard error $s$ is our estimate of $\sigma$, the standard deviation in winning speeds among races run in the same year.  

\[
s =\sqrt{\frac{\text{SSR}}{n-(p+1)}} = \sqrt{\frac{\text{SSR}}{n-(p+1)}} = \sqrt{\frac{97.8993}{122-(1+1)}}=0.9032
\]

The degrees of freedom associated with this estimate is $122-(1+1) = 120$.

* The Multiple R-Squared is:    

\[
R^2 = \frac{201.1791 - 97.8993}{201.1791} = 0.5134
\]

* The F-statistic is

\[
F=\frac{\frac{SST - SSR}{p}}{\frac{SSR}{n-(p+1)}} = \frac{\frac{201.1791 - 97.8993}{1}}{\frac{97.8993}{122-(1+1)}} = 126.6
\]

This F-statistic is associated with 1 and 120 degrees of freedom.   

To obtain the standard error estimates for $b_0$ and $b_1$, we need to calculate $\bar{x}$ and $\sum(x_i-\bar{x})^2$, where $x$ represents the explanatory variable, $\text{YearNew}$. 

```{r}
mean(derby.df$yearnew)
```

```{r}
sum((derby.df$yearnew-mean(derby.df$yearnew))^2)
```

 

\[
SE(b_0)=s\sqrt{\frac{1}{n}+\frac{\bar{x}^2}{\sum(x_i-\bar{x})^2}} = 0.9032317\sqrt{\frac{1}{122} + \frac{60.5^2}{151310.5} } = 0.1625
\]

$SE(b_0)$ represents the variability in expected winning speed in 1896, between different samples of 122 races that might have been run by these horses under similar conditions.    



\[
SE(b_1)=\sqrt{\frac{s^2}{\sum(x_i-\bar{x})^2}}=\sqrt{\frac{0.9032^2}{151310.5}} = 0.0023219
\]

$SE(b_1)$ represents the variability in rate of change in winning speed per year, between different samples of 122 races that might have been run by these horses under similar conditions.    

**Hypothesis Test for Intercept Line**

**Null Hypothesis:** The average winning speed among all races that might have been run by these horses, under similar conditions, in 1896 is 0. ($\beta_0=0$).   

**Alternative Hypothesis:** The average winning speed among all races that might have been run by these horses, under similar conditions, in 1896 is not 0. ($\beta_0 \neq 0$).  

Obviously, a horse that wins a race will not have a running speed of 0, so this is not a sensible hypothesis test.       

**Hypothesis Test for pH Line**

**Null Hypothesis:** There is no relationship between year and average winning speed, i.e., average winning speed does not change over time among all races that might have been run by these horses under similar conditions. ($\beta_1=0$).   

**Alternative Hypothesis:** There is a relationship between year and average winning speed, i.e., average winning speed does change over time among all races that might have been run by these horses under similar conditions. ($\beta_1 \neq 0$).  

**Test Statistic**: $t=\frac{{b_j}}{\text{SE}(b_j)} = \frac{-0.02612601}{0.002322013} = 11.25$ 

```{r, fig.height=4, fig.width=8}
ts=11.25145
gf_dist("t", df=120, geom = "area", fill = ~ (abs(x)> abs(ts)), show.legend=FALSE) + geom_vline(xintercept=c(ts, -ts), color="red")  + xlab("t")
```



```{r}
2*pt(-abs(ts), df=120)
```

The tiny p-value provides strong evidence of a relationship between year and winning speed. Kentucky Derby winners do indeed appear to be getting faster over time.    



### Checking Model Assumptions

```{r resid2, fig.align = "center", out.width = "90%", fig.cap = 'Residual plots for Model 2.', echo=TRUE, warning=FALSE, fig.height=10, fig.width=10}
# Residual diagnostics for Model 2
par(mar=c(4,4,4,4))
par(mfrow=c(2,2))
plot(model2)
par(mfrow=c(1,1))
```

The residual plots help tell us what trends/relationships our model is missing, or leaving unexplained. 

- The upper left plot, Residuals vs. Fitted, can be used to check the Linearity assumption.  Residuals should be patternless around Y = 0; if not, there is a pattern in the data that is currently unaccounted for.   
- The upper right plot, Normal Q-Q, can be used to check the Normality assumption.  Deviations from a straight line indicate that the distribution of residuals does not conform to a theoretical normal curve.
- The lower left plot, Scale-Location, can be used to check the Equal Variance assumption.  Positive or negative trends across the fitted values indicate variability that is not constant.
- The lower right plot, Residuals vs. Leverage, can be used to check for influential points.  Points with high leverage (having unusual values of the predictors) and/or high absolute residuals can have an undue influence on estimates of model parameters.  

There is typically no residual plot to evaluate the Independence assumption. Evidence for lack of independence comes from knowing about the study design and methods of data collection.  In this case, with a new field of horses each year, the assumption of independence is pretty reasonable.  



In this case, the Residuals vs. Fitted plot indicates that a quadratic fit might be better than the linear fit of Model 2; other assumptions look reasonable.    

### Quadratic Term for Year

Let's add a quadratic term to the model

\begin{equation*}
Y_{i}=\beta_{0}+\beta_{1}\textrm{Yearnew}_{i}+\beta_{2}\textrm{Yearnew}^2_{i}+\epsilon_{i}\quad \textrm{where}\quad \epsilon_{i}\sim \textrm{N}(0,\sigma^2).
\end{equation*}

### Quadratic Model in R

```{r model2Q, comment=NA}
derby.df <- mutate(derby.df, yearnew2 = yearnew^2)
model2q <- lm(speed ~ yearnew + yearnew2, data = derby.df)
```

```{r, echo=TRUE, message=FALSE}
coef(summary(model2q))
cat(" R squared = ", summary(model2q)$r.squared, "\n", 
    "Residual standard error = ", summary(model2q)$sigma)
```


```{r models2and2q, fig.align = "center", out.width = "90%", fig.cap = 'Linear (solid) vs. quadratic (dashed) fit.', echo=TRUE, warning=FALSE}
# Fitted models for Model 2 and Model 2Q
ggplot(derby.df, aes(x = year, y = speed)) +
  geom_point() +
  stat_smooth(method = "lm", formula = y ~ x, 
              se = FALSE, linetype = 1) +
  stat_smooth(method = "lm", formula = y ~ x + I(x^2), 
              se = FALSE, linetype = 2)
```


* This model suggests that the rate of increase in winning speeds is slowing down over time.  
* The low p-value on the quadratic term provides evidence that there is indeed a quadratic relationship between speed and year (as opposed to a linear one). Furthermore, the proportion of variation in winning speeds explained by the model has increased from 51.3\% to 64.1\%. 

### Quadratic Model Residual Plots

```{r resid2q, fig.align = "center", out.width = "90%", fig.cap = 'Residual plots for Model 2Q.', echo=TRUE, warning=FALSE, fig.height=10, fig.width=10}
# Residual diagnostics for Model 2
par(mar=c(4,4,4,4))
par(mfrow=c(2,2))
plot(model2q)
par(mfrow=c(1,1))
```

The quadratic trend in the residual vs fitted plot has disappeared, as the quadratic relationship is now explained in our model.   


## Multiple Linear Regression with Two Predictors

### Model with Year and Fast Track

We add an indicator variable for whether or not the track is fast in our model. 

Note that the text writes an indicator using the name of the 0-1 categorical variable, as opposed to the $\text{I}_{\text{Fast}}$ notation I used in STAT 255.    


$$
\begin{equation}
Y_{i}=\beta_{0}+\beta_{1}\textrm{Yearnew}_{i}+\beta_{2}\textrm{Fast}_{i}+\epsilon_{i}\quad \textrm{where}\quad \epsilon_{i}\sim \textrm{N}(0,\sigma^2).
\end{equation}
$$

### Multiple Regression Model in R

```{r model4, comment=NA}
model4 <- lm(speed ~ yearnew + fast, data = derby.df)
```

```{r, echo=TRUE, message=FALSE}
coef(summary(model4))
cat(" R squared = ", summary(model4)$r.squared, "\n", 
    "Residual standard error = ", summary(model4)$sigma)
```

**Interpretations:**    

* winning speeds are, on average, 1.23 ft/s faster under fast conditions after accounting for time trends (i.e. assuming year is held constant). The low p-value provides evidence that winning speeds increase over time, after accounting for track condition.          
* winning speeds are expected to increase by 0.023 ft/s per year, after accounting for track condition. The low p-value provides evidence that winning speeds are faster when the track is in fast condition, after accounting for year.  
      This yearly effect is also smaller than the 0.026 ft/s per year we estimated the previous model, that did not account for track condition. The single-variable model appears to have slightly overestimated the average increase in speed. This is probably because track conditions have also improved over time (due to improvements in track maintenence). The single variable model cannot distinguish between improvements in track conditions and improvements in speed of the horses. The multiple regression model can estimate these effects separately.    
* Based on the $R^2$ value, Model 4 explains 68.7\% of the year-to-year variability in winning speeds, a noticeable increase over using either explanatory variable alone.  

### Confidence Intervals from MLR Model

**Confidence Intervals for $\beta_0, \beta_1, \beta_2$.**   

Under LINE assumptions, a confidence interval for $\beta_j$ is given by $\hat{\beta_j} \pm t_{(n-p), (1-\alpha/2)}^* \text{SE}(\beta_j)$,   

where $t_{(n-p), (1-\alpha/2)}^*$ represents the $(1-\alpha/2)$ quantile of a t-distribution with $n-p$ degrees of freedom, $\alpha$ represents the level of significance (e.g. 0.05 for a 95% CI), and $p$ represents the number of parameters $\beta_0, \beta_1, \ldots...$

```{r}
confint(model4)
```

**Interpretations:**

- We can be 95\% confident that average winning speeds increase between 0.019 and 0.026 ft/s each year, after accounting for track condition.    
- We can be 95\% confident that average winning speeds under fast conditions are between 0.93 and 1.53 ft/s higher than under non-fast conditions, after accounting for the effect of year.    

To make a prediction for a new case, such as the winning speed in 2017, we use a prediction interval:   

```{r model4inf, comment=NA}
new.data <- data.frame(yearnew = 2017 - 1896, fast = 1) 
predict(model4, new = new.data, interval = "prediction")
```

- Based on our model, we can be 95\% confident that the winning speed in 2017 under fast conditions will be between 53.4 and 56.3 ft/s.  Note that Always Dreaming's actual winning speed (53.40) barely fit within this interval---the 2017 winning speed was a borderline outlier on the slow side.  

 - If we wanted to estimate the average value of Y among all cases with the given explanatory variable values, we would use `interval="confidence"`. This doesn't really make sense in this context, since there is only one winning speed each year.   
 

### Slopes for Fast, non-Fast Tracks

In model4, we assume that the expected rate of change in winning speed over time is the same, regardless of whether the track is fast or not. In either case, it is given by $\beta_1$.    

Thus, Model 4 produces a picture that looks like this:    

```{r, echo=TRUE, fig.height=5, fig.width=8}
equation1 <- function(x){coef(model4)[2]*x+coef(model4)[1]}
equation2  <- function(x){coef(model4)[2]*x+coef(model4)[1]+coef(model4)[3]}
ggplot(data=derby.df, aes(x=yearnew, y=speed, color=fastfactor)) + geom_point()+
        stat_function(fun=equation1,geom="line",color=scales::hue_pal()(3)[3]) +
        stat_function(fun=equation2,geom="line",color=scales::hue_pal()(3)[1]) 
```

Recall, however, that the data suggested that speeds have increased more rapidly for tracks that are not fast. 

```{r, fig.align = "center", out.width = "90%", fig.cap = 'Linear trends in winning speeds over time, presented separately for fast conditions vs. good or slow conditions.', echo=TRUE, warning=FALSE, message=FALSE}
# Coded scatterplot
ggplot(derby.df, aes(x = year, y = speed, colour = fastfactor)) +
  geom_point(aes(shape = fastfactor)) +
  geom_smooth(aes(linetype = fastfactor), method = lm, se = FALSE)
```

### MLR Model with Interaction

We want to build a model allows winning speeds to increase at different rates for fast tracks than for those that are not fast. (i.e. a model that includes an interaction between `fast` and `yearnew`)

Thus, consider Model 5:

$$
\begin{equation*}
\begin{split}
Y_{i}&= \beta_{0}+\beta_{1}\textrm{Yearnew}_{i}+\beta_{2}\textrm{Fast}_{i} \\
      &{}+\beta_{3}\textrm{Yearnew}_{i}\times\textrm{Fast}_{i}+\epsilon_{i}\quad \textrm{where}\quad \epsilon_{i}\sim \textrm{N}(0,\sigma^2)
\end{split}
\end{equation*}
$$
### Interaction Model Estimates

LLSR provides the following parameter estimates:

We can do this using either of the following commands
```{r model5, comment=NA}
model5 <- lm(speed ~ yearnew + fast + yearnew:fast, data=derby.df)
model5 <- lm(speed ~  yearnew*fast, data=derby.df)
```

```{r, echo=TRUE, message=FALSE}
coef(summary(model5))
cat(" R squared = ", summary(model5)$r.squared, "\n", 
    "Residual standard error = ", summary(model5)$sigma)
```

### Model Equations for Fast, Non-Fast Tracks

According to our model, estimated winning speeds can be found by:

$$
\begin{equation}
 \hat{Y}_{i}=50.53+0.031\textrm{Yearnew}_{i}+1.83\textrm{Fast}_{i}-0.011\textrm{Yearnew}_{i}\times\textrm{Fast}_{i}.
\end{equation}
$$

$$
\begin{align*}
 \textrm{Fast}=0: & \\
 \hat{Y}_{i} &= 50.53+0.031\textrm{Yearnew}_{i} \\
 \textrm{Fast}=1: & \\
 \hat{Y}_{i} &= (50.53+1.83)+(0.031-0.011)\textrm{Yearnew}_{i}
 \end{align*}
$$
 
 
**Interpretations**

- $\hat{\beta}_{0} = 50.53$.  The expected winning speed in 1896 under non-fast conditions was 50.53 ft/s.
- $\hat{\beta}_{1} = 0.031$.  The expected yearly increase in winning speeds under non-fast conditions is 0.031 ft/s.
- $\hat{\beta}_{2} = 1.83$.  The winning speed in 1896 was expected to be 1.83 ft/s faster under fast conditions compared to non-fast conditions.
- $\hat{\beta}_{3} = -0.011$.  The expected yearly increase in winning speeds under fast conditions is 0.020 ft/s, compared to 0.031 ft/s under non-fast conditions, a difference of 0.011 ft/s.


## Building a Multiple Linear Regression Model 

### Model Building Considerations

We now add additional variables, with the goal of building a final model that provides insight into relationships between winning speed and other variables.   

There is no single correct model, but a good model will have the following characteristics:     

- explanatory variables allow one to address primary research questions
- explanatory variables control for important covariates
- potential interactions have been investigated
- variables are centered where interpretations can be enhanced (e.g. subtract 1896 from year)
- unnecessary terms have been removed
- LINE assumptions and the presence of influential points have both been checked using residual plots
- the model tells a "persuasive story parsimoniously"

Most good models should lead to similar conclusions.    

### Model Diagnostics

Several tests and measures of model performance can be used when comparing different models for model building:

- $R^2$. Measures the variability in the response variable explained by the model.  One problem is that $R^2$ always increases with extra predictors, even if the predictors add very little information.
- adjusted $R^2$.  Adds a penalty for model complexity to $R^2$ so that any increase in performance must outweigh the cost of additional complexity.  We should ideally favor any model with higher adjusted $R^2$, regardless of size, but the penalty for model complexity (additional terms) is fairly ad-hoc.
- AIC (Akaike Information Criterion). Again attempts to balance model performance with model complexity, with smaller AIC levels being preferable, regardless of model size.  The BIC (Bayesian Information Criterion) is similar to the AIC, but with a greater penalty for additional model terms.
- extra sum of squares F test.  This is a generalization of the t-test for individual model coefficients which can be used to perform significance tests on **nested models**, \index{nested models} where one model is a reduced version of the other. 

### Three Possible Models

We'll consider three possible final models:   

Model A:

$$
\begin{equation}
\begin{split}
 Y_{i}&=\beta_{0}+\beta_{1}\textrm{Yearnew}_{i}+\beta_{2}\textrm{Yearnew}^2_{i}+\epsilon_{i}\quad 
      \textrm{where}\quad \epsilon_{i}\sim \textrm{N}(0,\sigma^2)
\end{split}
\end{equation}
$$


Model B:

$$
\begin{equation}
\begin{split}
 Y_{i}&=\beta_{0}+\beta_{1}\textrm{Yearnew}_{i}+\beta_{2}\textrm{Yearnew}^2_{i}+\beta_{3}\textrm{Fast}_{i}\\
      &{}+\beta_{4}\textrm{Good}_{i}+\beta_{5}\textrm{Starters}_{i}+\epsilon_{i}\quad 
      \textrm{where}\quad \epsilon_{i}\sim \textrm{N}(0,\sigma^2)
\end{split}
\end{equation}
$$

Note that this is equivalent to including the original track condition variable in a model. In this case, slow track is treated as the `baseline` variable, since we left the indicator for slow out of the model.   


Model C:

$$
\begin{equation}
\begin{split}
 Y_{i}&=\beta_{0}+\beta_{1}\textrm{Yearnew}_{i}+\beta_{2}\textrm{Yearnew}^2_{i}+\beta_{3}\textrm{Fast}_{i}\\
      &{}+\beta_{4}\textrm{Good}_{i}+\beta_{5}\textrm{Starters}_{i}  \\ 
      & + \beta_6\textrm{Yearnew}_{i}\textrm{Fast}_{i}+  \beta_7\textrm{Yearnew}_{i}\textrm{Good}_{i} \\
       & + \beta_8\textrm{Yearnew}^2_{i}\textrm{Fast}_{i}+  \beta_9\textrm{Yearnew}^2_{i}\textrm{Good}_{i} \\
      & + \epsilon_{i}\quad 
      \textrm{where}\quad \epsilon_{i}\sim \textrm{N}(0,\sigma^2)
\end{split}
\end{equation}
$$

### MLR Models Fit in R

We fit each model in R. 

```{r model0, comment=NA}
model0A <- lm(speed ~ yearnew + yearnew2 , data = derby.df)
model0B <- lm(speed ~ yearnew + yearnew2 + fast + good + starters, data = derby.df)
model0C <- lm(speed ~ yearnew + yearnew2 + fast + good + starters + 
                yearnew:fast + yearnew:good + yearnew2:fast + 
                yearnew2:good, data = derby.df)
```

```{r, echo=FALSE}
options(scipen = 999)
```

### Model 0A Output

```{r, echo=TRUE, message=FALSE}
coef(summary(model0A)) %>% round(6)
cat(" R squared = ", summary(model0A)$r.squared, "\n", 
    " Adjusted R squared = ", summary(model0A)$adj.r.squared, "\n",
    "Residual standard error = ", summary(model0A)$sigma, "\n",
"AIC = ", AIC(model0A))
```

### Model 0B Output

```{r}
coef(summary(model0B))%>% round(6)
cat(" R squared = ", summary(model0B)$r.squared, "\n", 
        " Adjusted R squared = ", summary(model0B)$adj.r.squared, "\n",
    "Residual standard error = ", summary(model0B)$sigma,"\n",
"AIC = ", AIC(model0B))
```

### Model 0C Output


```{r}
coef(summary(model0C))%>% round(6)
cat(" R squared = ", summary(model0C)$r.squared, "\n", 
        " Adjusted R squared = ", summary(model0C)$adj.r.squared, "\n",
    "Residual standard error = ", summary(model0C)$sigma, "\n",
"AIC = ", AIC(model0C))
```

### Goodness of Fit Tests

When two models are nested (that is, all the terms in the smaller model also appear in the larger model) we can compare them using a goodness of fit test.

Reduced Model: $\hat{y}_i = b_0 + b_1x_{i1} + b_2{x_i2} + \ldots + b_{q-1}x_{iq-1}$

Full Model:  $\hat{y}_i = b_0 + b_1x_{i1} + b_2{x_i2} + \ldots + b_{q-1}x_{iq-1} + b_{q}x_{i{q}} \ldots + b_{p}x_{i{p-1}}$

p = # parameters in Full Model   
q = # parameters in Reduced Model $(q<p)$  
n = number of observations

The hypothesis are:

Null Hypothesis: Smaller model adequately explains variability in the response variable.   
Alternative Hypothesis: Larger model better explains variability in the response variable than the smaller one.    

### ANOVA F-Statistic

We calculate an F-statistic using the formula:

$$
F = \frac{\frac{\text{SSR}_{\text{Reduced}}-\text{SSR}_{\text{Full}}}{p-q}}{\frac{\text{SSR}_{\text{Full}}}{n-p}}
$$

When the null hypothesis is true, this statistic follows an F-distribution with $p-q$ and $n-p$ degrees of freedom. 


```{r comment=NA, message=FALSE}
# Compare model0A and model0B
anova(model0A, model0B, test = "F")
```

There is very strong evidence that track condition and number of starters help explain variability in winning speed.   

```{r comment=NA, message=FALSE}
# Compare model0A and model0B
anova(model0B, model0C, test = "F")
```

There is evidence of interaction between year and track conditions.


Observations:

* There is strong evidence that model B is better than model A. Accounting for condition of track and number of starters helps explain variability in winning speeds.    

* Models B and C both seem like reasonable fits. Adjusted R^2, AIC, and the F-test all favor model C over model B. Model C is, however, much harder to interpret. The p-values on any single interaction term were large, even though the model testing for significance of interactions collectively was small. When in doubt, it's better to go with the simpler model, unless there is clear reason to choose the more complex one. 


**It is important to consider intuition, domain area knowledge, and interpretability when choosing a model. Do not choose a model based on statistical tests alone!**

### Final Model Residual Plots

We'll go with model B. 

We use residual plots to check model assumptions. 

```{r , fig.align = "center", out.width = "90%", fig.cap = 'Residual plots for Model 0B.', echo=TRUE, warning=FALSE, fig.height=10, fig.width=10}
# Residual diagnostics for Model B
par(mar=c(4,4,4,4))
par(mfrow=c(2,2))
plot(model0B)
par(mfrow=c(1,1))
```

There do not appear to be any major model violations.    


Model B Coefficients Table:

```{r}
coef(summary(model0B))%>% round(6)
cat(" R squared = ", summary(model0B)$r.squared, "\n", 
        " Adjusted R squared = ", summary(model0B)$adj.r.squared, "\n",
    "Residual standard error = ", summary(model0B)$sigma,"\n",
"AIC = ", AIC(model0B))
```

### Overall Conclusions

**Conclusions:**    
* The rate of increase in winning speeds is slowing over time (negative quadratic term)    
* The better the condition of the track, the faster the horses tend to run     
* larger field, with more starters, is associated with slower winning times   

Notice this last conclusion appears contradictory to our exploratory data analysis, which showed a positive relationship between starters and speed.  


```{r, fig.align = "center", out.width = "90%", fig.cap = 'Relationships between pairs of variables in the Kentucky Derby data set.', echo=TRUE, warning=FALSE, message = FALSE}
gg <- ggpairs(data = derby.df, 
              columns = c("condition", "year", "starters", "speed"))
gg
```

This happens because over time, the number of starters in the race has increased, as have winning speeds. So, it appears that having more starters is associated with faster winning speeds, but year is acting as a **confounding** variable. The multiple regression model is able to separate the effect of year from that of number of starters. The model tells us that assuming year is held constant, having more starters is actually associated with a slower winning speed.    

A situation like this, where adding a variable (such as year) to a model results in an apparent trend disappearing or reversing itself, is called **Simpson's Paradox.**

<!---

## Estimation and Testing in LLSR Model

We'll return to model 4. The full R summary output for the model is shown below. In this section, we explain how each of the estimates, standard errors, test statistics, and p-values shown in the output are obtained.   

```{r}
summary(model4)
```

The model equation is

$$
\begin{equation}
Y_{i}=\beta_{0}+\beta_{1}\textrm{Yearnew}_{i}+\beta_{2}\textrm{Fast}_{i}+\epsilon_{i}\quad \textrm{where}\quad \epsilon_{i}\sim \textrm{N}(0,\sigma^2).
\end{equation}
$$

This model contains four parameters ($\beta_0$, $\beta_1$, $\beta_2$, and $\sigma^2$). 

### Estimating $\beta_j$

* The estimates parameters $\hat{\beta_0}$, $\hat{\beta_1}$, and $\hat{\beta_2}$ are chosen in order to minimize the quantity 


$$
\begin{align*}
\text{SSR} &= \displaystyle\sum_{i=1}^{n}(y_i-\hat{y}_i)^2 \\
 &= \displaystyle\sum_{i=1}^{n}(y_i-(\hat{\beta}_0+\hat{\beta}_1x_{1i}+\hat{\beta}_2x_{2i}))^2  \\
& = \displaystyle\sum_{i=1}^{n}(\text{Speed}_i-(\hat{\beta}_0+\hat{\beta}_1\text{Yearnew}_i+\hat{\beta}_2\text{Fast}_i))^2 \\
& = \left(51.66-(\hat{\beta}_0+\hat{\beta}_1(0)+\hat{\beta}_2(0))\right)^2 + \left(49.81-(\hat{\beta}_0+\hat{\beta}_1(1)+\hat{\beta}_2(0))\right)^2 + \\\  & \ldots + \left(53.40-(\hat{\beta}_0+\hat{\beta}_1(121)+\hat{\beta}_2(1))\right)^2
 \end{align*}
$$
This is a minimization problem in three dimensions. It can be solved using multivariable calculus techniques.

**Notes:**    

1. In special cases (such as for a single categorical or quantitative explanatory variable) the estimates $\hat{\beta_j}$ can be found using formulas (see 2.4.3 and 2.4.4 in the Stat 255 notes).    

2. (Optional - intended for people who are familiar with linear algebra) If $X$ is a $n \times p$ matrix (of rank $p$) whose columns contain the values of each variable in the dataset (including a column of 1's corresponding to the intercept column), and $\vec{y}$ is a n-dimensional vector of response values, then the $p$-dimensional vector of regression coefficient estimates $\vec{\hat{\beta}}$ can is given by 

\[
\vec{\hat{\beta}} = (X^TX)^{-1}X^T\vec{y}
\]

This operation is projecting $\vec{y}$ onto the space spanned by the columns of $X$ (also called the column space of $X$).  

This calculation is shown below, for model 4.  

```{r}
y <- derby.df$speed
X <- cbind(1, derby.df$yearnew, derby.df$fast)
head(y)
head(X)
```

In R, $t(X)$ calculates the transpose of a matrix $X$, and `solve(X)` returns $X^{-1}$

```{r}
solve(t(X) %*% X) %*% t(X) %*% y
```

### Estimating $\sigma^2$

* The estimate of the error variance, $\hat{\sigma}^2$ is calculated as: 

\[
\hat{\sigma}^2=\frac{\displaystyle\sum_{i=1}^{n}(y_i-\hat{y}_i)^2}{n-p},
\]

where $p$ represents the number of terms in the model, including the intercept (which is the same as the number of lines in the coefficients table). 

This quantity represents the variance in unexplained deviations between individual response values and their expectation after accounting for the explanatory variables in the model.   

In the R-output, the **residual standard error** is the estimate $\hat{\sigma}$. 

### Standard Errors

Computing standard errors associated with regression coefficients requires matrix operations that go beyond the scope of this class, so we will trust the estimates provided by R. In simple cases, formulas exist to calculate these by hand:   

|Scenario| Standard Error | 
|---------|-----|     
| Intercept for baseline category of categorical variable | $SE(\hat{\beta}_0)=\frac{\hat{\sigma}}{\sqrt{n}}$ |   
| Estimated difference between two groups | $SE(\hat{\beta}_j)=\hat{\sigma}\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}$ |    
| Intercept in Simple Linear Regression | $SE(\hat{\beta}_0)=\hat{\sigma}\sqrt{\frac{1}{n}+\frac{\bar{x}^2}{\sum(x_i-\bar{x})^2}}$ |    
| Slope in Simple Linear Regression | $SE(\hat{\beta}_1)=\sqrt{\frac{\hat{\sigma}^2}{\sum(x_i-\bar{x})^2}}=\sqrt{\frac{1}{n-2}\frac{{\sum(\hat{y}_i-\bar{y})^2}}{\sum(x_i-\bar{x})^2}}$ | 

Note that in each case, the standard error of a regression coefficient is a function of both the estimated error variance, $\hat{\sigma}^2$, and the sample size $n$. 

### t-statistics

The third column of the coefficients table in R gives the ratio of an estimate $\hat{\beta}_j$ to its standard error $SE(\hat{\beta}_j)$. This quantity is called a **t-statistic**.

\[
t= \frac{\hat{\beta}_j}{\text{SE}(\hat{\beta}_j)}  
\]

Under the assumptions of the LLSR model, and the null hypothesis that $\beta_j=0$, this statistic follows a t-distribution with $n-p$ degrees of freedom.   

A **t-distribution** is a symmetric, bell-shaped curve, with thicker tails (hence more variability), than a standard normal $\mathcal{N}(0,1)$ distribution.   

```{r, fig.height=5, fig.width=10, warning=FALSE, message=FALSE, include=FALSE}
gf_dist("t", df=3, color = ~ "3 df", kind = "density")  %>%
gf_dist("t", df=10, color = ~ "10 df", kind = "density") %>%
gf_dist("t", df=20, color = ~ "20 df", kind = "density") %>%
gf_dist("t", df=30, color = ~ "30 df", kind = "density") %>%
gf_dist("norm", color = ~ "N(0,1)", kind = "density") + xlim(c(-3,3))
```

```{r, echo=FALSE, fig.height=5, fig.width=10}
dt1 <- function(x){
  dt(x, df=3)
}
dt2 <- function(x){
  dt(x, df=10)
}
dt3 <- function(x){
  dt(x, df=20)
}
dt4 <- function(x){
  dt(x, df=30)
}

```

```{r, echo=FALSE, fig.height=6, fig.width=8}
df <- data.frame(x = seq(from=-3, to=3, by=0.1), y = dnorm(seq(from=-3, to=3, by=0.1), 0,1/sqrt(3)))
p <- ggplot(df, aes(x = x, y = y)) +
  stat_function(fun=dnorm,geom="line",color=scales::hue_pal()(5)[1]) + 
  annotate(geom="text", x=0.5, y=0.4, label="N(0,1)",
              color=scales::hue_pal()(5)[1]) +
    stat_function(fun=dt1, geom="line",color=scales::hue_pal()(5)[2]) +
   annotate(geom="text", x=0, y=0.35, label="t with 3 df",
              color=scales::hue_pal()(5)[2]) +
    stat_function(fun=dt2, geom="line",color=scales::hue_pal()(5)[3]) +
    annotate(geom="text", x=0, y=0.37, label="t with 10 df",
              color=scales::hue_pal()(5)[3]) +
      stat_function(fun=dt3, geom="line",color=scales::hue_pal()(5)[4]) +
   annotate(geom="text", x=0.5, y=0.38, label="t with 20 df",
              color=scales::hue_pal()(5)[4]) +
     stat_function(fun=dt, geom="line",color=scales::hue_pal()(5)[5]) +
   annotate(geom="text", x=0.5, y=0.39, label="t with 30 df",
              color=scales::hue_pal()(5)[5]) 
p
```

As the degrees of freedom for a t-distribution approach $\infty$, the t-distribution converges to a standard normal distribution.   

### p-values  

The **p-value** associated with a regression coefficient is the probability of obtaining a sample that gives a regression estimate (or equivalently, a t-statistic) as extreme or more extreme than we did, when there is actually no relationship between that explanatory variable and the response (after accounting for other variables in the model). In the case of a categorical variable, this is equivalent to the probability of obtaining a sample that gives an estimated difference in average response between the given category and the baseline category as extreme or more extreme than we did, given that there is actually no difference between the two categories after accounting for other variables in the model. 

In mathematical terms, the p-value is equal to the probability of obtaining a sample that gives a value of $\hat{\beta}_j$ as extreme or more extreme than we did, when $\beta_j=0$. 

#### Example from `model4`

In model 4, the t-statistic associated with the variable `fast` is

\[
t= \frac{\hat{\beta}_2}{\text{SE}(\hat{\beta}_2)} = \frac{1.226846}{0.15072}=8.14 
\]

We calculate a p-value by finding the probability of obtaining a t-statistic greater than 8.14, or less than -8.14 when working with a t-distribution with $n-p = 122-3$ degrees of freedom.   


```{r, fig.height=4, fig.width=8}
tstat <- 8.14
gf_dist("t", df=119, geom = "area", fill = ~(abs(x)< abs(tstat)), show.legend=FALSE) + geom_vline(xintercept=c(tstat, -tstat), color="red")  + xlab("t")
```

We see that this probability is extremely low. We can calculate it precisely, using the `pt` command. 

This command calculates the probability of getting value to t-statistic the right of 8.14, which we then double, since the t-distribution is symmetric.

```{r}
2*pt(8.14, df=119, lower.tail=FALSE)
```

This small p-value provides strong evidence of a difference in speed between fast and non-fast tracks, after accounting for year.   


#### Example from `model0C`

In model 0C, the t-statistic associated with the variable `starters` is

\[
t= \frac{\hat{\beta}_5}{\text{SE}(\hat{\beta}_5)} = \frac{-0.018592}{0.013107}=-1.42. 
\]

We calculate a p-value by finding the probability of obtaining a t-statistic greater than -1.42, or less than 1.42 when working with a t-distribution with $n-p = 122-10$ degrees of freedom. (recall the model included 10 terms)  


```{r, fig.height=4, fig.width=8}
tstat <- -1.42
gf_dist("t", df=112, geom = "area", fill = ~(abs(x)< abs(tstat)), show.legend=FALSE) + geom_vline(xintercept=c(tstat, -tstat), color="red")  + xlab("t")
```


Note, since the t-statistic is negative, we set `lower.tail=TRUE` to find the probability in the left tail, and then double it.   

```{r}
2*pt(-1.42, df=112, lower.tail=TRUE)
```

This large p-value indicates that we do not have evidence of a relationship between in speed and number of starters in the race, after accounting for the other variables in the model.   

### Residual Standard Error

We've now seen how to calculate all of the quantities in the coefficients table, so we turn our attention to the three lines below the table in the summary output.  


* Residual Standard Error is the estimate of 

\[
\hat{\sigma}=\sqrt{\frac{\displaystyle\sum_{i=1}^{n}(y_i-\hat{y}_i)^2}{n-p}},
\]

representing variance in unexplained deviations between individual response values and their expectation after accounting for the explanatory variables in the model.  

### Degrees of Freedom

* Degrees of Freedom are given by $n-p$, that is, the sample size minus the number of terms in the model (i.e. number of $\beta$'s being estimated, including the intercept). These effect the amount of spread in the t-distributions associated with the regression estimates.     

### $R^2$

* The Multiple R-Squared value, representing the proportion of total variability in the response variable, that is explained by the model, is given by 

\[R^2=\frac{\text{Variability Explained by Model}}{\text{Total Variability}}=\frac{\text{SST-SSR}}{\text{SST}} =\frac{\displaystyle\sum_{i=1}^n(\hat{y}_i-\bar{y})^2}{\displaystyle\sum_{i=1}^n(y_i-\bar{y})^2},\]

where $SST = \displaystyle\sum_{i=1}^n (y_i - \bar{y})^2$ represents the total amount of variability in the response variable, without accounting for any explanatory variables, and $\text{SSR} =\displaystyle\sum_{i=1}^n(y_i-\hat{y}_i)^2$ represents the total amount of unexplained variability remaining, after accounting for the explanatory variables used in the model.

SST Calculation:   

```{r}
sum((derby.df$speed - mean(derby.df$speed))^2)
```

SSR Calculation: 

```{r}
sum((derby.df$speed - model4$fitted.values)^2)
```

$R^2 = \frac{201.1791-62.88574}{201.1791} = 0.6874$.  


$R^2$ can never decrease when an additional variable is added to a model. An adjusted version of R-squared, intended to penalize the addition of unimportant terms is also provided in the R-output.   

See Section 2.2 of the [Stat 255 notes](https://stat255-lu.github.io/Notes/) for more detail on $R^2$. 

### F-Statistic

* The F-statistic on the last line of the output is associated with goodness of fit test comparing the given model to one with only an intercept term. The null hypothesis associated with this test is that there is no relationship between the response variable and any of the explanatory variables in the model. Typically, a model that is at all useful, will yield a low p-value here. 

Under the assumptions of the LLSR model, and the null hypothesis that the reduced model explains as much variability in the response as the full model, the F-statistic follows a right-skewed distribution, known as an **F-distribution.** This distribution is defined by two parameters, $\nu_1, \nu_2$, called numerator and denominator degrees of freedom. 

```{r, fig.height=5, fig.width=10, echo=FALSE, warning=FALSE, message=FALSE}
gf_dist("f", df1=5, df2=5, color = ~ "5,5 df", kind = "density")  %>%
gf_dist("f", df1=5, df2=20, color = ~ "5,20 df", kind = "density") %>%
gf_dist("f", df1=20, df2=5, color = ~ "20,5 df", kind = "density") %>%
gf_dist("f", df1=20, df2=20, color = ~ "20,20 df", kind = "density") + xlim(c(0,10)) + xlab("F")
```

We show the calculation for the F-statistic in the model 4 output. 

$$
F = \frac{\frac{\text{SSR}_{\text{Reduced}}-\text{SSR}_{\text{Full}}}{p-q}}{\frac{\text{SSR}_{\text{Full}}}{n-p}}=\frac{\frac{201.1791-62.88574}{3-1}}{\frac{62.88574}{122-3}} = 130.8477
$$

The degrees of freedom associated with this F-distribution are (p-q and n-p), in this case, 2 and 119. 



```{r, fig.height=4, fig.width=8}
Fstat=130.8477
gf_dist("f", df1=2, df2=119, geom = "area", fill = ~ (abs(x)< abs(Fstat)), show.legend=FALSE) + geom_vline(xintercept=c(Fstat), color="red")  + xlab("F")
```

We calculate the p-value, using the `pf` command.

p-value:

```{r}
pf(Fstat, df1=2, df2=119, lower.tail=FALSE)
```

We can also use the `pf` command to calculate the p-value for the F-test we used to compare models 0A and 0B in the previous section.  

```{r comment=NA, message=FALSE}
# Compare model0A and model0B
anova(model0B, model0C, test = "F")
```
```{r, fig.height=4, fig.width=8}
Fstat=4.3117
gf_dist("f", df1=4, df2=112, geom = "area", fill = ~ (abs(x)< abs(Fstat)), show.legend=FALSE) + geom_vline(xintercept=c(Fstat), color="red")  + xlab("F")
```

p-value:

```{r}
pf(Fstat, df1=4, df2=112, lower.tail=FALSE)
```

-->