# Review of Multiple Linear Regression


This chapter provides an outline of Sections 1.4-1.7 of [Beyond Multiple Linear Regression](https://bookdown.org/roback/bookdown-BeyondMLR/) by Roback and Legler. Much of the text is either directly from the book, or lightly modified/summarized. Most of the code originates from the book's [Github repository](https://github.com/proback/BeyondMLR).  


```{r load_packages1, message = FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, fig.height = 3, fig.width = 6)
# Packages required for Chapter 1
library(knitr) 
library(gridExtra)
library(GGally)
library(kableExtra)
library(jtools)
library(rsample)
library(broom)
library(tidyverse)    
```


## Exploratory Data Analysis

### Kentucky Derby Data

We use data from the Kentucky Derby, a 1.25 mile race run annually at Churchill Downs race track in Louisville, Kentucky. 

Our data set `derbyplus.csv` contains data from 1896-2017, and includes the following variables: 

*  `year` of the race,    
*  winning horse (`winner`),   
*  `condition` of the track (fast, good, slow) ,    
*  average `speed` (in feet per second) of the winner,    
*   number of `starters` (horses who raced) 

We would like to use least squares linear regression techniques to model the speed of the winning horse as a function of track condition, field size, and trends over time.  


```{r introtable1,echo=TRUE, warning=FALSE}
derby.df <- read.csv("https://raw.githubusercontent.com/proback/BeyondMLR/master/data/derbyplus.csv")
head(derby.df)
```

### Some Data Wrangling

We modify the data to create:      
* indicator (0-1) variables for whether the track was in fast or good condition    
* a factor variable (`fastfactor`) telling whether or not the track was fast     
* a variable giving years since 1896 (`yearnew`)

```{r,echo=TRUE, warning=FALSE}
derby.df <- derby.df %>%
  mutate( fast = ifelse(condition=="fast",1,0), 
          good = ifelse(condition=="good",1,0),
          yearnew = year - 1896,
          fastfactor = ifelse(fast == 0, "not fast", "fast"))
table1 <- derby.df %>%
  filter(row_number() < 6 | row_number() > 117)
kable(table1, booktabs=T,caption="The first five and the last five observations from the Kentucky Derby case study.") %>%
  kable_styling(latex_options = "scale_down")
```


### Univariate Graphical Summaries

Distributions of winning speeds and number of starters    

```{r twohist, fig.align = "center", out.width="90%", fig.cap = 'Histograms of key continuous variables.  Plot (a) shows winning speeds, while plot (b) shows the number of starters.', echo=TRUE, message=FALSE}
# EDA graphs
speed_hist <- ggplot(data = derby.df, aes(x = speed)) + 
  geom_histogram(binwidth = 0.5, fill = "white",
                 color = "black") + 
  xlab("Winning speed (ft/s)") + ylab("Frequency") + labs(title="(a)")
starters_hist <- ggplot(data = derby.df, aes(x = starters)) + 
  geom_histogram(binwidth = 3, fill = "white",
                 color = "black") + 
  xlab("Number of starters") + ylab("Frequency") + labs(title="(b)")
grid.arrange(speed_hist, starters_hist, ncol = 2)
```

### Bivariate Graphical Summaries

The `ggpairs` function creates a scatterplot matrix displaying relationships between all pairs of variables.  

```{r bivariate, fig.align = "center", out.width = "90%", fig.cap = 'Relationships between pairs of variables in the Kentucky Derby data set.', echo=TRUE, warning=FALSE, message = FALSE}
gg <- ggpairs(data = derby.df, 
              columns = c("condition", "year", "starters", "speed"))
gg
```

* We see evidence of higher speeds on fast tracks and also a tendency for recent years to have more fast conditions.  

We examine how winning speeds have changed over time, when the track is fast and when it is not fast.   

```{r codeds, fig.align = "center", out.width = "90%", fig.cap = 'Linear trends in winning speeds over time, presented separately for fast conditions vs. good or slow conditions.', echo=TRUE, warning=FALSE, message=FALSE}
# Coded scatterplot
ggplot(derby.df, aes(x = year, y = speed, colour = fastfactor)) +
  geom_point(aes(shape = fastfactor)) +
  geom_smooth(aes(linetype = fastfactor), method = lm, se = FALSE)
```

* It appears that winning speeds have increased more rapidly for tracks that are not fast. This suggests an interaction between year and track condition, since the relationship between speed and year appears to differ depending on whether or not the track was fast.    


## Simple Linear Regression Model 

### Model for Winning Time and Year

We begin with a simple linear regression model for winning speed ($Y$), using year since 1896 as the explanatory variable. This model has the form:  

\begin{equation}
 Y_{i}=\beta_{0}+\beta_{1}\textrm{Yearnew}_{i}+\epsilon_{i} \quad \textrm{where} \quad \epsilon_{i}\sim \textrm{N}(0,\sigma^2).
\end{equation}

We obtain estimates of $\beta_0$ and $\beta_1$, denoted ($\hat{\beta_0}$ and $\hat{\beta_1}$) by minimizing the sum of squared residuals $SSR=\displaystyle\sum_{i=1}^{n}\left(Y_i- (\beta_{0}+\beta_{1}\textrm{Yearnew}_{i})\right)^2.$ 

### First Model R Output

We fit the model in R. 

```{r model2, comment=NA}
model2 <- lm(speed ~ yearnew, data = derby.df)
```

```{r, echo=TRUE, message=FALSE}
coef(summary(model2))
cat(" R squared = ", summary(model2)$r.squared, "\n", 
    "Residual standard error = ", summary(model2)$sigma)
```

**Interpretations:**

* The expected winning speed in 1896 is 51.59 ft/s.    
* Winning speed is expected to increase by 0.026 ft./s on average for each year since 1896. The low p-value provides evidence that average winning speed has increased over time.      
* 51\% of the total variability in winning speed is explained by the simple linear regression model with year since 1896 as the explanatory variable.    
* We estimate that the error standard deviation $\sigma$ is 0.90.   



### Checking Model Assumptions

```{r resid2, fig.align = "center", out.width = "90%", fig.cap = 'Residual plots for Model 2.', echo=TRUE, warning=FALSE, fig.height=10, fig.width=10}
# Residual diagnostics for Model 2
par(mar=c(4,4,4,4))
par(mfrow=c(2,2))
plot(model2)
par(mfrow=c(1,1))
```

The residual plots help tell us what trends/relationships our model is missing, or leaving unexplained. 

- The upper left plot, Residuals vs. Fitted, can be used to check the Linearity assumption.  Residuals should be patternless around Y = 0; if not, there is a pattern in the data that is currently unaccounted for.   
- The upper right plot, Normal Q-Q, can be used to check the Normality assumption.  Deviations from a straight line indicate that the distribution of residuals does not conform to a theoretical normal curve.
- The lower left plot, Scale-Location, can be used to check the Equal Variance assumption.  Positive or negative trends across the fitted values indicate variability that is not constant.
- The lower right plot, Residuals vs. Leverage, can be used to check for influential points.  Points with high leverage (having unusual values of the predictors) and/or high absolute residuals can have an undue influence on estimates of model parameters.  

There is typically no residual plot, to evaluate the Independence assumption. Evidence for lack of independence comes from knowing about the study design and methods of data collection.  In this case, with a new field of horses each year, the assumption of independence is pretty reasonable.  



In this case, the Residuals vs. Fitted plot indicates that a quadratic fit might be better than the linear fit of Model 2; other assumptions look reasonable.    

### Quadratic Term for Year

Let's add a quadratic term to the model

\begin{equation*}
Y_{i}=\beta_{0}+\beta_{1}\textrm{Yearnew}_{i}+\beta_{2}\textrm{Yearnew}^2_{i}+\epsilon_{i}\quad \textrm{where}\quad \epsilon_{i}\sim \textrm{N}(0,\sigma^2).
\end{equation*}

### Quadratic Model in R

```{r model2Q, comment=NA}
derby.df <- mutate(derby.df, yearnew2 = yearnew^2)
model2q <- lm(speed ~ yearnew + yearnew2, data = derby.df)
```

```{r, echo=TRUE, message=FALSE}
coef(summary(model2q))
cat(" R squared = ", summary(model2q)$r.squared, "\n", 
    "Residual standard error = ", summary(model2q)$sigma)
```


```{r models2and2q, fig.align = "center", out.width = "90%", fig.cap = 'Linear (solid) vs. quadratic (dashed) fit.', echo=TRUE, warning=FALSE}
# Fitted models for Model 2 and Model 2Q
ggplot(derby.df, aes(x = year, y = speed)) +
  geom_point() +
  stat_smooth(method = "lm", formula = y ~ x, 
              se = FALSE, linetype = 1) +
  stat_smooth(method = "lm", formula = y ~ x + I(x^2), 
              se = FALSE, linetype = 2)
```


* This model suggests that the rate of increase in winning speeds is slowing down over time.  
* The low p-value on the quadratic term provides evidence that there is indeed a quadratic relationship between speed and year (as opposed to a linear one). Furthermore, the proportion of variation in winning speeds explained by the model has increased from 51.3\% to 64.1\%. 

### Quadratic Model Residual Plots

```{r resid2q, fig.align = "center", out.width = "90%", fig.cap = 'Residual plots for Model 2Q.', echo=TRUE, warning=FALSE, fig.height=10, fig.width=10}
# Residual diagnostics for Model 2
par(mar=c(4,4,4,4))
par(mfrow=c(2,2))
plot(model2q)
par(mfrow=c(1,1))
```

The quadratic trend in the residual vs fitted plot has disappeared, as the quadratic relationship is now explained in our model.   


## Multiple Linear Regression with Two Predictors

### Model with Year and Fast Track

We add an indicator variable for whether or not the track is fast in our model. 

Note that the text writes an indicator using the name of the 0-1 categorical variable, as opposed to the $\text{I}_{\text{Fast}}$ notation I used in STAT 255.    


$$
\begin{equation}
Y_{i}=\beta_{0}+\beta_{1}\textrm{Yearnew}_{i}+\beta_{2}\textrm{Fast}_{i}+\epsilon_{i}\quad \textrm{where}\quad \epsilon_{i}\sim \textrm{N}(0,\sigma^2).
\end{equation}
$$

### Multiple Regression Model in R

```{r model4, comment=NA}
model4 <- lm(speed ~ yearnew + fast, data = derby.df)
```

```{r, echo=TRUE, message=FALSE}
coef(summary(model4))
cat(" R squared = ", summary(model4)$r.squared, "\n", 
    "Residual standard error = ", summary(model4)$sigma)
```

**Interpretations:**    

* winning speeds are, on average, 1.23 ft/s faster under fast conditions after accounting for time trends (i.e. assuming year is held constant). The low p-value provides evidence that winning speeds increase over time, after accounting for track condition.          
* winning speeds are expected to increase by 0.023 ft/s per year, after accounting for track condition. The low p-value provides evidence that winning speeds are faster when the track is in fast condition, after accounting for year.  
      This yearly effect is also smaller than the 0.026 ft/s per year we estimated the previous model, that did not account for track condition. The single-variable model appears to have slightly overestimated the average increase in speed. This is probably because track conditions have also improved over time (due to improvements in track maintenence). The single variable model cannot distinguish between improvements in track conditions and improvements in speed of the horses. The multiple regression model can estimate these effects separately.    
* Based on the $R^2$ value, Model 4 explains 68.7\% of the year-to-year variability in winning speeds, a noticeable increase over using either explanatory variable alone.  

### Confidence Intervals from MLR Model

**Confidence Intervals for $\beta_0, \beta_1, \beta_2$.**   

Under LINE assumptions, a confidence interval for $\beta_j$ is given by $\hat{\beta_j} \pm t_{(n-p), (1-\alpha/2)}^* \text{SE}(\beta_j)$,   

where $t_{(n-p), (1-\alpha/2)}^*$ represents the $(1-\alpha/2)$ quantile of a t-distribution with $n-p$ degrees of freedom, $\alpha$ represents the level of significance (e.g. 0.05 for a 95% CI), and $p$ represents the number of parameters $\beta_0, \beta_1, \ldots...$

```{r}
confint(model4)
```

**Interpretations:**

- We can be 95\% confident that average winning speeds increase between 0.019 and 0.026 ft/s each year, after accounting for track condition.    
- We can be 95\% confident that average winning speeds under fast conditions are between 0.93 and 1.53 ft/s higher than under non-fast conditions, after accounting for the effect of year.    

To make a prediction for a new case, such as the winning speed in 2017, we use a prediction interval:   

```{r model4inf, comment=NA}
new.data <- data.frame(yearnew = 2017 - 1896, fast = 1) 
predict(model4, new = new.data, interval = "prediction")
```

- Based on our model, we can be 95\% confident that the winning speed in 2017 under fast conditions will be between 53.4 and 56.3 ft/s.  Note that Always Dreaming's actual winning speed (53.40) barely fit within this interval---the 2017 winning speed was a borderline outlier on the slow side.  

 - If we wanted to estimate the average value of Y among all cases with the given explanatory variable values, we would use `interval="confidence"`. This doesn't really make sense in this context, since there is only one winning speed each year.   
 

### Slopes for Fast, non-Fast Tracks

In model4, we assume that the expected rate of change in winning speed over time is the same, regardless of whether the track is fast or not. In either case, it is given by $\beta_1$.    

Thus, Model 4 produces a picture that looks like this:    

```{r, echo=TRUE, fig.height=5, fig.width=8}
equation1 <- function(x){coef(model4)[2]*x+coef(model4)[1]}
equation2  <- function(x){coef(model4)[2]*x+coef(model4)[1]+coef(model4)[3]}
ggplot(data=derby.df, aes(x=yearnew, y=speed, color=fastfactor)) + geom_point()+
        stat_function(fun=equation1,geom="line",color=scales::hue_pal()(3)[3]) +
        stat_function(fun=equation2,geom="line",color=scales::hue_pal()(3)[1]) 
```

Recall, however, that the data suggested that speeds have increased more rapidly for tracks that are not fast. 

```{r, fig.align = "center", out.width = "90%", fig.cap = 'Linear trends in winning speeds over time, presented separately for fast conditions vs. good or slow conditions.', echo=TRUE, warning=FALSE, message=FALSE}
# Coded scatterplot
ggplot(derby.df, aes(x = year, y = speed, colour = fastfactor)) +
  geom_point(aes(shape = fastfactor)) +
  geom_smooth(aes(linetype = fastfactor), method = lm, se = FALSE)
```

### MLR Model with Interaction

We want to build a model allows winning speeds to increase at different rates for fast tracks than for those that are not fast. (i.e. a model that includes an interaction between `fast` and `yearnew`)

Thus, consider Model 5:

$$
\begin{equation*}
\begin{split}
Y_{i}&= \beta_{0}+\beta_{1}\textrm{Yearnew}_{i}+\beta_{2}\textrm{Fast}_{i} \\
      &{}+\beta_{3}\textrm{Yearnew}_{i}\times\textrm{Fast}_{i}+\epsilon_{i}\quad \textrm{where}\quad \epsilon_{i}\sim \textrm{N}(0,\sigma^2)
\end{split}
\end{equation*}
$$
### Interaction Model Estimates

LLSR provides the following parameter estimates:

We can do this using either of the following commands
```{r model5, comment=NA}
model5 <- lm(speed ~ yearnew + fast + yearnew:fast, data=derby.df)
model5 <- lm(speed ~  yearnew*fast, data=derby.df)
```

```{r, echo=TRUE, message=FALSE}
coef(summary(model5))
cat(" R squared = ", summary(model5)$r.squared, "\n", 
    "Residual standard error = ", summary(model5)$sigma)
```

### Model Equations for Fast, Non-Fast Tracks

According to our model, estimated winning speeds can be found by:

$$
\begin{equation}
 \hat{Y}_{i}=50.53+0.031\textrm{Yearnew}_{i}+1.83\textrm{Fast}_{i}-0.011\textrm{Yearnew}_{i}\times\textrm{Fast}_{i}.
\end{equation}
$$


$$
\begin{align*}
 \textrm{Fast}=0: & \\
 \hat{Y}_{i} &= 50.53+0.031\textrm{Yearnew}_{i} \\
 \textrm{Fast}=1: & \\
 \hat{Y}_{i} &= (50.53+1.83)+(0.031-0.011)\textrm{Yearnew}_{i}
 \end{align*}
 $$
 
 
**Interpretations**

- $\hat{\beta}_{0} = 50.53$.  The expected winning speed in 1896 under non-fast conditions was 50.53 ft/s.
- $\hat{\beta}_{1} = 0.031$.  The expected yearly increase in winning speeds under non-fast conditions is 0.031 ft/s.
- $\hat{\beta}_{2} = 1.83$.  The winning speed in 1896 was expected to be 1.83 ft/s faster under fast conditions compared to non-fast conditions.
- $\hat{\beta}_{3} = -0.011$.  The expected yearly increase in winning speeds under fast conditions is 0.020 ft/s, compared to 0.031 ft/s under non-fast conditions, a difference of 0.011 ft/s.


## Building a Multiple Linear Regression Model 

### Model Building Considerations

We now add additional variables, with the goal of building a final model that provides insight into relationships between winning speed and other variables.   

There is no single correct model, but a good model will have the following characteristics:     

- explanatory variables allow one to address primary research questions
- explanatory variables control for important covariates
- potential interactions have been investigated
- variables are centered where interpretations can be enhanced (e.g. subtract 1896 from year)
- unnecessary terms have been removed
- LINE assumptions and the presence of influential points have both been checked using residual plots
- the model tells a "persuasive story parsimoniously"

Most good models should lead to similar conclusions.    

### Model Diagnostics

Several tests and measures of model performance can be used when comparing different models for model building:

- $R^2$. Measures the variability in the response variable explained by the model.  One problem is that $R^2$ always increases with extra predictors, even if the predictors add very little information.
- adjusted $R^2$.  Adds a penalty for model complexity to $R^2$ so that any increase in performance must outweigh the cost of additional complexity.  We should ideally favor any model with higher adjusted $R^2$, regardless of size, but the penalty for model complexity (additional terms) is fairly ad-hoc.
- AIC (Akaike Information Criterion). Again attempts to balance model performance with model complexity, with smaller AIC levels being preferable, regardless of model size.  The BIC (Bayesian Information Criterion) is similar to the AIC, but with a greater penalty for additional model terms.
- extra sum of squares F test.  This is a generalization of the t-test for individual model coefficients which can be used to perform significance tests on **nested models**, \index{nested models} where one model is a reduced version of the other. 

### Three Possible Models

We'll consider three possible final models:   

Model A:

$$
\begin{equation}
\begin{split}
 Y_{i}&=\beta_{0}+\beta_{1}\textrm{Yearnew}_{i}+\beta_{2}\textrm{Yearnew}^2_{i}+\epsilon_{i}\quad 
      \textrm{where}\quad \epsilon_{i}\sim \textrm{N}(0,\sigma^2)
\end{split}
\end{equation}
$$


Model B:

$$
\begin{equation}
\begin{split}
 Y_{i}&=\beta_{0}+\beta_{1}\textrm{Yearnew}_{i}+\beta_{2}\textrm{Yearnew}^2_{i}+\beta_{3}\textrm{Fast}_{i}\\
      &{}+\beta_{4}\textrm{Good}_{i}+\beta_{5}\textrm{Starters}_{i}+\epsilon_{i}\quad 
      \textrm{where}\quad \epsilon_{i}\sim \textrm{N}(0,\sigma^2)
\end{split}
\end{equation}
$$

Note that this is equivalent to including the original track condition variable in a model. In this case, slow track is treated as the `baseline` variable, since we left the indicator for slow out of the model.   


Model C:

$$
\begin{equation}
\begin{split}
 Y_{i}&=\beta_{0}+\beta_{1}\textrm{Yearnew}_{i}+\beta_{2}\textrm{Yearnew}^2_{i}+\beta_{3}\textrm{Fast}_{i}\\
      &{}+\beta_{4}\textrm{Good}_{i}+\beta_{5}\textrm{Starters}_{i}  \\ 
      & + \beta_6\textrm{Yearnew}_{i}\textrm{Fast}_{i}+  \beta_7\textrm{Yearnew}_{i}\textrm{Good}_{i} \\
       & + \beta_8\textrm{Yearnew}^2_{i}\textrm{Fast}_{i}+  \beta_9\textrm{Yearnew}^2_{i}\textrm{Good}_{i} \\
      & + \epsilon_{i}\quad 
      \textrm{where}\quad \epsilon_{i}\sim \textrm{N}(0,\sigma^2)
\end{split}
\end{equation}
$$

### MLR Models Fit in R

We fit each model in R. 

```{r model0, comment=NA}
model0A <- lm(speed ~ yearnew + yearnew2 , data = derby.df)
model0B <- lm(speed ~ yearnew + yearnew2 + fast + good + starters, data = derby.df)
model0C <- lm(speed ~ yearnew + yearnew2 + fast + good + starters + 
                yearnew:fast + yearnew:good + yearnew2:fast + 
                yearnew2:good, data = derby.df)
```

```{r, echo=FALSE}
options(scipen = 999)
```

### Model 0A Output

```{r, echo=TRUE, message=FALSE}
coef(summary(model0A)) %>% round(6)
cat(" R squared = ", summary(model0A)$r.squared, "\n", 
    " Adjusted R squared = ", summary(model0A)$adj.r.squared, "\n",
    "Residual standard error = ", summary(model0A)$sigma, "\n",
"AIC = ", AIC(model0A))
```

### Model 0B Output

```{r}
coef(summary(model0B))%>% round(6)
cat(" R squared = ", summary(model0B)$r.squared, "\n", 
        " Adjusted R squared = ", summary(model0B)$adj.r.squared, "\n",
    "Residual standard error = ", summary(model0B)$sigma,"\n",
"AIC = ", AIC(model0B))
```

### Model 0C Output


```{r}
coef(summary(model0C))%>% round(6)
cat(" R squared = ", summary(model0C)$r.squared, "\n", 
        " Adjusted R squared = ", summary(model0C)$adj.r.squared, "\n",
    "Residual standard error = ", summary(model0C)$sigma, "\n",
"AIC = ", AIC(model0C))
```

### Goodness of Fit Tests

When two models are nested (that is, all the terms in the smaller model also appear in the larger model) we can compare them using a goodness of fit test. 

Reduced Model: $\hat{y}_i = b_0 + b_1x_{i1} + b_2{x_i2} + \ldots + b_qx_{iq}$

Full Model:  $\hat{y}_i = b_0 + b_1x_{i1} + b_2{x_i2} + \ldots + b_qx_{iq} + b_{q+1}x_{i{q+1}} \ldots + b_px_{ip}$

p = # parameters in Full Model   
q = # parameters in Reduced Model  
n = number of observations

The hypothesis are:

Null Hypothesis: Smaller model adequately eplains variability in the response variable.   
Alternative Hypothesis: Larger model better explains variability in the response variable than the smaller one.    

### ANOVA F-Statistic

We calculate an F-statistic using the formula:

$$
F = \frac{\frac{\text{SSR}_{\text{Reduced}}-\text{SSR}_{\text{Full}}}{p-q}}{\frac{\text{SSR}_{\text{Full}}}{n-(p+1)}}
$$

When the null hypothesis is true, this statistic follows an F-distribution with $p-q$ and $n-p$ degrees of freedom. 


```{r comment=NA, message=FALSE}
# Compare model0A and model0B
anova(model0A, model0B, test = "F")
```

There is very strong evidence that track condition helps explain variability in winning speed.   

```{r comment=NA, message=FALSE}
# Compare model0A and model0B
anova(model0B, model0C, test = "F")
```

There is evidence of interaction between year and track conditions.

Observations:

* There is strong evidence that model B is better than model A. Accounting for condition of track and numnber of starters helps explain variability in winning speeds.    

* Models B and C both seem like reasonable fits. Asjusted R^2, AIC, and the F-test all favor model C over model B. Model C is, however, much harder to interpret. The p-values on any single interaction term were large, even though the model testing for significance of interactions collectively was small. When in doubt, it's better to go with the simpler model, unless there is clear reason to choose the more complex one. 


**It is important to consider intuition, domain area knowledge, and interpretability when choosing a model. Do not choose a model based on statistical tests alone!**

### Final Model Residual Plots

We'll go with model B. 

We use residual plots to check model assumptions. 

```{r , fig.align = "center", out.width = "90%", fig.cap = 'Residual plots for Model 0B.', echo=TRUE, warning=FALSE, fig.height=10, fig.width=10}
# Residual diagnostics for Model B
par(mar=c(4,4,4,4))
par(mfrow=c(2,2))
plot(model0B)
par(mfrow=c(1,1))
```

There do not appear to be any major model violations.    


Model B Coefficients Table:

```{r}
coef(summary(model0B))%>% round(6)
cat(" R squared = ", summary(model0B)$r.squared, "\n", 
        " Adjusted R squared = ", summary(model0B)$adj.r.squared, "\n",
    "Residual standard error = ", summary(model0B)$sigma,"\n",
"AIC = ", AIC(model0B))
```

### Overall Conclusions

**Conclusions:**    
* The rate of increase in winning speeds is slowing over time (negative quadratic term)    
* The better the condition of the track, the faster the horses tend to run     
* larger field, with more starters, is associated with slower winning times   

Notice this last conclusion appears contradictory to our exploratory data analysis, which showed a positive relationship between starters and speed.  


```{r, fig.align = "center", out.width = "90%", fig.cap = 'Relationships between pairs of variables in the Kentucky Derby data set.', echo=TRUE, warning=FALSE, message = FALSE}
gg <- ggpairs(data = derby.df, 
              columns = c("condition", "year", "starters", "speed"))
gg
```

This happens because over time, the number of starters in the race has increased, as have winning speeds. So, it appears that having more starters is associated with faster winning speeds, but year is acting as a **confounding** variable. The multiple regression model is able to separate the effect of year from that of number of starters. The model tells us that assuming year is held constant, having more starters is actually associated with a slower winning speed.    

A situation like this, where adding a variable (such as year) to a model results in an apparent trend disappearing or reversing itself, is called **Simpson's Paradox.**
