# Multilevel Generalized Linear Models 


These notes provide a summary of Chapter 11 in [Beyond Multiple Linear Regression](https://bookdown.org/roback/bookdown-BeyondMLR/) by Roback and Legler. Much of the code that appears here comes from the textbook's [Github repository](https://github.com/proback/BeyondMLR/). 




```{r load_packages11, message = FALSE}
# Packages required for Chapter 11
library(gridExtra)
library(lme4)
library(pander)
library(ggmosaic)
library(knitr)
library(kableExtra)
library(broom)
library(tidyverse)
```

In basketball, do referees tend to "even out" calls over the course of a game? Is a team more likely to have a foul called on them if the last foul was called on the other team, or if the other team has had more fouls called in the game up to that point? 


## Basketball Referees Dataset

### Data Overview

Data was collected for 4972 fouls over 340 college basketball games during the 2009-2010 season. We focus on fouls called during the first half to avoid the issue of intentional fouls by the trailing team at the end of games. 

The dataset includes the following variables. 

- `game` = unique game identification number
- `date` = date game was played (YYYYMMDD)
- `visitor` = visiting team abbreviation
- `hometeam` = home team abbreviation
- `foul.num` = cumulative foul number within game
- `foul.home` = indicator if foul was called on the home team
- `foul.diff` = the difference in fouls before the current foul was called (home - visitor)
- `score.diff` = the score differential before the current foul was called (home - visitor)
- `lead.home` = indicator if home team has the lead
- `previous.foul.home` = indicator if previous foul was called on the home team
- `foul.type` = categorical variable if current foul was offensive, personal, or shooting
- `time` = number of minutes left in the first half when foul called


```{r}
refdata <- read.csv("https://raw.githubusercontent.com/proback/BeyondMLR/master/data/basketball0910.csv")
refdata <- refdata %>% select(game, visitor, hometeam, foul.num, foul.home, foul.diff, score.diff, lead.home, previous.foul.home, foul.type, time)
head(refdata)       # examine first 6 rows
```


For our initial analysis, our primary response variable is the binary variable `foul.home`.  

Our hypothesis is that the probability a foul is called on the home team is inversely related to the foul differential; that is, if more fouls have been called on the home team than the visiting team, the next foul is less likely to be on the home team.

Our data are measured at multiple levels:  

* Level 1 Observational Unit: Individual fouls    
* Level 1 Explanatory Variables: foul.num, foul.diff, score.diff, lead.home, previous.foul.home, time, 
* Level 2 Observational Unit: Games    
* Level 2 Variables: Home and Visiting Teams 

We don't have data on these, but other potentially relevant level 2 variables might include attendance, or teams rankings. 

Our response variable (whether or not the fouls was on the home team) is a binary variable that might be modeled using logistic regression.  

We have not yet worked with logistic regression, or other generalized linear models, with multilevel datasets.  


### Histograms for Level One Covariates


Histograms for the continuous Level One covariates (time remaining, foul differential, and score differential).  

```{r}
# Summarize Level 1 covariates (and responses) by ignoring 
# within subject correlation and pretending all observations 
# are independent
time.hist <- ggplot(data = refdata, aes(x = time)) + 
  geom_histogram(binwidth = 2, color = "black", fill = "white") + 
  xlab("Time left in first half") +  ylab("Frequency") + labs(title = "(a)")

score.hist <- ggplot(data = refdata, aes(x = score.diff)) + 
  geom_histogram(binwidth = 5, color = "black", fill = "white") + 
   xlab("Score difference (home-visitor)") +
  ylab("Frequency") + labs(title = "(b)")

foul.hist <- ggplot(data = refdata, aes(x = foul.diff)) + 
  geom_histogram(binwidth = 1.5, color = "black",  fill = "white") + 
   xlab("Foul difference (home-visitor)") +
  ylab("Frequency") + labs(title = "(c)")
```

```{r gmu-histmat1, fig.cap= "Histograms showing distributions of the 3 continuous Level One covariates: (a) time remaining, (b) score difference, and (c) foul difference.", fig.align="center", echo=FALSE}
grid.arrange(time.hist, score.hist, foul.hist, ncol=3, nrow=1)
```


```{r}
refdata %>% summarize(Mean_Score_Diff=mean(score.diff),
                      Home_Ahead = mean(score.diff>0),
                      Mean_Foul_Diff = mean(foul.diff),
                      Prop_Fouls_Home=mean(foul.home) )
```

On average, the home team is ahead by 2 points averaging across all observations. The home team is ahead in 57% of all observations.   

48% of fouls called were against the home team. On average, the home team had 0.35 fewer fouls than the visitor at any given time. 

### Average Fouls by Team

Accounting for the effect of home and visiting team will likely be an important part of our model, since some teams tend to play in games with twice as many fouls called as others, and other teams see a noticeable disparity in the total number of fouls depending on if they are home or away.


```{r, table2chp11, echo=FALSE, warning=FALSE}
three <- c("Top 3",""," "," ","Bottom 3 ",""," ")
homet <- c("Duke","VaTech","Nova"," ","Mich","Ill","MN")
homes <- c("20.0","19.4","19.1"," ","10.6","11.6","12.1")
visitt <- c("WVa","Nova","Wake"," ","Wisc","Mich","PSU")
visits <- c("21.4","19.0","18.6"," ","10.4","11.1","11.3")
Difft <- c("Duke","Wisc","Pitt"," ","WVa","Mia","Clem")
Diffs <- c("4.0","2.6","2.3"," ","-6.9","-2.7","-2.6")
table2chp11 <- data.frame(three, homet, homes, visitt, 
                          visits, Difft, Diffs)
colnames(table2chp11) <- c(" ", "Team", "Fouls", "Team", 
                           "Fouls", "Team", "Fouls")
kable(table2chp11) %>%
  add_header_above(c(" ","Home"=2,"Visitor"=2, "Difference"=2))
```

* Lots of fouls are called in games where Duke, VaTech, and Nova are the home team, or when WVa, Nova, or Wake are the away team.    

* Few fouls are called when Mich, Ill, and MN are the home team, or when Wisc, Mich, and PSU are the away team.    

* There are more total fouls called in games where Duke, Wisc, and Pitt are home than when they are away. The opposite is true of WVa, Mia, and Clem. 

### Examining Bivariate Relationships

We begin by observing broad trends involving all 4972 fouls called, even though fouls from the same game may be correlated.  The conditional density plots in the first row examine continuous Level One covariates. 

```{r}
foul.df <- refdata %>%
  filter(foul.diff >= -7 & foul.diff <= 5) %>%
  group_by(foul.diff) %>%
  summarise(foul.phats = mean(foul.home)) %>%
  mutate(foul.elogits = log(foul.phats/(1 - foul.phats)) )
```

```{r}
score.df <- refdata %>%
  filter(score.diff >= -11 & score.diff <= 18) %>%
  group_by(score.diff) %>%
  summarise(score.phats = mean(foul.home)) %>%
  mutate(score.elogits = log(score.phats/(1 - score.phats)) )
```


```{r}
time.df <- refdata %>% 
  mutate(group = cut(time, 
    breaks = c(-Inf, 2, 4, 6, 8, 10, 12, 14, 16, 18, Inf),
    labels = c(1, 3, 5, 7, 9, 11, 13, 15, 17, 19))) %>%
  mutate(times = as.numeric(levels(group))[group]) %>%
  select(-group) %>%
  group_by(times) %>%
  summarise(time.phats = mean(foul.home)) %>%
  mutate(time.elogits = log(time.phats/(1 - time.phats)) )
```

```{r}
refdata <- refdata %>%
  mutate(foul.factor = as.factor(ifelse(foul.home == 1, 
                                        "Home", "Visitor")) )
```

```{r}
foul.cd <- ggplot(data = refdata, aes(x = foul.diff)) + 
  theme(legend.title = element_blank())  +
  geom_density(aes(fill = foul.factor), position = "fill", 
               adjust = 2, alpha = 0.5) + 
  xlab("Foul difference (H-V)") + 
  ylab("Probability of Home Foul") + 
  labs(title="(a)") + 
  scale_fill_manual(values = c("grey20", "grey80"))
score.cd <- ggplot(data = refdata, aes(x = score.diff)) + 
  theme(legend.title = element_blank())  +
  geom_density(aes(fill = foul.factor), position = "fill", 
               adjust = 2, alpha = 0.5) + 
  xlab("Score difference (H-V)") + 
  ylab("Probability of Home Foul") + 
  labs(title="(b)") + 
  scale_fill_manual(values = c("grey20", "grey80"))
time.cd <- ggplot(data = refdata, aes(x = time)) + 
  theme(legend.title = element_blank()) +
  geom_density(aes(fill = foul.factor), position = "fill", 
               adjust = 2, alpha = 0.5) + 
  xlab("Time left in half") + 
  ylab("Probability of Home Foul") + 
  labs(title="(c)") + 
  scale_fill_manual(values = c("grey20", "grey80"))
foul.el <- ggplot(data = foul.df, aes(x = foul.diff, 
                                      y = foul.elogits)) + 
  geom_point(color="dark grey") + xlab("Foul difference (H-V)") + 
  ylab("Empirical Log-odds of Home Foul") + 
  labs(title = "(d)") +
  geom_smooth(se = FALSE, method = "lm", color = "black")
score.el <- ggplot(data = score.df, aes(x = score.diff, 
                                        y = score.elogits)) + 
  geom_point(color="dark grey") + 
   xlab("Score difference (H-V)") + 
  ylab("Empirical Log-odds of Home Foul") + 
  labs(title = "(e)") +
  geom_smooth(se = FALSE, method = "lm", color = "black")
time.el <- ggplot(data = time.df, aes(x = times, 
                                      y = time.elogits)) + 
  geom_point(color="dark grey") + 
   xlab("Time left in half") + 
  ylab("Empirical Log-odds of Home Foul") + 
  labs(title = "(f)") +
  geom_smooth(se = FALSE, method = "lm", color = "black")
```

```{r, gmu-cdelogitmat1, fig.cap= "Conditional density and empirical logit plots of the binary model response (foul called on home or visitor) vs. the three continuous Level One covariates (foul differential, score differential, and time remaining).  The dark shading in a conditional density plot shows the proportion of fouls called on the home team for a fixed value of (a) foul differential, (b) score differential, and (c) time remaining.  In empirical logit plots, estimated log odds of a home team foul are calculated for each distinct foul (d) and score (e) differential, except for differentials at the high and low extremes with insufficient data; for time (f), estimated log odds are calculated for two-minute time intervals and plotted against the midpoints of those intervals.", fig.align="center", echo=FALSE, message=F, fig.height=12, fig.width=10}
grid.arrange(foul.cd, score.cd, time.cd,
  foul.el, score.el, time.el, ncol = 3, nrow = 2)
```



Figure (a) provides support for our primary hypothesis about evening out foul calls, indicating a very strong trend for fouls to be more often called on the home team at points in the game when more fouls had previously been called on the visiting team.  

Figures (b) and (c) then show that fouls were somewhat more likely to be called on the home team when the home team's lead was greater and (very slightly) later in the half.  

Conclusions from the conditional density plots in Figures (a)-(c) are supported with associated empirical logit plots in Figures (d)-(f).  If a logistic link function is appropriate, these plots should be linear, and the stronger the linear association, the more promising the predictor.  

We see in Figure (d) further confirmation of our primary hypothesis, with lower log-odds of a foul called on the home team associated with a greater number of previous fouls the home team had accumulated compared to the visiting team.  

Figure (e) shows that game score may play a role in foul trends, as the log-odds of a foul on the home team grows as the home team accumulates a bigger lead on the scoreboard.  

Figure (f) shows a very slight tendency for greater log-odds of a foul called on the home team as the half proceeds (since points on the right are closer to the beginning of the game).

### Tabular Summary by Fouling Team

```{r}
refdata %>% group_by(foul.home) %>% summarize(Mean_foul.diff=mean(foul.diff), 
                                              Mean_diff=mean(score.diff), 
                                              Mean_time=mean(time))

```      

Conclusions about continuous Level One covariates are further supported by summary statistics calculated separately for fouls called on the home team and those called on the visiting team.  For instance, when a foul is called on the home team, there is an average of 0.64 additional fouls on the visitors at that point in the game, compared to an average of 0.10 additional fouls on the visitors when a foul is called on the visiting team.  Similarly, when a foul is called on the home team, they are in the lead by an average of 2.7 points, compared to an average home lead of 1.4 points when a foul is called on the visiting team.  As expected, the average time remaining in the first half at the time of the foul is very similar for home teams and visitors (9.2 vs. 9.5 minutes, respectively).



### Mosaic Plots


```{r, fig.height=12, fig.width=10}
refdata <- refdata %>%
  mutate(leadyes = ifelse(lead.home == 0, "No", "Yes"),
    prevyes = ifelse(previous.foul.home == 0, "No", "Yes")) %>%
  rename(whofoul = foul.factor)

barplot2 <- ggplot(data = refdata) +
  geom_mosaic(aes(weight = 1, x = product(whofoul, leadyes), 
                  fill = whofoul)) +
  xlab("Home Team in Lead") +
  ylab("Proportion within Leading Team") + 
  labs(title = "(a)") + scale_fill_grey() +
  theme(legend.title = element_blank()) 
barplot3 <- ggplot(data = refdata) +
  geom_mosaic(aes(weight = 1, x = product(whofoul, prevyes), 
                  fill = whofoul)) +
  xlab("Previous Foul on Home Team") +
  ylab("Proportion within Previous Foul") + 
  labs(title = "(b)") + scale_fill_grey() +
  theme(legend.title = element_blank()) 
```

```{r gmu-barmat1, fig.cap= "Mosaic plots of the binary model response (foul called on home or visitor) vs. the categorical Level One covariates (team in the lead (a), and team called for the previous foul (b)).  Each bar shows the percentage of fouls called on the home team vs. the percentage of fouls called on the visiting team for a particular category of the covariate.  The bar width shows the proportion of fouls at each of the covariate levels.", fig.align="center", fig.height=10, fig.width=10, echo=FALSE}
grid.arrange(barplot2, barplot3, ncol = 2, nrow = 2)
```

Fouls were more likely to be called on the home team when the home team was leading, when the previous foul was on the visiting team



## Multilevel Generalized Linear Model

### Motivation for a Statistical Model   

The exploratory analyses presented above are an essential first step in understanding our data, seeing univariate trends, and noting bivariate relationships between variable pairs.  However, our important research questions (a) involve the effect of foul differential after adjusting for other significant predictors of which team is called for a foul, (b) account for potential correlation between foul calls within a game (or within a particular home or visiting team), and (c) determine if the effect of foul differential is constant across game conditions.  In order to address research questions such as these, we need to consider multilevel, multivariate statistical models for a binary response variable.



We'll begin by modeling the probability of a foul on the home team, using foul difference as the explanatory variable. 

Let $Y_{ij}$ represent an indicator variable for whether the $j$th foul in game $i$ was on the home team. That is   

\[ Y_{ij} =\begin{cases} 
     1 & \text{if $j$th foul in game $i$ was on home team}  \\
     0 & \text{if $j$th foul in game $i$ was on away team } 
   \end{cases}
\]

We assume:

\[
Y_{ij}\sim\text{Ber}(p_{ij})
\]


In an ordinary logistic regression model, we would say

  \[ \log\bigg(\frac{p_{ij}}{1-p_{ij}}\bigg)=\beta_0+\beta_1\text{foul.diff}_{ij} \]
  

### A GLM Approach 

We fit the logistic regression model in R

```{r, comment = NA}
# Logistic regression model (not multilevel)
M0 = glm(foul.home ~ foul.diff, 
           family = binomial, data = refdata)
summary(M0)
```

### Adding Random Effect for Game 

The ordinary logistic regression model, treats observations (fouls) as independent. We might expect fouls in the same game to be correlated. To account for this, we'll add a random effect $u_i$ for games. This gives the link function:   

  \[ \log\bigg(\frac{p_{ij}}{1-p_{ij}}\bigg)=\beta_0+\beta_1\text{foul.diff}_{ij} + u_i, \]
  
  where $u_i\sim\mathcal{N}(0,\sigma_u^2)$.    
  
  
### Two Level Logistic Model 

Let $Y_{ij}$ represent an indicator variable for whether the $j$th foul in game $i$ was on the home team. That is   

\[ Y_{ij} =\begin{cases} 
     1 & \text{if $j$th foul in game $i$ was on home team}  \\
     0 & \text{if $j$th foul in game $i$ was on away team } 
   \end{cases}
\]

We assume:

\[
Y_{ij}\sim\text{Ber}(p_{ij})
\]
  
where, 

  \[ \log\bigg(\frac{p_{ij}}{1-p_{ij}}\bigg)=\beta_0+\beta_1\text{foul.diff}_{ij} + u_i, \]
  
  and $u_i\sim\mathcal{N}(0,\sigma_u^2)$.    


### Multilevel GLM in R

We fit a multilevel generalized linear model in R using the `glmer()` function.  

```{r}
M1 <- glmer(foul.home ~ foul.diff + (1|game), family = binomial(link="logit"), data = refdata)
summary(M1)
```

Assuming the foul differential is even, the odds of a foul being called on the home team are: $e^{-0.18886} = 0.83:1$

Equivalently, the probability of a foul called going against the home team when the foul differential is even is $\frac{e^{-0.18886}}{1+e^{-0.18886}}\approx0.45$.   

Considering foul differential, for each additional fouls that the home team has, compared to the away team, the odds of the next foul going against the home team multiply by a factor of $e^{-0.26821} = 0.76$, on average.   

The estimate of $\sigma_u$ is 0.5225. This is the standard deviation in game level random effects. This is difficult to interpret in a meaningful way. (Why does it not represent the standard deviation in number of fouls called between different games?)       


Notice that estimates change after accounting for in-game correlation, and standard errors increase.   


### Add Random Slope    

The previous model assumes that the effect of foul differential on the probability of the next foul going on the home team is the same across games.  

We might add a random slope term to allow this effect to vary between games.   

Model:   

\[
Y_{ij}\sim\text{Ber}(p_{ij})
\]
  
where, 

  \[ \log\bigg(\frac{p_{ij}}{1-p_{ij}}\bigg)=\beta_0+\beta_1\text{foul.diff}_{ij} + u_i + v_i\text{foul.diff}_{ij}, \]
  
and 
\[ \left[ \begin{array}{c}
            u_i \\ v_i
          \end{array}  \right] \sim N \left( \left[
          \begin{array}{c}
            0 \\ 0
          \end{array} \right], \left[
          \begin{array}{cc}
            \sigma_{u}^{2} & \\
            \sigma_{uv} & \sigma_{v}^{2}
          \end{array} \right] \right) \]


### Random Slopes Model in R
  

```{r}
M2 <- glmer(foul.home ~ foul.diff + (foul.diff|game), 
            family = binomial(link="logit"), data = refdata)
summary(M2)
```

### AIC, BIC Comparison

```{r}
AIC(M1)
AIC(M2)
```

```{r}
BIC(M1)
BIC(M2)
```

It's not clear that adding the random slope makes much difference or is warranted.   


### Random Error Terms

\[ Y_{ij} =\begin{cases} 
     1 & \text{if $j$th foul in game $i$ was on home team}  \\
     0 & \text{if $j$th foul in game $i$ was on away team } 
   \end{cases}
\]

We assume:

\[
Y_{ij}\sim\text{Ber}(p_{ij})
\]
  
where, 

  \[ \log\bigg(\frac{p_{ij}}{1-p_{ij}}\bigg)=\beta_0+\beta_1\text{foul.diff}_{ij} + u_i, \]
  
  and $u_i\sim\mathcal{N}(0,\sigma_u^2)$.    
  
**Thought Question** Why is there no $\epsilon_{ij}$ term in the link function?


## Crossed Random Effects


### Random Effects for Teams

Our exploratory analysis showed evidence that the probability a foul is called on the home team changes if we know precisely who the home and visiting teams are.  

However, if we were to include an indicator variable for each distinct team, we would need 38 indicator variables for home teams and 38 more for visiting teams. This complicates the model and gives a lot of estimates we don't really care about (since we're not interested in comparing individual teams). It also means spending 38 degrees of freedom, which reduces precision of intervals and power of tests.   

Instead, we can treat home and away team as random effects.   

### Crossed vs Nested Random Effects      

Besides the fact that our response variable is binary, there's a fundamental difference in the nature of this model compared to prior random effects models we've seen.   

Recall previous random effects models we've seen. For example, the plants in pots and trays.   

```{r, echo=FALSE, out.width = '45%'}
knitr::include_graphics("Ch10Ill.png")
```

In that study, we used random effects for trays, and for pots, but an individual pot could only be within one tray. Thus, all plants in the same pot were necessarily in the same tray. This is an example of **nested random effects**.    

All other random effects models we've seen to this point have involved nested random effects.   

By contrast, the same home team (an visiting team), appears in different games. Thus, the random effect for team is not nested within games. Game, home team, and visiting team are all level two variables, and none is nested in another. These are examples of **crossed random effects**.    

### Models for Crossed Random Effects

When using notation like $Y_{ijk}$, we're used to having the observational unit indexed by $k$ nested within the observational unit indexed by $j$, which is in turn nested within the observational unit indexed by $i$.    

We need a new notation to make sense of crossed random effects.   

Let $Y_{i[vh]j}$ denote the $j$ foul in the $i$th game involving visiting team $v$ and home team $h$. We list $v$ and $h$ after $i$, since they are on the same level as game, but place them inside brackets.

Then, 

\[
Y_{i[vh]j}\sim\text{Ber}(p_{i[vh]j})
\]
  
where, 

  \[ \log\bigg(\frac{p_{i[vh]j}}{1-p_{i[vhj}}\bigg)=\beta_0+\beta_1\text{foul.diff}_{ij} + u_i + w_h+z_v. \]
  
We assume that the error terms are independent and normally distributed.

$u_i\sim\mathcal{N}(0,\sigma_u^2), w_h\sim\mathcal{N}(0,\sigma_w^2), z_v\sim\mathcal{N}(0,\sigma_z^2)$.  


- $\beta_{0}$ is the average log odds of a foul on the home team when the foul differential is 0 (fixed)      
- $\beta_{0}$ is the average multiplicative increase in log odds of the next foul being on the home team, for every additional one foul differential in the home team's favor     
- $u_{i}$ is the effect of Game $i$ (random)
- $w_{h}$ is the effect of Home Team $h$ (random)    
- $z_{v}$ is the effect of Visiting Team $v$ (random)     

### Fitting Model with Crossed Random Effects in R

```{r,}
M3 <- glmer(foul.home ~ foul.diff + (1|game) + 
    (1|hometeam) + (1|visitor), 
    family = binomial(link="logit"), data = refdata)
summary(M3)
```

**Interpretations**

- $\hat{\alpha}_{0}=-0.188=$ the mean log odds of a home foul at the point where total fouls are equal between teams.  In other words, when fouls are balanced between teams, the probability that a foul is called on the visiting team (.547) is 20.7\% ($1/e^{-.188}=1.207$) higher than the probability a foul is called on the home team (.453).
- $\hat{\beta}_{0}=-0.264=$ the decrease in mean log odds of a home foul for each 1 foul increase in the foul differential.  More specifically, the odds the next foul is called on the visiting team rather than the home team increases by 30.2\% with each additional foul called on the home team ($1/e^{-.264}=1.302$).
- $\hat{\sigma}_{u}^{2}=0.172=$ the variance in intercepts from game-to-game.
- $\hat{\sigma}_{w}^{2}=0.068=$ the variance in intercepts among different home teams.
- $\hat{\sigma}_{z}^{2}=0.023=$ the variance in intercepts among different visiting teams.

Based on the t-value (-6.80) and p-value ($p<.001$) associated with foul differential in this model, we have significant evidence of a negative association between foul differential and the odds of a home team foul.  That is, we have significant evidence that the odds that a foul is called on the home team shrinks as the home team has more total fouls compared with the visiting team.  Thus, there seems to be preliminary evidence in the 2009-2010 data that college basketball referees tend to even out foul calls over the course of the first half.  Of course, we have yet to adjust for other significant covariates.

An estimated 65.4\% of variability in the intercepts is due to differences from game-to-game, while 25.9\% is due to differences among home teams, and 8.7\% is due to differences among visiting teams.

### More on Crossed Effects

Although this was the only time we saw crossed random effects in this course, they are not unique to models with a binomial response. They could have come up in the linear mixed effects models we considered in the first half of the course. 


### A Final Model for Examining Referee Bias 

Section 11.7 in the [Roback and Legler text](https://bookdown.org/roback/bookdown-BeyondMLR/ch-GLMM.html#sec:finalmodel-glmm)

provides a potential final model that accounts for score differential, time remaining, type of foul, and other potentially relevant covariates.    


Among their conclusions, the authors write

"In general, we see a highly significant negative effect of foul differentialâ€”a strong tendency for referees to even out foul calls when one team starts amassing more fouls than the other. Important covariates to control for (because of their effects on the odds of a home foul) include score differential, whether the home team held the lead, time left in the first half, and the type of foul called."

## Parametric Bootstrapping

### When and Why to Bootstrap

The maximum likelihood estimates, confidence intervals, and hypothesis tests that we've obtained throughout the class have been based on statistical theory telling us things like:

1. In LLSR and linear mixed effects models, regression coefficients follow $t$-distributions.     
2. In generalized linear regresson models, when the sample size is large, regression coefficients are approximately normally distributed.    
3. Likelihood ratio based tests (like drop-in-deviance tests) follow $\chi^2$ distributions (or F-distributions for models based on quaasilikelihood).     

All of these are based on model assumptions, as well as "large-sample" theory which will never be exactly true, but are often reasonable approximations.   

If we have doubts about model assumptions, like normality, or if our sample size is not that big, we might instead use a simulation-based method to calculate p-values and confidence intervals. 

A popular simulation-based approach is the **parametric bootstrap**.   

This is different than the bootstrapping procedude we learned in Stat 255, which is actually called the **non-parametric bootstrap.**


### Parametric Bootstrap Procedure  

1. Fit the model to the actual data to estimate all parameters ($\beta$'s, $\sigma$'s, etc.)     
2. Simulate many datasets from model using estimated parameter values.    
3. For each simulated dataset, estimate parameters using simulated data.     
4. Calculate relevant statistics (t-statistics, F-statistics, Likelihood ratio's, etc.)     
5. Form confidence intervals using distribution of simulated values.   


### A Simple Example      

We'll start with a simple example, using a LLSR model. Recall the Kentucky Derby Example in Chapter 1 of the notes. 

We used a LSSR model to model a horse's winning speed, with year (since) 1896 as the explanatory variable.    

```{r}
derby.df <- read.csv("https://raw.githubusercontent.com/proback/BeyondMLR/master/data/derbyplus.csv")
derby.df <- derby.df %>%
  mutate( fast = ifelse(condition=="fast",1,0), 
          good = ifelse(condition=="good",1,0),
          yearnew = year - 1896,
          fastfactor = ifelse(fast == 0, "not fast", "fast"))
```


1. Fit the model to the actual data to estimate all parameters ($\beta$'s, $\sigma$'s, etc.)     

```{r, comment=NA}
M <- lm(speed ~ yearnew, data = derby.df)
summary(M)
```

2. Simulate many datasets from model using estimated parameter values, and    
3. For each simulated dataset, estimate parameters using simulated data.     

```{r}
# record estimates from the model
b0 <- M$coefficients[1]
b1 <- M$coefficients[2]
sigma <- summary(M)$sigma
nreps <- 10000
bootstrap_b0 <- c(rep(NA, nreps))
bootstrap_b1 <- c(rep(NA, nreps))
bootstrap_sigma <- c(rep(NA, nreps))
B_Data <- derby.df
# simulate data and fit model
for (i in 1:nreps){
   # simulate new data
B_Data <- B_Data %>% mutate(SimSpeed = b0 + b1*yearnew + rnorm(n= nrow(derby.df), mean=0, sd=sigma))
Mb <- lm(data=B_Data, SimSpeed~yearnew)   #fit model to simulated data
bootstrap_b0[i] <- Mb$coefficients[1]        #record b0 from model on simulated data
bootstrap_b1[i] <- Mb$coefficients[2]        #record b1 from model on simulated data
bootstrap_sigma[i] <- summary(Mb)$sigma      #record sigma from model on simulated data
}
Bootstrap_Results <- data.frame(bootstrap_b0, bootstrap_b1, bootstrap_sigma)
```

4. Calculate relevant statistics (t-statistics, F-statistics, Likelihood ratio's, etc.)     
5. Form confidence intervals using distribution of simulated values.   


### Parametric Bootstrap Confidence Intervals 

```{r}
p1 <- ggplot(data=Bootstrap_Results, aes(x=bootstrap_b0)) + geom_histogram() + geom_vline(xintercept=quantile(bootstrap_b0, c(.025, .975)), color="red")
p1
```

```{r}
quantile(bootstrap_b0, c(.025, .975))
```

```{r}
p2 <- ggplot(data=Bootstrap_Results, aes(x=bootstrap_b1)) + geom_histogram() + geom_vline(xintercept=quantile(bootstrap_b1, c(.025, .975)), color="red")
p2
```

```{r}
quantile(bootstrap_b1, c(.025, .975))
```


```{r}
p3 <- ggplot(data=Bootstrap_Results, aes(x=bootstrap_sigma)) + geom_histogram() + geom_vline(xintercept=quantile(bootstrap_sigma, c(.025, .975)), color="red")
p3
```


```{r}
quantile(bootstrap_sigma, c(.025, .975))
```

Theory-Based intervals (based on t-distribution)

```{r}
confint(M)
```

**Thought Question:** How is this approach to bootstrapping different than the non-parametric bootstrap we saw in  3.5.8 in the [Stat 255 notes](https://bookdown.org/ajsage/statistics_for_data_science_notes/)? What assumption does the parametric bootstrap make that the non-parameteric bootstrap doesn't?    


### Model Comparison Tests with Parametric Bootstrap     


The distributions of ANOVA F-statistics and other likelihood-ratio-based test statistics for model comparison are vulnerable to deviations from model assumptions. When the assumptions are not valid, these stistics may not follow the distributions they are supposed to (F, $\chi^2$), etc.     

We can use parametric bootstrapping to approximate the null distribution of these statistics in such situations.     

Process:    

1. Fit **full** and **reduced** models and calculate relevant statistic (F-statistic, LRT statistic, etc.)      
2. Simulate many datasets from the **reduced model** using estimated parameter values.    
3. For each simulated dataset, fit the **reduced model** and **full model**.
4. Calculate statistic for model comparison (F-statistics, Likelihood ratio's, etc.) on the models fit to the simulated data.     
5. Look at where the statistic from the actual data (calculated in (1)) lies, relative to those calculated from the simulated data in (4). (Thought question: Under what assumption were these data simulated?). The simulation-based p-value is the proportion of simulated statistics as extreme or more extreme as the one we observed.    

### Model Comparison for Kentucky Derby Data

```{r}
M_Red <- lm(speed ~ yearnew, data = derby.df)
M_Full <- lm(speed ~ yearnew + fast + yearnew:fast, data=derby.df)
anova(M_Red, M_Full)
```

The observed F-statistic is 38.914. The associated p-value was calculated from an F-distribution with 2 and 118 df.

If we have concerns about model assumptions, especially normality, the F-statistic might not really follow this F-distribution.    

### Code for Boostrap Model Comparison

We'll simulate the distribution of the F-statistic, using the parametric bootstrap.    

```{r}
set.seed(02272022)
# record estimates from reduced model
b0 <- M_Red$coefficients[1]
b1 <- M_Red$coefficients[2]
sigma <- summary(M_Red)$sigma
nreps <- 10000
bootstrap_F <- c(rep(NA, nreps))
B_Data <- derby.df
# simulate data and fit model
for (i in 1:nreps){
   # simulate new data from reduced model
B_Data <- B_Data %>% mutate(SimSpeed = b0 + b1*yearnew + rnorm(n= nrow(derby.df), mean=0, sd=sigma))
Mb_Red <- lm(data=B_Data, SimSpeed~yearnew)   #fit reduced model to simulated data
Mb_Full <- lm(data=B_Data, SimSpeed ~ yearnew + fast + yearnew:fast)   #fit full model to simulated data
bootstrap_F[i] <- anova(Mb_Full, Mb_Red)$F[2]
}
Bootstrap_Results <- data.frame(bootstrap_F)
```

### Simulation-Based F-Test

```{r}
p1 <- ggplot(data=Bootstrap_Results, aes(x=bootstrap_F)) + geom_histogram() + geom_vline(xintercept = 38.914, color="red", linetype="dotted", size=2) 
p1
```

```{r}
mean(bootstrap_F>38.914)
```

None of our simulations produced a F-statistic even close to the one we observed in our actual data.   


There is virtually no chance we would have obtained an F-statistic as large as we saw in the data by chance, if the reduced model was really appropriate. We have strong evidence that the full model is a better fit.    

This is consistent with the theory-based F-test.   


### Model Comparison in Multilevel GLM     

```{r}
M1 <- glmer(foul.home ~ foul.diff + (1|game), 
            family = binomial(link="logit"), data = refdata)
M2 <- glmer(foul.home ~ foul.diff + (foul.diff|game), 
            family = binomial(link="logit"), data = refdata)
```

```{r}
anova(M1, M2)
```


The $\chi^2$ statistic of 5.4682 and fairly small p-value provide some evidence in favor of the larger model.

Research has shown that when estimates of variance and covariance of random effects are impacted by boundary constraints, "theory-based" tests like the $\chi^2$ test used here are too conservative and produce higher p-values than they should.  

### Multilevel GLM Bootstrap Code

Fitting the model manually gets complicated. The `drop` and `simulate` functions in the `lme4` package do this automatically. 

We'll simulate data from the reduced model, fit both models, and calculate the $\chi^2$ statistic, and repeat this 1,000 times. 

This establishes a bootstrap distribution for where we would expect this statistic to lie if the reduced model is actually "correct". 

```{r, eval=FALSE}
# This takes a LONG time to run!
set.seed(02272022)
nreps <- 1000
ChiSq <- rep(NA, nreps)
for(i in 1:nreps){
SimData <- drop(simulate(M1))  # this command simulates data directly from a model
M1B <-refit(M1, newresp=SimData)  # refits M1 to simulated data
M2B <-refit(M2, newresp=SimData)  # refits M2 to simulated data
ChiSq[i] <- anova(M1B,M2B)$Chisq[2]
}
ChiSq<- write.csv(ChiSq, file="ChiSq.csv")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
ChiSq <- read.csv("ChiSq.csv")
ChiSq <- ChiSq$x
```


### Simulation-Based $\chi^2$ Test

```{r}
p <- ggplot(data=data.frame(ChiSq), aes(x=ChiSq)) + geom_histogram() + 
  geom_vline(xintercept = 5.4682, color="red", linetype="dotted", size=2) 
p
```

```{r}
mean(ChiSq>5.4682)
```

The simulation-based p-value is 0.037. This is slightly smaller than the one based on the Chi-sqare distribution. Research has shown that when boundary constraints are an issue in estimating variance and correlation of random effects, "thory-based" tests are too conservative, and often yield p-values that are higher than they should be. 

Our results are consistent with this observation.   


